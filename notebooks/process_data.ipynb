{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717c5eec-8502-4b64-9030-e13017add2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils import batch_run\n",
    "from tseval.utils import load_llms, call_llm_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "134e6e81-6232-4ec7-9413-296886319acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_map = load_llms()\n",
    "gpt = llm_map['gpt-4o-mini-2024-07-18']\n",
    "\n",
    "TEMP_DIR = Path('../data/intermediate')\n",
    "RAG_INPUT_DIR = Path('../data/rag_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b882144a-69e8-4f9e-bb1a-e1c4ea12ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Process TechQA Stage 1 =====\n",
    "# Filter out the questions targeted on actionable instructions using GPT + Manual Inspection.\n",
    "# Format the actionable instructions (if present) with ordered list.\n",
    "# Output: techqa_stage1.json & techqa_stage1_annotated.json\n",
    "\n",
    "TECHQA_DIR = Path('../raw_data/techqa')\n",
    "\n",
    "# 910 in total\n",
    "techqa = pd.concat([pd.read_json(TECHQA_DIR / 'training_Q_A.json'), pd.read_json(TECHQA_DIR / 'dev_Q_A.json')]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5aa546-b0f2-4907-92a0-49f7c161bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 610 answerable\n",
    "answerable_techqa = techqa[techqa['ANSWERABLE'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1840336f-7e7a-4eb6-8bc3-111d434273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_extraction_prompt = \"\"\"\n",
    "Analyze the response to the technical support question and determine whether it contains actionable instructions. If actionable instructions are present, extract each step in order and organize it into summary and description fields as follows:\n",
    "- The `summary` field should be concise, staying as consistent as possible with the original wording. \n",
    "- The `description` field should provide details of the step. If no details are provided in the original response, leave the description field empty.\n",
    "Both fields must be closely based on the original text, without adding any interpretation or inference not present in the response. Each step should be self-contained, meaning that any pronouns or vague references must be expanded to ensure clarity.\n",
    "If no actionable instructions are present, output an empty JSON object.\n",
    "\n",
    "Response:\n",
    "{text}\n",
    "\n",
    "Output Format:\n",
    "{{\n",
    "  \"steps\": [\n",
    "    {{\n",
    "      \"summary\": \"\",\n",
    "      \"description\": \"\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "If no actionable instructions are included in the response, return:\n",
    "{{}}\n",
    "\"\"\"\n",
    "\n",
    "action_extraction = {'template': action_extraction_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eea32a6-f575-409a-b117-5eceee5b142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_steps(data: dict):\n",
    "    steps = data.get('steps')\n",
    "    if not steps:\n",
    "        return None\n",
    "    items = []\n",
    "    for i, step in enumerate(steps):\n",
    "        summary = step['summary']\n",
    "        desc = step['description']\n",
    "        desc = ('\\n' + desc.strip()).replace('\\n', '\\n   ')\n",
    "        items.append(str(i + 1) + '. ' + summary.strip() + desc)\n",
    "\n",
    "    return '\\n'.join(items)\n",
    "\n",
    "async def extract_action(answer: str) -> None:\n",
    "    res, _ = await call_llm_func(gpt, action_extraction, {'text': answer})\n",
    "    return format_steps(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6043b88b-6e46-469a-848b-49face11aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████████████████████████████████████████████████████████████████████████████████| 610/610 [01:48<00:00,  5.60it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs = [{'question_id': row['QUESTION_ID'], 'answer': row['ANSWER']} for _, row in answerable_techqa.iterrows()]\n",
    "\n",
    "def extract_action_sync(data: dict):\n",
    "    return asyncio.run(extract_action(data['answer']))\n",
    "    \n",
    "outputs = batch_run(extract_action_sync, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23f169cd-9b7c-457b-88ea-94b5a6206505",
   "metadata": {},
   "outputs": [],
   "source": [
    "technotes = pd.read_json(TECHQA_DIR / 'training_dev_technotes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f6a0749-db6b-477a-80d1-8e2eb8e32882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = answerable_techqa.merge(pd.DataFrame(map(lambda x: {'QUESTION_ID': x[0], 'extracted_answer': x[1]}, outputs.items())), on='QUESTION_ID', how='left')\n",
    "df['question_id'] = 'TECHQA_' + df['QUESTION_ID']\n",
    "df = df[~df['extracted_answer'].isna()].reset_index(drop=True)\n",
    "df['question'] = df['QUESTION_TITLE'].apply(lambda s: s.strip()) + '\\n' + df['QUESTION_TEXT'].apply(lambda s: s.strip())\n",
    "df['ground_truth'] = df['extracted_answer']\n",
    "df['reference_doc'] = df['DOCUMENT'].apply(lambda doc_id: technotes[doc_id]['title'].strip() + '\\n\\n' + technotes[doc_id]['text'].strip())\n",
    "df = df.rename(columns={'ANSWER': 'original_ground_truth', 'DOCUMENT': 'reference_doc_id', 'START_OFFSET': 'start_offset', 'END_OFFSET': 'end_offset', 'DOC_IDS': 'doc_ids'})\n",
    "df = df[['question_id', 'question', 'ground_truth', 'reference_doc', 'original_ground_truth', 'start_offset', 'end_offset', 'reference_doc_id', 'doc_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dc1aaad-eb29-4acb-a04a-c04a3af21f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(TEMP_DIR / 'techqa_stage1.json', orient='records', indent=2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51d993-2af3-4a15-a6fe-f9fe43c87349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9cffc-fb8d-478a-8a74-703ce318d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Process TechQA Stage 2 =====\n",
    "# Highligt the key facts in the ground truth (Human Annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3a265fd-a106-4256-8445-17b467bf9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(TEMP_DIR / 'techqa_stage1_annotated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcf64236-e49c-452e-8d21-7d53ffacacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df[~df['valid'].isna()].reset_index(drop=True)\n",
    "valid_df = valid_df[[\n",
    "    'question_id', 'question', 'ground_truth_refined', 'reference_doc',\n",
    "    'original_ground_truth', 'start_offset', 'end_offset', 'reference_doc_id', 'doc_ids'\n",
    "]].rename(columns={'ground_truth_refined': 'ground_truth'})\n",
    "valid_df.to_json(TEMP_DIR / 'techqa_stage2.json', orient='records', indent=2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a39520-cf6c-4dbd-9398-b28ac217aca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87d867cd-74c2-4ddf-aafc-f0840fac88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After annotation, write to inputs for RAG systems\n",
    "df = pd.read_json(TEMP_DIR / 'techqa_stage2_annotated.json')\n",
    "valid_df = df[[\n",
    "    'question_id', 'question', 'reference_doc', \n",
    "    'ground_truth_refined', 'start_offset', 'end_offset' # These attributes would not be used by RAG systems\n",
    "]].rename(columns={'ground_truth_refined': 'ground_truth'})\n",
    "\n",
    "valid_df.to_json(RAG_INPUT_DIR / 'techqa.json', orient='records', indent=2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb43c8e-e985-4eec-a723-90ec6017ccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a48e1-3555-4e2a-b066-840d6ef8e53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c681c9-a356-4e5e-a368-f69e5518252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8eb73-0175-4e7c-a33c-58483ea66842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Process TechQA Stage 3 =====\n",
    "# Generate answers for each question via 3 RAG systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f0dc8b0-d610-40a2-92c8-28802d851f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import markdown\n",
    "\n",
    "def markdown_to_html(text):\n",
    "    text = re.sub(r'([^\\n])\\n', r'\\1  \\n', text)\n",
    "    return markdown.markdown(html.escape(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1d63b688-90a1-4524-9cf4-5b7daa86bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(TEMP_DIR / 'techqa_stage2_annotated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c23496a-766e-4a2d-8057-00807f154e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df[[\n",
    "    'question_id', 'question', 'ground_truth_refined', 'reference_doc',\n",
    "    'original_ground_truth', 'start_offset', 'end_offset', 'reference_doc_id', 'doc_ids'\n",
    "]].rename(columns={'ground_truth_refined': 'ground_truth'})\n",
    "\n",
    "valid_df['ground_truth_html'] = valid_df['ground_truth'].apply(lambda s: markdown_to_html(s))\n",
    "\n",
    "valid_df.to_json(TEMP_DIR / 'techqa_stage3.json', orient='records', indent=2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c25f9-4ed4-4cb8-9c7b-5075e39b8b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ec7b1-5eb3-4eda-8708-9a39b34e39a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607d57d-1099-4d95-a60b-5864b40f95a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbb501c-b2a9-47af-8422-cb158fb79d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc730a18-7e07-4c27-b368-8e54950b5b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0693b5-3c1b-42ca-8dda-73c6fadfba71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9d549-8d8a-4b74-98c3-32b64605eaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c7d28-b9b8-4924-bb57-c47fbd416535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tseval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
