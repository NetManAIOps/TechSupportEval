[
  {
    "question_id": "TECHQA_TRAIN_Q000",
    "question": "User environment variables no longer getting picked up after upgrade to 4.1.1.1 or 4.1.1.2?\nHave you found that after upgrade to Streams 4.1.1.1 or 4.1.1.2, that environment variables set in your .bashrc are no longer being set? For example ODBCINI is not set for the database toolkit and you get\n\n     An SQL operation failed. The SQL state is 08003, the SQL code\n     is 0 and the SQL message is [unixODBC][Driver\n     Manager]Connnection does not exist.",
    "ground_truth": "1. Set environment variables that are needed by the application directly in the instance.\n   Use the command **streamtool setproperty** followed by the parameters '-d <domain> -i <instance>' and '--application-ev <VARIABLE NAME>=<VARIABLE VALUE>' to configure the environment variables.",
    "answer": "To resolve the issue of user environment variables not being picked up after upgrading to Streams 4.1.1.1 or 4.1.1.2, you need to set the environment variables directly in the instance using the `streamtool` command. Specifically, you can use the following command to set the environment variable:\n\n```\nstreamtool setproperty -d <domain> -i <instance> --application-ev <VARIABLE NAME>=<VARIABLE VALUE>\n```\n\nReplace `<domain>`, `<instance>`, `<VARIABLE NAME>`, and `<VARIABLE VALUE>` with the actual values for your environment. For example, to set the `ODBCINI` environment variable, you would use:\n\n```\nstreamtool setproperty -d <domain> -i <instance> --application-ev ODBCINI=/path/to/odbc.ini\n```\n\nThis will ensure that the environment variables are set correctly for your Streams application.",
    "id": "TECHQA_TRAIN_Q000_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q001",
    "question": "Netcool/Impact (all versions): How is the Exit() action function expected to work with User Defined Functions?\nNetcool/Impact (all versions)\n\nUsing the Exit() action function within a User Defined Function in a Policy will not exit the Policy process.",
    "ground_truth": "1. Set a variable that is then tested immediately after the **User Defined Function call**.",
    "answer": "The Exit() action function within a User Defined Function in a Netcool/Impact Policy will not exit the Policy process. Instead, it will only exit the User Defined Function. To exit the Policy process from within a Custom Function, you need to set a global variable that is then tested immediately after the User Defined Function call. For example, you can use `SetGlobalVar(\"ExitNow\", 1)` within the User Defined Function and then check the variable outside the function using `If(GetGlobalVar(\"ExitNow\") == 1) { Exit(); }`. This will allow you to exit the Policy process.",
    "id": "TECHQA_TRAIN_Q001_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q003",
    "question": "How to configure SSL mutual authentication in IBM HTTP Server?\nWe are running IHS v7 and our application team has a specific webservice that they require SSL mutual authentication to be enabled for at the http server. Does anyone know how to set this up on IHS? Or any documentation?\n\nThanks",
    "ground_truth": "1. Confirm that the **Global Security Kit (GSKit)** is installed and meets the minimum requirements\n   \n2. Create a key database file and certificates needed to authenticate the Web server during an SSL handshake\n   \n3. Enable **SSL directives** within the IBM HTTP Server configuration file (httpd.conf)\n   \n4. Information that IBM WebSphere\u00ae Support needs to debug SSL configuration and certificate issues related to the IBM HTTP Server\n   ",
    "answer": "To configure SSL mutual authentication in IBM HTTP Server (IHS) v7, you will need to follow these steps:\n\n1. **Confirm that the Global Security Kit (GSKit) is installed and meets the minimum requirements**.\n2. **Create a key database file and certificates** needed to authenticate the Web server during an SSL handshake.\n3. **Enable SSL directives within the IBM HTTP Server configuration file (httpd.conf)**:\n   - Verify that the SSL modules are uncommented. For IHS v7, the specific module and its location might differ from what's mentioned for v8.5 and v9.0, so refer to the documentation specific to your version.\n   - Create an SSL virtual host stanza in the httpd.conf file. This involves specifying the SSL protocol, certificates, and other SSL-related directives.\n4. **Specifically for mutual authentication**, you will need to configure the server to request a client certificate during the SSL handshake. This typically involves setting the `SSLVerifyClient` directive to `require` within the virtual host configuration. For example:\n   ```\n   <VirtualHost *:443>\n       # Other SSL directives...\n       SSLVerifyClient require\n       SSLVerifyDepth 10\n       # Path to the client certificate database or other verification settings\n   </VirtualHost>\n   ```\n   Note: The exact directives and their values may vary depending on your specific requirements and the version of IHS you are using.\n\n5. **Ensure that the client certificates are properly configured and trusted** by the server. This may involve setting up a Certificate Revocation List (CRL) or an Online Certificate Status Protocol (OCSP) responder, and ensuring that the server's key database includes the necessary trusted root certificates.\n\nFor detailed and version-specific instructions, I recommend consulting the official IBM documentation for IHS v7, as the provided context links to documentation for v8.5 and v9.0. Additionally, IBM support resources and technical notes specific to your version of IHS can provide more precise guidance on configuring SSL mutual authentication.",
    "id": "TECHQA_TRAIN_Q003_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q009",
    "question": "Unable to locate the More tab of Document class - Property definition tab - property template configuration to update Is Required setting.\nUnable to locate the More tab of Document class - Property definition tab - property template configuration to update Is Required setting. Environment is running on Content Engine 5.2.0.3.",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the Class Definition tab and click Save\n   ",
    "answer": "To update the \"Is Required\" setting for a property template configuration in the Document class using FileNet Content Engine - ACCE, follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click the object store to open the Object store tab.\n3. Expand the Data Design folder and Classes folder. Click the document class to open the Document Class tab.\n4. From the Properties tab, open the Property Definitions drop-down and select the property definition you want to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the \"Is Required\" setting as needed.\n7. Go back to the Class Definition tab and click Save.\n\nNote: The \"More\" tab is not explicitly mentioned in the provided context, but the steps above should allow you to update the property definition properties, including the \"Is Required\" setting. If the \"More\" tab is specifically required, the provided context does not contain enough information to locate it.",
    "id": "TECHQA_TRAIN_Q009_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q011",
    "question": "Load SPSS 25 on a new computer\nI purchased SPSS 25 with a 12 month license on Jan 27. I loaded it and used it on my MacBook Pro. I now have a new MacBookPro. I was able to download the program but get a message that says I don't have a license. I do have the activation code. Can you please help me use this product on my new computer? Thanks!",
    "ground_truth": "1. If open, close the IBM SPSS Statistics product.\n2. If open, close the License Authorization Wizard.\n3. Open Finder.\n4. Select the 'Go' menu.\n5. Select the **Utilities** menu.\n6. Open the **Terminal** program.\n7. Type (copy/paste) the following command: **cd /Applications/IBM/SPSS/Statistics/**\n8. Press Enter/Return.\n9. Type (copy/paste) the following command:\n   Run the command 'sudo chown -R root:admin 25 in the Terminal.\n10. Press Enter/Return.\n11. Close Terminal.\n12. Launch the License Authorization Wizard.\n13. The warning message should no longer appear.\n14. License your IBM SPSS Statistics product.\n   ",
    "answer": "To resolve the issue with licensing SPSS 25 on your new MacBook Pro, follow these steps:\n\n1. Close the IBM SPSS Statistics product and the License Authorization Wizard if they are open.\n2. Open Finder, select the 'Go' menu, and then select 'Utilities'.\n3. Open the 'Terminal' program.\n4. Type the following command: `cd /Applications/IBM/SPSS/Statistics/`\n5. Press Enter/Return.\n6. Type the following command: `sudo chown -R root:admin 25`\n7. Press Enter/Return.\n8. Close Terminal.\n9. Launch the License Authorization Wizard.\n10. Enter your activation code to license your IBM SPSS Statistics product.\n\nThis should resolve the issue with the warning message and allow you to license SPSS 25 on your new computer. If you encounter any further issues, you may need to contact your Mac IT support or IBM SPSS Support for additional assistance.",
    "id": "TECHQA_TRAIN_Q011_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q012",
    "question": "Are there any instructions for ulimit settings for WebSphere running on Linux?\nAre there any instructions for ulimit settings for WebSphere running on Linux?",
    "ground_truth": "1. Set the ulimit -u or nproc to a value of **131072** when running on Linux.\n   This adjustment is recommended by WebSphere Application Server Support to safely account for all the forked threads within processes that could be created.",
    "answer": "To determine the ulimit settings for a WebSphere Application Server process running on Linux, refer to the IBM support document \"How to determine the ulimit settings of a running WebSphere Application Server process on Linux\" (http://www-01.ibm.com/support/docview.wss?uid=swg21407889). \n\nWebSphere Application Server Support recommends setting the ulimit -u (or nproc) to a value of 131072 when running on Linux. This can be done to safely account for all the forked threads within processes that could be created. \n\nAfter increasing the ulimit, the WebSphere Application Server will need to be restarted to use the new setting. In the case of WebSphere Application Server ND, the nodeagent and the servers on the nodes will need to be restarted. \n\nNote: Increasing the limit to the suggested value should have no negative impact, but if the number of threads/processes reaches the recommended number, the issue may be deeper and continuing to increase the -u ulimit will only prove to be a temporary fix.",
    "id": "TECHQA_TRAIN_Q012_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q013",
    "question": "Can I apply a TIP 2.2 fix pack directly to a TIP 2.1 installation?\nCan I apply a TIP 2.2 fix pack directly to a TIP 2.1 installation?",
    "ground_truth": "1. Upgrade to TIP 2.2.0.1 by downloading the following items from **IBM Fix Central**:\n  - **2.2.0.1-TIV-TIP-<platform>-RP0001**\n  - 2.2.0.1-TIV-TIP-FITSuit-RP0001vx\n  - 2201-fixpack-guide-PDF.pdf\n\n2. After upgrading, you can then apply the TIP 2.2 fix packs.",
    "answer": "No, you cannot apply a TIP 2.2 fix pack directly to a TIP 2.1 installation. To apply TIP 2.2 fix packs, you must first upgrade your TIP 2.1 installation to TIP 2.2 using the TIP 2.2.0.1 feature pack, which can be obtained from IBM Fix Central.",
    "id": "TECHQA_TRAIN_Q013_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q016",
    "question": "What can be done about \"Too many open files\" messages in the DASH systemOut?\nWhat can be done about \"Too many open files\" messages in the DASH systemOut log?",
    "ground_truth": "1. Use the command **ulimit -Xa** to display all current settings.",
    "answer": "To resolve \"Too many open files\" messages in the DASH systemOut log, you can increase the number of file descriptors using the `ulimit -n [value]` command. However, this change will only take effect after restarting your application server and nodeagent, and you must restart from the same command line where you executed the `ulimit` command.\n\nIf increasing the file descriptor limit does not resolve the issue, you may have a file descriptor leak in your application code. You can use the `lsof` command to investigate the quantity and types of file descriptors in use.\n\nNote that on certain Linux versions, such as Red Hat Enterprise Linux 5, you may not be able to set the limit to \"unlimited\", and the maximum limit is 1048576. IBM recommends a limit of 8000 for WebSphere Application Server.\n\nTo display the current ulimit settings, use the `ulimit -a` command. You can also use `ulimit -H` or `ulimit -S` to display hard or soft limits specifically.",
    "id": "TECHQA_TRAIN_Q016_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q019",
    "question": "i cannot enter SPSS statistics trial program\nI've downloaded the 14-days trial of SPSS subscription for 32bit, windows. After opening the program I'm asked to login and after entering my username and password a blank page comes up. And there is no way to proceed from here. I already saw previous answers about SPSS trial Login error, and there is a link(https://ibm.box.com/s/huaafbjzabkyblh47n7g4l0o4gxp4zdy) to download the zip file of 'jxbrowser'. But i cannot enter the link, and the webpage says \"probably the address was changed or deleted.\"\n\ni'm using Windows 7(32bit), and just want to know how can i resolve it.",
    "ground_truth": "1. Uninstall the 32bit IBM SPSS Statistics Subscription software.\n   Remove the 32bit version of the software from your machine.\n2. Download and install the 64bit application from your **Products & Services** window on IBM.com.\n   Access your Products & Services window on the IBM.com website to find and install the 64bit version of IBM SPSS Statistics Subscription.\n3. If the issue persists, open a Service Request using the Client Support Portal.\n   Use the link **http://ibm.biz/IBMClientSuccessPortal** to submit a Service Request for further assistance.",
    "answer": "The issue you're experiencing with a blank page after logging in to the SPSS Statistics trial program is likely due to a compatibility issue, but the provided context doesn't directly address your specific situation since it mentions a solution for a 32-bit installation on a 64-bit machine, and you're using a 32-bit Windows 7.\n\nHowever, given that you're unable to access the suggested link for the 'jxbrowser' zip file, which might have provided a workaround, and considering the context provided doesn't directly apply to your 32-bit Windows 7 setup, the best course of action would be to open a Service Request using the IBM Client Support Portal: http://ibm.biz/IBMClientSuccessPortal. This will allow you to get personalized support for your specific issue, as the general troubleshooting steps provided don't match your exact scenario.",
    "id": "TECHQA_TRAIN_Q019_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q020",
    "question": "HATS Plugin Download\nHi\n\nI have RDZ 9.0 and want to install the HATS plugin.\n\nI've downloaded from this link:\n\nhttp://www.ibm.com/developerworks/downloads/ws/whats/\n\nHATS 9.0.0.0 but it won't install because RDZ itself is not enough and it sais I need one of the following:\n\nIBM Rational Application Developer for WebSphere Software\n\nIBM Rational Software Architect for WebSphere Software\n\nIBM Rational Developer for i for SOA Construction\n\nIBM Rational Business Developer\n\nIBM Integration Developer\n\nwhich I don't have.\n\nWhere can I download the HATS version that is compatible with RDZ 9.0 and doesn't need anything else?",
    "ground_truth": "1. See Installing HATS in the **Rational Host Access Transformation Services (HATS) V9.0 Information Center**.\nRefer to the installation instructions provided at the link: **http://pic.dhe.ibm.com/infocenter/hatshelp/v90/topic/com.ibm.hats.doc/doc/gsinstal.htm**",
    "answer": "The provided context does not contain enough information to solve the problem. The user is looking for a HATS plugin version that is compatible with RDZ 9.0 and does not require any additional software, but the context only provides information on the system requirements and installation instructions for HATS 9.0, which still requires one of the specified IBM Rational products. I don't know where to download a compatible HATS version that meets the user's requirements.",
    "id": "TECHQA_TRAIN_Q020_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q024",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM\u00ae SPSS\u00ae Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message: \n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction. \nNo additional authorizations are permitted on this code. \nWhat should I do?",
    "ground_truth": "1. Contact your **vendor**\n   For installation & licensing issues on the Student version and Graduate pack.",
    "answer": "To resolve the issue with transferring your SPSS 24 license key to a new computer, you should contact the vendor from whom you originally purchased the software. The error message you're receiving indicates that the activation code has been used the maximum number of times allowed, which suggests you need to deactivate the license on your old computer or request assistance from the vendor to reset or reissue the license.\n\nHere are the steps you can follow:\n\n1. **Identify Your Vendor**: Determine from which vendor you bought the IBM SPSS Statistics Standard GradPack 24. Common vendors include Hearne, On the Hub, StudentDiscounts.com, JourneyEd, thinkEDU, and Studica.\n\n2. **Contact the Vendor**: Reach out to the vendor's support team using the contact information provided:\n   - Hearne: http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ\n   - On the Hub: http://onthehub.com/\n   - StudentDiscounts.com: http://studentdiscounts.com/contact-us.aspx\n   - JourneyEd: https://www.journeyed.com/contact\n   - thinkEDU: https://thinkedu.desk.com/\n   - Studica: http://www.studica.com/technical-support\n\n3. **Explain Your Issue**: Inform the vendor's support team about the error message you're receiving and your intention to transfer the license to a new computer. They should be able to guide you through the process of deactivating the old license or provide you with a new activation code if necessary.\n\nBy following these steps, you should be able to resolve the licensing issue and successfully transfer your SPSS 24 license key to your new computer.",
    "id": "TECHQA_TRAIN_Q024_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q031",
    "question": "Request fails with \"non idempotent request method - RFC 2616 sec 10.3. \"\nWhen a request is routed through DataPower and a redirect is done on a POST, the redirect will fail in DataPower and we can expect the following message to be logged in the error message: \"non idempotent request method - RFC 2616 sec 10.3.\"  How do I solve the problem?",
    "ground_truth": "1. Configure the IBM WebSphere **DataPower SOA** appliance web application firewall to handle 302 Redirects.",
    "answer": "To resolve the issue of the \"non idempotent request method - RFC 2616 sec 10.3\" error when a POST request is redirected through DataPower, you can configure the IBM WebSphere DataPower SOA appliance web application firewall to handle 302 redirects. \n\nTo do this, follow these steps:\n\n1. Obtain the ResetLocation.xsl stylesheet from the provided documentation.\n2. Edit the stylesheet according to your environment's specific requirements.\n3. Configure the web application firewall to use the edited ResetLocation.xsl stylesheet to handle redirects.\n\nThis configuration should allow the DataPower appliance to properly handle 302 redirects for POST requests, resolving the error.",
    "id": "TECHQA_TRAIN_Q031_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q037",
    "question": "How can multiple TDWC users logon into TDWC with same TWS user id?\nGiven that one TDWC user is already accessing TDWC and a second TDWC user using the same logon id wants to logon to TDWC sees the following error:\n\nAnother user is currently logged in with the same user ID. Select from the following options:\n\n    List item\n\nLog out the other user with the same user ID. You can recover changes made during the other user's session.\n\n    List item\n\nReturn to the Login page and enter a different user ID.\n\nHow can multiple users logon without one user needing to logout?",
    "ground_truth": "1. Log in as an administrative user.\n   \n2. Navigate to: **tip_home_dir/profiles/TIPProfile/config/cells/TIPCell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF/**\n   \n3. Edit **consoleProperties.xml**.\n   \n4. Locate the property with a id attribute of **ENABLE.CONCURRENT.LOGIN** and set its value to true.\n   \n5. Save the file and exit from the text editor.\n   \n6. Restart TIP server.\n   ",
    "answer": "To allow multiple TDWC users to log in with the same TWS user ID, you need to configure the Tivoli Integrated Portal (TIP) to enable concurrent logins. Here are the steps:\n\n1. Log in as an administrative user.\n2. Navigate to the `tip_home_dir/profiles/TIPProfile/config/cells/TIPCell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF/` directory.\n3. Edit the `consoleProperties.xml` file.\n4. Locate the property with an `id` attribute of `ENABLE.CONCURRENT.LOGIN` and set its value to `true`.\n5. Save the file and exit the text editor.\n6. Restart the TIP server.\n\nNote: This solution only applies to TIP version 2.1 and higher. After completing these steps, multiple users should be able to log in to TDWC with the same TWS user ID without one user needing to log out.",
    "id": "TECHQA_TRAIN_Q037_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q038",
    "question": "We want to backout the Cognos component of Business Monitor to a previous version. What do we have to take care of?\nWe want to backout the Cognos component of Business Monitor to a previous version. What do we have to take care of?",
    "ground_truth": "1. Stop the Cognos service and ensure that **Cognos Configuration** is not running.\n   \n2. Create a backup of the content store prior to upgrading.\n\n3. Restore the backup if a rollback to the original version is required.\n\n4. Refer to the notes on the fix pack.\n   The notes will include prerequisites on Backup/Restore of content store and other requirements.\n5. Check the backup directory for versions 8 - 10.2.1.\n   In the **<cognos_install>/uninstall/backup** directory, there will be a list of date stamped folders with the applied fix packs and/or interim fixes.\n6. Check the backup directory for versions **10.2.1 FP1** and above.\n   This information is stored in the **<cognos_install>/bkp** directory.\n7. Go into the folders and check the **cmplst.txt** file.\n   Look for the correct version to revert to.\n8. Copy the contents of the whole folder.\n   Paste it at the <cognos_install> level to overwrite the files applied by fix pack or interim fix update.\n9. Start the Cognos service.\n   ",
    "answer": "To back out the Cognos component of Business Monitor to a previous version, follow these steps:\n\n1. **Stop the Cognos service** and ensure that Cognos Configuration is not running.\n2. **Restore the content store backup** that was created before upgrading to the new version. This will revert the content store to its previous state, but any work done after the upgrade will be lost.\n3. **Check the backup directories** for the correct version to revert to:\n\t* For versions 8 - 10.2.1, check the `<cognos_install>/uninstall/backup` directory.\n\t* For versions 10.2.1 FP1 and above, check the `<cognos_install>/bkp` directory.\n4. **Go into the folders** and check the `cmplst.txt` file to confirm the correct version to revert to.\n5. **Copy the contents of the whole folder** and paste it at the `<cognos_install>` level, overwriting the files applied by the fix pack or interim fix update.\n6. **Start the Cognos service**.\n\nAdditionally, be aware of the following:\n\n* If you try to revert back to an earlier environment configured against the upgraded content store, you may get an error.\n* Care must be taken when removing interim fixes to ensure that later interim fixes are not affected.\n* It is recommended to perform a full system and content store backup before attempting to roll back.",
    "id": "TECHQA_TRAIN_Q038_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q039",
    "question": "How to remove the default -Xcompressedrefs from my WebSphere Application Server\nMy understanding is that for performance reasons, the WebSphere Application server on 64bit JVMs is, by default, using compressed references (-Xcompressedrefs). Due to native OutOfMemory error, I would like to remove that default, so there is no such limitation imposed on my native memory size.",
    "ground_truth": "1. Use the JVM argument **-Xgc:preferredHeapBase=<address>**\n   This argument can be used to ensure the Java heap is allocated above the **4GB** address space.",
    "answer": "To remove the default -Xcompressedrefs from your WebSphere Application Server, you can set the generic JVM argument `-Xnocompressedrefs`. This will remove the use of compressed references and the lower 4GB memory restriction on the Class Pointers and Monitors/Locks. However, please note that this will result in a significant increase in Java heap memory requirements, potentially up to 70% more heap space.\n\nBefore making this change, ensure that you have ruled out the possibility of a native memory leak, as using `-Xnocompressedrefs` will allow native memory to grow unbounded. Additionally, consider adjusting the Java heap size to a larger value and monitoring garbage collection to avoid performance issues.\n\nYou can set the `-Xnocompressedrefs` argument in the generic JVM arguments, as described in the IBM support documentation.",
    "id": "TECHQA_TRAIN_Q039_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q042",
    "question": "Non-admin users cannot access webDAV filestore. What is the likely reason?\nA non-admin user trying to access the webDAV filestore is unable to do so and they see the below exception in the portal logs:\r\nCaused by: com.ibm.icm.da.DBAccessException: User id can not be null at com.ibm.icm.da.portable.connection.Logon.logon(Logon.java:159) at com.ibm.icm.da.portable.connection.ConnectionManager.logon(ConnectionManager.java:45)",
    "ground_truth": "1. Create/update the **store.puma_default.user.fbadefault.filter** custom property for the WP PumaStoreService Resource Environment Provider.",
    "answer": "The likely reason non-admin users cannot access the webDAV filestore is that the authenticated user does not have the attribute defined in the backend user registry that matches the attribute defined in the `store.puma_default.user.fbadefault.filter` property in the WP PumaStoreService Resource Environment Provider. \n\nTo resolve this issue, you need to create or update the `store.puma_default.user.fbadefault.filter` custom property for the WP PumaStoreService Resource Environment Provider via the Integrated Solutions Console to an attribute that exists for all Portal users in the backend user registry, such as \"cn\". \n\nYou can follow these steps:\n1. Check the `resources.xml` file to see if the `store.puma_default.user.fbadefault.filter` property is defined. If not, the default value is \"uid\".\n2. Verify the attribute defined for the value in `resources.xml` or use the default value \"uid\".\n3. Check the LDIF export for the user to confirm if the attribute is defined.\n4. Update the `store.puma_default.user.fbadefault.filter` property to an attribute that exists for all Portal users in the backend user registry, such as \"cn\", via the Integrated Solutions Console.",
    "id": "TECHQA_TRAIN_Q042_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q044",
    "question": "Authorization code missing for SPSS 25?\nI purchased the IBM SPSS from Amazon, and I do not know where to locate the authorization code of license code/key. Can anyone help me?",
    "ground_truth": "1. Contact your **vendor**\n   For installation and licensing issues on the Student version and Graduate pack, you should get in touch with the vendor.",
    "answer": "To locate the authorization code or license key for your IBM SPSS 25, you should contact the vendor from whom you purchased the software, which in your case is Amazon. However, since Amazon is not listed among the specific vendors mentioned for student or graduate pack support, you may want to start by checking your purchase receipt or email from Amazon to see if the authorization code was included.\n\nIf you cannot find the code through Amazon's purchase records, you can try contacting Amazon's customer support to inquire about how to obtain the authorization code for your IBM SPSS 25 software. They should be able to provide you with further assistance or direct you to the appropriate resource for obtaining your license key.",
    "id": "TECHQA_TRAIN_Q044_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q048",
    "question": "How to change the maximun string length for properties in ACCE\nHI I am trying to change the maximum string length in ACCE like we will do in FEM but in the more Tab I am not seeing the option\n\nPlease guide me",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the **Class Definition** tab and click Save\n   ",
    "answer": "To change the maximum string length for properties in ACCE, follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click the object store to open the Object store tab.\n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab.\n4. From Properties tab, open Property Definitions drop down and select the property definition you want to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the property definition as required, including changing the maximum string length.\n7. Go back to the Class Definition tab and click Save.\n\nNote: The \"More\" tab is not the correct location to modify property definitions in ACCE. Instead, use the steps above to access and modify the property definition.",
    "id": "TECHQA_TRAIN_Q048_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q049",
    "question": "Help with Security Bulletin: A security vulnerability has been identified in WebSphere Application Server shipped with WSRR (CVE-2017-1731)\nI need to understand details regarding Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with IBM WebSphere Service Registry and Repository (CVE-2017-1741). We are running WAS traditional V8.5.  What is the recommended fix?",
    "ground_truth": "1. Upgrade to a minimal fix pack levels as required by interim fix and then apply Interim Fix **PI89498**.\n   ",
    "answer": "The recommended fix for the security vulnerability in WebSphere Application Server shipped with WSRR (CVE-2017-1731) for WAS traditional V8.5 is to apply the interim fix, Fix Pack or PTF containing APARs PI89498. However, the provided context does not specify the exact fix pack level for V8.5. \n\nTo find the correct fix, I recommend checking the IBM website for the latest fix pack levels and applying the one that includes the interim fix PI89498 for WebSphere Application Server traditional V8.5. You can also subscribe to My Notifications to receive important product support alerts and check the System z Security Portal for the latest critical security and integrity service. \n\nAdditionally, note that the context provided is for CVE-2017-1731, but you mentioned CVE-2017-1741. If the issue is related to CVE-2017-1741, the provided context may not be applicable, and you should search for a specific security bulletin for that CVE.",
    "id": "TECHQA_TRAIN_Q049_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q055",
    "question": "P8 CPE 5.2.1 error:  FNRCC0110E - ERROR FixedContentProviderCache.getProvider failed to init provider\nNew P8 CPE 5.2.1 install does not see the Centera Fixed Storage. The following error is returned:\n\nFNRCC0110E: CONTENT_FCP_OPERATION_FAILED: The [initialize] operation on the fixed content provider [com.filenet.engine.content.fcprovider.centera.CenteraFCP(0)] failed. FPLibrary (Not found in java.library.path)\n\nHow do I fix this?",
    "ground_truth": "1. Restart **WebSphere** from the IBM console.\n   After making any changes to the **setCenteraLibPath.sh** or **setCenteraLibPath.bat** file, you need to restart WebSphere from the IBM console or the changes will not be detected.",
    "answer": "To fix the error FNRCC0110E, you need to ensure that the CenteraSDK path is loaded correctly. The issue is caused by the `FPLibrary` not being found in the `java.library.path`. \n\n1. Check the `setCenteraLibPath.sh` or `setCenteraLibPath.bat` file to ensure it is correctly configured to point to the CenteraSDK library.\n2. After making any changes to the `setCenteraLibPath.sh` or `setCenteraLibPath.bat` file, restart WebSphere from the IBM console. Restarting from within the WebSphere console may not detect the changes.\n3. Verify that the `setCenteraLibPath.sh` file is added to the `setupcmdLine.sh` file and recognized by the WebSphere startup script.\n\nBy following these steps, you should be able to resolve the error and successfully initialize the Centera Fixed Content Provider.",
    "id": "TECHQA_TRAIN_Q055_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q059",
    "question": "Uninstalling I5 OS agent failed\nI need to uninstall the I5OS agent before reinstalling a newer release of the same.\n\nCommand: DLTLICPGM LICPGM(5724C04)\n\nis anyway failing and I don't know how to proceed further. \n\nCan you please let me know the manual steps to uninstall the i5OS agent correctly ?",
    "ground_truth": "1. Run command: DLTLIB QAUTOMON.\n\n2. Run command: DLTLIB QAUTOTMP.\n\n3. Run command: DLTUSRPRF QAUTOMON and choose to remove all objects owned by this user.\n\n4. Start qsh.\n\n5. Delete /QIBM/USERDATA/IBM/ITM and all subdirectories in it.\n\n6. Delete /QIBM/PRODDATA/IBM/ITM and all subdirectories in it.\n\n7. Retry the RSTLICPGM commands specified in the user guide.",
    "answer": "To manually uninstall the i5OS agent, follow these steps:\n\n1. Try running the `DLTLICPGM 5724C04` command again. If it fails, proceed to the next steps.\n2. Run the following i5/OS commands:\n   - `DLTLIB QAUTOMON`\n   - `DLTLIB QAUTOTMP`\n   - `DLTUSRPRF QAUTOMON` and choose to remove all objects owned by this user.\n3. Start the QSH (Qshell) by running the command `start qsh`.\n4. Delete the following directories and all their subdirectories:\n   - `/QIBM/USERDATA/IBM/ITM`\n   - `/QIBM/PRODDATA/IBM/ITM`\n5. After completing these steps, retry the `RSTLICPGM` commands as specified in the user guide.\n\nThese manual steps should help you correctly uninstall the i5OS agent. If you encounter further issues, refer to the IBM support documentation for additional troubleshooting guidance.",
    "id": "TECHQA_TRAIN_Q059_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q062",
    "question": "SAP Agent user authorizations\nHello, I cannot use the default SAP user IBMMON_AGENT provided by the SAP Agent transport. Internal rules requires to create a new user respecting specific naming convention. I know how to do it but I don't know the authorization I need to assign to the new user. Where can I find them ?\n\nThanks",
    "ground_truth": "1. If you don't want to use the default userid and profile, you need to create your own userid.\n   Create a new userid that will replace the default userid IBMMON_AGENT.\n2. Refer to the values specified for the **/IBMMON/AUTH** profile available in the transport.\n   Check the /IBMMON/AUTH profile in the transport to understand the necessary authorizations needed for the new userid.\n3. By looking at this profile, you can obtain the needed authorization information.\n   Use the information from the /IBMMON/AUTH profile to ensure that the new userid has the correct authorization settings.",
    "answer": "To find the required authorizations for your new SAP Agent user, you can refer to the `/IBMMON/AUTH` profile that is created when ITM transports are imported into the SAP system. This profile contains the minimum authorization settings required for the SAP Agent to logon to the SAP system. You can use these settings as a reference to assign the necessary authorizations to your new user. Specifically, for MySAP agent 6.2 IF16, you can check the authorization defined for the `/IBMMON/AUTH` profile, which is available in the transport. By assigning the same set of authorizations to your new user, you should be able to ensure successful data collection.",
    "id": "TECHQA_TRAIN_Q062_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q065",
    "question": "For Solaris how to write verbose gc output to a log file other than the native_stdout?\nA customer asked why no gc logs generated even if they use the -Xverbosegc option. So How can I write verbose gc output to a log file other than the native_stdout for SunOS?",
    "ground_truth": "1. Add the following parameters to the generic JVM arguments:\n   **-XX:+PrintGCDetails**, **-XX:+PrintGCDateStamps**, **-XX:+PrintHeapAtGC**, **-Xloggc:/tmp/gc.log**",
    "answer": "To write verbose GC output to a log file other than the native_stdout in Solaris, you need to add the following parameters to the generic JVM arguments:\n\n-XX:+PrintGCDetails \n-XX:+PrintGCDateStamps \n-XX:+PrintHeapAtGC \n-Xloggc:/tmp/gc.log\n\nThis will write the verbose GC output to a file named `/tmp/gc.log`. \n\nTo enable log file rotation, you can add the following parameters:\n\n-XX:+UseGCLogFileRotation\n-XX:NumberOfGCLogFiles=10\n-XX:GCLogFileSize=10M\n\nThis will rotate the log file when it reaches 10M in size, keeping up to 10 rotated log files. \n\nNote: Replace `/tmp/gc.log` with the desired log file path and name.",
    "id": "TECHQA_TRAIN_Q065_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q067",
    "question": "ODM 8.7 TeamServer users active authoring rules and they get kicked out - transaction timeout or session timeout?\nSome of my users are being kicked out of TeamServer while actively authoring rules. What value would be controlling this behavior? Session timeout is at it's default 30 minutes. Does transaction timeout come in to play here or is there a different setting that might be causing this. Thanks.",
    "ground_truth": "1. Increase the **timeout** value in the **web.xml** file.\n   Locate the web.xml file in the RTS/DC EAR file, specifically found at **jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF**. Change the value of the property **ilog.rules.teamserver.transaction.timeout**.",
    "answer": "The issue you're experiencing with users being kicked out of TeamServer while actively authoring rules is likely due to the transaction timeout, not the session timeout. The default transaction timeout is 10 minutes (600 seconds), which is set in the `web.xml` file of the TeamServer EAR file. If the rule authoring operation takes longer than this timeout, the transaction is rolled back, and the user is kicked out.\n\nTo resolve this issue, you can try increasing the transaction timeout value in the `web.xml` file by changing the `ilog.rules.teamserver.transaction.timeout` property. For example, you can increase the value to 1200 seconds (20 minutes) or more, depending on your specific requirements.\n\nAdditionally, you should also check the application server-specific transaction timeout configurations, such as the \"Maximum transaction timeout\" in WebSphere Application Server, and increase it as needed.\n\nIt's worth noting that the session timeout, which is set to 30 minutes in your case, is not directly related to this issue, as it controls the duration of the user's session, not the transaction timeout.",
    "id": "TECHQA_TRAIN_Q067_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q070",
    "question": "How do I search for a string which has reserved words or characters when searching in documents in Atlas?\nHow do I search for a string which has reserved words or characters when searching in documents in Atlas?",
    "ground_truth": "1. Use \"\\\" in front of the \"-\" when searching for a **string** that contains a \"-\".\n",
    "answer": "To search for a string with reserved words or characters in Atlas, you need to use a special option. When searching for a string with a \"-\", place a \"\\\" in front of the \"-\". For example, to search for \"String1-String2\", use \"String1\\-String2\". Refer to the Oracle documentation for Special Characters in Oracle Text Queries for more information on searching with reserved words or characters.",
    "id": "TECHQA_TRAIN_Q070_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q071",
    "question": "Why does my upgrade to BigFix version 9.2.5 take a very long time?\nMy upgrade to BigFix version 9.2.5 takes a very long time. What do I need to do?",
    "ground_truth": "1. Allow the upgrade to complete.\n   Do not attempt to cancel or kill the upgrade process.\n2. Verify the upgrade is still active.\n   Check that the following process is still running: Windows: **BESAdmin.exe** or Linux: **BESAdmin**.",
    "answer": "To determine if your BigFix version 9.2.5 upgrade is still in progress, check if the BESAdmin process is running on your system. On Windows, look for \"BESAdmin.exe\" and on Linux, look for \"BESAdmin\". Even if the CPU usage is minimal, the existence of this process indicates that the upgrade is still active. Additionally, you can monitor the BFEnterprise or BFENT database for activity using SQL Server Profiler or the DB2 'CREATE EVENT MONITOR' statement. Allow the upgrade to complete without attempting to cancel or kill the process, as this may cause issues with the upgrade.",
    "id": "TECHQA_TRAIN_Q071_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q080",
    "question": "Help with Action required for IIB H.E. V9 and WMB H.E. V8 for security vulnerabilities in Red Hat Linux (CVE-2011-5320, CVE-2017-15670, CVE-2017-15671, CVE-2017-15804)\nI need to understand details regarding Action required for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0 for security vulnerabilities in Red Hat Linux. Where can I find this information?",
    "ground_truth": "1. Contact Red Hat to obtain and install fixes for Red Hat Enterprise Linux (RHEL) Server **6.2**.",
    "answer": "To address the security vulnerabilities in Red Hat Linux (CVE-2011-5320, CVE-2017-15670, CVE-2017-15671, CVE-2017-15804) for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0, you should contact Red Hat to obtain and install fixes for Red Hat Enterprise Linux (RHEL) Server 6.2. This is the recommended action by IBM to remediate these vulnerabilities.",
    "id": "TECHQA_TRAIN_Q080_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q081",
    "question": "'Access is denied' install errors with ICC\nInstalling ICC 4.0.1 and then FP2 gives the 'Access is denied' error on WASSERVICE.exe. How to resolve this?",
    "ground_truth": "1. Apply IBM Content Collector V4.0.1 Fix Pack **3** to upgrade from IBM Content Collector V4.0.1 to IBM Content Collector **V4.0.1.3**.\n",
    "answer": "The 'Access is denied' error on WASSERVICE.exe when installing ICC 4.0.1 and then FP2 is likely related to APAR HE12537, which describes a \"CONTENT COLLECTOR INSTALLATION FAILS WITH ACCESS IS DENIED ERROR ON WASSERVICE.EXE FILE\" issue. \n\nTo resolve this issue, I recommend checking the prerequisites for IBM Content Collector V4.0.1 and ensuring that all necessary requirements are met before attempting the installation. Additionally, reviewing the fix pack readme files for specific installation instructions may provide further guidance. \n\nIf the issue persists, it may be helpful to consult the IBM support documentation or contact IBM support directly for further assistance, as the provided context does not offer a specific solution to the 'Access is denied' error.",
    "id": "TECHQA_TRAIN_Q081_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q082",
    "question": "XGS 5.3.0.6: Is there a way to replicate an inspection object under the same policy repository?\nIs there a way to replicate an inspection object under the same policy repository?",
    "ground_truth": "1. Right-click on an **IPS** object.\n   \n2. Left-click on **Clone**.\n   ",
    "answer": "Yes, you can replicate an inspection object under the same policy repository in XGS 5.3.0.6. To do this, right-click on the existing IPS object and left-click on \"Clone\" to derive a new IPS object from it. This feature is mentioned in the IPS Policy enhancements section of the release notes.",
    "id": "TECHQA_TRAIN_Q082_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q085",
    "question": "WebSphere Business Integration (WBI) Adapter for Siebel timeouts: unable to process large orders?\nI receive the following error message when WebSphere Business Integration (WBI) Adapter for Siebel V2.6 tries to process an event in the event table for a large order:\n\nOMRPC Request xxx on connection xxx was abandoned after 600133 ms because it timed out. (SBL-JCA-317)\n\nWhat should I do?",
    "ground_truth": "1. Create a **siebel.properties** file and save it in the **classpath** of the adapter.\n\n2. Restart the adapter and broker to pick up the settings to establish the required connections.\n",
    "answer": "To resolve the timeout issue when processing large orders with WebSphere Business Integration (WBI) Adapter for Siebel V2.6, you can modify the connection settings by creating a `siebel.properties` file. \n\nSpecifically, you can increase the `siebel.conmgr.txtimeout` value, which indicates the transaction timeout in milliseconds (default is 600000, or 10 minutes), and/or adjust the `siebel.conmgr.sesstimeout` value, which indicates the session timeout in seconds (default is 2700, or 45 minutes).\n\nHere's an example of how you can update these values in the `siebel.properties` file:\n\n```\nsiebel.conmgr.txtimeout = 1200000  # Increase transaction timeout to 20 minutes\nsiebel.conmgr.sesstimeout = 5400  # Increase session timeout to 90 minutes\n```\n\nAfter updating the `siebel.properties` file, save it in the classpath of the adapter (e.g., `<adapter project>\\connectorModule`) and restart the adapter and broker to apply the changes.\n\nBy increasing these timeout values, you may be able to prevent the timeout error (SBL-JCA-317) and successfully process large orders. However, be cautious when adjusting these settings, as increasing timeouts can impact system performance. Monitor your system's behavior after making these changes to ensure they have the desired effect.",
    "id": "TECHQA_TRAIN_Q085_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q087",
    "question": "Installation manager (IIM) fails to start on AIX, generates core file from GPF even though all GTK libs are installed.\nTrying to install DASH 3.1.3 on AIX but IIM won't start and instead creates a dump file with a GPF noted. We found a technical note with a list of the required libs for IIM on AIX and we have all of the latest versions of those libs. Why is the installer failing to start?",
    "ground_truth": "1. Install the **gtk+** RPM and dependencies on **AIX**.\n",
    "answer": "The issue you're experiencing with the Installation Manager (IIM) failing to start on AIX and generating a core file with a GPF (General Protection Fault) error, despite having all the required GTK libraries installed, suggests that there might be an issue with the configuration or the environment variables. \n\nGiven the error messages, particularly the \"Could not load SWT library\" error, it indicates that the Java Virtual Machine (JVM) is unable to find the necessary SWT (Standard Widget Toolkit) libraries for GTK. This is crucial for the graphical user interface (GUI) of the Installation Manager.\n\nTo resolve this issue, ensure that the `LIBPATH` environment variable includes the path to the installed GTK libraries. For example, if the libraries are installed in `/opt/freeware/lib/`, you should have `LIBPATH=/opt/freeware/lib/` set in your environment.\n\nAdditionally, verify that the SWT library for GTK (`libswt-pi-gtk-4234.a` or similar) exists in the specified paths and that the file is not corrupted. If the file does not exist, you may need to reinstall the GTK bundle or ensure that the Installation Manager package includes the necessary SWT libraries for AIX.\n\nIf the issue persists after checking the `LIBPATH` and verifying the existence of the SWT library, consider running the Installation Manager in console mode or silent mode as a workaround, as these modes do not require the GUI and thus do not need the GTK libraries. The command-line mode is supported by all packages, and for console mode, check your product documentation to see if it's supported.\n\nLastly, ensure that all the RPMs and their dependencies are installed at the minimum required versions, and consider reinstalling the `gtk2_bundle_v2.tar` package using the provided install script to ensure all necessary components are correctly installed and configured.",
    "id": "TECHQA_TRAIN_Q087_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q091",
    "question": "Keys couldn't be imported. Unable to encrypt the FIPS key\nOn windows10 machine when I attempt to import the encryption key I am getting the error: \"Keys couldn't be imported. Unable to encrypt the FIPS key\". Because I cannot import the keys, I am unable to validate parameters.",
    "ground_truth": "1. Select **Local Security Policy** under Administrative tools\n   \n2. Navigate to Local Policies - Security Options\n   \n3. Select System Cryptography: Use **FIPS** compliant algorithms for encryption, hashing and signing and be sure it is Disabled\n   \n4. Run **dcskey e** again to export the key\n   ",
    "answer": "To resolve the \"Keys couldn't be imported. Unable to encrypt the FIPS key\" error on your Windows 10 machine, you need to disable the FIPS compliant algorithms for encryption, hashing, and signing security policy. Here's how:\n\n1. Go to Administrative tools and select Local Security Policy.\n2. Navigate to Local Policies - Security Options.\n3. Find the \"System Cryptography: Use FIPS compliant algorithms for encryption, hashing and signing\" setting and ensure it is Disabled.\n4. After disabling this setting, try importing the encryption key again.\n\nThis should allow you to import the keys and validate parameters.",
    "id": "TECHQA_TRAIN_Q091_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q092",
    "question": "ClassCastException IlrStorePolicy$SerializedENamedElement incompatible with EStructuralFeature\nWe keep getting the following error when navigating in Decision Center on Websphere Application Server.\n\njava.lang.ClassCastException: ilog.rules.teamserver.web.IlrStorePolicy$SerializedENamedElement incompatible with org.eclipse.emf.ecore.EStructuralFeature\n\nDoes anyone know how we can avoid this error?",
    "ground_truth": "1. Ensure there is no session object that is not **serializable**.\n   The object needs to implement java\u2122.io.Serializable interface.\n   ",
    "answer": "The error message `java.lang.ClassCastException: ilog.rules.teamserver.web.IlrStorePolicy$SerializedENamedElement incompatible with org.eclipse.emf.ecore.EStructuralFeature` is occurring in Decision Center on Websphere Application Server. \n\nTo resolve this issue, you need to ensure that all session objects are serializable. The provided context does not directly address the ClassCastException, but it does mention a similar issue with NotSerializableException. \n\nGiven the information, it's likely that the ClassCastException is related to serialization issues. To avoid this error, you should review your code and ensure that all objects being stored in the session implement the `java.io.Serializable` interface. \n\nIf this does not resolve the issue, further investigation into the specific classes and objects involved in the error would be necessary, as the provided context does not contain enough information to provide a more specific solution.",
    "id": "TECHQA_TRAIN_Q092_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q098",
    "question": "Restore JazzSM DASH login page to default images\nWe've changed the JazzSM DASH login page images and want to restore them. What values do we use to revert those changes?",
    "ground_truth": "1. Stop the DASH server\n   \n2. Make a backup copy of the current xml files in the following directory\n   **<JazzSM_Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF**\n3. Go to **<JazzSM_Home>/profile/backups** and find a backup file from a previous day/time that contains the missing xml files\n   Example: isc_stores_backup_1427324004938.zip\n4. Unpack the zip file to a temporary location.\n   \n5. Restore these files in the **WEB-INF** directory from the backup.\n   \n6. Start **DASH**\n   \n7. Test if you can access the DASH Portal.\n   ",
    "answer": "To restore the JazzSM DASH login page to default images, you need to restore the relevant xml files from a backup. Here are the steps:\n\n1. Stop the DASH server.\n2. Make a backup copy of the current xml files in the WEB-INF directory.\n3. Go to `<JazzSM_Home>/profile/backups` and find a backup file from a previous day/time that contains the default xml files (e.g., `isc_stores_backup_1427324004938.zip`).\n4. Unpack the zip file to a temporary location.\n5. Restore the relevant xml files (e.g., `navigation.xml`, `portletEntities.xml`) from the backup to the WEB-INF directory.\n6. Start DASH.\n7. Test if you can access the DASH Portal.\n\nNote: The specific xml files that control the login page images are not specified in the provided context. You may need to examine the contents of the backup files to determine which files need to be restored.",
    "id": "TECHQA_TRAIN_Q098_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q101",
    "question": "Installed an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\nInstalled an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\n\nI get the following messages in the logs:-\n\n/tmp/guard_stap.stderr.txt on the DB Server :- \"Server wasn't heard from for nn sec during this attempt nnn sec total), closing and re-opening\"\n\nand from the Guardium Appliance - via fileserver in the /log/opt-ibm-guardium-log/snif/snif.log \"Unauthorized client connecting from ,rejecting\"",
    "ground_truth": "1. Uncheck the **Approval** box\n   The S-TAPs should start connecting\n   ",
    "answer": "To resolve the issue with the STAP not showing up on your Appliance in S-TAP Control, you need to check the S-TAP Certification screen on the Guardium Appliance. If the \"S-TAP Approval Needed\" box is checked, uncheck it. This should allow the S-TAPs to start connecting properly. The error messages you're seeing in the logs, such as \"Server wasn't heard from for nn sec during this attempt\" and \"Unauthorized client connecting from,rejecting\", are likely due to this setting. Unchecking the \"S-TAP Approval Needed\" box should resolve the issue.",
    "id": "TECHQA_TRAIN_Q101_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q104",
    "question": "Updating SCA applications & internal SCA module queues\nWhen updating an existing SCA module using the ISC, I noticed that internal SCA queues (sca/<module>/...) on the SCA.SYSTEM bus) are deleted and recreated.\n\nDoes this mean that any messages that may still reside on these internal queues would be deleted on a module update? If so, when updating SCA modules in a production environment, should these internal queues be monitored to be empty before updating a SCA module (to prevent loosing messages)?",
    "ground_truth": "1. Use the **SCA.recycleDestinations** custom Java\u2122 virtual machine (JVM) property for the module.\n   Set the property to **false** to preserve SCA destinations.\n   ",
    "answer": "When updating an existing SCA module using the ISC, internal SCA queues (sca/<module>/...) on the SCA.SYSTEM bus are deleted and recreated. This means that any messages that may still reside on these internal queues would be deleted on a module update.\n\nTo prevent losing messages, it is recommended to monitor these internal queues to ensure they are empty before updating a SCA module in a production environment. Alternatively, you can use the `SCA.recycleDestinations` custom Java virtual machine (JVM) property for the module and set it to `false` to preserve SCA destinations, including the internal queues. This will prevent the deletion of messages on the queues during the update process.",
    "id": "TECHQA_TRAIN_Q104_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q109",
    "question": "Help with Action required for IIB H.E. V9 & WMB H.E. V8 for security vulnerabilities in Red Hat Linux\nI need to understand details regarding Action required for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0 for security vulnerabilities in Red Hat Linux.\nThis is related to CVE-ID:\nCVE-2017-14746\nCVE-2017-15085\nCVE-2017-15086\nCVE-2017-15087\nCVE-2017-15275\n\nWhere can I find this information?",
    "ground_truth": "1. Contact Red Hat to obtain and install fixes for Red Hat Enterprise Linux (RHEL) Server **6.2**",
    "answer": "To address the security vulnerabilities in Red Hat Linux for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0, related to the CVE-IDs listed (CVE-2017-14746, CVE-2017-15085, CVE-2017-15086, CVE-2017-15087, CVE-2017-15275), you should contact Red Hat to obtain and install the necessary fixes for Red Hat Enterprise Linux (RHEL) Server 6.2. This is the recommended action by IBM to remediate these vulnerabilities. You can find more detailed information and specific instructions on the Red Hat website or by directly contacting their support.",
    "id": "TECHQA_TRAIN_Q109_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q110",
    "question": "Why does my install of the latest Installation Manager on a Linux Ingram Server not function?\nI've installed the latest Installation Manager on an Ingram Server that I mount to different Linux machines where I have installed WebSphere Application Server. I received the following error when trying to use the Installation Manager:\n\n     00:02.25 ERROR [main] org.eclipse.equinox.log.internal.\n     ExtendedLogReaderServiceFactory safeLogged\n       Application error\n       java.lang.NoClassDefFoundError: org.eclipse.jface.dialogs.\n     ProgressMonitorDialog\n         at java.lang.ClassLoader.defineClassImpl(Native Method)\n         at java.lang.ClassLoader.defineClass(ClassLoader.java:324)\n         at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.\n     defineClass(DefaultClassLoader.java:188)\n         at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.\n     defineClassHoldingLock(ClasspathManager.java:632)\n\nI have unmounted and remounted the drive but does not appear to resolve the issue.",
    "ground_truth": "1. Only install the **Installation Manager** on a local disk.\n   ",
    "answer": "The issue you're experiencing with the Installation Manager on your Linux Ingram Server is due to installing it on an NFS mounted disk. According to IBM's guidelines, Installation Manager should not be installed on an NFS mounted disk because it can cause issues with uninstallation and other operations.\n\nTo resolve the problem, uninstall the Installation Manager from the NFS mounted disk and then reinstall it on a local disk. This should fix the error you're seeing and allow the Installation Manager to function properly.",
    "id": "TECHQA_TRAIN_Q110_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q112",
    "question": "WAS 8.5.x - Writing a JMS message to a remote queue takes a long time. How to write the message faster?\nWe are writing a jms message from a websphere cell (cellA) to a queue hosted by another websphere cell (cellB). Sometimes we noticed that writing a message is very slow. Usually when a local queue will be used the time to write this messages is about 8 ms, but if the queue is located on a other cell is took significant longer (about 3000ms+ ).\n\nOur findings: After enabling following trace \"=info: com.ibm.ws.sib.trm.=finest\" the problem is related to:\n- com.ibm.ws.cluster.selection.NoAvailableTargetExceptionImpl\n- WaitForWLMDat 3 (com.ibm.ws.sib.trm.wlm.client.WaitForWLMData) [:] Sleeping for 2999 ms \"\n\nBecause of the sleep time the writing to the queue is slowed down. How to prevent the sleeping time of 3 seconds, when writing a message to a remote queue?",
    "ground_truth": "1. Check for hung threads in the **SystemOut.log**.\n\n2. Consider increasing the value of **sib.trm.linger** from three to give the HA manager more time to locate a messaging engine.\n\n3. Restart the server after changing the property.\n   Once the **sib.trm.linger** property has been modified, restart the server to apply the changes.",
    "answer": "To prevent the sleeping time of 3 seconds when writing a message to a remote queue, you can try increasing the value of `sib.trm.linger` from 3 to a higher value. This will give the HA manager more time to locate a messaging engine.\n\nTo do this, you can add the following property to the `sib.properties` file:\n\n`sib.trm.linger=<new_value>`\n\nWhere `<new_value>` is the new linger time in seconds.\n\nYou can add this property to either the `<WAS_HOME>/properties` or `<PROFILE_ROOT>/properties` location, depending on your specific setup. If you add it to both locations, the property defined at `<PROFILE_ROOT>/properties` will take precedence.\n\nAfter making this change, you must restart the server for it to take effect.\n\nAdditionally, you can also check the SystemOut.log for any hung threads or errors related to the messaging engine, and resolve them if possible. You can also verify that the provider endpoints are correctly configured and that the messaging engines are started and running.",
    "id": "TECHQA_TRAIN_Q112_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q113",
    "question": "How do I configure logging for Atlas Extensions in Atlas 6.0.3.3?\nHow do I configure logging for Atlas Extensions in Atlas 6.0.3.3?",
    "ground_truth": "1. Navigate to **<Atlas_Install_folder>/Atlas/Properties folder**\n\n2. Edit **log4j.properties** file\n\n3. Update the path Information for the following three properties\n   (1) **log4j.appender.MATTER_APPENDER.File=matter_adapter.log** (2) log4j.appender.PERSON_APPENDER.File=person_adapter.log (3) log4j.appender.ORG_UNIT_APPENDER.File=org_unit_adapter.log\n4. Save the file\n\n5. Restart Atlas application server",
    "answer": "To configure logging for Atlas Extensions in Atlas 6.0.3.3, follow these steps:\n\n1. Navigate to the `<Atlas_Install_folder>/Atlas/Properties` folder.\n2. Edit the `log4j.properties` file.\n3. Update the path information for the following three properties:\n   - `log4j.appender.MATTER_APPENDER.File=matter_adapter.log`\n   - `log4j.appender.PERSON_APPENDER.File=person_adapter.log`\n   - `log4j.appender.ORG_UNIT_APPENDER.File=org_unit_adapter.log`\n4. Save the file.\n5. Restart the Atlas application server.\n\nThis will configure logging for Atlas Extensions in Atlas 6.0.3.3.",
    "id": "TECHQA_TRAIN_Q113_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q118",
    "question": "Installation of Portal 7.0 CF fails with version mismatch\nInstallation of Portal 7.0 CF fails with message,\n\n\"Profile version is not the same as portal binary version before updating portal binary.\"",
    "ground_truth": "1. Use the command to update profiles not included in **AutoUpdateMultipleProfiles**.\n   Execute the command: **<wp_profile_root>/PortalServer/bin/UpdateProfile.bat|.sh install CF**\n2. Ensure all profiles are at the same level for future upgrades.\n   Confirm that all profiles are at the same level to allow for the application of future upgrades.",
    "answer": "The installation of Portal 7.0 CF is failing due to a version mismatch, with the error message indicating that the profile version is not the same as the portal binary version. \n\nTo resolve this issue, verify that all profiles are at the same level before starting the upgrade, as mentioned in the context (point 3). If using multiple profiles, ensure they are all at the same level.\n\nThen, try updating the profile using the following command:\n```\n<wp_profile_root>/PortalServer/bin/UpdateProfile.sh install CF\n```\nor \n```\n<wp_profile_root>/PortalServer/bin/UpdateProfile.bat install CF\n```\ndepending on your platform.\n\nIf the issue persists, you may need to manually update the war files or restart nodes in the cluster, as described in the context under \"Problem\" and \"Solution\" sections. However, these steps are specific to other issues and may not directly address the version mismatch error.\n\nIf none of these steps resolve the issue, it may be necessary to re-extract the Combined Cumulative Fix and WebSphere Portal Update Installer, and re-run the update process. \n\nPlease note that the provided context does not offer a direct solution to the version mismatch error. For a more accurate diagnosis and resolution, it is recommended to consult the official IBM documentation or contact their support team.",
    "id": "TECHQA_TRAIN_Q118_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q120",
    "question": "I am receiving AC power supply failures on my DataPower 9235 appliance. How can I resolve this?\nI am observing the following errors on my DataPower 9235 device:\n\n[failure] Power supply '1' has no AC input power, or is not present. [failure] Power supply '2' has no AC input power, or is not present.\n\nHow can this be resolved?",
    "ground_truth": "1. Reboot the **appliance**.\n   In most cases, rebooting the appliance will reset the sensors.",
    "answer": "To resolve the AC power supply failures on your DataPower 9235 appliance, you can try rebooting the appliance. This can be done in two ways:\n\n1. **From the WebGUI**: Go to Control Panel \u2192 System Control \u2192 In the \u201cShutdown\u201d section, choose \u201cReboot System\u201d and then click \u201cShutdown\u201d.\n2. **From the CLI**: Run the commands `top` and then `shutdown reboot`, confirming with `y` when prompted.\n\nRebooting the appliance should reset the sensors and clear the false error messages. If the issue persists, you may want to contact IBM DataPower support with the requested information, including the output of several CLI commands (show clock, show version, show ipmi, show sensors-other, config, service show, and test hardware), as well as how many times you've seen the issue on the same appliance.\n\nAdditionally, you can verify that the power supplies are working normally by checking the LED status on the power supplies. If the LEDs are green, the power supplies are functioning correctly.",
    "id": "TECHQA_TRAIN_Q120_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q121",
    "question": "ncp_poller failed with Out-of-memory in ITNM 3.9 FP4+IF1. What went wrong?.\nncp_poller is failed with out-fo-memory even if we have ITNM 3.9 FP4+IF1 latest FP\n\n2016-04-11T03:02:09: Fatal: F-RIV-002-014: [31869t] CRivError.cc(386) Out-of-memory - This process has run out of memory or exceeded the operating system memory limit for a 32 bit application - You must take action to reduce the amount of data this application is having to process new handler called\n\nHow to resolve this issue?.",
    "ground_truth": "1. Modify and uncomment the following line in **$NCHOME/etc/precision/NcPollerSchema.cfg**\n   **//update config.properties set BatchExtraThreads = 150;**",
    "answer": "The `ncp_poller` failed with an out-of-memory error in ITNM 3.9 FP4+IF1. This issue occurs when the process exceeds the operating system memory limit for a 32-bit application. \n\nTo resolve this issue, you can try increasing the number of threads assigned to `ncp_poller` by modifying the `NcPollerSchema.cfg` file. By default, 100 threads are assigned to `ncp_poller`. You can increase this value by uncommenting and modifying the line `//update config.properties set BatchExtraThreads = 150;` in the `$NCHOME/etc/precision/NcPollerSchema.cfg` file. \n\nFor example, you can change the value to 150 or a higher number, depending on your system's available resources. After making the changes, restart the `ncp_poller` service to apply the updates. Monitor the system's performance to ensure the increased thread count resolves the out-of-memory issue without causing other problems. \n\nIf increasing the thread count does not resolve the issue, you may need to investigate other possible causes, such as optimizing the system's configuration, reducing the amount of data being processed, or upgrading to a 64-bit application to increase the available memory.",
    "id": "TECHQA_TRAIN_Q121_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q123",
    "question": "Updating SCA applications & internal SCA module queues\nWhen updating an existing SCA module using the ISC, I noticed that internal SCA queues (sca/<module>/...) on the SCA.SYSTEM bus) are deleted and recreated.  One can potentially loose messages on these queues. Is there a fix to the problem?",
    "ground_truth": "1. Use the **SCA.recycleDestinations** custom Java\u2122 virtual machine (JVM) property for the module.\n   Setting the property to **false** will preserve SCA destinations.",
    "answer": "To prevent the loss of messages on internal SCA queues when updating an existing SCA module, you can use the `SCA.recycleDestinations` custom Java virtual machine (JVM) property. Set this property to `false` to preserve SCA destinations, including the internal SCA queues. This will ensure that the queues are not deleted and recreated during the update process, thereby preventing potential message loss.",
    "id": "TECHQA_TRAIN_Q123_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q125",
    "question": "completeness report causes StackOverflowError in Decision Center\nWhen running the completeness report in Decision Center we sometimes get a StackOverflowError such as:\n\n     ...\n     Caused by: java.lang.StackOverflowError\n         at ilog.rules.validation.solver.IlcIntScalProd.extract(IlcIntScalProd.java:89)\n         at ilog.rules.validation.solver.IlcIntExpr.getPIntExp(IlcIntExpr.java:156)\n     ...",
    "ground_truth": "1. Adjust the stack sizes (Xss and Xmso) options.\n   ",
    "answer": "To resolve the StackOverflowError when running the completeness report in Decision Center, you can try increasing the stack size of the Java Virtual Machine (JVM) process. This can be done by adding the following parameter to the JVM startup options: `-Xss1024k` (or a larger value if needed). This will increase the stack size to 1024 kilobytes.\n\nAdditionally, you can check the server logs for any recursive calls or infinite loops that may be causing the StackOverflowError. Look for messages containing \"StackOverflow\" or \"Out of Memory\" in the SystemOut.log or SystemErr.log files.\n\nIf the issue persists, you can try analyzing the javacore file generated by the IBM SDK to identify the root cause of the problem. The javacore file can provide more detailed information about the thread stack and the error message.\n\nIt's also recommended to check the application code for any potential infinite recursion or deeply nested calls that may be causing the StackOverflowError.",
    "id": "TECHQA_TRAIN_Q125_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q129",
    "question": "How do I identify Indexing errors in Atlas database?\nHow do I identify Indexing errors in Atlas database?",
    "ground_truth": "1. Login to Atlas database as **PSSAPL** user\n   \n2. Run **select * from ctx_user_index_errors;**\n   \n3. Copy the value in the **ERR_TEXTKEY** Field\n   \n4. Run **select * from documentlibrary where rowid='<value from Step 3> ';**\n   \n5. This will list the document which has the indexing error\n   ",
    "answer": "To identify indexing errors in the Atlas database, follow these steps:\n\n1. Log in to the Atlas database as the PSSAPL user.\n2. Run the query `select * from ctx_user_index_errors;`\n3. Copy the value in the `ERR_TEXTKEY` field from the results.\n4. Run the query `select * from documentlibrary where rowid='<value from Step 3>';`\n5. This will list the document that has the indexing error.\n\nNote: Indexing errors can sometimes be caused by encrypted and password-protected documents.",
    "id": "TECHQA_TRAIN_Q129_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q131",
    "question": "Is it possible to move all the P8 logs out of the default location?\nWe are looking to move all the P8 logs out of the default FileNet folder in Websphere. The trace log can be moved easily; however, the error log and PE logs also need to be moved.",
    "ground_truth": "1. Add the system property **user.dir** in the JVM argument to the application server.\n   ",
    "answer": "Yes, it is possible to move all the P8 logs out of the default location. To do this, you need to add the system property 'user.dir' in the JVM argument to the WebSphere Application Server. For example, if you want to change the log location to 'c:\\logs', you can follow the instructions for WebSphere Application Server. This will override the default directory location for CPE logs, including the error log and PE logs.",
    "id": "TECHQA_TRAIN_Q131_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q132",
    "question": "How can I format a trace for CMOD v9.0 on Windows?\nHow can I format a CMOD trace on Windows?",
    "ground_truth": "1. Open command prompt\n\n2. Navigate to the CMOD\\9.0\\bin directory\n\n3. Issue ARSTFMT command\n   Use the ARSTFMT command as follows: **arstfmt -i C:\\Users\\IBM_ADMIN\\path\\to\\file -o C:\\Users\\IBM_ADMIN\\path\\to\\file\\name.txt**",
    "answer": "To format a CMOD v9.0 trace on Windows, navigate to the CMOD\\9.0\\bin directory in the Command Prompt and use the ARSTFMT command. The syntax is:\n\n`arstfmt -i <input_file> -o <output_file>`\n\nReplace `<input_file>` with the path to the unreadable trace file and `<output_file>` with the desired path and name of the formatted trace file (e.g., `name.txt`). For example:\n\n`arstfmt -i C:\\Users\\IBM_ADMIN\\path\\to\\file -o C:\\Users\\IBM_ADMIN\\path\\to\\file\\name.txt`\n\nThis will convert the binary trace file to a readable format.",
    "id": "TECHQA_TRAIN_Q132_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q134",
    "question": "Why Plug-in log file reports an error message after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver.\nDuring web server start-up, errors like the following will be logged into the Plug-in log file (http_plugin.log):\n\nERROR: lib_security: loadSecurityLibrary: Failed to load gsk library from /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64 ERROR: ws_transport: transportInitializeSecurity: Unable to load security library ERROR: ws_server: serverAddTransport: Failed to initialize security ERROR: ws_server: serverAddTransport: HTTPS Transport is skipped\n\nNote: This is an Apache 2.4 version on a Linux platform",
    "ground_truth": "1. Set the **LD_LIBRARY_PATH** environment variable.\n   Set the **LD_LIBRARY_PATH** environment variable to point to the library directory of the GSKit that comes with the IBM web server Plug-in.\n",
    "answer": "To resolve the error messages in the Plug-in log file (http_plugin.log) after installing and configuring the WebSphere Plugin 8.5 version on an Apache 2.4 web server, you need to set the LD_LIBRARY_PATH environment variable to point to the library directory of the GSKit that comes with the IBM web server Plug-in.\n\nSince you are using a 64-bit Apache 2.4 web server with the 64-bit Plug-in v8.x, you should use the following command:\n\n```\nexport LD_LIBRARY_PATH=/opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n```\n\nHowever, simply setting the LD_LIBRARY_PATH environment variable from the command line prior to starting the web server may not work. You need to set this variable in a way that it is set when the web server is started.\n\nFor Linux platforms, you can add the export command into the appropriate file:\n\n* For SLES and SUSE Linux, add the export command into the `/usr/sbin/envvars` file.\n* For RHEL Linux, add the export command into the `/etc/sysconfig/httpd` file.\n\nFor example, you can add the following line to the appropriate file:\n\n```\nexport LD_LIBRARY_PATH=/opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n```\n\nThis will enable the Plug-in to locate the appropriate GSKit libraries and initialize SSL transports. After setting the LD_LIBRARY_PATH environment variable, restart the Apache web server to apply the changes.",
    "id": "TECHQA_TRAIN_Q134_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q140",
    "question": "A .NET API error is thrown when attempting to install ICC 4.0.1\nA .NET API error is thrown when attempting to install ICC 4.0.1. The error claims that either an incorrect version of the IBM FileNet P8 Content Processing Engine (CPE) .NET API 5.2.1.2 is installed or that it is missing some components.  How do I fix this?",
    "ground_truth": "1. Copy the software on a local disk.\n2. Start the re-installation of the .NET API.\n3. Select all sub-components of .NET framework **4.5** that were not listed before.",
    "answer": "To fix the.NET API error when installing ICC 4.0.1, you need to re-install the CPE 5.2.1.2.NET API. Here are the steps:\n\n1. Copy the CPE 5.2.1.2 software to a local disk.\n2. Start the re-installation of the.NET API.\n3. Select all sub-components of.NET framework 4.5 that were not listed before (select them all if unsure).\n\nThis should resolve the issue, and you should no longer encounter errors regarding missing components during the next installation of ICC 4.0.1.",
    "id": "TECHQA_TRAIN_Q140_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q141",
    "question": "How do I downgrade an IBM Gateway, DataPower, appliance to a lower major firmware release?\nI would like to know the proper, and supported, method to downgrade an appliance to prevent any issues or problems.",
    "ground_truth": "1. Use the **reinit** CLI command.\n   This command will allow you to reconfigure an IBM WebSphere DataPower SOA appliance. It will allow you to delete (not erase) all existing configuration and data from an IBM WebSphere DataPower SOA appliance.",
    "answer": "To downgrade an IBM Gateway, DataPower, appliance to a lower major firmware release, you should use the \"reinitialize\" CLI command. However, before doing so, ensure you have a working serial connection to the appliance and a firmware image is available on the appliance. If the appliance has optional RAID or HSM, reinitialize them according to the provided instructions.\n\nHere are the steps:\n\n1. **Verify the firmware image**: Use the DataPower's File Management WebGUI option or the CLI commands (`configure`, `dir image:`) to confirm a firmware image is present on the appliance. If not, load a firmware image into the `image:///` directory.\n2. **Reinitialize the appliance**: Run the \"reinitialize\" CLI command. This will delete all existing configuration and data from the appliance.\n3. **Reconfigure the appliance**: After the appliance reboots, you will need to configure your Ethernet and all other settings again using the information in the product information center available from the library page.\n4. **Accept the license (if necessary)**: If the firmware image used was for V5 or newer, you will need to accept the license at first logon to the WebGUI.\n5. **Configure the appliance**: Configure the appliance per the instructions in the appliance's configuration guide.\n\nNote: The \"reinitialize\" command will revert the admin password to the initial value of \"admin\" and remove all existing configuration and data. Make sure you have a working serial connection to the appliance before running the command.",
    "id": "TECHQA_TRAIN_Q141_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q145",
    "question": "How can I obtain a Java thread dump against an execution group in IIB v10?\nThis Q&A is abstracted from a PMR\n\nHow can I obtain a Java thread dump against an execution group in IIB v10?",
    "ground_truth": "1. Use this command to generate a Java dump on IIB v10.0.0.9+:\n   Execute the following command: **mqsichangeproperties <Int.Node> -e <Int.Server> -o ComIbmInternalSupportManager/Java/JVM -n dump -v <dump_type>**",
    "answer": "To obtain a Java thread dump against an execution group in IIB v10, you can use the following command:\n\n`mqsichangeproperties <Int.Node> -e <Int.Server> -o ComIbmInternalSupportManager/Java/JVM -n dump -v core`\n\nReplace `<Int.Node>` with the name of your integration node and `<Int.Server>` with the name of your execution group. This command will generate a Java core dump (javacore) that contains information about all Java threads running in the process.\n\nNote: This procedure requires the use of the IBM JRE and is only applicable for operating systems that use the IBM JRE, excluding Solaris and HP platforms.\n\nAlternatively, if you are using a version of IIB prior to v10.0.0.9, you can create a custom message flow to trigger a Java dump. However, this method is more complex and requires creating a new message flow with a JavaCompute node that calls the `com.ibm.jvm.Dump.JavaDump()` method.",
    "id": "TECHQA_TRAIN_Q145_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q150",
    "question": "Error: \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" occurs at portal startup\nWe are using Portal Server 8.5 and when starting the Portal server we see following error:\n\n0000005e MBeanStarter E com.ibm.wps.scripting.server.MBeanStarter loadExtensions failed to load extension: key: ServerExt.applications / value: com.ibm.wps.scripting.server.ApplicationServerExtensions\n\nHow can we resolve this error without installing a fix?",
    "ground_truth": "1. Open the **WebSphere Application Server (WAS)** admin console\n\n2. Navigate to Resources > Resource environment providers > WP ScriptingService > Custom properties\n\n3. Locate an entry with the name **ServerExt.applications** and value **com.ibm.wps.scripting.server.ApplicationServerExtensions**\n\n4. Delete this entry, save and restart the server",
    "answer": "To resolve the \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" error at portal startup without installing a fix, follow these steps:\n\n1. Open the WebSphere Application Server (WAS) admin console.\n2. Navigate to Resources > Resource environment providers > WP ScriptingService > Custom properties.\n3. Locate the entry with the name \"ServerExt.applications\" and value \"com.ibm.wps.scripting.server.ApplicationServerExtensions\".\n4. Delete this entry.\n5. Save the changes and restart the server.\n\nThis should resolve the error. Note that a permanent fix is available through the WebSphere Portal 8.5.0.0 Combined Cumulative Fixes, but the above steps provide a temporary workaround.",
    "id": "TECHQA_TRAIN_Q150_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q152",
    "question": "EIF probe not receiving itm events\nWhy is the event in the netcool isn't cleaned ?",
    "ground_truth": "1. Set the **connection_mode** in your **om_tec.config** on the ITM Server (TEMS) to use connection_less.\n   Modify the configuration file om_tec.config located on the ITM Server (TEMS) to change the setting for connection_mode from connection oriented to connection_less.",
    "answer": "To resolve the issue of the EIF probe not receiving ITM events and the event not being cleared in Netcool, you need to modify the `om_tec.conf` file on the ITM Server (TEMS). Specifically, change the `ConnectionMode` from `co` (connection oriented) to `connection_less`. After making this change, restart the EIF on your ITM by running the command `tacmd refreshTECinfo -t eif`. This should allow the clearing event to be properly received and processed, clearing the event in OMNIbus.",
    "id": "TECHQA_TRAIN_Q152_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q154",
    "question": "IBM SPSS Statistics Subscription Installer not supported on Mac OS version OS X 10.9.5\nAttempted several times to install IBM SPSS statistics subscription installer. Followed online instructions to double click the blue and white statisticsSub_Installer and click open. The result a message installer not supported OS version. Attempted to turn off fire wall and install without success. Suggestions?",
    "ground_truth": "1. Install Apple Java SE **6 (1.6.0_65)** on OS X 10.9.\n2. Install IBM SPSS Statistics **22**.",
    "answer": "The issue you're experiencing with the IBM SPSS Statistics Subscription Installer not being supported on Mac OS version OS X 10.9.5 (Mavericks) can be resolved by installing an older version of IBM SPSS Statistics that is compatible with your operating system. According to the provided context, IBM SPSS Statistics 22 can be installed on Mac OS X 10.9 (Mavericks) if you first install Apple Java SE 6 (1.6.0_65) on your system. \n\nHere are the steps you can follow:\n\n1. Download and install Apple Java SE 6 (1.6.0_65) from the Apple support website: http://support.apple.com/kb/dl1572.\n2. Once Java is installed, attempt to install IBM SPSS Statistics 22. This version is known to be compatible with OS X 10.9.\n\nNote: Ensure your Mac has an Intel processor, as this is a requirement for installing IBM SPSS Statistics software on Apple Macintosh OSX operating systems.\n\nIf you continue to encounter issues, consider checking for any known issues or fixes related to your specific version of IBM SPSS Statistics and Mac OS X 10.9, or contact IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q154_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q159",
    "question": "Why can't IBM FileNet Content Platform Engine successfully connect to IBM FileNet Content Search Services?\nWhy can't IBM FileNet Content Platform Engine successfully connect to IBM FileNet Content Search Services? I see the following error in my p8_server_error.log.\n\nIQQG0205E The client [version: 5.2.0.2] is not compatible with the server [version: 2.1.0.0-1.1-4140.FP4].",
    "ground_truth": "1. Check the readme files for the installed IBM FileNet Content Platform Engine and **IBM FileNet Content Search Services** fix packs.",
    "answer": "The issue is due to a version compatibility problem between the IBM FileNet Content Search Services client embedded in the IBM FileNet Content Platform Engine and the IBM FileNet Content Search Services server. The client version is 5.2.0.2, while the server version is 2.1.0.0-1.1-4140.FP4. \n\nTo resolve this issue, you need to ensure that the version of the IBM FileNet Content Search Services client files included in the IBM FileNet Content Platform Engine matches the version of the IBM FileNet Content Search Services server. \n\nPlease check the readme files for your installed IBM FileNet Content Platform Engine and IBM FileNet Content Search Services fix packs to determine the required fix pack versions. You may need to apply a fix pack to either the client or the server to achieve version compatibility. \n\nFor example, you can check the prerequisites for the IBM Content Search Services 5.2.1.5 fix pack, which requires specific versions of P8CSS and P8CPE fix packs. Apply the necessary fix packs to ensure version compatibility between the client and the server.",
    "id": "TECHQA_TRAIN_Q159_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q162",
    "question": "Crash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\nDetails of gpf crash events: A VerifyError was thrown due to \"Inaccessible class\" at offset 39(0x27) of the method executeInternal(Lorg/springframework/http/HttpHeaders;[B)Lorg/springfram ework/http/client/ClientHttpResponse of the above class org/springframework/http/client/HttpComponentsClientHttpRequest.\n\nLooking at method the bytecodes :\n\n31 invokespecial 15 org/apache/http/entity/ByteArrayEntity.([B)V 34 astore 4 36 aload3 37 aload 4 39 invokeinterface2 41 invokeinterface 16 org/apache/http/HttpEntityEnclosingRequest.setEntity(Lorg/apache/http/Ht tpEntity;)V\n\nThe above sequence of bytecodes indicates it created an instance of org/apache/http/entity/ByteArrayEntity, trying to cast it to type Lorg/apache/http/HttpEntity; which in turns led to the \"Inaccessible class\" VerifyError message.\n\nIt is clear that class org/apache/http/HttpEntity was not loaded at all:\n\n    allclasses | grep org/apache/http/HttpEntity",
    "ground_truth": "1. Update the application with HTTPCore and **HTTPClient** libraries bundled.\n   The application may need to be updated to include the HTTPCore and **HTTPClient** libraries to resolve the NoClassDefFoundError.",
    "answer": "The crash occurred due to the \"Inaccessible class\" VerifyError, which was caused by the Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577). To resolve this issue, you need to apply the fix PI50993, which can be downloaded from the IBM Fix Central website.\n\nAfter applying the fix, you may encounter a NoClassDefFoundError because the API in HTTPCore and HTTPClient libraries are no longer visible to the application. To resolve this error, you may need to update your application with the HTTPCore and HTTPClient libraries bundled.\n\nHere are the steps to follow:\n\n1. Download the fix PI50993 from the IBM Fix Central website.\n2. Review the readme.txt file for detailed installation instructions.\n3. Apply the fix to your WebSphere Application Server.\n4. If you encounter a NoClassDefFoundError, update your application with the HTTPCore and HTTPClient libraries bundled.\n\nIf you need further assistance, you can contact IBM Support using SR or visit the WebSphere Application Server support web site.",
    "id": "TECHQA_TRAIN_Q162_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q165",
    "question": "Is Java 8 supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or later?\nIs Java 8 supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or later?",
    "ground_truth": "1. Upgrade to WebSphere Application Server V9.\n   To deploy JDK **8** compiled web applications, please upgrade to WebSphere Application Server V9.",
    "answer": "No, Java 8 is not supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or later versions below 9. According to the context, \"the tool can only deploy Java EE applications compiled with a JDK level of 7 or below\" in WebSphere Application Server 8.5.5.x and below. To deploy JDK 8 compiled web applications, you need to upgrade to WebSphere Application Server V9.",
    "id": "TECHQA_TRAIN_Q165_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q166",
    "question": "Application code is overriding session timeout in WebSphere Application Server 7.0\nHow to check if application code is overriding session timeout? Is there a WebSphere trace that will show this information?",
    "ground_truth": "1. Reproduce the problem with **session tracing** enabled.\n\n2. Add debug code to the application.\n   Incorporate debug statements in your application to make it easier to identify the problem.",
    "answer": "To check if application code is overriding session timeout in WebSphere Application Server 7.0, you can enable a diagnostic trace. Here's how:\n\n1. Go to the WebSphere Application Server administrative console, expand the Troubleshooting section, and click Logs and Trace.\n2. Click the link for your server and then click Diagnostic Trace.\n3. Enable logging and specify a file name.\n4. Click Change Log Level Details and enter the following trace string in the Trace Specification text box: `com.ibm.ws.session.*=all:com.ibm.ws.webcontainer.srt.*=all` (if you don't use persistence), or the corresponding string for database or memory-to-memory persistence.\n5. Apply and save your configuration, then stop and restart the Application Server.\n6. Reproduce the problem and collect the trace file, as well as other log files and configuration files as specified in the instructions.\n\nThe trace file will show you if the application code is overriding the session timeout. Look for messages related to session timeout and override in the trace file. If you're still unsure, you can also try adding debug code to the application to simplify the task of identifying the problem. \n\nAdditionally, you can also enable a plug-in trace by changing the LogLevel attribute from Error to Trace in the plugin-cfg.xml file, and collect the http_plugin.log file for further analysis. \n\nBy following these steps, you should be able to determine if the application code is overriding the session timeout in WebSphere Application Server 7.0.",
    "id": "TECHQA_TRAIN_Q166_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q174",
    "question": "Can not create a portal wcm syndicator-subscriber pair. The \"Subscribe Now\" window pops up but is blank or corrupted. Why?\nCan not create a portal wcm syndicator-subscriber pair. The \"Subscribe Now\" window pops up but is blank or corrupted.",
    "ground_truth": "1. Make sure that the page on which the WCM authoring portlet is installed uses a theme with client-side rendering such as the **Page Builder** theme.\n\n2. Deploy the hidden Portal page on which the reserved authoring portlet is installed.\n\n3. Run the following task from the **wp_profile_root** / Config Engine directory.",
    "answer": "To resolve the issue of not being able to create a portal WCM syndicator-subscriber pair due to a blank or corrupted \"Subscribe Now\" window, follow these steps based on the provided context:\n\n1. **Ensure Correct Theme**: Verify that the page on which the WCM authoring portlet is installed uses a theme with client-side rendering, such as the Page Builder theme.\n\n2. **Deploy Hidden Portal Page**: Deploy the hidden Portal page on which the reserved authoring portlet is installed. This step is crucial for ensuring that all necessary components for WCM functionality are properly set up after migration.\n\n3. **Run ConfigEngine Task**: Execute the following command from the `wp_profile_root/ConfigEngine` directory to install the WCM hidden authoring page:\n   - For Windows: `ConfigEngine.bat install-wcm-hidden-authoring-page -DWasPassword=password`\n   - For UNIX/Linux: `./ConfigEngine.sh install-wcm-hidden-authoring-page -DWasPassword=password`\n   Replace `password` with your actual WebSphere Application Server password.\n\nThese steps are aimed at resolving issues related to the migration process disabling new out-of-the-box features, including those necessary for WCM syndication. If the problem persists after completing these steps, it may be necessary to investigate further or consult additional resources specific to your environment and version of IBM WebSphere Portal and Web Content Manager.",
    "id": "TECHQA_TRAIN_Q174_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q178",
    "question": "ILMT agent doesn`t show the hostname on inventory hardware\nHello community: I have a problem with a host. I installed ILMT agent and i exec all the task (install scan,initiate scan,run capacity and upload results....) after that i not see the hostname at the ILMT webpage, i only recognized the host by the System ID. The Hypervisor is KVM. I do this tasks with many other host like that and i not found problems.I attached an image.\n\nCan you help me to manage this issue?\n\nThank you and Best regards.",
    "ground_truth": "1. Ensure that the import is not running and stop the BFI/SUA/LMT server.\n   \n2. To reset the sequence for all data sources and import all data, run the following query on the BFI/SUA/LMT database:\n   DB2:\n   **UPDATE dbo.DATASOURCE_SEQUENCES set LAST_SEQUENCE = blob(x'0000000000000000');**\n   \n   MSSQL:\n   **UPDATE dbo.datasource_sequences set last_sequence = 0x0000000000000000;**\n3. Start the BFI/SUA/LMT.\n   \n4. Run an import.\n   ",
    "answer": "To resolve the issue with the ILMT agent not showing the hostname on inventory hardware, follow these steps:\n\n1. Ensure that the import is not running and stop the BFI/SUA/LMT server.\n2. Run the following query on the BFI/SUA/LMT database to reset the sequence for all data sources and import all data:\n   - For MSSQL: `UPDATE dbo.datasource_sequences set last_sequence = 0x0000000000000000;`\n   - For DB2: `UPDATE dbo.DATASOURCE_SEQUENCES set LAST_SEQUENCE = blob(x'0000000000000000');`\n3. Start the BFI/SUA/LMT server.\n4. Run an import.\n\nThis procedure will impact the length of the first import after the sequence is reset, and all data from all endpoints available on the BigFix server side will be imported. For big environments, the impact may be huge, and it is better to re-run scans on selected endpoints instead.\n\nAdditionally, if the issue persists, consider re-running the scans on the affected host to re-generate the missing data. \n\nNote: The provided context suggests that the issue might be related to a database restoration, which can cause a gap in imported data. The above steps should help resolve the issue, but if you are unsure or the problem persists, it's recommended to consult the IBM BigFix documentation or contact their support for further assistance.",
    "id": "TECHQA_TRAIN_Q178_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q184",
    "question": "I am trying to install Portal 8.5 on Windows and getting error, CRIMA1217E in the IIM logs\nWhile trying to install Portal 8.5 using IIM it fails and the following is in the IIM logs...\n\n     549 ERROR CRIMA1217E 01:01:00.16 A problem occurred during the\n     execution of the\n     C:\\IBM\\WebSphere\\PortalServer\\installer\\wp.config\\wizard\\repository\\repo\n     sitory_actions.xml file.\n           ERROR: Error executing the work flow.  Step 'Basic\n     Config' FAILED!.  Check the logs for additional error messages.\n     [C:\\IBM\\WebSphere\\PortalServer\\installer\\wp.config\\wizard\\repository\\rep\n     ository_actions.xml:622]\n         A package has an issue that cannot be resolved by\n     Installation Manager.\n         Identify the package that has the issue by looking at\n     the installation history. In Installation Manager, click File >\n     Installation History. In console mode, enter S: View Installation\n     History. Contact IBM customer support.\n     \n     550 ERROR  01:01:00.16 Creating WebSphere Portal Profile.  This\n     will take several minutes.",
    "ground_truth": "1. Stop all **WebSphere** processes on the machine\n\n2. Attempt to install the second Portal instance again",
    "answer": "To resolve the CRIMA1217E error in the IIM logs while installing Portal 8.5 on Windows, you should stop all running WebSphere and related processes on the machine before attempting to install the second Portal instance. This is because the error is likely caused by the first Portal install still running when the second Portal install is attempted. After stopping all WebSphere processes, try installing the second Portal instance again. If the issue persists, review the installation history in Installation Manager (File > Installation History) to identify any package issues and consider contacting IBM customer support for further assistance.",
    "id": "TECHQA_TRAIN_Q184_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q187",
    "question": "How to resolve coach service timeout or expired issue?\nCustomer has followed http://www-01.ibm.com/support/docview.wss?uid=swg21633251 and http://www-01.ibm.com/support/docview.wss?uid=swg21601357 to set up long time session but customer still got error message: \"The service you are trying to run has expired.\" only when the user keep a coach session idle that over 30 minutes.  How to resolve this issue?",
    "ground_truth": "1. Check Override in the **Override Session Management** section\n\n2. Select to set the time-out and the time-out value\n   This sets the application session to overwrite those values set at the parent, which in this case is the Server level.",
    "answer": "To resolve the coach service timeout or expired issue, you need to adjust the HTTP Session time-out settings. Since you've already followed the provided links to set up long-time sessions, but still encounter the issue when the coach session is idle for over 30 minutes, you should try the following:\n\n1. **Check the current settings**: Verify the current HTTP Session time-out settings at the server, Enterprise application, and Web application levels in the WebSphere Application Server Administrative Console.\n2. **Override the settings**: Ensure that the \"Override\" option is selected in the Session Management section for the Enterprise Application and/or Web Application levels, and set the desired time-out value (e.g., more than 30 minutes).\n3. **Set the time-out at the application level**: If the above steps don't work, try setting the HTTP Session time-out in the application code using the `setMaxInactiveInterval()` method on the `HttpSession` object.\n4. **Save the master configuration**: After making any changes, save the master configuration to apply the updates.\n\nBy following these steps, you should be able to resolve the coach service timeout or expired issue. If the problem persists, you may want to review the HTTP Session time-out Override Precedence Summary to ensure that the correct settings are being applied.",
    "id": "TECHQA_TRAIN_Q187_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q190",
    "question": "Does anyone know how to disable HTTPS to HTTP redirection for BPC Explorer?\nIt appears that by default, BPC comes configured with https instead of http.\n\nIs there a way to configure BPC to use http instead or are there steps for configuring BPC to use http? Need to avoid accessing BPC explorer via https.",
    "ground_truth": "1. Download the **unsecureExplorer.ant** script file.\n   The unsecureExplorer.ant script file is attached near the bottom of the page.\n2. Delete the old (invalid) backup **EAR** file before running the script.\n   If you previously switched Business Process Choreographer Explorer to use HTTP and are now installing an interim fix, fix pack, or refresh pack that updated Business Process Choreographer Explorer to the default HTTPS protocol, you must delete the following file: On Linux, UNIX-based and z/OS platforms, delete the install_root/ProcessChoreographer/internal/bpcexplorer_secure_backup.ear file. On Microsoft Windows platforms, delete the install_root\\ProcessChoreographer\\internal\\bpcexplorer_secure_backup.ear file.\n3. Run the script to patch the **bpcexplorer.ear** file.\n   In a network deployment environment, you must run the script on the deployment manager. On Linux, UNIX-based and z/OS platforms, enter the following command: install_root/ws_ant.sh -f unsecureExplorer.ant. On Windows platforms, enter the following command: install_root\\ws_ant.bat -f unsecureExplorer.ant. A backup copy of the original EAR file is created named bpcexplorer_secure_backup.ear.\n4. Deploy the patched **bpcexplorer.ear** file by updating the profile.\n   For more information about updating profiles for an interim fix, see the relevant documents for your version: For version 8.0.1.x: Profile update instructions for IBM Business Process Manager (BPM) interim fixes [http://www.ibm.com/support/docview.wss?uid=swg21608414]. For version 8.5 and later: Profile update instructions for IBM Business Process Manager (BPM) interim fixes [http://www.ibm.com/support/docview.wss?uid=swg21637449].",
    "answer": "To disable HTTPS to HTTP redirection for BPC Explorer, you can follow these steps:\n\n1. Download the `unsecureExplorer.ant` script file.\n2. Run the script to switch the protocol used from HTTPS to HTTP.\n\nNote: Before running the script, if you have previously switched to HTTP and are now reinstalling an interim fix, fix pack, or refresh pack that updated Business Process Choreographer Explorer, you must first delete the old (invalid) backup EAR file:\n\t* On Linux, UNIX-based and z/OS platforms, delete the `install_root/ProcessChoreographer/internal/bpcexplorer_secure_backup.ear` file.\n\t* On Microsoft Windows platforms, delete the `install_root\\ProcessChoreographer\\internal\\bpcexplorer_secure_backup.ear` file.\n\nPlease be aware that using HTTP instead of HTTPS may open your organization to possible security problems, as it is not recommended to use the insecure HTTP protocol.",
    "id": "TECHQA_TRAIN_Q190_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q195",
    "question": "How to resolve \"StringIndexOutOfBoundsException = null\"\nWhen importing a projects.csv file, the import fails with following error in the import logs:\n\nERROR - FAILED: Create failed for Projects row 1: StringIndexOutOfBoundsException = null Ensure that the COORDINATOR column is in the loginId:Role format to prevent errors.",
    "ground_truth": "1. Ensure that the **COORDINATOR** column is in the **loginId:Role** format",
    "answer": "To resolve the \"StringIndexOutOfBoundsException = null\" error, ensure that the COORDINATOR column in your projects.csv file is in the correct format, which is \"loginId:Role\". Verify that every entry in the COORDINATOR column follows this format to prevent the import from failing. If the format is correct, check for any empty or null values in the COORDINATOR column, as these may also cause the error. Correct any formatting issues or empty values, and then retry the import.",
    "id": "TECHQA_TRAIN_Q195_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q199",
    "question": "How to start PC DMgr as a Windows service?\nhi all. I just installed BPM 8.5.0.1 Process Center on a Windows 2008 R2 cloud server. The default BPM85 typical installation installs ProcessCenter Quickstart web page for starting the Dmgr and NodeMgr servers using the installation admin user . However, logout stops the services started by and attached to the admin user. I need to have this ProcessCenter (and Deployment Env Process SErvers) BPM85 DMgr / Node/ WASND started as a managed Windows managed service. I didn't see a Service Definition page to select run as Windows service. Can I possibly run BPMConfig -start dmgrprofile as a Windows service or is a profile update to my dmgr (hope not) needed to do this?",
    "ground_truth": "1. Place the **WASServiceCmd.exe** utility in the following directory:\n   Move the **WASServiceCmd.exe** utility file to the **install_root\\bin** directory.\n2. Launch the command from the command line.\n   The WASServiceCmd utility prompts you to select specific options and settings from a list and then calls the WASService.exe command passing all selected parameters.",
    "answer": "To start PC DMgr as a Windows service, you can use the WASServiceCmd utility. Here are the steps:\n\n1. Place the WASServiceCmd.exe utility in the `install_root\\bin` directory.\n2. Launch the command from the command line.\n3. Follow the prompts to select the specific options and settings for your Windows service, including the server name, profile path, log root, and log file.\n4. The WASServiceCmd utility will call the WASService.exe command with the selected parameters and create the Windows service.\n\nAlternatively, for WebSphere Application Server v8 and later, you can use the WASServiceHelper.bat utility in the bin directory.\n\nNote: You can also refer to the IBM Knowledge Center article \"Using the WASServiceHelper utility to create Windows services for application servers\" for more detailed information.\n\nExample command:\n```\nWASService.exe -add \"Deployment Mgr01\" -serverName \"dmgr\" -profilePath \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\" -logRoot \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\\logs\\dmgr\" -logFile \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\\logs\\dmgr\\WS_startdmgr.log\" -encodeParams -stopArgs \"-username vanno -password ****** \" -startType manual -restart false\n```\nMake sure to replace the placeholders with your actual values.",
    "id": "TECHQA_TRAIN_Q199_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q201",
    "question": "The config task wp-add-property is failing with \"Can not find EJB\" message while running on our Portal 8.5 cluster\nWe are trying to perform the following steps on our Portal cluster...\n\nhttp://www.ibm.com/support/knowledgecenter/SSHRKX_8.5.0/mp/install/add_attributes.html\n\nWe successfully ran the wp-la-install-ear task but now when attempting to run the wp-add-property task we see the following error in the ConfigTrace.log....\n\n [wplc-add-property] [2016-10-11 15:57:32.065] Can not find EJB:\n ejb/com/ibm/websphere/wim/ejb/WIMServiceHome\n [wplc-add-property] javax.naming.NameNotFoundException: Context:\n dmgrCell01/nodes/dmgrNode01/servers/dmgr, name:\n ejb/com/ibm/websphere/wim/ejb/WIMServiceHome: First component in name\n websphere/wim/ejb/WIMServiceHome not found. [Root exception is\n org.omg.CosNaming.NamingContextPackage.NotFound:",
    "ground_truth": "1. Uninstall the WIMSYSTEM enterprise application from the **WebSphere_Portal** server.\n\n2. Follow the steps in Document **#1358381** to install the .ear file on the **DMGR**.\n",
    "answer": "To resolve the \"Can not find EJB\" error when running the `wp-add-property` task on your Portal 8.5 cluster, follow these steps:\n\n1. **Uninstall the WIMSYSTEM enterprise application**: Use the WebSphere Administrative console to uninstall the WIMSYSTEM enterprise application from the WebSphere_Portal server.\n2. **Install the.ear file on the DMGR**: Follow the steps in Document #1358381 to install the.ear file on the Deployment Manager (DMGR).\n3. **Verify the installation**: Check the ConfigTrace.log to ensure the.ear file was installed successfully on the DMGR.\n4. **Rerun the wp-add-property task**: After completing the above steps, rerun the `wp-add-property` task to add the required properties.\n\nAdditionally, ensure that:\n\n* The bootstrap address information in the URL is correct.\n* The target name server is running.\n* The network environment and workstation network configuration are properly set up.\n\nBy following these steps, you should be able to resolve the \"Can not find EJB\" error and successfully run the `wp-add-property` task on your Portal 8.5 cluster.",
    "id": "TECHQA_TRAIN_Q201_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q202",
    "question": "How to find if Table was Created as NOT LOGGED INITIALLY?\nHow to find if Table was Created as NOT LOGGED INITIALLY?",
    "ground_truth": "1. Check if the table was created as 'Not Logged Initially' using **db2cat**.\n   Run the command **db2cat -db <dbname> -n <TableName> -s <Schema> -t | grep \"Table not logged\"** to check the table's logging status. If the output shows 'Table not Logged: 0', it indicates that the table was not created as NLI. If it shows '1', then the table was created as NLI.",
    "answer": "To find if a table was created as NOT LOGGED INITIALLY, you can use one of the following methods:\n\n1. **Using db2cat**: Run the command `db2cat -db <dbname> -n <TableName> -s <Schema> -t | grep \"Table not logged\"`. If the output shows \"Table not logged : 1\", it means the table was created as NOT LOGGED INITIALLY. If it shows \"Table not logged : 0\", it means the table was not created as NOT LOGGED INITIALLY.\n\n2. **Using db2look**: Run the command `db2look -d <database_name> -t <table_name> -e -o <output_file_name.out>`. This will generate a DDL statement for the table, which will include the \"NOT LOGGED INITIALLY\" clause if the table was created with it.\n\nNote: These methods will not detect if a table was altered with ACTIVATE NOT LOGGED INITIALLY, as this only applies to the current unit of work. Also, in DB2 V9 and later, the LOG_ATTRIBUTE column in the SYSCAT.TABLES table is no longer used and will always have a value of 0.",
    "id": "TECHQA_TRAIN_Q202_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q203",
    "question": "Limitations of sylog-TCP log target using DataPower Gateways\nI am trying to configure a log target using type syslog-TCP. It seems that the payload is getting truncated when I try to record custom logs to it using log-action. How can I workaround it.",
    "ground_truth": "1. Configure a server daemon to listen and capture the **DataPower** devices events.",
    "answer": "The issue you're experiencing with payload truncation when using a syslog-TCP log target with DataPower Gateways is likely due to the finite amount of space available on the device for holding larger than average log files. \n\nTo work around this limitation, consider the following options:\n\n1. **Configure a server daemon to listen and capture the DataPower device's events**: This can help ensure that log events are not dropped and can be stored for longer periods.\n2. **Use syslog-ng instead of syslog**: Syslog-ng operates over TCP, which ensures packet delivery, reducing the likelihood of log events being dropped.\n3. **Use an NFS static mount to capture log targets**: This approach can provide a more reliable way to log messages, but be aware of NFS limitations, such as file size and permission settings.\n4. **Use a file type log target with a backup method**: This allows log events to be written to a local file on the device's file system and then uploaded to a destination with a unique time and date stamp.\n5. **Consider using an HTTP service on the device**: This can be a clever method to capture log events in certain scenarios.\n\nBy exploring these alternatives, you can find a suitable workaround for the payload truncation issue when using a syslog-TCP log target with DataPower Gateways.",
    "id": "TECHQA_TRAIN_Q203_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q207",
    "question": "How to configure the Data Power Agent to communicate on TLSv1.2 ?\nAPM agent for data power is not able to communicate with data power server when SSL is enabled. Since we are connecting to TLS version 1, where data power server supports only TLS 1.2.",
    "ground_truth": "1. Change the value of the configuration item **KBN_SOMA_PROTOCOL**.",
    "answer": "To configure the Data Power Agent to communicate on TLSv1.2, you need to update the \"KBN_SOMA_PROTOCOL\" configuration item to \"TLSv1.2\". \n\nFor Windows platform:\n1. Update the value of \"KBN_SOMA_PROTOCOL\" in KBNENV to \"TLSv1.2\".\n2. Restart the agent instance.\n\nFor Linux/Unix platform:\n1. Update the value of \"KBN_SOMA_PROTOCOL\" in bn.ini to \"TLSv1.2\".\n2. Restart the agent instance.\n\nNote: After updating the configuration, the agent instance must be restarted to enable the new configuration change.",
    "id": "TECHQA_TRAIN_Q207_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q210",
    "question": "How to wrap table column text in list tab for a specific table?\nI would like to wrap the text of table column into new a line.",
    "ground_truth": "1. Wrap table column text according to number of characters.\n   Use the property **wraplength** in the **tablecol tag**.",
    "answer": "To wrap table column text in a list tab for a specific table, you can use the `wraplength` property in the `tablecol` tag. For example:\n\n```html\n<tablecol dataattribute=\"description\" id=\"results_showlist_tablebody_3\" sortable=\"false\" width=\"200\" wraplength=\"100\"/>\n```\n\nThis will wrap the text once it reaches 100 characters into a new line. You can adjust the `wraplength` value to suit your specific needs.",
    "id": "TECHQA_TRAIN_Q210_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q215",
    "question": "Is ITNM exposed to vulnerability CVE-2017-1194?.\nIs ITNM versions are affected by vulnerability CVE-2017-1194, because ITNM does shipped with WebSphere Application Server,  where I can find the details?.",
    "ground_truth": "1. Consult the security bulletin Cross-site request forgery in WebSphere Application Server (CVE-2017-1194)\n   Visit the URL **http://www-01.ibm.com/support/docview.wss?uid=swg22001226** for vulnerability details and information about fixes.",
    "answer": "Yes, ITNM (IBM Tivoli Network Manager) is exposed to vulnerability CVE-2017-1194, as it is shipped with WebSphere Application Server, which is affected by this vulnerability. The affected ITNM versions are 3.9, 4.1, 4.1.1, and 4.2. For more details and information about fixes, you can refer to the security bulletin \"Cross-site request forgery in WebSphere Application Server (CVE-2017-1194)\" at [http://www-01.ibm.com/support/docview.wss?uid=swg22001226].",
    "id": "TECHQA_TRAIN_Q215_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q217",
    "question": "Download link for application support for OMEGAMON for Messaging on z/OS V7.5\nWhere is download link for application support for IBM OMEGAMON for Messaging on z/OS V7.5.0 on ITM SLES zlinux servers?",
    "ground_truth": "1. Download the IBM Tivoli OMEGAMON XE for Messaging V7.5.0 Data Files for z/OS DVD.\n   Access the following URL to download the DVD: **ftp://public.dhe.ibm.com/software/tivoli_support/misc/PandA/tools_agent/tools/appsupt/LCD7-3513-09.zip**.",
    "answer": "The provided context does not contain a download link for application support for IBM OMEGAMON for Messaging on z/OS V7.5.0. The context only provides information on earlier versions, such as V7.3.0 and V7.1.0, and their respective download links. Therefore, I don't know the download link for application support for IBM OMEGAMON for Messaging on z/OS V7.5.0. You may want to check the official IBM website or contact IBM support directly for the most up-to-date information.",
    "id": "TECHQA_TRAIN_Q217_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q221",
    "question": "Case Analyzer is not working\nCaseAnalyzer is not working, no latest audit log although service is running\n\nError in log:\n\n\"CAPublisher c2dce3b9 [Error] Unexpected exception occurred while processing task CAPublisher for store CASTORE.; Exception: com.microsoft.sqlserver.jdbc.SQLServerException: The query processor ran out of internal resources and could not produce a query plan. This is a rare event and only expected for extremely complex queries or queries that reference a very large number of tables or partitions. Please simplify the query. If you believe you have received this message in error, contact Customer Support Services for more information.\"",
    "ground_truth": "1. Set the BATCH value for the **analyzer.db.updateMode** parameter.\n   Execute the following SQL query in the Case Analyzer store database: **UPDATE X_CAProperties SET PropValue='BATCH' WHERE PropName ='analyzer.db.updateMode'**",
    "answer": "To resolve the issue with Case Analyzer not working and the error message indicating that the query processor ran out of internal resources, you can try setting the `analyzer.db.updateMode` parameter to `BATCH`. This can potentially simplify the queries and improve performance.\n\nTo set the `analyzer.db.updateMode` parameter to `BATCH`, run the following query in the Case Analyzer store database:\n\n`UPDATE X_CAProperties SET PropValue='BATCH' WHERE PropName ='analyzer.db.updateMode'`\n\nAfter updating the parameter, restart the Case Analyzer service and check if the issue is resolved. If the problem persists, it may be necessary to contact Customer Support Services for further assistance.",
    "id": "TECHQA_TRAIN_Q221_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q224",
    "question": "Help with Security Bulletin: Vulnerability in Diffie-Hellman ciphers affects IBM WebSphere MQ Internet Passthru (CVE-2015-4000)\nI need to understand details regarding Security Bulletin: Vulnerability in Diffie-Hellman ciphers affects IBM WebSphere MQ Internet Passthru (CVE-2015-4000). What is the recommended fix?",
    "ground_truth": "1. Upgrade to IBM WebSphere MQ Internet Pass-Thru **2.1.0.2**",
    "answer": "To address the Security Bulletin regarding the Vulnerability in Diffie-Hellman ciphers affecting IBM WebSphere MQ Internet Passthru (CVE-2015-4000), the recommended fix is to upgrade to IBM WebSphere MQ Internet Pass-Thru 2.1.0.2. This is specifically advised for users of versions 2.1.0.1, 2.0, and older releases. You can find the upgrade at [http://www.ibm.com/support/docview.wss?uid=swg24006386](http://www.ibm.com/support/docview.wss?uid=swg24006386).",
    "id": "TECHQA_TRAIN_Q224_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q225",
    "question": "Why the Portal 7.0.0.2 - CF29 upgrade is failing ?\nWhy the Portal 7.0.0.2 - CF29 upgrade is failing ?",
    "ground_truth": "1. Increase the **was.notification.timeout** to **1200** (seconds) in WP DeploymentService.\n\n2. Re-run the **upgrade-profile** task.",
    "answer": "The Portal 7.0.0.2 - CF29 upgrade is failing due to a timeout issue during the redeployment of a Web Module. The error messages EJPPH0044E, EJPPH0001E, and ADMC0009E indicate a problem with the WebSphere Application Server administration interface and a SOAP RPC call failure.\n\nTo resolve the issue, increase the `was.notification.timeout` property to 1200 seconds in the WP DeploymentService, either through the WebSphere Admin Console or Dmgr. If the property is not listed, add it and then re-run the `upgrade-profile` task to proceed with the migration.",
    "id": "TECHQA_TRAIN_Q225_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q226",
    "question": "Can I disable RC4 cyphers in TIP?\nHow can one disable the RC4 cypers in Tivoli Integrated Portal?",
    "ground_truth": "1. Log into the Websphere Application server and navigate to: SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n\n2. Select the **RC4** ciphers from the **Selected ciphers** list, and then click the **<<Remove** button.\n\n3. Click the 'Apply' button, and then the 'Save (to the master configuration)' link.\n\n4. Restart **TIP**.\n   ",
    "answer": "To disable RC4 ciphers in Tivoli Integrated Portal (TIP), follow these steps:\n\n1. Log into the Websphere Application server and navigate to: SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n2. Select the RC4 ciphers from the \"Selected ciphers\" list and click the \"Remove\" button.\n3. Click the \"Apply\" button, and then the \"Save (to the master configuration)\" link.\n4. Restart TIP.\n\nThis will remove RC4 ciphers from TIP, addressing potential security concerns identified by security scans.",
    "id": "TECHQA_TRAIN_Q226_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q227",
    "question": "Why SET CHLAUTH ACTION(REMOVE) is not successful\nI have the following CHLAUTH records defined for channel BMMADMIN.SVRCONN:\n\n     DIS CHLAUTH(BMM*) ALL\n          1 : DIS CHLAUTH(BMM*) ALL\n     AMQ8878: Display channel authentication record details.\n        CHLAUTH(BMMADMIN.SVRCONN)               TYPE(USERMAP)\n        DESCR(BTMA channel)                     CUSTOM( )\n        ADDRESS(10.199.103.0)                   CLNTUSER(CHADVT3UTBMMPA$)\n        MCAUSER(mqm)                            USERSRC(MAP)\n        ALTDATE(2016-01-26)                     ALTTIME(20.38.12)\n     AMQ8878: Display channel authentication record details.\n        CHLAUTH(BMMADMIN.SVRCONN)               TYPE(USERMAP)\n        DESCR( )                                CUSTOM( )\n        ADDRESS( )                              CLNTUSER(chadvt3utbm)\n        MCAUSER(mqm)                            USERSRC(MAP)\n        ALTDATE(2016-01-27)                     ALTTIME(18.03.44)\n\nI am attempting to remove the first of the two records above with this command, but receive the response \"record not found\":\n\n     SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)\n          3 : SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)\n     AMQ8884: Channel authentication record not found.\n\nHow do I fix this problem??",
    "ground_truth": "1. Include the **single** quotes when specifying the value during an ACTION(REMOVE)",
    "answer": "To fix the problem, you need to specify the correct parameters when using the `SET CHLAUTH` command with the `ACTION(REMOVE)` option. \n\nIn your case, the command should be:\n\n`SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) ADDRESS('10.199.103.0') CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)`\n\nNote that you should include the `ADDRESS` parameter with the correct value, and the `CLNTUSER` value should be surrounded by single quotes. \n\nAlso, be aware that the `USERSRC` attribute is not a valid parameter for the `REMOVE` action, so you should not include it in the command. \n\nBy using the correct parameters, you should be able to successfully remove the channel authentication record.",
    "id": "TECHQA_TRAIN_Q227_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q228",
    "question": "DB2 Non Reclaimable Storage .\nWe have tablespaces defined under DB2 9.5 that apparently are not able\nto reclaim storage back to the OS, but does that mean DB2 cannot reuse\nthis space as well?",
    "ground_truth": "1. Create the **DMS** or automatic storage tablespaces in DB2 Version **9.7** or later.\n",
    "answer": "Based on the provided context, if a tablespace in DB2 9.5 has `RECLAIMABLE_SPACE_ENABLED` set to 0, it means that the tablespace is not enabled for reclaimable storage, and DB2 cannot reclaim the storage back to the OS. However, this does not necessarily mean that DB2 cannot reuse the space internally.\n\nIn other words, even if a tablespace is not enabled for reclaimable storage, DB2 can still reuse the space within the tablespace for other data. The `RECLAIMABLE_SPACE_ENABLED` flag only controls whether the storage can be reclaimed back to the operating system, not whether DB2 can reuse the space internally.\n\nTo confirm, you can check the value of `RECLAIMABLE_SPACE_ENABLED` for your specific tablespace using the `MON_GET_TABLESPACE` table function, as shown in the example:\n\n`db2 \"SELECT varchar(tbsp_name, 30) as tbsp_name, tbsp_type, RECLAIMABLE_SPACE_ENABLED FROM TABLE(MON_GET_TABLESPACE('',-2))\"`\n\nIf the value is 0, it means that the tablespace is not enabled for reclaimable storage, but DB2 can still reuse the space internally.",
    "id": "TECHQA_TRAIN_Q228_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q231",
    "question": "Netcool/Impact (all versions): OMNIbusEventReader Filter Analyzer error \"rule includes an unsupported expression\"\nNetcool/Impact (all versions): OMNIbusEventReader Filter Analyzer error \"rule includes an unsupported expression\"\n\nThis occurs when comparing two ObjectServer fields against each other in a Filter.",
    "ground_truth": "1. Locate the **EventReader** properties file.\nNavigate to the following file path: **$NCHOME/impact/etc/[ImpactServerName]_[EventReaderName].props**, where [ImpactServerName] is the name of the ImpactServer (NCI by default) and [EventReaderName] is the lower-case name of the EventReader (for example: omnibuseventreader).\n2. Add the consolidatefilters property.\nInsert the following line into the properties file: **impact.[EventReaderName].consolidatefilters=false**, where [EventReaderName] is the lower-case name of the EventReader (for example: omnibuseventreader).\n3. Restart the ImpactServer.\nOnce the property has been added to the file, restart the ImpactServer to enable the changes.",
    "answer": "To resolve the \"rule includes an unsupported expression\" error in the Filter Analyzer when comparing two ObjectServer fields or a field against GetDate within an EventReader Filter, you need to add a property to the EventReader properties file. \n\n1. Locate the file at `$NCHOME/impact/etc/[ImpactServerName]_[EventReaderName].props`, where `[ImpactServerName]` is the name of the ImpactServer (default is NCI) and `[EventReaderName]` is the lower-case name of the EventReader (e.g., omnibuseventreader).\n\n2. Add the property `impact.[EventReaderName].consolidatefilters=false` to the file. For example, if your EventReader name is omnibuseventreader, the property should be `impact.omnibuseventreader.consolidatefilters=false`.\n\n3. After adding the property, restart the ImpactServer to enable the change. If you are in a Clustered environment, first stop the Secondary ImpactServer(s), then stop and restart the Primary ImpactServer, and finally restart the Secondary ImpactServer(s) to ensure the property is distributed correctly and not overwritten.\n\nThis solution does not affect the EventReader's ability to parse the Filter but is specifically related to the use of the Filter Analyzer. If you encounter issues with the Filter not being applied to the outgoing SQL for the EventReader, refer to the TechNote \"EventReader Filters not applied to SQL select statement\" for further assistance.",
    "id": "TECHQA_TRAIN_Q231_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q234",
    "question": "How do I create a windows service for WebSphere Application Server version 7.0.X?\nIs there a tool that can help me create the windows service in an automated form?",
    "ground_truth": "1. Place the **WASServiceCmd.exe** utility in the **install_root\\bin** directory.\n2. Launch the command from the command line.\n   ",
    "answer": "To create a Windows service for WebSphere Application Server version 7.0.X, you can use the WASServiceCmd.exe utility. Here's how:\n\n1. Download the WASServiceCmd.zip file and rename it with a \".zip\" extension if your browser doesn't download it correctly.\n2. Extract the WASServiceCmd.exe utility and place it in the `install_root\\bin` directory of your WebSphere Application Server installation.\n3. Launch the WASServiceCmd.exe utility from the command line.\n4. Follow the prompts to select the specific options and settings for your Windows service.\n5. The WASServiceCmd utility will call the WASService.exe command with the selected parameters to create the Windows service.\n\nThis utility simplifies the process of creating a Windows service for WebSphere Application Server and reduces the opportunity for user errors. Note that in WebSphere Application Server v8 and later, this utility is shipped with the product under the name of WASServiceHelper.bat in the bin directory.",
    "id": "TECHQA_TRAIN_Q234_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q235",
    "question": "Cannot start Maximo/SCCD with error BMXAA4087E - The MAXMESSAGE value for group login and key username could not be retrieved.\nCannot start Maximo/SCCD with error BMXAA4087E - The MAXMESSAGE value for group login and key username could not be retrieved.",
    "ground_truth": "1. Make sure **MXServer** is stopped.\n\n2. Connect to database back end and update mxe.db.format.nullvalue by running following query.\nRun the query: **update maximo.maxpropvalue set propvalue='COALESCE' where propname='mxe.db.format.nullvalue';**\n3. Start **MXServer** again.",
    "answer": "To resolve the error BMXAA4087E, you need to update the `mxe.db.format.nullvalue` property in the Maximo database. Since you are using an IBM DB2 database, the value should be set to 'COALESCE'. \n\nHere are the steps to follow:\n\n1. Stop the MXServer.\n2. Connect to the database backend.\n3. Run the following query to update the `mxe.db.format.nullvalue` property:\n   ```\n   update maximo.maxpropvalue set propvalue='COALESCE' where propname='mxe.db.format.nullvalue';\n   ```\n4. Start the MXServer again.\n\nThis should resolve the error and allow you to start Maximo/SCCD successfully.",
    "id": "TECHQA_TRAIN_Q235_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q236",
    "question": "Cannot Authorize SPSS 19 Installation on New Computer,Need to Authorize SPSS 19 on a New Computer\nI'm currently using SPSS 19 and need to install it on a new computer, however, it will not authorize. I've spoken to SPSS support by phone but they recommended checking here. I'm running on a Mac, OS X Sierra, for SPSS 19. Would someone please be able to assist?,I'm currently running SPSS 19 and need to install it on a new computer. When I try to authorize it, it fails. I've spoken to SPSS over the phone to no avail. I'm running OS X Sierra. Could anyone please help?",
    "ground_truth": "1. No older SPSS **Statistics** releases are supported on Sierra.",
    "answer": "The issue you're experiencing with authorizing SPSS 19 on a new computer running OS X Sierra (10.12) is due to the fact that SPSS 19 is not supported on Sierra. According to the provided context, only IBM SPSS Statistics 25 and 24 are supported on Sierra. \n\nTo resolve this issue, you have a few options:\n\n1. **Upgrade to a supported version**: Consider upgrading to IBM SPSS Statistics 25 or 24, which are supported on OS X Sierra. You can contact the IBM Sales department to renew your contract and obtain the latest version.\n\n2. **Use a different operating system**: If possible, you could install a different operating system that supports SPSS 19, such as OS X El Capitan (10.11) or earlier. However, please note that using an older operating system may have its own set of security and compatibility issues.\n\n3. **Contact IBM Sales department**: Reach out to the IBM Sales department to inquire about potential alternatives or solutions for using SPSS 19 on your current operating system.\n\nUnfortunately, since SPSS 19 is no longer supported by IBM, there may not be a straightforward solution to authorize it on your new computer running OS X Sierra.",
    "id": "TECHQA_TRAIN_Q236_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q237",
    "question": "What is the best practice for working with BPM support\nWhen working with the BPM product set there are a lot of configuration files, logs and applications which can be exported for analysis by the support team. What are the best practices for working with the BPM support team?",
    "ground_truth": "1. Collect the following troubleshooting data if you need help from IBM **Business Process Manager** Support.\n   ",
    "answer": "To work effectively with the BPM support team, follow these best practices:\n\n1. **Gather necessary information**: Before contacting support, collect relevant data, including configuration files, logs, and application exports, to help the support team diagnose the issue.\n2. **Use the IBM Support Assistant**: Utilize the IBM Support Assistant to search for known problems in product documentation, forums, technotes, and more.\n3. **Search for known problems**: Look for known issues on the IBM dW Answers or IBM Business Process Manager developerWorks community pages.\n4. **Review system logs**: Check the SystemOut.log file for error messages related to the issue.\n5. **Search product support sites**: Visit the relevant product support site (e.g., IBM Business Process Manager Advanced, Standard, or Express) to search for known problems using symptoms like message numbers and error codes.\n6. **Collect troubleshooting data**: Use the MustGather documentation to collect necessary troubleshooting data, such as logs and configuration files, to expedite the troubleshooting process.\n7. **Check for fixes**: Search Fix Central for interim fixes that may resolve the issue.\n\nBy following these steps, you can provide the necessary information to the BPM support team, enabling them to efficiently diagnose and resolve your issue.",
    "id": "TECHQA_TRAIN_Q237_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q250",
    "question": "Why are the changes not reflected in the user interface when you update a Notice Questionnaire Template or Publish a Hold Notice using IBM Atlas?\nWhy are the changes not reflected in the user interface when you.update a Notice Questionnaire Template or Publish a Hold Notice using IBM Atlas?",
    "ground_truth": "1. Contact **Oracle** support\n   \n2. Apply the Patch: **17501296**\n   ",
    "answer": "The changes are not reflected in the user interface when you update a Notice Questionnaire Template or Publish a Hold Notice using IBM Atlas because of an Oracle bug (17501296) in version 11.2.0.4.0. To resolve the issue, contact Oracle support and apply the patch 17501296.",
    "id": "TECHQA_TRAIN_Q250_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q254",
    "question": "Why is my delete virtual portal timing out after 120 seconds?\nWhen deleting a virtual portal via the Portal Admin User Interface (UI), it fails to complete. Examination of the SystemOut.log shows the following message:\n\nWTRN0006W: Transaction 0000014BB8A229770000000161570720292692D3DEAA2109E6D66CBE4D063A1626DCF4E80000014BB8A229770000000161570720292692D3DEAA2109E6D66CBE4D063A1626DCF4E800000001 has timed out after 120 seconds.\n\n00000006 TimeoutManage I WTRN0124I: When the timeout occurred the thread with which the transaction is, or was most recently, associated was Thread[WebContainer : 2,5,main]. The stack trace of this thread when the timeout occurred was: java.net.SocketInputStream.socketRead0(Native Method) java.net.SocketInputStream.read(SocketInputStream.java:140)\n....",
    "ground_truth": "1. Increase the total transaction lifetime timeout and maximum transaction timeout values.\nSet the timeout values to **600** seconds or greater using the instructions in the Related information section below.\n2. Update to Cumulative Fix (CF) **9** or later.\nDo this if the problem persists after addressing the change in suggestion #1 and the error in SystemOut.log shows that the timeout still occurs after 120 seconds. This update will provide the fix for APAR PI04872.\n3. Add or update the custom property to the **WCM_WCMConfigService** Resource Environment Provider.\nSet the Name to **wcm.transaction.timeout** and the Value to **600** (for example).",
    "answer": "The delete virtual portal operation is timing out after 120 seconds due to the increased transaction time required for removing managed pages in WebSphere Portal 8.0. To resolve this issue, you can try the following steps:\n\n1. Increase the total transaction lifetime timeout and maximum transaction timeout values to 600 seconds or greater. You can find instructions on how to do this in the Related information section.\n2. If the problem persists, update to Cumulative Fix (CF) 9 or later to get the fix for APAR PI04872. Then, add or update the custom property `wcm.transaction.timeout` to the WCM_WCMConfigService Resource Environment Provider with a value of 600 (or a suitable value for your environment).\n\nNote that there is no one-size-fits-all target value for transaction timeouts, and you should aim to find a value that allows the virtual portal deletion to succeed without introducing significant delays in other transaction timeouts.",
    "id": "TECHQA_TRAIN_Q254_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q256",
    "question": "Error running krzgrant.sql script provided with 6.3.1.2-TIV-ITM_KRZ-IF0003.tar\nWhen running the krzgrant.sql script provided in the package - 6.3.1.2-TIV-ITM_KRZ-IF0003.tar get the following errors:\n\nERROR at line 1:\nORA-00942: table or view does not exist ORA-06512: at line 50 \n\nHow to correct this?",
    "ground_truth": "1. Run the **krzgrant.sql** script in **6.3.1-TIV-ITM_KRZ-FP0001**",
    "answer": "To correct the error you're experiencing when running the `krzgrant.sql` script provided with the `6.3.1.2-TIV-ITM_KRZ-IF0003.tar` package, you should first ensure that all necessary tables and views are granted to the Oracle Database Extended agent user. The error message `ORA-00942: table or view does not exist` indicates that the agent lacks the necessary permissions to access certain tables or views.\n\nGiven the context, it seems that running the `krzgrant.sql` script from the `6.3.1-TIV-ITM_KRZ-FP0001` package could resolve this issue, as it is mentioned as a workaround for a similar problem. However, if you are using a customized `sql xml` file, you might need to adjust the `QueryName` and `GrantName` elements to `'dual'` to avoid the `ORA-00942` error.\n\nAdditionally, ensure that the Oracle Database Extended agent user has all the necessary authorities and permissions, especially `SELECT` permissions on views like `SYS.DBA_QUEUES`, `dba_objects`, `SYS.DBA_JOBS`, and `SYS.DBA_USERS`, as mentioned in the context.\n\nIf the issue persists after trying these steps, it might be helpful to review the specific SQL queries and the permissions required for the Oracle Database Extended agent to function correctly, and adjust the `krzgrant.sql` script accordingly.",
    "id": "TECHQA_TRAIN_Q256_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q258",
    "question": "Hide a page in dotedit step\nI am working on datacap 8.1 version. I have 2 pages in a batch. Page 1 with status as 1, Page 2 with status as 20. Both are of same page type. In verification step (dotedit) I want to hide the page which is with status 20. I have given status 20 in ignored page status in web administrator for verify. But still when I navigate through pages in dotedit batch view the respective panel is loading. I am able to submit the batch even if I have one page in a batch with 20 as status.\n\nIs there any way to hide the page (we have multiple same type of pages in a batch) from dotedit based on the page status?",
    "ground_truth": "1. Create a special page type attached at the batch level called something like DeleteMe.\n   \n2. Use an action like BlankPagesIDBySize to identify the blank page.\n   Use the function BlankPagesIDBySize with parameters (1000, DeleteMe) to find the blank pages.\n3. Create a rule with the action **DeleteChildType(DeleteMe)** and attach it at the batch level.\n   This rule will remove all pages with the page type DeleteMe from the batch.",
    "answer": "To hide a page in the dotedit step based on the page status in Datacap 8.1, you can create a custom rule that utilizes the `DeleteChildType` action from the Validations library. Here's a step-by-step solution:\n\n1. Create a new page type, e.g., \"HidePage\", attached at the batch level.\n2. Use an action to identify the pages with status 20, e.g., `PageStatusIDByValue (20, HidePage)`.\n3. Create a rule with the action `DeleteChildType(HidePage)` and attach it at the batch level. This will remove all pages with page type \"HidePage\" (i.e., pages with status 20) from the batch view.\n\nBy doing this, when you navigate through pages in dotedit batch view, the panel for the page with status 20 should not load, and you should not be able to submit the batch if it's the only page left.\n\nNote that this approach effectively removes the page from the batch view, rather than just hiding it. If you want to simply hide the page without removing it, you may need to explore other customization options or consult the Datacap documentation for alternative solutions.",
    "id": "TECHQA_TRAIN_Q258_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q260",
    "question": "Framework Manager data source error\nUsers receive the following error on selecting a data source from the list defined in IBM Cognos within Framework Manager 10.2.2 Fix Pack 5\n\nalt text\n\nThat error (BMT-IMP-0002 Failed to Execute Metadata request. CM-REQ-4342 An error occurred with the client. CAF-WRN-2082 An error has occurred.) prevents all users to add an existing data source via Framework Manager.\n\nHow can we fix this?",
    "ground_truth": "1. Grant user the required **Import relational metadata** capability.",
    "answer": "To fix the Framework Manager data source error (BMT-IMP-0002), you need to grant the users the required \"Import relational metadata\" capability. Here are the steps:\n\n1. Launch IBM Cognos Administration from Cognos Connection.\n2. Select the 'Security' tab.\n3. Choose 'Capabilities' on the left side.\n4. Click \"Actions\" > Set Properties beside \"Import relational metadata\".\n5. Select the 'Permissions' tab.\n6. Add the required user, group, or role to the capability, granting them Read, Execute, and Traverse permissions.\n\nBy following these steps, you should be able to resolve the error and allow users to add existing data sources via Framework Manager.",
    "id": "TECHQA_TRAIN_Q260_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q262",
    "question": "Scroll bar in search results resets to the top position in Internet Explorer\nIn IBM Content Navigator, scroll bar in search results resets to the top position in Internet Explorer V9, V10, and V11. This does not happen with Mozilla Firefox or Google Chrome.",
    "ground_truth": "1. Upgrade to **Microsoft Edge** browser",
    "answer": "To resolve the issue of the scroll bar in search results resetting to the top position in Internet Explorer (V9, V10, and V11) when using IBM Content Navigator, upgrade to the Microsoft Edge browser, as this issue has been fixed in Edge.",
    "id": "TECHQA_TRAIN_Q262_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q263",
    "question": "Where can I get ITM 6.3.0 Fixpack 6 ?  Is it available now ?\nWhere can I get ITM 6.3.0 Fixpack 6 ? Is it available now ?",
    "ground_truth": "1. Access the fix download page.\nVisit the URL: **http://www.ibm.com/support/fixcentral/swg/quickorder?parent=ibm%7ETivoli&product=ibm/Tivoli/IBM+Tivoli+Monitoring&release=All&platform=All&function=fixId&fixids=6.3.0-TIV-ITM-FP0006&source=fc** to download the fix 6.3.0-TIV-ITM-FP0006.",
    "answer": "You can download ITM 6.3.0 Fixpack 6 from the IBM Fix Central website. It is available now. To access the download, visit the Fix Central website at [http://www.ibm.com/support/fixcentral/swg/quickorder?parent=ibm%7ETivoli&product=ibm/Tivoli/IBM+Tivoli+Monitoring&release=All&platform=All&function=fixId&fixids=6.3.0-TIV-ITM-FP0006&source=fc](http://www.ibm.com/support/fixcentral/swg/quickorder?parent=ibm%7ETivoli&product=ibm/Tivoli/IBM+Tivoli+Monitoring&release=All&platform=All&function=fixId&fixids=6.3.0-TIV-ITM-FP0006&source=fc). The fix pack was released on December 11, 2015.",
    "id": "TECHQA_TRAIN_Q263_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q270",
    "question": "How to resolve \"An unexpected error occurred. Contact your system administrator. ICWPA1001E\"\nWhen trying to add people to a matter request when there are more than 1000 people in the clipboard, the following error is reported:\n\nAn unexpected error occurred. Contact your system administrator. ICWPA1001E\"",
    "ground_truth": "1. When you add people from the clipboard, add fewer than **1000** people at one time.\n",
    "answer": "To resolve the \"An unexpected error occurred. Contact your system administrator. ICWPA1001E\" error, you need to add fewer than 1000 people from the clipboard to the matter request at one time. This is a known limitation in the system, and adding people in batches of less than 1000 will allow you to successfully add them to the matter request without encountering the error.",
    "id": "TECHQA_TRAIN_Q270_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q274",
    "question": "Error when using profilePath parameter with BPMConfig to create a profile\nWhen creating a profile using the BPMConfig command and the -profilePath parameter to define a custom directory to store the profile data, the creation fails with the following error message if the directory already exists (even if it is empty):\ncom.ibm.bpm.config.BPMConfig.main(): The profile path <profile_path> must not exist.....",
    "ground_truth": "1. Make sure a **profilePath** value does not exist.",
    "answer": "To resolve the error when using the `profilePath` parameter with `BPMConfig` to create a profile, ensure that the directory specified by the `profilePath` does not already exist. If the directory exists, even if it's empty, the creation will fail. \n\nInstead, create the parent directory of the desired profile path, but do not create the profile directory itself. For example, if you want to create a profile under `/usr/BPM850profiles/myProfile`, create the `/usr/BPM850profiles` directory, but do not create the `/usr/BPM850profiles/myProfile` directory. This way, when you run the `BPMConfig` command with the `-profilePath` parameter set to `/usr/BPM850profiles/myProfile`, it will be able to create the profile directory successfully. \n\nAdditionally, ensure that the user running the `BPMConfig` command has write privileges to the parent directory, allowing the creation of the new profile directory.",
    "id": "TECHQA_TRAIN_Q274_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q276",
    "question": "Netcool/Impact (all versions): JMSListener does not reconnect when JMS server is restarted\nJMSListener does not reconnect when JMS server is restarted.\nCreated JMS datamodel to connect to JMS queue. Restart the JBOSS service on JBOSS server on which JMS queue exists Impact attempt to connect to JMS queue fails and it says connection could not be made. However, restart Impact process and click on test connection it gives connection OK message.\n\nHave configured reconnect properties:\n\n     impact.MyJMSListener.jms.autoreconnect=true\n     impact.MyJMSListener.jms.autoreconnect.pollinterval=20000",
    "ground_truth": "1. Locate the properties file for the **JMSListener**.\n   The properties file can be found at the following path: $NCHOME/impact/etc/[ImpactServerName]_[JMSListenerName].props, where [ImpactServerName] is the name of the ImpactServer (for example: NCI) and [JMSListenerName] is the name of the JMSListener Service (for example: MyJMSListener).\n2. Set the **autoreconnect** property.\n   Add the following line to the properties file: impact.[JMSListenerName].autoreconnect=true, replacing [JMSListenerName] with the name of the JMSListener Service (for example: MyJMSListener).\n3. Set the autoreconnect poll interval.\n   Add the following line to the properties file: impact.[JMSListenerName].autoreconnect.pollinterval=[TimeValue], where [JMSListenerName] is the name of the **JMSListener Service** and [TimeValue] is the desired polling interval value in milliseconds (for example: 30000 which is equivalent to 30 seconds). Note that the properties should not include the additional .jms bit.",
    "answer": "The issue is due to a misconception in the configuration of the JMSListener AutoReconnect properties. To resolve the problem, you need to correct the properties in the file `$NCHOME/impact/etc/[ImpactServerName]_[JMSListenerName].props`.\n\nChange the properties from:\n```\nimpact.MyJMSListener.jms.autoreconnect=true\nimpact.MyJMSListener.jms.autoreconnect.pollinterval=20000\n```\nto:\n```\nimpact.MyJMSListener.autoreconnect=true\nimpact.MyJMSListener.autoreconnect.pollinterval=20000\n```\nRemove the `.jms` part from the property names. This should allow the JMSListener to reconnect when the JMS server is restarted.",
    "id": "TECHQA_TRAIN_Q276_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q277",
    "question": "No data in some workspaces for MySQL agent\nWhy Monitoring agent for MySQL when configured to monitor MySQL server versions 5.7.6 and above does not collect data for some of the attribute groups?",
    "ground_truth": "1. Enable the 'show_compatibility_56' system variable.\n   This system variable affects whether MySQL 5.6 compatibility is enabled concerning how system and status variable information is provided by the INFORMATION_SCHEMA. It should be used when running the agent on MySQL server versions 5.7.6 and above.",
    "answer": "To resolve the issue of the MySQL agent not collecting data for some attribute groups when monitoring MySQL server versions 5.7.6 and above, you need to enable the `show_compatibility_56` system variable. This variable can be set in two ways:\n\n1. **From the MySQL command prompt**: Run the command `set global show_compatibility_56=ON;` to enable the compatibility mode.\n2. **In the MySQL server configuration file (my.cnf)**: Add the line `show_compatibility_56=ON` to the `my.cnf` file, located at `<MySQL_Installation_Dir>/my.cnf` for Windows or `/etc/my.cnf` for UNIX/Linux. After making this change, you will need to restart the MySQL server for the changes to take effect.\n\nYou can check the current value of the `show_compatibility_56` variable by running the command `show global variables like \"show_compatibility_56\";` from the MySQL command prompt.",
    "id": "TECHQA_TRAIN_Q277_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q278",
    "question": "How to control SDMS database size?\nITCAM for SOA 7.1.1 was installed about 3 years ago. I already know that SDMS database size may increase with no limit. Has anyone found a way to keep under control this behavior?",
    "ground_truth": "1. Schedule a daily job to run the **kd4TrimDB2db** utility.\n   To keep only the latest 24 hours of data every day, you should set up a task that executes the **kd4TrimDB2db** utility on a daily basis.",
    "answer": "To control the SDMS database size in ITCAM for SOA 7.1.1, you can schedule a daily job to run the `kd4TrimDB2db` utility. This will allow you to regularly prune the database and keep it under control. Specifically, you can use this utility to keep only the latest 24 hours of data every day. Please refer to the provided Wiki page for more information: https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Tivoli+Composite+Application+Manager/page/Pruning+SDMS+Relationship+Metrics+Tables. Note that ITCAM for SOA 7.1.1 is out of support since 2015, so it's recommended to consider upgrading to a newer version, such as 7.2, which has a built-in cleanup task to manage database size.",
    "id": "TECHQA_TRAIN_Q278_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q280",
    "question": "How to set database specific custom properties in WebSphere Application Server?\nI am using Websphere Application Server (WAS) v8.5.x with Oracle 11.1 JDBC drivers and I want to set some oracle specific custom properties, when connecting to the database in Websphere Application Server. How to set such specific properties in Websphere Application Server?",
    "ground_truth": "1. Set a Custom Property in the datasource.\n   In the datasource, configure a Custom Property with the Name set to **connectionProperties** and the Value set to 'propertyA=valueA;propertyB=valueB'.",
    "answer": "To set Oracle-specific custom properties in WebSphere Application Server (WAS) v8.5.x, you can use the `connectionProperties` custom property in the datasource. \n\nHere's how to do it:\n\n1. Go to the datasource settings in your WAS console.\n2. Add a new custom property or edit an existing one.\n3. Set the `Name` to `connectionProperties`.\n4. Set the `Value` to the desired Oracle-specific properties, separated by semicolons. For example: `oracle.jdbc.V8Compatible=true;propertyB=valueB`.\n\nThis will allow you to pass Oracle-specific properties to the JDBC driver when connecting to the database.",
    "id": "TECHQA_TRAIN_Q280_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q283",
    "question": "What is the latest Alcatel 5620 SAM probe?\nWe have the nco_p_alcatel_5620_sam_v13 probe, is there a newer version of the probe.\nDoes this probe support Release 14 of the 5620 SAM?",
    "ground_truth": "1. Download the package from the IBM Passport Advantage website.\n   Visit the IBM Passport Advantage website at **www-01.ibm.com/support/knowledgecenter/SSSHTQ/omnibus/probes/nokia_nfmp/wip/concept/nknfmp_intro.html** to download the package you require.",
    "answer": "I don't know the latest version of the Alcatel 5620 SAM probe or if it supports Release 14 of the 5620 SAM. The provided context is about a Nokia Network Functions Manager for Packet probe and does not mention the Alcatel 5620 SAM probe.",
    "id": "TECHQA_TRAIN_Q283_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q285",
    "question": "How do I upgrade my virtual DataPower Appliance from 5.0 firmware to 6.0+ firmware?\nWhen attempting to upgrade my Virtual DataPower Appliance from 5.0.0.0 firmware version to 6.0+ firmware versions, I receive a failure message.",
    "ground_truth": "1. Install the **5.0.0.8** or later fix pack.",
    "answer": "To upgrade your virtual DataPower Appliance from 5.0 firmware to 6.0+ firmware, you must first ensure that your current firmware version is 5.0.0.8 or later. If it is not, you will need to upgrade to 5.0.0.8 or a later version before attempting to upgrade to 6.0.0.0 or later. The 5.0.0.8 fix pack contains a required fix that allows the larger sized firmware image to fit, which is necessary for the upgrade to 6.0.0.0 or later. Once you have upgraded to 5.0.0.8 or later, you can then proceed with the upgrade to 6.0.0.0 or later. Make sure to only install fix packs from Fix Central that are compatible with your virtual deployment, as specified in the provided context.",
    "id": "TECHQA_TRAIN_Q285_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q286",
    "question": "Port number error starting 9.0 Launcher\nI'm attempting to start up v9.0 for the first time with one .msl file on a Windows server and get the following error.  I also have v8.4 on this server and it starts fine.  I do not have v8.4 running when I attempt to start v9.0.\n\nCannot recognize if the system RecordChangeSystem.msl; has started. Reason: Server is unable to get the status of the system on port number 6,002.\n\nI have the port range set to 7000/8000.  I've never seen this error before.\n\nAny help?  Thanks.",
    "ground_truth": "1. Obtain patch for APAR **PI64816**.\n   ",
    "answer": "The provided context does not seem to relate directly to the issue of a port number error when starting the 9.0 Launcher. The context discusses an issue with the IBM Transformation Extender (ITX) Launcher failing when specific settings are used, which does not appear to be relevant to the port number error described in the question.\n\nGiven the information provided in the question, it seems that the issue might be related to the port range setting (7000/8000) and the specific port number mentioned in the error message (6002). However, without more context or details about how the port range is configured or how it interacts with the system's ability to recognize if the RecordChangeSystem.msl has started, it's difficult to provide a precise solution.\n\nTherefore, I don't know the exact solution to the user's technical support question based on the provided context. Further investigation into the port configuration and how it affects the system's startup process would be necessary to resolve the issue.",
    "id": "TECHQA_TRAIN_Q286_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q294",
    "question": "IZE0106E Connect failed with \"Unsupported CICS release\" after upgrading CICS TS V5.x\nDo I have to upgrade my CICS Explorer to the same release as CICS Transaction Server for z/OS (CICS TS)? I recently upgraded to a new release of CICS TS and now when I attempt to connect to CICS Explorer using a CMCI connection, I get message \nIZE0106E Connect failed with \"Unsupported CICS release\" after upgrading \nin CICS Explorer.",
    "ground_truth": "1. Upgrade to the latest release of **CICS** Explorer.\n",
    "answer": "To resolve the \"Unsupported CICS release\" error (IZE0106E) after upgrading CICS TS V5.x, you don't necessarily need to upgrade your CICS Explorer to the same release as CICS Transaction Server for z/OS (CICS TS). According to IBM, new releases of CICS Explorer are compatible with all earlier versions of CICS TS. For example, CICS Explorer V5.4 is compatible with CICS TS V4.1 through V5.4. \n\nHowever, it is recommended to upgrade to the latest release of CICS Explorer to obtain the most recent functionality and service. You should check the compatibility of your current CICS Explorer version with your newly upgraded CICS TS version and consider upgrading CICS Explorer if necessary. Additionally, ensure that you have applied the necessary updates and fixes, including those related to WebSphere Application Server Liberty Profile, as outlined in the provided context.",
    "id": "TECHQA_TRAIN_Q294_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q295",
    "question": "Why are ITNM or Omnnibus WebGUI java applets fail to load with \"Missing Permissions manifest attribute in main jar\"\nWhy are ITNM or Omnnibus WebGUI java applets fail to load with \"Missing Permissions manifest attribute in main jar\"",
    "ground_truth": "1. Use the HATool.{bat|sh} command located in the **<TIP HOME>/profiles/TIPProfile/bin/ha** directory.\n\n2. Run the command with the following syntax: **HATool.{bat|sh} modules <db2 username> <db2 password>**",
    "answer": "The provided context does not contain information related to the issue of ITNM or Omnnibus WebGUI java applets failing to load with the \"Missing Permissions manifest attribute in main jar\" error. The context appears to be related to High Availability/load balancing configuration for Tivoli Integrated Portal, which is not relevant to the issue at hand.\n\nTherefore, I don't know the solution to the problem based on the provided context. To resolve the issue, I would need more information or a different context that specifically addresses the error message \"Missing Permissions manifest attribute in main jar\" in relation to ITNM or Omnnibus WebGUI java applets.",
    "id": "TECHQA_TRAIN_Q295_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q296",
    "question": "Is it possible to controle which ciphers are available in Tivoli Integrated Portal?\nIs it possible to controle which ciphers are available in Tivoli Integrated Portal?",
    "ground_truth": "1. Log into the Websphere Application server and navigate to:\n   SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n2. Select the **RC4** ciphers from the **Selected ciphers** list, and then click the **<<Remove** button.\n\n3. Click the 'Apply' button, and then the 'Save (to the master configuration)' link.\n\n4. Restart **Tivoli Integrated Portal (TIP)**.",
    "answer": "Yes, it is possible to control which ciphers are available in Tivoli Integrated Portal. To do so, follow these steps:\n\n1. Log into the Websphere Application server and navigate to: SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n2. Select the desired ciphers from the list and use the \"Add\" or \"Remove\" buttons to modify the \"Selected ciphers\" list.\n3. Click the \"Apply\" button, and then the \"Save (to the master configuration)\" link.\n4. Restart TIP.\n\nThis process allows you to customize the available ciphers, including disabling specific ones like RC4 if needed.",
    "id": "TECHQA_TRAIN_Q296_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q297",
    "question": "What action is required for IBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server for the GNU C library (glibc) vulnerability (CVE-2015-0235)?\nIBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server requires customer action for the GNU C library (glibc) vulnerability that has been referred to as \"GHOST\". What action is required?",
    "ground_truth": "1. Contact **Red Hat** to obtain fixes.\n\n2. Install fixes for Red Hat Enterprise Linux (RHEL).",
    "answer": "To address the GNU C library (glibc) vulnerability (CVE-2015-0235), also known as \"GHOST\", in IBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server, you should contact Red Hat to obtain fixes and install the fixes for Red Hat Enterprise Linux (RHEL). IBM strongly recommends this action to remediate the vulnerability. You can find more information on the Red Hat Customer Portal regarding the GHOST vulnerability.",
    "id": "TECHQA_TRAIN_Q297_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q300",
    "question": "How to access the 2nd portal profile?\nHello,\n\nI created a second WebSphere portal profile (wp_profile2) under C:\\IBM\\WebSphere as part of setting up multi-profile environment on windows using WebSphere Portal 8.0.0.1 CF04/WAS 8.0.0.10. I started the WebSphere_Portal under this profile successfully and am trying to access this new portal profile from a web browser using http://<host>:port/wps/myportal. I tried all the ports listed in SystemOut log but none of them seem to work and the one that appears to work is writing below error in logs and is showing a blank page:\n\n \n\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O javax.servlet.jsp.JspException: com.ibm.portal.resolver.exceptions.LocalizedIOException: RT7507E: Unable to initialize Repository: Default.\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O  at com.ibm.wps.engine.templates.themes.Default.render(Default.java:237)\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O  at com.ibm.wps.engine.templates.ThemeTemplate.render(ThemeT\n\n \n\nDoes anyone have any idea of how to fix the above issues and get the portal access working?\n\nAppreciate your help regarding this.\n\n \n\nThank you.",
    "ground_truth": "1. Remove the copy so that the only file in .\\wp_profile\\PortalServer\\jcr\\lib\\com\\ibm\\icm is **icm.properties**",
    "answer": "To access the 2nd portal profile (wp_profile2), you need to resolve the error \"RT7507E: Unable to initialize Repository: Default\" that is causing a blank page when trying to access the portal. \n\nThe root cause of this error is likely having another copy of icm.properties in the.\\wp_profile\\PortalServer\\jcr\\lib\\com\\ibm\\icm directory. To resolve this issue, remove any backup copies of icm.properties, so that the only file in this directory is icm.properties.\n\nAfter resolving this issue, you should be able to access the portal using the URL http://<host>:port/wps/myportal, where <host> is the hostname or IP address of your server and <port> is the port number assigned to the wp_profile2 profile. Make sure to use the correct port number, which can be found in the SystemOut log. \n\nIf you are still having trouble accessing the portal, check the server logs for any other errors or issues that may be preventing access.",
    "id": "TECHQA_TRAIN_Q300_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q301",
    "question": "How do you switch on the indexing of sparse file in StoredIQ?\nBy default these are skipped - does anyone know where to switch them on on the dataserver?",
    "ground_truth": "1. SSH into the Data Server(s) and enter the following command at the prompt;\n   Use SSH to connect to the Data Server(s). Once connected, input the command: **psql -U dfuser dfdata -c \"insert into adminknobs (name,value,description,valuetype,use) VALUES ('read_sparse_files','1','Read sparse data objects','int','1')\"**.\n2. Verify that the output of the command is **INSERT 0 1**.\n\n3. If so, enter the following command and wait for the UI to come back up: **service siqinit restart**.",
    "answer": "To switch on the indexing of sparse files in StoredIQ, follow these steps:\n\n1. Ensure no jobs are running.\n2. SSH into the Data Server(s) and run the command: `psql -U dfuser dfdata -c \"insert into adminknobs (name,value,description,valuetype,use) VALUES ('read_sparse_files','1','Read sparse data objects','int','1')\"`\n3. Verify that the command returns `INSERT 0 1`.\n4. Restart the service by running the command: `service siqinit restart`.\n5. Wait for the UI to come back up.\n\nAfter completing these steps, sparse data objects will be processed during harvests. Note that this may cause space issues if you're using a policy that backs up original files and leaves a sparse file viewable.",
    "id": "TECHQA_TRAIN_Q301_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q304",
    "question": "In FileNet Workplace XT .csv files open as a text file instead of using MS Excel\nThe .csv file was created through WorkplaceXT and it only can be opened as the text file instead of the Excel file, and the mime type is text/csv, not application/vnd.ms-excel. However, when creating the same .csv document through ACCE, the mime Type is \"application/vnd.ms-excel\" shown under the Properties tab and Content Element tab.",
    "ground_truth": "1. Add a section to **Web.xml** mapping the extension to the mime type.\n   Include the following <mime-mapping> section in the Web.xml file: **<mime-mapping><extension>csv</extension><mime-type>application/vnd.ms-excel</mime-type></mime-mapping>**.",
    "answer": "To resolve the issue of.csv files opening as text files instead of using MS Excel in FileNet Workplace XT, you need to update the Web.xml file by adding a mime-mapping section. This section should map the.csv extension to the mime type \"application/vnd.ms-excel\". \n\nHere's how you can do it:\n\n1. Locate the Web.xml file.\n2. Add the following lines to the file:\n```\n<mime-mapping>\n  <extension>csv</extension>\n  <mime-type>application/vnd.ms-excel</mime-type>\n</mime-mapping>\n```\n3. Save the changes to the Web.xml file.\n\nAfter making this update,.csv files created through WorkplaceXT should open in MS Excel instead of as text files.",
    "id": "TECHQA_TRAIN_Q304_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q305",
    "question": "Need help accessing my SPSS access code?\nI downloaded SPSS GradPack (Standard) 25 6 Months for my Mac. The IBM SPSS Statistics 24 licensing page pops up for me to enter the code. I enter the code provided and then hit next, and it tells me the code is too short to be valid? What code do I use then? I need this resolved fast, my first assignment is due soon. I was only given a 16-digit access code, not a 20-digit?\n\n\n\nThis dW Answers question is about an IBM document with the Title:\nSPSS Student Version and Graduate Pack Resources",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To resolve the issue with your SPSS access code, you should contact the vendor from whom you purchased the SPSS GradPack. Since you were given a 16-digit access code but the system is asking for a longer code, it's possible that there was an error in the code provided or that there are specific instructions for using the code that you haven't received.\n\nGiven that you downloaded SPSS GradPack (Standard) 25 for your Mac, but the licensing page for IBM SPSS Statistics 24 is appearing, there might also be a version mismatch or confusion. However, the primary step is to reach out to your vendor for support, as they can provide the correct access code or guide you through the licensing process.\n\nThe vendors listed in the provided context include Hearne, On the Hub, StudentDiscounts.com, JourneyEd, thinkEDU, and Studica. You should identify which vendor you purchased from and contact their support team for assistance. They can help resolve the issue with your access code and ensure you can access SPSS for your assignment.",
    "id": "TECHQA_TRAIN_Q305_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q306",
    "question": "Hey, how can I transfer my spss 24 licence from my old macbook to the new one?\nI made the backup from my laptop to my new one, but SPSS doesnt allow me to start, because of the licence! Also I tried the SPSS Licence wizard on the new macbook, but it is not possible to fill in my licence\n\nI didn't find a option to deactivate the licence on the previous macbook.. how can I solve this problem?",
    "ground_truth": "1. Type (copy/paste) the following command:\n   Run the command 'sudo chown -R root:admin 24' in the Terminal.\n2. Press Enter/Return.\n\n3. Close Terminal.\n\n4. Launch the **License Authorization Wizard**.",
    "answer": "To transfer your SPSS 24 license from your old MacBook to your new one, you'll need to deactivate the license on the old MacBook and then reactivate it on the new one. However, the provided context doesn't explicitly mention how to deactivate the license on the old MacBook.\n\nThe context does provide a solution for a related issue, which is the \"You do not have the correct administrator privileges\" warning when attempting to license SPSS Statistics on a Mac. To resolve this, follow these steps for SPSS Statistics Release 24:\n\n1. Close the IBM SPSS Statistics product and the License Authorization Wizard if they're open.\n2. Open Finder, select the 'Go' menu, and then 'Utilities'.\n3. Open the 'Terminal' program.\n4. Type the following command: `cd /Applications/IBM/SPSS/Statistics/`\n5. Press Enter/Return.\n6. Type the following command: `sudo chown -R root:admin 24`\n7. Press Enter/Return.\n8. Close Terminal.\n9. Launch the License Authorization Wizard.\n\nHowever, to specifically address your issue of transferring the license, you should contact IBM SPSS Support or your network administrator for assistance with deactivating the license on your old MacBook, as this step is not covered in the provided context. They can guide you through the process of releasing the license from the old device and help you reactivate it on your new MacBook.",
    "id": "TECHQA_TRAIN_Q306_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q307",
    "question": "Product upgrade installed a second instance of the DE, causing upgrade failure.\nThe Deployment Engine should only have one instance installed on a server with IBM products installed. In this case, a second DE was installed, which caused the failure of the Product upgrade. Error: Wrong Deployment Engine.\n\nProduct install failed. You will get a message similar to this: You are updating an instance of (Product name) that was installed using the Tivoli Deployment Engine (DE) located at \"/home/nc_admin/.acsi_FQDN\". However you are now using the DE located at \"/home/nc_admin/.acsi_HOSTNAME\".\n\nWhen the DE is installed as non-root ( in this case nc_admin ), it will install the DE in the user home directory, in this case /home/nc_admin, and use the FQDN in the name: /home/nc_admin/.acsi_FQDN",
    "ground_truth": "1. Removing the newly created **Deployment Engine (DE)**, which shouldn't have been created, then creating a link to the existing DE is the best work around in this case. The Product upgrade will see the link and add the information to the valid DE install.",
    "answer": "To resolve the issue of a second instance of the Deployment Engine (DE) being installed, causing a product upgrade failure, follow these steps:\n\n1. **Identify the valid DE installation**: Refer to the error message in the \"Symptom\" section to determine which DE instance is valid. The message will indicate the location of the valid DE, typically in the format `/home/nc_admin/.acsi_<FQDN>`.\n\n2. **Backup the original DE installation directory**: Before making any changes, backup the original DE installation directory to prevent data loss. The directory to backup is the one identified as valid in step 1, typically named `.acsi_<FQDN>`.\n\n3. **Remove the invalid DE directory**: Move the newly created, invalid DE directory (typically named `.acsi_<hostname>`) to a backup location. This directory was created by the failed product upgrade.\n\n4. **Create a soft link to the valid DE installation**: \n    - Navigate to the DE home directory (`<DE_HOME>`) in the terminal.\n    - Create a soft link to the valid DE installation using the command: `ln -s <DE_HOME>/.acsi_<FQDN>.acsi_<hostname>`.\n    - Confirm the link was created successfully by listing the directory contents with `ls -lart`. The output should show a link from `.acsi_<hostname>` to `.acsi_<FQDN>`.\n\n5. **Retry the product install**: After successfully creating the soft link, retry the product upgrade. Ensure there's no required cleanup before retrying the upgrade.\n\nAlternatively, you can also try to ensure that the current upgrade uses the same version of JVM as the original install, as mentioned in the first option for resolving the problem. However, the steps provided above directly address the issue of the duplicate DE instance.",
    "id": "TECHQA_TRAIN_Q307_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q310",
    "question": "What may be the cause of unclosed MQ object connections on DataPower?\nHow can I resolve open MQ object connections that did not close out on DataPower?",
    "ground_truth": "1. Change the **cache timeout** on the IBM WebSphere DataPower MQ manager (mq-qm) object.\n   Consider using the cache timeout at **60** seconds. Best practice is to use a value less than the **KeepAlive Timeout** of the MQ Queue Manager (qmgr).",
    "answer": "The cause of unclosed MQ object connections on DataPower may be due to the default cache timeout setting on the IBM WebSphere DataPower MQ manager (mq-qm) object. To resolve open MQ object connections that did not close out, you can try changing the cache timeout on the mq-qm object to a value of 60 seconds or less, ensuring it is less than the KeepAlive Timeout of the MQ Queue Manager (qmgr). This should help close idle connections and prevent them from remaining open.",
    "id": "TECHQA_TRAIN_Q310_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q314",
    "question": "how to Configure the server to only accept strong encryption protocols such as TLS1.1?\nhow to Configure the server to only accept strong encryption protocols such as TLS1.1?",
    "ground_truth": "1. Add the following directive to the **httpd.conf** file to disable SSLv3 and SSLv2:\n   '# Disable SSLv3 for CVE-2014-3566'\n   '# SSLv2 is disabled in V8R0 and later by default, and in typical V7'\n   '# and earlier configurations disabled implicitly when SSLv3 ciphers'\n   '# are configured with SSLCipherSpec.'\n   **SSLProtocolDisable SSLv3 SSLv2**\n\n2. Stop and restart **IBM HTTP Server (IHS)** for the changes to take effect.",
    "answer": "To configure the server to only accept strong encryption protocols such as TLS 1.1, you need to disable weaker protocols like SSLv3 and SSLv2. You can do this by adding the following directive to the httpd.conf file for each context that contains \"SSLEnable\":\n\n```\nSSLProtocolDisable SSLv3 SSLv2\n```\n\nAdditionally, to enable only strong encryption protocols like TLS 1.1, you can use the `SSLProtocolEnable` directive (available in IHS 7.0 and newer) to specify the protocols you want to enable. For example:\n\n```\nSSLProtocolEnable TLSv1.1 TLSv1.2\n```\n\nThis will enable only TLS 1.1 and TLS 1.2 protocols, and disable all other protocols, including SSLv3 and SSLv2.\n\nAfter making these changes, stop and restart the IBM HTTP Server (IHS) for the changes to take effect.\n\nNote: If you configure SSL with SSLEnable in the global (non-virtualhost) scope, you will need to move SSLEnable into a virtualhost scope to add SSLProtocolDisable or SSLProtocolEnable directives.",
    "id": "TECHQA_TRAIN_Q314_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q318",
    "question": "fixlets do not appear in console bigfix\nWork with ILTM 9.2.7 / 9.5.4.38. In the bigfix console the fixlets do not appear, under the tree: Sites-> IBM License Reporting (ILTM) v9 -> Fixlets and Task.\n\nAttached image. Do you have any ideas?\n\nGreetings and thank you BigFix",
    "ground_truth": "1. Check with the firewall/proxy/IPS/network admin.\n   Ask the firewall, proxy, IPS, or network administrator to check the logs for any dropped packets or downloads.\n2. Adjust rules to allow **BES** Support site content.\n   Request the administrator to adjust the rules to allow the BES Support site content to pass through.\n3. Try turning off **Internet Explorer Enhanced Security Configuration**.\n",
    "answer": "To resolve the issue of fixlets not appearing in the BigFix console under the tree: Sites-> IBM License Reporting (ILTM) v9 -> Fixlets and Task, follow these steps:\n\n1. **Check for network interference**: Verify if there's an Intrusion Prevention System (IPS), firewall, or proxy appliance between the BigFix server and the sync.bigfix.com content servers that might be blocking the download of site content. Ask your network administrator to check the logs for dropped packets or downloads and adjust the rules to allow the BES Support site content through.\n\n2. **Disable Internet Explorer Enhanced Security Configuration**: If the BigFix server is running on a Windows machine, try disabling Internet Explorer Enhanced Security Configuration for Administrators. This can be done by following the instructions provided in the Microsoft Technet blog: https://blogs.technet.microsoft.com/chenley/2011/03/10/how-to-turn-off-internet-explorer-enhanced-security-configuration/.\n\nIf these steps do not resolve the issue, it may be necessary to investigate further by checking the BESRelay.log and GatherDB.log on the BigFix server for error messages similar to \"Unexpected HTTP response: 404\" to identify any other potential causes.",
    "id": "TECHQA_TRAIN_Q318_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q319",
    "question": "Why does my login fail when I use the ltpa-usrnm attribute?\nYou use a Domino server as your LDAP, and the login attribute you want to use is ltpa-usrnm. This is acceptable, as the login attribute can be set accordingly in the wimconfig.xml. When the search string is built for the login, it is in the form, cn=username, o=orgname.\n\nThis cause the following exception to the returned:\n\n[3/30/16 9:56:03:453 CDT] 000000f7 exception E com.ibm.ws.wim.adapter.ldap.LdapConnection getAttributes CWWIM4520E The 'javax.naming.InvalidNameException: \"CN=username/O=orgname\": [LDAP: error code 34 - Invalid DN Syntax]; remaining name '\"CN=username/O=orgname'\";",
    "ground_truth": "1. Set a custom property using the command.\n   **$AdminTask configureAdminWIMUserRegistry {-customProperties {\"com.ibm.ws.wim.registry.allowDNPrincipalNameAsLiteral =true\"}}**",
    "answer": "The issue you're experiencing with your login failing when using the `ltpa-usrnm` attribute is due to the login attribute value containing an equal sign (=), which is being treated as a distinguished name (DN) by Virtual Member Manager (VMM). To resolve this issue, you need to set a custom property using the following command:\n\n`$AdminTask configureAdminWIMUserRegistry {-customProperties {\"com.ibm.ws.wim.registry.allowDNPrincipalNameAsLiteral=true\"}}`\n\nThis will allow VMM to determine whether the login name ends with a baseEntry, and if not, it will not be treated as a DN, resulting in a successful login.",
    "id": "TECHQA_TRAIN_Q319_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q330",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator v2.0.3, to fit content by height or width?",
    "ground_truth": "1. Click **New** in the **Additional Settings** section.\n\n2. Add the parameter-value pair.\n\n3. Save the changes.\n\n4. Re-launch the viewer.",
    "answer": "To change the default 'fit content by' behavior of Daeja viewer in IBM Content Navigator v2.0.3, you can add a parameter-value pair to the Additional Settings section of the Daeja ViewONE panel in the admin desktop. \n\nFor Content Navigator v2.0.3:\n- Go to the admin desktop and access the Daeja ViewONE panel.\n- In the Additional Settings section, click \"New\" to add a parameter-value pair.\n- To fit content by width, specify: `scale: \"ftow\"`.\n- To fit content by height, specify: `scale: \"ftoh\"`.\n- Save the changes.\n\nNote: Make sure to add the parameter-value pair to the correct tab (Professional or Virtual) depending on the viewer you want to modify. The changes should take effect when the viewer is re-launched.",
    "id": "TECHQA_TRAIN_Q330_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q331",
    "question": "mirandabarby\nI have purchased a grad pack of SPSS. How do I enter the authorisation code to activate/license",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To enter the authorization code and activate/license your SPSS Grad Pack, you should contact the vendor from whom you purchased the software. The vendors listed include Hearne, On the Hub, StudentDiscounts.com, JourneyEd, thinkEDU, and Studica. You can visit their websites for support, and they should be able to guide you through the process of entering the authorization code. Specifically, you can try the following:\n\n- Hearne: http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ\n- On the Hub: http://onthehub.com/\n- StudentDiscounts.com: http://studentdiscounts.com/contact-us.aspx\n- JourneyEd: https://www.journeyed.com/contact\n- thinkEDU: https://thinkedu.desk.com/\n- Studica: http://www.studica.com/technical-support\n\nThey will provide you with the necessary steps to activate your SPSS Grad Pack.",
    "id": "TECHQA_TRAIN_Q331_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q334",
    "question": "Datetime export to FileNet\nHi there\n\n \n\nI created an application in Datacap that export to FileNet a Datetime field. In FEM I have a property type of Datetime. I'm using the following to send value to FileNet:\n\nFNP8_SetProperty (\"DataEmissao,@DATE(dd/MM/yyyy)+@STRING( )+@TIME(HH:MM),Datetime\")\n\n \n\nThe export works fine, but if I check the Datetime property in FEM I can see that the TIME was stored wrong, exactly 3 hours less.\n\ne.g:\n\nCurrent Datetime is: 19/08/2013 18:10\n\nValue stored in FEM: 19/08/2013 15:10\n\n \n\nCan someone help me? What I'm doing wrong?\n\n \n\nThank's",
    "ground_truth": "1. Modify the date/time value into proper GMT/UTC format of YYYY-MM-DDTHH:MM[:SS]\n\n2. Add a time offset to account for the GMT time difference, e.g. YYYY-MM-DDTHH:MM:SS-HH:MM",
    "answer": "The issue you're experiencing with the time being stored 3 hours less in FileNet is due to the difference between your local time zone and UTC (Coordinated Universal Time), which FileNet uses to store timestamps. \n\nTo resolve this, you need to modify the date/time value into the proper GMT/UTC format and add a time offset to account for the GMT time difference. \n\nYou can use the `IsFieldDateWithReformat` action with the parameter \"s\" to format your local date/time value to UTC, and then append the GMT offset using an action like `rrSet`.\n\nFor example, if your current datetime is `19/08/2013 18:10` and you are in a timezone that is 3 hours behind UTC (e.g., UTC-3), you would first convert this to UTC format: `2013-08-19T18:10:00`. Then, you would append the GMT offset: `2013-08-19T18:10:00-03:00`.\n\nSo, your `FNP8_SetProperty` call should be adjusted to include this conversion and offset. \n\nHere's an example of how you might do this:\n\n1. Convert your datetime to UTC format using `IsFieldDateWithReformat(s)`.\n2. Append the GMT offset using `rrSet`.\n\nGiven your original code:\n```sql\nFNP8_SetProperty (\"DataEmissao,@DATE(dd/MM/yyyy)+@STRING( )+@TIME(HH:MM),Datetime\")\n```\nYou would need to adjust it to something like:\n```sql\n// Assuming @DATE and @TIME are your date and time fields\n// First, convert to UTC and append offset\n// Note: The exact syntax might vary based on your Datacap version and available functions\nIsFieldDateWithReformat(s, @DATE, @TIME) // Convert to UTC\nrrSet(@F + @CHR(43) + \"03:00\", @F) // Append \"+03:00\" offset, adjust as necessary for your timezone\nFNP8_SetProperty (\"DataEmissao,@F,Datetime\")\n```\nPlease note, the exact implementation details (like function names and parameters) might vary depending on the specific version of Datacap and FileNet you are using, as well as your local timezone. This example is intended to guide you towards the correct approach rather than being a direct copy-paste solution.",
    "id": "TECHQA_TRAIN_Q334_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q336",
    "question": "Why does silent install abort indicating files are locked?\nSilent installs can fail reporting that there are locked files under the ITM installation directory on Windows platform. Why does this happen?\n\nExample:\n\nC:\\IBM\\ITM\\InstallITM\\\nAbort IBM Tivoli Monitoring 20160203 1832.log\n\n02-03-2016 18:37:10: File C:\\IBM\\ITM\\TMAITM6\\deploy.jar is locked.\n02-03-2016 18:37:10: File C:\\IBM\\ITM\\TMAITM6\\deploy.jar could not be renamed, errors may occur.\n02-03-2016 18:37:17: Directory C:\\IBM\\ITM has locked files.\n02-03-2016 18:37:17: Correct and launch setup again.\n02-03-2016 18:37:17: Directory C:\\IBM\\ITM has locked files, unable to continue.\n02-03-2016 18:37:17: SEVERE: ERROR - Install aborted.",
    "ground_truth": "1. Shut down all components before performing any product upgrade.\n   Ensure that all components, including **monitoring servers**, portal server, and portal clients, are shut down before proceeding with the product upgrade.",
    "answer": "The silent install aborts indicating that files are locked because the installer has detected that some product files are currently in use (locked) by running processes. This is a limitation of silent installations, which is designed to prevent the installer from overwriting files that are currently being used.\n\nTo resolve this issue, you can follow these steps:\n\n1. Search the installation log for instances of the \"CheckLockedFiles\" string to identify the locked files.\n2. Identify the process that is locking the files.\n3. Stop the process that is locking the files.\n4. Modify the response file for the installation by adding the line \"Locked Files=continue\" to the [INSTALLATION SECTION] area. This will allow the silent installation to continue even if locked files are detected.\n\nNote: If you use the \"Locked Files=continue\" parameter, you must reboot the computer before bringing up ITM or running another installation to avoid corrupting the <ITMHOME> directory.",
    "id": "TECHQA_TRAIN_Q336_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q337",
    "question": "Why does the other instance of my multi-instance qmgr seem to hang after a failover?\nQueue manager will not start after failover.",
    "ground_truth": "1. Rename the file **amqalchk.fil**, which is found under **mq\\qmgrs\\qmgrname\\** on the shared drive (to something like amqalchk.fil_OLD).\n2. Restart the **queue manager**.\n   ",
    "answer": "The issue you're experiencing with your multi-instance queue manager hanging after a failover is likely due to a logger failure at restart caused by missing or damaged logs. To resolve this problem, try renaming the file `amqalchk.fil` found under `mq\\qmgrs\\qmgrname\\` on the shared drive to something like `amqalchk.fil_OLD`, and then restart the queue manager. This should allow the queue manager to start successfully on the secondary node after a failover.",
    "id": "TECHQA_TRAIN_Q337_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q338",
    "question": "VScan not working after migrating Datacap Application from 8.1 to 9.0.1\nI have recently migrated one datacap application developed in Datacap 8.1 to Datacap 9.0.1. I followed the complete instruction provided in the link \n\nhttp://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.develop.doc/dcadv001.htm\n\n \n\nAfter migration, when I tried to execute the application using Datacap Desktop. I got errors that \"This batch has no data to process. Aborting\" and \"Unable to run queue\". I am attaching the screenshots of error. I am also attaching the DStudio rule's screenshot.\n\nI have verified and configured all the required settings.\n\nPlease guide if someone has faced the similar issue and resolved it.",
    "ground_truth": "1. Ensure the DCO name matches as it appears in **Datacap Studio**.\n   Check the DCO name for both correct spelling and case-sensitivity.",
    "answer": "The issue you're experiencing with VScan not working after migrating your Datacap application from 8.1 to 9.0.1, resulting in errors \"This batch has no data to process. Aborting\" and \"Unable to run queue,\" can be resolved by checking the case sensitivity of the DCO name in the panel settings. \n\nTo resolve this issue, follow these steps:\n\n1. Log in to the TMWeb client.\n2. Go to the Administrator tab.\n3. Select the VScan task from the Workflow.\n4. Click Setup under Program.\n5. Ensure the value of the Panel matches exactly (including case sensitivity) what is defined in Datacap Studio. For example, if your panel is named \"TravelDocs\" in Datacap Studio, make sure it's not set to \"TRAVELDOCS\" in the TMWeb client setup.\n6. Click Save after making the necessary adjustments.\n\nThis should resolve the issue and allow VScan to work properly in your migrated Datacap 9.0.1 application.",
    "id": "TECHQA_TRAIN_Q338_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q339",
    "question": "Why I get pop-up message of \"undefined\" when accessing TCR 3.1.2.1 in IE 11?\nWhen I access Tivoli Common Reporting -> Launch -> Administration, will get repeated message window with content of \"underfined\". This happened only with IE11 and TCR 3.1.2.1",
    "ground_truth": "1. Access the Tivoli Common Reporting dispatcher link.\n   Navigate to the following URL: **https://JazzSM_hostname:port/tarf/servlet/dispatch**",
    "answer": "The issue you're experiencing with the \"undefined\" pop-up message when accessing TCR 3.1.2.1 in IE 11 is due to browser mode compatibility issues between Dashboard Application Services Hub and Tivoli Common Reporting. To resolve this issue, try accessing Tivoli Common Reporting using the dispatcher link:\n\nhttps://JazzSM_hostname:port/tarf/servlet/dispatch\n\nReplace \"JazzSM_hostname\" and \"port\" with your actual JazzSM hostname and port number. For example:\n\nhttps://JazzSM_hostname:16311/tarf/servlet/dispatch\n\nThis should allow you to access Tivoli Common Reporting without the \"undefined\" pop-up message.",
    "id": "TECHQA_TRAIN_Q339_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q340",
    "question": "Why is an error seen while running run-svrssl-config?\nFollowing error is seen while running run-svrssl-config ConfigEngine task:\n\n     action-run-pdjrte-config-zos-wp.ac.impl: \n     [validateHost] Validating hostname(s) in the following argument: tam001:7136:1,tam002:7136:2\n          [echo] Command to run is: java com.tivoli.pd.jcfg.SvrSslCfg -action config -admin_id sec_master -admin_pwd ****** -appsvr_id myAppSvr -port 7223 -mode remote -policysvr\n     tam001:7135:1,tam002:7135:2 -authzsvr tam001:7136:1,tam002:7136:2 -cfg_file /opt/WebSphere/AppServer/tivoli/tam/PdPerm.properties -key_file /opt/WebSphere/AppServer/tivoli/tam/pdperm.ks\n          [java] Executing java with empty input string\n          [java] Exception in thread \"main\"\n          [java] [\n          [java] HPDMG0759W The user name already exists in the registry.\n          [java] ]\n          [java] at com.tivoli.pd.jutil.ob.a(ob.java:40)\n          [java] at com.tivoli.pd.jutil.ob.a(ob.java:66)",
    "ground_truth": "1. Use a unique value for **wp.ac.impl.PDServerName** parameter.\n   ",
    "answer": "The error HPDMG0759W is seen while running the `run-svrssl-config` task because the user name (appsvr_id) already exists in the Tivoli Access Manager's registry. To resolve this issue, you can either:\n\na) Use a unique value for `wp.ac.impl.PDServerName` in the `wkplc_comp.properties` file.\n\nor\n\nb) Run the following command manually from a command prompt on the portal server to remove the appsvr_id value from Tivoli Access Manager's repository:\n\n`java com.tivoli.pd.jcfg.SvrSslCfg -action unconfig -admin_id sec_master -admin_pwd ****** -appsvr_id myAppSvr -port 7223 -mode remote -policysvr tam001:7135:1,tam002:7135:2 -authzsvr tam001:7136:1,tam002:7136:2 -cfg_file /opt/WebSphere/AppServer/tivoli/tam/PdPerm.properties -key_file /opt/WebSphere/AppServer/tivoli/tam/pdperm.ks`\n\nAfter taking one of these steps, you can re-run the `run-svrssl-config` task to create the AMJRTE properties file.",
    "id": "TECHQA_TRAIN_Q340_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q341",
    "question": "How to check IBM Java ORB build version in WebSphere Application Server?\nJust a simple question: How to check IBM Java ORB build version in WebSphere Application Server?",
    "ground_truth": "1. Run command: **<washome>/java/bin/java -Xbootclasspath/p:<washome>/java/jre/lib/ext/ibmorb.jar com.ibm.rmi.util.Version**",
    "answer": "To check the IBM Java ORB build version in WebSphere Application Server, you can use the following command:\n\n`<washome>/java/bin/java -Xbootclasspath/p:<washome>/java/jre/lib/ext/ibmorb.jar com.ibm.rmi.util.Version`\n\nThis command will display the version of the IBM Java ORB. Replace `<washome>` with the actual path to your WebSphere Application Server installation directory.",
    "id": "TECHQA_TRAIN_Q341_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q348",
    "question": "Why does DSM error log have errors for SQLCODE=-206 errors reported for ISAS core warehouse database?\nDSM error log have errors for SQLCODE=-206 errors reported for ISAS core warehouse database. How do Isolve the problem?",
    "ground_truth": "1. Run the **db2updvnn** command according to the db2level of your monitored database",
    "answer": "To resolve the SQLCODE=-206 errors reported for the ISAS core warehouse database in the DSM error log, you need to update the database system catalog to support the new fix pack that you have installed. \n\n1. **Verify the DB2 level**: Run the command `db2 \"select versionnumber from sysibm.sysversions order by 1 desc\"` on the monitored database to check the version number.\n2. **Check supported DB2 levels**: Refer to the system requirements for IBM Data Server Manager (version 1.1.2 or 2.1) to see the supported DB2 levels.\n3. **Run the db2updvnn command**: Based on the db2level of your monitored database, run the corresponding command:\n   - For DB2 V9.7, run `db2updv97`.\n   - For DB2 V10.1, run `db2updv10`.\n   - For DB2 V10.5, run `db2updv105`.\n   - For DB2 V11.1, run `db2updv111`.\n\nThis should resolve the SQLCODE=-206 errors by ensuring that your database system catalog is updated to support the new fix pack.",
    "id": "TECHQA_TRAIN_Q348_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q350",
    "question": "Missing option to fill in attributes when trying to deploy a pattern\nI tried to deploy a pattern and I have some parameters to modify at deployment time. But I can't see my parts/attributes in the Component Attribute List.",
    "ground_truth": "1. Lock any one of the attributes, such as the **name** attribute.\n   This action causes the other component attributes to be displayed for configuration.",
    "answer": "To resolve the issue of missing attributes in the Component Attribute List during pattern deployment, try locking one of the attributes, such as the name attribute, for the component with a data dependency. This should cause the other component attributes to be displayed for configuration, allowing you to modify them as needed.",
    "id": "TECHQA_TRAIN_Q350_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q353",
    "question": "CQWEB  can\\'t retrieve repository dropdown list options in RedHat Linux, how to deal with it ?\nI setup a cq demo env in redhat linux with oracle database, CQ 7.1.2, LRKS 8.1.3,  Linux CQ client can login CQ as the following picture 1, but CQWEB login page can't retrieve the repository dropdown list options as the following picture 2.  I used cqreg to register CQ database:\n\ncqreg add_dbset -v ORACLE -s 192.168.0.84 -d ESBDB -u cqadmin -p cqadmin -dbset CQ_DEMO_ORACLE -co LOB_TYPE=CLOB -force\n\n How do I deal with it?",
    "ground_truth": "1. Run **cqreg initialize**.\n2. Ensure the **CQ_DATABASES** environment variable is set to the desired registry path.\n3. Run the previously mentioned commands again.",
    "answer": "To resolve the issue of CQWEB not being able to retrieve the repository dropdown list options in RedHat Linux, you should first ensure that the `cqreg initialize` command has been successfully run. This command creates the necessary registry structure for database sets, which might not have been set up correctly during the installation.\n\nHere are the steps to follow:\n\n1. **Verify the existence of the CQDB_rgys directory**: Check if the directory `/opt/rational/clearquest/CQDB_rgys/cqdb_registry/` exists. If it does not, proceed to the next step.\n\n2. **Run `cqreg initialize`**: Execute the `cqreg initialize` command to create the registry structure. This command should be run as the root user if the issue persists after a normal run.\n\n3. **Set the `CQ_DATABASES` environment variable**: Ensure that the `CQ_DATABASES` environment variable is set to the desired registry path. If it's not set, you can set it using the command `export CQ_DATABASES=/path/to/registry` (replace `/path/to/registry` with the actual path, typically `/opt/rational/clearquest/CQDB_rgys/cqdb_registry/`).\n\n4. **Retry the `cqreg add_dbset` command**: After initializing the registry and setting the environment variable, retry the `cqreg add_dbset` command to add the database set.\n\nBy following these steps, you should be able to resolve the issue preventing CQWEB from retrieving the repository dropdown list options. If the problem persists, consider checking the permissions and ensuring that all commands are executed with the appropriate user privileges.",
    "id": "TECHQA_TRAIN_Q353_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q358",
    "question": "Cannot create syndication pair between Virtual Portals with a different user repository than Base Portal\nSteps:\r\nI have two different user repositories one to manage my base portal and Virtual Portals. (p.e: For Base Portal I use ITDS, and for VPs I use AD) with differents admin users each.\r\nThen I created two VPs using the AD repository, and my VPs admin user on the credential vault.\r\nTried to create a syndication relationship , that is failing with the error:\r\n\"Could not communicate with the target URL. Please check that the Syndicator URL details are entered correctly, and that the credential slot user exists on the target server.\"",
    "ground_truth": "1. Make the **Admin** user visible on both base and virtual Portals",
    "answer": "To resolve the issue of creating a syndication pair between Virtual Portals with a different user repository than the Base Portal, you need to ensure that the Admin user is visible on both the Base Portal and the Virtual Portal. \n\nThe error message indicates that the credential slot user does not exist on the target server, which in this context means the Virtual Portal. This is because the Admin user listed as the Domain Admin, retrieved by `com.presence.connect.wmmcomms.UserManagementServiceImpl.getPortalAdministrator()`, does not have access to the Virtual Portal.\n\nTo fix this, you should make the Admin user visible on both the Base Portal and the Virtual Portal. This involves ensuring that the Admin user who is supposed to have access to the Virtual Portal for syndication purposes is properly configured and exists in the user repository of the Virtual Portal.\n\nIn your case, since you are using ITDS for the Base Portal and AD for the Virtual Portals, you need to ensure that the Admin user for syndication is recognized and has the appropriate permissions in both ITDS and AD, or at least that there is a user in the AD repository that matches or is equivalent to the Admin user in ITDS for the purposes of syndication.\n\nBy making the Admin user visible and ensuring they have the necessary permissions on both the Base Portal and the Virtual Portal, you should be able to establish the syndication relationship successfully.",
    "id": "TECHQA_TRAIN_Q358_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q360",
    "question": "Is it possible to monitor Memory/LPAR metrics using ITM HMC agent?\nI understand the ITM AIX Premium agent captures these metrics but like to know if it is possible to monitor Memory/LPAR metrics using ITM HMC agent?",
    "ground_truth": "1. Use the Query Editor and select Server **LPARs_V9** under **KPH SERVER LPARS**.",
    "answer": "Yes, it is possible to monitor Memory/LPAR metrics using the ITM HMC agent. According to the provided context, specifically the feature 208626, the ITM HMC agent has been enhanced to include new attributes for LPAR Memory, such as \"Current_Memory\" and \"Running_Memory\", which can be displayed in the Tivoli Enterprise Portal. This suggests that the HMC agent is capable of collecting and reporting on these metrics.",
    "id": "TECHQA_TRAIN_Q360_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q366",
    "question": "How do to restore corrupted Object server DB using data from Backup Object server in Linux?\nError: E-REG-002-025: Region 'table_store', from directory '/opt/IBM/tivoli/netcool/omnibus/db/NCOMS/', has been recovered in a corrupt state: Extent statistics mismatch Error: E-OBX-102-020: Failed to start the storage system. (-490:Extent statistics mismatch)",
    "ground_truth": "1. Create a temporary directory using the command **mkdir /tmp/backup**\n2. Use nco_sql to obtain a backup\n   Execute **./nco_sql -server NCOMS**, enter the password when prompted, and then run the commands 'alter system backup '/tmp/backup';' followed by 'go'. After that, type 'quit' to exit the nco_sql.\n3. Verify that /tmp/backup contains *.tab files.\n   \n4. Compressed /tmp/backup\n   \n5. Copy of **ObjectServers** properties file (i.e. NCOMS.props)\n   \n6. If you can provide the root password, do so.\n   ",
    "answer": "To restore a corrupted ObjectServer DB using data from a Backup Object server in Linux, follow these steps:\n\n1. **Stop the ObjectServer**: Ensure the ObjectServer is stopped before attempting the restore.\n2. **Delete the corrupted database files**: Remove the corrupted database files from the `/opt/IBM/tivoli/netcool/omnibus/db/NCOMS/` directory.\n3. **Restore from backup**: Use the `nco_sql` command to restore the database from the backup files. Run the following command:\n   ```\n  ./nco_sql -server NCOMS\n   Password: \n   1> alter system restore '/path/to/backup';\n   2> go\n   (0 rows affected)\n   1> quit\n   ```\n   Replace `'/path/to/backup'` with the actual path to the backup directory containing the `*.tab` files.\n4. **Verify the restore**: After the restore, verify that the database is intact and functional by checking the ObjectServer logs and attempting to connect to the database using `nco_sql`.\n5. **Restart the ObjectServer**: Once the restore is verified, restart the ObjectServer.\n\nNote: Make sure to replace `NCOMS` with the actual name of your ObjectServer and provide the correct password when prompted. Also, ensure that the backup files are from a valid and complete backup of the ObjectServer database.\n\nIf you encounter any issues during the restore process, refer to the IBM documentation and support resources for further assistance.",
    "id": "TECHQA_TRAIN_Q366_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q367",
    "question": "1040ez 9.0 Application\nHi\n\nI have downloaded sample Datacap 9 applications (1040ez, Express, Survey) using below link and copied in my local system C:\\Datacap and added reference in Datacap.xml file.\n\nIBM Datacap 9.0 and IBM Datacap 9.0.1 DDK sample applications\n\nBut i'm unable to login Datacap Studio & Tmweb.net . (I tried to with re generating encryption keys but no luck).\n\nCan anyone let me know the reason, anything I missed in configuration ?\n\nMy Datacap version in Local Machine\n\nIBM Datacap 9.0.0.3\n\nBuild: v 9.0.0.72\n\nThanks",
    "ground_truth": "1. If this is a new server where **Datacap** has never been run and encryption has not been set up at all, follow the instructions at Exporting encryption keys\n\n2. If this is an existing server or a new server where the previous steps have been completed, distribute the **dc_ktf.xml** file to the client folder for all clients that will be used following the instructions at Importing encryption keys to **Datacap** computers",
    "answer": "To resolve the issue of being unable to log in to Datacap Studio and Tmweb.net, follow these steps:\n\n1. **Verify Encryption Setup**: Ensure that encryption is fully set up on your Taskmaster Server. Since you've tried regenerating encryption keys without success, double-check that the process was completed correctly.\n\n2. **Export Encryption Keys**: If this is a new server where Datacap has never been run, follow the instructions at [http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain011_copyto_cs1.htm](http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain011_copyto_cs1.htm) to export the encryption keys.\n\n3. **Distribute dc_ktf.xml File**: If this is an existing server or the previous steps have been completed, distribute the dc_ktf.xml file to the client folder for all clients that will be used. Follow the instructions at [http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain010_copyto_wtminstall1.htm](http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain010_copyto_wtminstall1.htm) to import the encryption keys to Datacap computers.\n\n4. **Review Datacap Version and Configuration**: Ensure that your version of Datacap (IBM Datacap 9.0.0.3, Build: v 9.0.0.72) is compatible with the applications and configurations you are using. Also, double-check that the Datacap.xml file has been correctly updated with the necessary references.\n\nIf after following these steps you still encounter issues, it may be helpful to consult the IBM Datacap documentation or contact IBM support for further assistance, as the problem might be specific to your environment or configuration.",
    "id": "TECHQA_TRAIN_Q367_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q368",
    "question": "Does ITCAM for MQ monitoring agent (kmq) use SYSTEM.MQXR.COMMAND.QUEUE causing Unknown Object Name [2085] event?\nUsing the ITCAM MQ Monitoring agent, we have a situation that generates alerts when a 2085 event (object unknown) occurs. We have recently seen alerts for the queue SYSTEM.MQXR.COMMAND.QUEUE\nWe found following technote:\nUnknown Object Name [2085], SYSTEM.MQXR.COMMAND.QUEUE\nhttp://www-01.ibm.com/support/docview.wss?uid=swg21681687\n\nThis technote does not mention Tivoli monitoring product, and only mentions monitoring products such as Nastel and InfraRed360.\nDoes Tivoli monitoring agent for WebSphere MQ use the SYSTEM.MQXR.COMMAND.QUEUE? We are try to find out which application is causing the 2085 event.",
    "ground_truth": "1. Invoke the command under runmqsc.\n   The complete command is: display conn(*) where(objname eq Q1) all.",
    "answer": "The provided context does not explicitly state whether the ITCAM for MQ monitoring agent (kmq) uses the SYSTEM.MQXR.COMMAND.QUEUE, which could be causing the Unknown Object Name [2085] event. The context provides information on how to identify an application that has a WebSphere MQ queue open, but it does not specifically mention the ITCAM for MQ monitoring agent or its interaction with the SYSTEM.MQXR.COMMAND.QUEUE.\n\nTo determine if the ITCAM for MQ monitoring agent is causing the 2085 event, you can use the `display conn(*) where(objname eq SYSTEM.MQXR.COMMAND.QUEUE) all` command under runmqsc to find the process ID (PID) and application name associated with the queue. If the APPLTAG field in the output matches the ITCAM for MQ monitoring agent, it would indicate that the agent is using the queue and potentially causing the event. However, without explicit information linking the ITCAM for MQ monitoring agent to the SYSTEM.MQXR.COMMAND.QUEUE, the exact cause of the 2085 event remains uncertain based on the provided context.",
    "id": "TECHQA_TRAIN_Q368_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q372",
    "question": "How to fix error CRIMA1217E when upgrade JAZZ from 1.1.0 to 1.1.3 failed?\nHow to fix problem when upgrade JAZZ from 1.1.0 to 1.1.3 failed?",
    "ground_truth": "1. Use the attached script to initiate the upgrade.\n   This script is necessary to give the **non-root** user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process. Usage: **./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\"**",
    "answer": "To fix the error CRIMA1217E when upgrading JAZZ from 1.1.0 to 1.1.3 failed, you need to use the provided script `JazzSMgrpModeUpgrade.sh` to initiate the upgrade process. This script gives the non-root user the correct permissions for the upgrade.\n\nFor silent installation, use the following command with three arguments:\n```\n./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location\" \"Response_file_with_absolute_Path\"\n```\nFor example:\n```\n./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"\n```\nFor GUI mode installation, use the following command with two arguments:\n```\n./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location\"\n```\nThis will invoke Installation Manager in GUI mode and lead you through the rest of the upgrade process.\n\nNote: Replace the `IM_Install_Location`, `JazzSM_Install_Location`, and `Response_file_with_absolute_Path` with your actual installation paths and response file.",
    "id": "TECHQA_TRAIN_Q372_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q373",
    "question": "RecognizePageFieldsICR_C aborts with Page Type change\nI have an DeveloperWorks application that runs: Survey.  In the application PageID Task there is a function that sets the Page Type to ReliefForm (based on a barcode)\n\nDoes anyone know why when I change the SetPageType to set another name, the RecognizePageFieldsICR_C in the Profiler Task aborts?  If I put the name back the action runs fine.",
    "ground_truth": "1. Set the c_cr variable to USA prior to the call to recognition.\nUse the command **SaveAsCurrentObjVariable(\"c_cr\", \"USA\")** to set the variable.",
    "answer": "The issue you're experiencing with RecognizePageFieldsICR_C aborting when you change the Page Type is likely due to the fact that the `c_cr` variable for ICR_C recognition is not set for the new page type. \n\nTo resolve this, you need to set the `c_cr` variable to the appropriate value (e.g., \"USA\") before calling the RecognizePageFieldsICR_C action. You can do this by adding the following line of code before the RecognizePageFieldsICR_C action:\n\n`SaveAsCurrentObjVariable(\"c_cr\", \"USA\")`\n\nThis will ensure that the ICR_C engine is properly configured for the new page type, and the RecognizePageFieldsICR_C action should run without aborting.",
    "id": "TECHQA_TRAIN_Q373_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q380",
    "question": "How do I view Custodian Notes in Atlas Preservation Plan?\nHow do I view Custodian Notes in Atlas Preservation Plan?",
    "ground_truth": "1. Click the **Show Custodian Notes** button.",
    "answer": "To view Custodian Notes in Atlas Preservation Plan, click on the Notes tab in a Preservation Plan, then click the \"Show Custodian Notes\" button. This will list the custodian notes. If you want to go back to Plan Notes, click the \"Show Plan Notes\" button.",
    "id": "TECHQA_TRAIN_Q380_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q382",
    "question": "Where to download SPSS Statistics 24.0 Fix Pack 2\nI found the pack from following link: https://www-01.ibm.com/support/docview.wss?uid=swg24043574\n\nBut where should I download it?",
    "ground_truth": "1. Log in as a local administrator.\n2. Ensure that no versions of Statistics are running.\n3. Download the Fix Pack to a temporary location on your hard drive.\n4. Run the Statistics 24.0.0.2 Fix Pack executable.\n   Remember to use Run as Administrator by first right-clicking on the executable file.\n5. Statistics 24.0.0.2 is ready to run.\n   Navigate to the **Help -> About** menu to confirm that version 24.0.0.2 is the installed version.",
    "answer": "To download SPSS Statistics 24.0 Fix Pack 2, you should visit the IBM Fix Central website. The direct links to download the fix pack for different platforms are provided in the context:\n\n- For Windows 64-bit: https://www-933.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.0&platform=All&function=fixId&fixids=24.0-IM-S24STATS-WIN64-FP001&includeRequisites=1&includeSupersedes=0&downloadM\n- For AIX: https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATS-AIX-FP002&includeRequisites=1&includeSupersedes=0&downloadMet\n- For Windows 32-bit: https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATC-WIN32-FP002&includeRequisites=1&includeSupersedes=0&downloadM\n- For Mac: The link is not directly provided in the context for Mac, but you can visit the IBM Fix Central website and search for \"SPSS Statistics 24.0 Fix Pack 2\" for Mac to find the appropriate download link.\n\nEnsure you follow the installation instructions provided in the context after downloading the fix pack suitable for your operating system.",
    "id": "TECHQA_TRAIN_Q382_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q384",
    "question": "Where do I find list of all document formats indexable and supported by ICC Content Search Services Support (CSSS)?\nWhere do I find list of all document formats indexable and supported by ICC Content Search Services Support (CSSS)?",
    "ground_truth": "1. Visit the following link to determine which document types are supported by CSS/Outside In: **http://www-01.ibm.com/support/knowledgecenter/SSNW2F_5.2.1/com.ibm.p8.ce.admin.tasks.doc/cbr/csscbr_indexable_documenttype.htm?lang=en**",
    "answer": "To find the list of all document formats indexable and supported by ICC Content Search Services Support (CSSS), you can reference the following link: \n\nhttp://www-01.ibm.com/support/knowledgecenter/SSNW2F_5.2.1/com.ibm.p8.ce.admin.tasks.doc/cbr/csscbr_indexable_documenttype.htm?lang=en\n\nThis link provides information on the document types supported by CSS/Outside In, which is used by Content Search Services for text conversion. Note that the supported document types may depend on the version of Oracle Outside In Technology used in Content Search Services. For CSS V5.2.1, it uses Outside In V8.4.1.",
    "id": "TECHQA_TRAIN_Q384_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q388",
    "question": "How to set database specific custom properties in WebSphere Application Server?\nI am using Websphere Application Server (WAS) v8.5.x with Oracle 11.1 JDBC drivers and I want to set some oracle specific properties, when connecting to the database in Websphere Application Server. (specifically: defaultRowPrefetch). How to set such specific properties in Websphere Application Server?",
    "ground_truth": "1. Load the property into a Properties object.\n2. Call **getConnection** with the Properties object.",
    "answer": "To set the Oracle-specific property `defaultRowPrefetch` in WebSphere Application Server (WAS) v8.5.x with Oracle 11.1 JDBC drivers, you cannot set it as a custom property in the datasource. Instead, you need to load it into a `Properties` object in your code and then call `getConnection` with the `Properties` object.\n\nHere's an example of how to do it:\n```java\nProperties props = new Properties();\nprops.setProperty(\"defaultRowPrefetch\", \"your_desired_value\");\nConnection conn = DriverManager.getConnection(url, props);\n```\nReplace `\"your_desired_value\"` with the value you want to set for `defaultRowPrefetch`.\n\nAlternatively, you can also set it as a JVM property, but you need to prefix it with `oracle.jdbc.`. For example:\n```java\n-Doracle.jdbc.defaultRowPrefetch=your_desired_value\n```\nNote that setting it as a JVM property will apply to all Oracle JDBC connections, whereas setting it in the code will only apply to the specific connection.",
    "id": "TECHQA_TRAIN_Q388_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q389",
    "question": "What are the supported Macintosh Operating System versions for IBM SPSS Statistics 19, 20, 21, 22 and 23?\nI would like to know what are the supported Macintosh Operating system versions for IBM SPSS Statistics versions 18, 19, 20, 21, 22 and 23?",
    "ground_truth": "1. Visit the following URL to access the IBM Software Product Compatibility Reports: **http://publib.boulder.ibm.com/infocenter/prodguid/v1r0/clarity/index.jsp**.",
    "answer": "The supported Macintosh Operating System versions for IBM SPSS Statistics are as follows:\n\n- IBM SPSS Statistics 18, 19, and 20: These versions are no longer supported by IBM. \n- IBM SPSS Statistics 21: Supported on Mac OSX Snow Leopard (10.6), Mac OSX Lion (10.7), and Mac OSX Mountain Lion (10.8).\n- IBM SPSS Statistics 22: Supported on Mac OSX Mountain Lion (10.8), Mac OSX Mavericks (10.9) if Apple Java SE 6 (1.6.0_65) is installed first, and Mac OSX Yosemite (10.10) with Fixpack 2 installed.\n- IBM SPSS Statistics 23: Supported on Mac OSX Mavericks (10.9), Mac OSX Yosemite (10.10), and Mac OSX El Capitan (10.11).\n- IBM SPSS Statistics 24: Supported on Mac OSX Yosemite (10.10), Mac OSX El Capitan (10.11), and Mac OSX Sierra (10.12) with FixPack 2 installed.\n- IBM SPSS Statistics 25: Supported on Mac OSX Sierra (10.12) and Mac OSX High Sierra (10.13), with a known issue on High Sierra 13.0 and 13.1 beta versions that can be resolved by updating to the official 10.13.1 build.",
    "id": "TECHQA_TRAIN_Q389_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q390",
    "question": "Netcool/Impact (all versions): DataType incorrect on Secondary\nThe DataType is not being correctly replicated across the ImpactServer Cluster. The .type file of the Secondary ImpactServer configuration is truncated with the error message:\n\nError 500: Mark invalid",
    "ground_truth": "1. Add the property to a file, the file is typically found at **$NCHOME/impact/etc/<SERVERNAME>_server.props**.\n   The property must be added to the specified server properties file where the size limit can be set to values such as 8192, 16384, 32768, etc.\n2. Restart the ImpactServer to enable the new property\n3. Ensure the ImpactServer started as **Primary** has the correct, uncorrupted **.type** file\n4. Ensure there are no trailing white-space characters on the property\n   Make sure that there are no trailing white-space characters in the property being added, as these can invalidate properties in lower versions of Impact.",
    "answer": "To resolve the issue of the DataType not being correctly replicated across the ImpactServer Cluster due to the error \"Error 500: Mark invalid\" and the truncated `.type` file on the Secondary ImpactServer, you need to add a new property to the `$NCHOME/impact/etc/<SERVERNAME>_server.props` file on all ImpactServers in the Cluster. This property increases the file size limit to handle large character lengths for the `USERPARAMETERS` parameter.\n\nHere are the steps to follow:\n\n1. **Identify the required file size limit**: Determine the appropriate size limit (e.g., 8192, 16384, 32768, etc.) based on the length of your `USERPARAMETERS` property, including the property name and definition.\n\n2. **Add the property to the configuration files**: On each ImpactServer in the Cluster, open the `<SERVERNAME>_server.props` file located in `$NCHOME/impact/etc/` and add the following line, replacing `<size>` with your chosen size limit:\n   ```\n   nci.type.file.size.limit=<size>\n   ```\n   Ensure there are no trailing white-space characters, as they can invalidate properties in lower versions of Impact.\n\n3. **Restart the ImpactServers**: After adding the property to all servers, restart each ImpactServer to enable the new configuration. It's crucial that the ImpactServer started as Primary has the correct, uncorrupted `.type` file to be replicated across the Cluster.\n\n4. **Verify the resolution**: After restarting, check the `.type` file on the Secondary ImpactServer to ensure it is no longer truncated and that the DataType is correctly replicated.\n\nThis solution applies to all versions of Netcool/Impact, although the specific APAR (IZ81446) mentioned is not an issue in Impact 6 and 7. However, adding the property is still necessary to handle large character lengths for the `USERPARAMETERS` parameter in those versions.",
    "id": "TECHQA_TRAIN_Q390_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q391",
    "question": "Can an update query be run against the C&DS repository to update job results?\nWe have jobs set up in SPSS Deployment Manager. We would like to do a mass change of the location set up on the location set on the location tab.",
    "ground_truth": "1. Work with your **IT administrator** to clean up your file system.\n2. Point your file system to a new location or manually update all of your jobs.",
    "answer": "No, an update query cannot be run against the C&DS repository to update job results. The job data is stored as metadata, and there is no query or batch process available for mass updates. To change the location of the results tab, you will need to either manually update all of your jobs or work with your IT administrator to clean up your file system or point it to a new location.",
    "id": "TECHQA_TRAIN_Q391_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q393",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?",
    "ground_truth": "1. In Content Navigator v2.0.2, set the value of the parameter 'scale' as follows.\n   In the **..navigator.war/applets/filenetViewer_properties.jsp** file, set the parameter 'scale' to **scale: \"ftow\"** to fit content by width or **scale: \"ftoh\"** to fit content by height.",
    "answer": "To change the default 'fit content by' behavior of Daeja viewer in IBM Content Navigator, follow these steps:\n\n**For Content Navigator v2.0.2:**\n\n1. Locate the `filenetViewer_properties.jsp` file in the `..navigator.war/applets/` directory or the `ECMClient\\configure\\explodedformat\\navigator\\applets` folder.\n2. Set the value of the `scale` parameter as follows:\n\t* To fit content by width, specify: `scale: \"ftow\"`\n\t* To fit content by height, specify: `scale: \"ftoh\"`\n3. Save the changes and rebuild and redeploy the ear file.\n4. Restart the application server.\n\n**For Content Navigator v2.0.3:**\n\n1. Go to the Admin desktop and open the Daeja ViewONE panel.\n2. Click on the Additional Settings section of the:\n\t* Professional tab (for Daeja Professional viewer)\n\t* Virtual tab (for Daeja Virtual viewer)\n3. Click New and add the parameter-value pair:\n\t* To fit content by width, specify: `scale: \"ftow\"`\n\t* To fit content by height, specify: `scale: \"ftoh\"`\n4. Save the changes.\n\nAfter making these changes, the new 'fit content by' behavior should take effect when the viewer is re-launched.",
    "id": "TECHQA_TRAIN_Q393_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q398",
    "question": "Cannot create syndication pair between Virtual Portals with a different user repository than Base Portal\nSteps:\n\nI have two different user repositories one to manage my base portal and Virtual Portals. (p.e: For Base Portal I use ITDS, and for VPs I use AD) with differents admin users each.\n\nThen I created two VPs using the AD repository, and my VPs admin user on the credential vault.\n\nTried to create a syndication relationship , that is failing with the error:\n\n\"Could not communicate with the target URL. Please check that the Syndicator URL details are entered correctly, and that the credential slot user exists on the target server.\"",
    "ground_truth": "1. Make the **Admin** user visible on both base and virtual Portals.",
    "answer": "To resolve the issue of creating a syndication pair between Virtual Portals with a different user repository than the Base Portal, you need to ensure that the Admin user exists on both the Base Portal and the Virtual Portal. \n\nThe error message indicates that the credential slot user does not exist on the target server, which in this context means the Virtual Portal. The provided context explains that when syndicating to Virtual Portals, the Administrator User (retrieved with `com.presence.connect.wmmcomms.UserManagementServiceImpl.getPortalAdministrator()`) should have access to the Virtual Portal.\n\nTo fix this, you should make the Admin user visible on both the Base Portal and the Virtual Portal. This involves ensuring that the Admin user who is listed as the Domain Admin has access to the Virtual Portal, even if the Virtual Portal uses a different user repository (like AD) than the Base Portal (like ITDS).\n\nIn practical terms, you may need to synchronize the user repositories or manually ensure that the Admin user account exists in both repositories with the appropriate permissions. This will allow the syndication process to successfully communicate with the target URL and complete the syndication relationship setup.",
    "id": "TECHQA_TRAIN_Q398_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q401",
    "question": "How do I tell when there are mismatched MQ jars in my application server?\nMismatched jar files can cause strange and unpredictable errors when using the MQ JMS classes from a .war file.",
    "ground_truth": "1. Remove any **MQ** jar files bundled with the **Java EE** application.\n",
    "answer": "To determine if there are mismatched MQ jars in your application server, you can use the `mqjavalist.sh` script. Here's how:\n\n1. Run the `mqjavalist.sh` script and review its output.\n2. Check for multiple versions of the MQ jar files, such as `com.ibm.mqjms.jar`, in the output.\n3. If you find multiple versions, verify that the implementation versions are the same. If they are not, it may indicate a mismatch.\n4. Check if the `wmq.jmsra.rar` file contains a copy of the MQ jar at the correct level for the application server.\n5. If you find a mismatch, you can try extracting the correct version of the MQ jar from the `wmq.jmsra.rar` archive and replacing the incorrect version.\n6. Also, check the classpath for the application server and your Java SE application to ensure that there are no extra copies of the MQ jar files being picked up.\n7. If your Java EE application (.ear or.war) bundles a copy of any MQ jar files, remove them and rely on the ones from the installed MQ Resource Adapter instead.\n\nBy following these steps, you should be able to identify and resolve any mismatched MQ jar issues in your application server.",
    "id": "TECHQA_TRAIN_Q401_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q413",
    "question": "VScan not working after migrating Datacap Application from 8.1 to 9.0.1\nHello,\n\nI have recently migrated one datacap application developed in Datacap 8.1 to Datacap 9.0.1. I followed the complete instruction provided in the link \n\nhttp://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.develop.doc/dcadv001.htm\n\n \n\nAfter migration, when I tried to execute the application using Datacap Desktop. I got errors that \"This batch has no data to process. Aborting\" and \"Unable to run queue\". I am attaching the screenshots of error. I am also attaching the DStudio rule's screenshot.\n\nI have verified and configured all the required settings.\n\nPlease guide if someone has faced the similar issue and resolved it.\n\nThanks.",
    "ground_truth": "1. Ensure the DCO name matches as it appears in **Datacap Studio**.\n   The DCO name must be spelled correctly and match in case-sensitivity to avoid issues.",
    "answer": "To resolve the issue with VScan not working after migrating your Datacap application from 8.1 to 9.0.1, follow these steps:\n\n1. **Check Case Sensitivity**: Ensure that the \"Bind DCO type to panel\" for Datacap Desktop matches the DCO name as it appears in Datacap Studio, including both spelling and case-sensitivity.\n\n2. **Update Panel Value**:\n   - Log on to the TMWeb client.\n   - Go to the Administrator tab.\n   - Select the VScan task from the Workflow.\n   - Click Setup under Program.\n   - Update the value of the Panel to exactly match what is in Datacap Studio (e.g., change \"TRAVELDOCS\" to \"TravelDocs\" if necessary).\n   - Click Save.\n\nBy following these steps, you should be able to resolve the errors \"This batch has no data to process. Aborting\" and \"Unable to run queue\" that you're encountering when trying to execute the application using Datacap Desktop after the migration.",
    "id": "TECHQA_TRAIN_Q413_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q421",
    "question": "Authorization code issue\nlike many of the other questions posted on here ... I'm having trouble authenticating my SPSS authorization code. Then there is an issue getting a license code back from the IBM proxy server to complete my download. Please help.",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To resolve the authorization code issue and obtain a license code for your IBM SPSS Student Version or Graduate Pack software, follow these steps:\n\n1. Contact your vendor for support with installation and licensing issues. You can find the contact information for various vendors on the provided links:\n\t* Hearne: http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ\n\t* On the Hub: http://onthehub.com/\n\t* StudentDiscounts.com: http://studentdiscounts.com/contact-us.aspx\n\t* JourneyEd: https://www.journeyed.com/contact\n\t* thinkEDU: https://thinkedu.desk.com/\n\t* Studica: http://www.studica.com/technical-support\n2. Reach out to your vendor's technical support team and provide them with your authorization code issue details. They should be able to assist you in resolving the issue and obtaining a license code from the IBM proxy server.\n\nIf you're unsure about who your vendor is or need further assistance, you can try contacting the vendors listed above to see if they can help you with your specific issue.",
    "id": "TECHQA_TRAIN_Q421_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q423",
    "question": "Report stuck in current queue\nWe have one report that has been showing in the admin current\nactivities status tab for 20+ days and we have had 2 full re-starts\nsince then. Also it appears we have interactive jobs staying around as well for past days and days.\n\nHow can we clean this up ?",
    "ground_truth": "1. Stop the **Cognos Service**\n\n2. Take a physical backup of the Content Store or Notification database\n\n3. Select the appropriate folder for your content store or notification database type under **<install>/configuration/schemas/delivery/<dbtype>/**\n\n4. Run **NC_DROP_<dbtype>.sql** against the content store or notification database\n\n5. Restart **Cognos Services**",
    "answer": "To clean up the stuck report and interactive jobs, follow these steps:\n\n1. Stop the Cognos Service.\n2. Take a physical backup of the Content Store or Notification database.\n3. Select the appropriate folder for your content store or notification database type under `<install>/configuration/schemas/delivery/<dbtype>/`.\n4. Run `NC_DROP_<dbtype>.sql` against the content store or notification database.\n5. Restart Cognos Services.\n\nIf dropping the NC* tables does not resolve the issue, restore the content or notification store from the last backup version. This should help resolve the corruption in the Content Store and clear out the stuck reports and jobs.",
    "id": "TECHQA_TRAIN_Q423_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q424",
    "question": "Unable to unistall Data Studio 3.1.1 on Windows\nWe use Data Studio 3.1.1.0 with DB2 WSE V9.7 FP11 on Windows 2008. While trying to new version of Data Studio 4.1.2, we are able to install it successfully. But unable to uninstall the existing 3.1.1.0, getting the jvm error \"Could not find the main class\". How we can delete it?",
    "ground_truth": "1. Uninstall all products including Install Manager (IM)\n\n2. Reinstall Install Manager (IM) and Data Studio **4.1.2**\n   ",
    "answer": "To uninstall Data Studio 3.1.1, which is failing due to a JVM error, follow these steps as a workaround:\n\n1. **Uninstall as many packages as possible** using the Installation Manager (IM).\n2. **Manually clean up remaining packages**. On Windows, this includes deleting directories such as `C:\\Program Files\\IBM\\{IBMIMShared | SDPShared}`.\n3. **Delete IBM Installation Manager**:\n   - Delete the IM install directory: `C:\\Program Files\\IBM\\Installation Manager\\`.\n   - Delete the AppData directory (IM Agent Data): `C:\\ProgramData\\IBM\\Installation Manager` (on Windows 7 or similar paths for other Windows versions).\n   - Delete the Windows registry entry: `HKEY_LOCAL_MACHINE\\SOFTWARE\\IBM\\Installation Manager`.\n4. **Reinstall Installation Manager**.\n5. **Reinstall Data Studio 4.1.2** and any other necessary products.\n\nThis process should resolve the issue with uninstalling Data Studio 3.1.1 due to the known limitation when having two versions installed. If you encounter further issues, consider contacting IBM support or submitting a Request For Enhancement.",
    "id": "TECHQA_TRAIN_Q424_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q425",
    "question": "Upgrading the feature level to 8 for a VOB and ACLs\nWe have upgraded to Clearcase version 8.0.1.3  ( on Windows 2008 Server) \nHow to upgrade the feature level of a single VOB from 5 to 8 ?",
    "ground_truth": "1. Run the command **cleartool chflevel -replica <new feature level> replica:<replica name>@\\<vob tag>**\n2. Run the command **cleartool chflevel -family <new feature level> vob:\\<vob tag>**",
    "answer": "To upgrade the feature level of a single VOB from 5 to 8, follow these steps:\n\n1. Open a command prompt and navigate to the VOB tag.\n2. Mount the VOB and change the directory into the VOB tag.\n3. Describe the VOB to show the current feature level using the command: `cleartool describe -long vob:.`\n4. Determine the replica name (by default, it is \"original\") using the command: `cleartool lsreplica`\n5. Change the feature level by executing the following two commands:\n   - `cleartool chflevel -replica 8 replica:original@\\<vob tag>`\n   - `cleartool chflevel -family 8 vob:\\<vob tag>`\n6. Describe the VOB again to show the new feature level using the command: `cleartool describe -long vob:.`\n\nNote: If the VOB is used in a UCM environment, ensure that the PVOB and all Component VOBs are at the same feature level to utilize the features of that level. Also, be aware of the considerations for replicated VOBs as mentioned in the MultiSite Administrator's Guide.",
    "id": "TECHQA_TRAIN_Q425_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q429",
    "question": "Does Portal 7.0.0.2 CF20 support upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60?\nDoes Portal 7.0.0.2 CF20 support upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60?",
    "ground_truth": "1. Obtain the fix from DB2 on **z/OS support** or **IBMLINK**.",
    "answer": "The provided context does not specifically mention the DB2 JDBC Driver versions 4.11.77 and 4.18.60, nor does it explicitly state the compatibility of upgrading from one version to the other for WebSphere Portal 7.0.0.2 CF20. The context primarily discusses the compatibility of WebSphere Portal with various DB2 versions and fix packs, along with required APARs for certain configurations. Without direct information on the JDBC driver versions, I don't know if Portal 7.0.0.2 CF20 supports upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60.",
    "id": "TECHQA_TRAIN_Q429_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q430",
    "question": "DASH 3.1.2.1 to 3.1.3.0 taking long time\nDASH 3.1.2.1 to 3.1.3.0 taking long time. How to fix this?",
    "ground_truth": "1. Use the upgrade script to initiate the upgrade.\n   The script is required to start the upgrade process. The script provides the non-root user, who originally installed the Jazz for Service Management instance, with the necessary permissions for the upgrade.",
    "answer": "The provided context does not directly address the issue of the DASH 3.1.2.1 to 3.1.3.0 upgrade taking a long time. The context discusses a permission denied error when upgrading Jazz for Service Management to Version 1.1.3.0 using Installation Manager and provides a script to resolve this specific issue. \n\nTo fix the issue of the DASH upgrade taking a long time, I don't know the solution based on the provided context. The context does not provide information related to the duration of the upgrade process or any potential causes for delays. If you're experiencing issues with the upgrade taking a long time, I recommend checking the system logs for any errors or warnings, verifying that the system meets the necessary hardware and software requirements for the upgrade, and potentially reaching out to IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q430_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q431",
    "question": "Install path under \"Program Files\"\nMy path for the OS agent is e:\\Program Files\\IBM. Is there any issues or underlying problems if I install under \"Program Files\"? Just want to make sure no issues with a \"space\" in the install path.",
    "ground_truth": "1. Specify location with no **spaces** for the installation path.",
    "answer": "Installing under \"Program Files\" with a space in the path may cause issues. According to the provided context, some system settings may not allow installation paths with blanks or spaces. \n\nTo avoid potential problems, you have two options:\n\n1. Remove the space in the directory path and install the OS agent in a directory without spaces, such as `E:\\IBM`.\n2. Check the NTFS 8.3 name creation setting and enable it to allow installation on a directory path with spaces. You can do this by checking the value of `NtfsDisable8dot3NameCreation` in the registry location `HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem` and running the command `fsutil 8dot3name query E:` to verify the 8.3 name creation setting for the volume where you plan to install.\n\nIt's recommended to choose the first option to avoid any potential issues with spaces in the installation path.",
    "id": "TECHQA_TRAIN_Q431_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q440",
    "question": "SCM check analyses showing as not reported in the SCA user interface\nSCM check analyses showing as <not reported> the SCA user interface.\n\nCheck analyses in the SCA interface are showing as in the SCA user interface where at one point they were activated and returning data. Now they are not activated and not returning data.\n\nHow do I solve this issue?",
    "ground_truth": "1. Have an active operator reactivate the check analyses.\n   \n2. Run a new import in **SCA**.\n",
    "answer": "To solve the issue of SCM check analyses showing as \"not reported\" in the SCA user interface, you need to have an active operator reactivate the check analyses and then run a new import in SCA. It is recommended to create a dedicated operator account for activating the SCM check analyses, which should never be deleted to prevent this issue from happening again.",
    "id": "TECHQA_TRAIN_Q440_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q441",
    "question": "How to serve static images from our HTTP Server instead of WebSphere 8.5 application?\nHow to serve static images from our HTTP Server instead of WebSphere 8.5 application?",
    "ground_truth": "1. Use **fileServingEnabled=\"true\"** in the **ibm-web-ext.xmi** file.\n   This will cause the plug-in to use a wildcard entry for the context-root of your web application.\n   ",
    "answer": "To serve static images from your HTTP Server instead of WebSphere 8.5 application, follow these steps:\n\n1. Create a subdirectory called \"static\" under the IHS DocumentRoot directory and put the static files you want IHS to serve into that directory.\n2. In your web application, reference those files using relative references like \"static/picture.jpg\".\n3. In the IHS config, use RewriteCond and RewriteRule to watch for these references and redirect to get them from IHS. For example:\n\n```\n<ifModule mod_rewrite.c>\nRewriteEngine on\nRewriteRule ^/myapp/static/(.*) /static/$1 [PT]\n</ifModule>\n```\n\nThis will rewrite the URI to /static/* and serve the file from the static directory under IHS DocumentRoot.\n\nNote: Make sure to set `fileServingEnabled=\"true\"` in the `ibm-web-ext.xmi` file to serve other static files from the web application in WAS.",
    "id": "TECHQA_TRAIN_Q441_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q443",
    "question": "How to get debug information when the IBM Content Navigator Installer is failing on the Unix Platform?\nHow to get debug information when the IBM Content Navigator Installer is failing on the Unix Platform?",
    "ground_truth": "1. Enter one of the following commands based on the shell you are using: **export LAX_DEBUG=true**, **setenv LAX_DEBUG true**, **LAX_DEBUG=true**, or **set LAX_DEBUG**.\n\n2. Run your installer.\n",
    "answer": "To get debug information when the IBM Content Navigator Installer is failing on the Unix Platform, you need to enable debug output before running the installer. To do this, enter one of the following commands at the command line, depending on your Unix shell:\n\n- `export LAX_DEBUG=true`\n- `setenv LAX_DEBUG true`\n- `LAX_DEBUG=true`\n- `set LAX_DEBUG`\n\nThen, run the installer. This will produce output that can help debug the installer.\n\nIf you want to save the debug output to a file, set `LAX_DEBUG=file` and then run the installer. After the installation is complete, a file named `jx.log` will be generated in the same directory as your installer, containing the entire debug output.",
    "id": "TECHQA_TRAIN_Q443_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q449",
    "question": "How do I identify people in scope across Matters in Atlas?\nHow do I identify people in scope across Matters in Atlas?",
    "ground_truth": "1. Create a query by joining REP_PEOPLE_INSCOPE_VW view with other views.\n   Join the REP_PEOPLE_INSCOPE_VW view with the **REP_MATTER_VW**, **REP_REQUEST_VW**, **REP_NOTICES_VW**, and **REP_PERSON_VW** views to create a query.",
    "answer": "To identify people in scope across Matters in Atlas, you can use the REP_PEOPLE_INSCOPE_VW view and create a query by joining it with other relevant views such as REP_MATTER_VW, REP_REQUEST_VW, REP_NOTICES_VW, and REP_PERSON_VW. For more details, refer to the reporting views documentation at the provided IBM Knowledge Center link: https://www.ibm.com/support/knowledgecenter/SS5JP8_6.0.3/com.ibm.aps.use.doc/apsrv0044.html.",
    "id": "TECHQA_TRAIN_Q449_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q452",
    "question": "Cannot start the IBM Content Collector Configuration Store Service\nHow to resolve when the IBM Content Collector Configuration Store Service cannot be started?",
    "ground_truth": "1. Shutdown the IBM Content Collector Configuration Store Service if it is running.\n\n2. Make a backup copy of all files under the directory: **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore**\n\n3. Free up disk space on the drive.\n\n4. Delete the following files:\n   - **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\logs\\* **\n   - **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solmsg.out**\n   - **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solerror.out**\n\n5. If restoring the configuration store to a previously backed up copy is required, run **afuConfigStoreTool -backup**. See production documentation for more information on running this tool. Otherwise, proceed to the next step.\n\n6. Restart IBM Content Collector services.",
    "answer": "To resolve the issue of the IBM Content Collector Configuration Store Service not starting, follow these steps:\n\n1. **Shutdown the service**: If the service is running, shut it down.\n2. **Backup configuration files**: Make a copy of all files under `C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore`. Ensure you can see hidden folders by adjusting your Folder and Search options.\n3. **Free up disk space**: Ensure there is enough disk space available on the drive.\n4. **Delete specific files**: Delete the files under `C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\logs\\`, `solmsg.out`, and `solerror.out`. Do not delete the `logs` folder itself.\n5. **Restore from backup (if necessary)**: If you need to restore the configuration store from a previous backup, use the `afuConfigStoreTool -backup` command. Refer to the production documentation for more information.\n6. **Restart services**: Restart the IBM Content Collector services.\n\nBy following these steps, you should be able to resolve the issue caused by database corruption due to the transaction log being corrupted when the server runs out of disk space.",
    "id": "TECHQA_TRAIN_Q452_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q454",
    "question": "Column Analysis on Informix database using odbc connector fails with error SQLSTATE = HY000: Native Error Code = -256\nColumn Analysis on Informix database using odbc connector fails with error SQLSTATE = HY000: Native Error Code = -256",
    "ground_truth": "1. Set the Transaction handling>Isolation Level from **none** to **Auto-Commit**.\n   ",
    "answer": "To resolve the error SQLSTATE = HY000: Native Error Code = -256 when performing Column Analysis on an Informix database using an ODBC connector, you should set the Transaction handling > Isolation Level from \"none\" to \"Auto-Commit\". This change should help resolve the \"Transaction not available\" error reported by the ODBC Informix Wire Protocol driver.",
    "id": "TECHQA_TRAIN_Q454_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q455",
    "question": "How can I query the Derby database in Portal via SQL statements?\nI have a Portal system I just installed. I have not yet run database-transfer to copy the data from the Derby database to a DB2, Oracle, or SQL Server database. I don't wish to transfer to an external database and I have a need to run a SQL query against a table or two in the Derby database to troubleshoot an issue. \r\nHow can I perform this action?",
    "ground_truth": "1. Use **dblook** and **ij** utilities to obtain the data and structure of the WebSphere Portal database.",
    "answer": "To query the Derby database in Portal via SQL statements, you can use the ij utility, which is a command-line SQL processor. Here are the steps:\n\n1. Open a command prompt or terminal window and change the directory to the location of the ij utility, typically found in the `<was_root>/AppServer/derby/bin/embedded` directory.\n2. Start the ij utility by entering the command `ij`.\n3. You will see the ij shell with the prompt `ij>`.\n4. Connect to the Derby database by entering the command `connect 'jdbc:derby:C:\\IBM\\WebSphere\\wp_profile\\derby\\wpsdb';` (replace the path with the actual location of your Derby database).\n5. Set the schema to the desired one, for example, `set schema=release;`.\n6. Run your SQL query, for example, `select * from user_desc where oid=1000;`.\n7. You can also run a SQL script by using the `run` command, for example, `run 'myquery.sql';`.\n\nNote: Make sure to back up your Derby database before making any changes, and stop the Portal server before accessing the database.",
    "id": "TECHQA_TRAIN_Q455_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q458",
    "question": "Error TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during import-nodes sub-task\nError TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during import-nodes sub-task",
    "ground_truth": "1. Navigate to **Applications > WebSphere enterprise applications > JavaContentRepository**.\n   \n2. Target a specific application status.\n   \n3. Check the box for the **WebSphere_Portal** server.\n   \n4. Click **Enable Auto Start**.\n   \n5. Save changes.\n   \n6. Restart **Portal**.\n\n7. After making this change, attempt the CF upgrade again.\n   ",
    "answer": "To resolve the Error TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during the import-nodes sub-task, follow these steps:\n\n1. Go to the WAS Admin Console.\n2. Navigate to Applications > WebSphere enterprise applications > JavaContentRepository.\n3. Click on Target specific application status.\n4. Check the box for the WebSphere_Portal server.\n5. Click Enable Auto Start.\n6. Save the changes.\n7. Restart Portal.\n\nAfter making these changes, attempt the CF upgrade again. This should resolve the issue caused by the previously disabled autostart on several applications, which was intended to improve Portal startup time.",
    "id": "TECHQA_TRAIN_Q458_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q460",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM\u00ae SPSS\u00ae Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message: \n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction. \nNo additional authorizations are permitted on this code. \nWhat should I do?\n\n\n\nThis dW Answers question is about an IBM document with the Title: \nSPSS Student Version and Graduate Pack Resources",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To resolve the issue with transferring your SPSS 24 license key to a new computer, you should contact the vendor from whom you originally purchased the software. The error message \"You are not allowed to generate any more new licenses\" suggests that the license key has been used the maximum number of times allowed.\n\nAccording to the provided context, for installation and licensing issues on the Student version and Graduate pack, you should reach out to one of the following vendors for support:\n\n1. Hearne: http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ\n2. On the Hub: http://onthehub.com/\n3. StudentDiscounts.com: http://studentdiscounts.com/contact-us.aspx\n4. JourneyEd: https://www.journeyed.com/contact\n5. thinkEDU: https://thinkedu.desk.com/\n6. Studica: http://www.studica.com/technical-support\n\nThey should be able to assist you with reactivating or transferring your license key to the new computer.",
    "id": "TECHQA_TRAIN_Q460_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q461",
    "question": "How can I configure TIP to clear the ARGUS cache without having to do a system restart?\nArgus stores it's role authorizations in memory cache, and is not cleaned out unless the TIP is restarted. The \"cacheTime\" variable in the configFile.xml configuration file controls this, which is set to -1 by default. If the number of TIP roles is high, it can cause Java OOM errors.",
    "ground_truth": "1. Configure \u2018cacheTime\u2019 to non -1 value.\n   Set the value of 'cacheTime' to **1200000**, which is equivalent to 20 minutes.\n2. Restart the TIP server, which is normally referred to as **server1**.",
    "answer": "To configure TIP to clear the ARGUS cache without having to do a system restart, you need to modify the `cacheTime` variable in the `config.xml` file. \n\n1. Locate the `config.xml` file in the `<TIP_HOME>/profiles/TIPProfile/config/cells/TIPCell/commonauthz/` directory.\n2. Open the file and look for the `cacheTime` variable, which is set to `-1` by default.\n3. Change the value of `cacheTime` to a non-negative value, such as `1200000` (which is equivalent to 20 minutes).\n4. Save the changes to the `config.xml` file.\n5. Restart the TIP server (normally `server1`) to apply the changes.\n\nThis will configure TIP to clear the ARGUS cache at the specified interval, helping to prevent Java OutOfMemory errors caused by a large number of TIP roles.",
    "id": "TECHQA_TRAIN_Q461_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q466",
    "question": "What happens if I lost my seed and salt value?\nIn ISDS, what happens if I lost my seed and salt value?\n\n\n\nThis dW Answers question is about an IBM document with the Title:\nOpen Mic Webcast: Configuring SDS 8.0.1 Virtual Appliance with a remote DB2 database - Tuesday, 17 Jan 2017 [presentation slides are attached; includes link to replay]",
    "ground_truth": "1. Create a new instance with a new encryption seed value.\n   \n2. Use the **db2ldif** utility to export data.\n   \n3. Use the **ldif2db** utility to import data.",
    "answer": "If you lost your seed and salt value in ISDS, there is no way to recover the seed value used during instance creation. The only workaround is to create a new instance with a new encryption seed value and then use the db2ldif and ldif2db utilities to export and import data respectively, preserving the data and passwords. \n\nTo do this, follow these steps:\n\n1. Set up a new instance with a new encryption seed value.\n2. Note the new encryption seed and salt value generated by the new server instance.\n3. Use the db2ldif utility to export data from the old instance with the forgotten encryption seed, using the new encryption seed and salt value.\n4. Use the ldif2db utility to import the exported data into the new server instance.\n\nThis will allow you to recover your data, but you will not be able to recover the original seed and salt value.",
    "id": "TECHQA_TRAIN_Q466_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q467",
    "question": "How can we change the password for LDAP bind user?\nWe need to change our LDAP bind user due to security requirement. Is there any documentation for the procedure?",
    "ground_truth": "1. Follow a coordinated update procedure when needing to change the user account and/or password.\n",
    "answer": "To change the password for the LDAP bind user, follow these steps:\n\n1. **Change the password on the LDAP server**: Use the LDAP interface to change the password for the existing CE Directory Service account, or create a new user account if needed.\n2. **Update FEM**:\n\t* Go to Domain properties > Directory Configuration > Select Directory Configuration > click on the Modify button.\n\t* In the General Tab, modify the Directory Service User with the new user's full distinguish name (DN).\n\t* Click on the Change password check box, enter the new password, and click OK.\n3. **Update the application server's directory configuration**:\n\t* For Websphere: Go to Global Security > Configure under User Account Repository > Modify Bind Distinguished Name (DN) > Modify Bind Password > click OK and Save changes.\n\t* For WebLogic: Go to Security Realms > myrealm > Providers > ldap provider and click on \"Provider Specific\" tab, then change \"Principal\" and \"Credential\".\n\t* For JBoss: Edit \"login-config.xml\" in the <JBoss Home>\\server\\<CE Server>\\conf directory, find \"FileNet\" application-policy, and change bindDN/bindCredential in the login module.\n4. **Restart the application server**: After completing the above steps, restart the application server to incorporate the changes.\n5. **Update the CE Bootstrap user (if applicable)**: If the same user account is used as the CE Bootstrap user, update the BootstrapConfig.properties file according to the documentation: http://publib.boulder.ibm.com/infocenter/p8docs/v4r5m1/index.jsp?topic=/com.ibm.p8.doc/admin/security/sec_how_change_bootstrap_pwd.htm\n\nRefer to the IBM documentation for detailed instructions and additional information: http://publib.boulder.ibm.com/infocenter/p8docs/v4r5m1/index.jsp?topic=/com.ibm.p8.doc/admin/security/sec_how_update_os.htm and http://publib.boulder.ibm.com/infocenter/p8docs/v4r5m1/index.jsp?topic=/com.ibm.p8.doc/admin/security/sec_how_change_bootstrap_pwd.htm.",
    "id": "TECHQA_TRAIN_Q467_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q470",
    "question": "Does Logout button get disabled in ICM for SSO with Tivoli Access Manager ?\nDoes Logout button get disabled in ICM for SSO with Tivoli Access Manager ?",
    "ground_truth": "1. Remove the **Log Out** option by customizing the banner user session context menu.",
    "answer": "The provided context does not specifically mention ICM (IBM Case Manager) or Tivoli Access Manager. It discusses an issue with IBM Content Navigator in a SPNEGO/Kerberos Single Sign-On environment where the Log Out option is enabled but should be disabled. \n\nGiven the information, I don't know if the Logout button gets disabled in ICM for SSO with Tivoli Access Manager, as the context does not provide enough information to solve this specific problem.",
    "id": "TECHQA_TRAIN_Q470_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q472",
    "question": "The Ping Probe will not start with SetUID configured\nThe Netcool OMNIbus Ping Probe will not start with SetUID configured. What should I check?",
    "ground_truth": "1. Change the owner to **root** and permissions to **setuid**.\n   \n2. Put either a copy of the required libraries, or a symbolic link to the required libraries in one of the trusted paths.\n   The trusted paths include **/lib** or **/usr/lib**.",
    "answer": "To resolve the issue with the Ping Probe not starting with SetUID configured, you should:\n\n1. Change the owner to root and permissions to setuid:\n   - `cd $OMNIHOME/probes/aix5/`\n   - `chown root:root nco_p_ping`\n   - `chmod +s nco_p_ping`\n\n2. Put a symbolic link to the required libraries in a trusted path like `/usr/lib`. The required libraries can be identified by running:\n   - `dump -H $NCHOME/omnibus/platform/aix5/nco_p_ping`\n\nExample symbolic links to create in `/usr/lib`:\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libgsk*`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libPa_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libnetcool_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libslclient_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libOpl_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libsybct_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libsybcs_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libsybtcl_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libsybcomn_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libtre.a`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libsybintl_r.so`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libicuuc40.a`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libicui18n40.a`\n   - `ln -s /opt/IBM/netcool/platform/aix5/lib/libicudata40.a`\n\nNote: It's recommended to create these symbolic links again after applying any Fix Pack for OMNIbus core.",
    "id": "TECHQA_TRAIN_Q472_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q473",
    "question": "Why Summarization and pruning are failing with SQL Error Code = -4220 on AIX_LPAR table?\nSummarization and pruning are failing with SQL Error Code = -4220 on AIX_LPAR table.  What's the fix?",
    "ground_truth": "1. Update the invalid data with a valid **UTF-8** character string.",
    "answer": "The issue with Summarization and pruning failing with SQL Error Code = -4220 on the AIX_LPAR table is due to invalid UTF-8 data in a character column. To resolve this, you can either update the invalid data with a valid UTF-8 character string or set the JCC configuration property `db2.jcc.charsetDecoderEncoder=3` to return the Unicode REPLACEMENT CHARACTER (U+FFFD) instead of throwing an exception. \n\nTo identify the invalid data, you can use the HEX function, for example: `SELECT HEX(column_name) FROM AIX_LPAR`. This will help you find the byte values in the column that are causing the issue. \n\nOnce you've identified the invalid data, you can update it with a valid UTF-8 character string. Alternatively, if you're using a compatible JCC driver version (DB2 LUW 9.5 Fix Pack 8 or later, DB2 LUW 9.7 Fix Pack 5 or later, or DB2 10.1 onwards), you can set the `db2.jcc.charsetDecoderEncoder=3` property to avoid the exception.",
    "id": "TECHQA_TRAIN_Q473_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q475",
    "question": "How can I fix blank pull down  \"Console Settings\" menu after successful install of JazzSM 1.2.1.1 and WebSphere 8.5.5.9?\nWebSphere version 8.5.5.9 didn't include jar files that were available in previous releases of WebSphere that are required by DASH for various tasks.",
    "ground_truth": "1. Download DASH **3.1.2.1** Cumulative Patch 5 from the provided site.\n   You can download the missing jar files from the following URL: **http://www-933.ibm.com/support/fixcentral/swg/selectFixes?parent=ibm~Tivoli&product=ibm/Tivoli/Jazz+for+Service+Management&release=1.1&platform=All&function=all**.",
    "answer": "To fix the blank \"Console Settings\" menu after a successful install of JazzSM 1.2.1.1 and WebSphere 8.5.5.9, you need to download and install DASH 3.1.2.1 Cumulative Patch 5. This patch includes the missing jar files required by DASH that were not included in WebSphere 8.5.5.9. You can download the patch from the IBM Fix Central website: http://www-933.ibm.com/support/fixcentral/swg/selectFixes?parent=ibm~Tivoli&product=ibm/Tivoli/Jazz+for+Service+Management&release=1.1&platform=All&function=all. After installation, you can verify that the patch has been installed by running the command `<JazzSM_HOME>/ui/bin/consolecli Version` and checking for the patch number in the output.",
    "id": "TECHQA_TRAIN_Q475_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q478",
    "question": "How to define shared libraries for ODM ruleApps on WAS traditional?\nWhat is the proper way to define a shared lib for RuleApps without giving up the isolated mode of the XU resource adapter? Is it \"works as designed\" that isolating of the XU prevents the resource adapter from seeing shared lib classes from other classloaders?",
    "ground_truth": "1. Go to the **JDBC Provider** and enable 'isolate the resource provider'.\n   Enabling 'Isolate this resource provider' ensures that only the jar specified in the classpath will be used for all the datasources under that particular JDBC provider.",
    "answer": "To define shared libraries for ODM ruleApps on WAS traditional without giving up the isolated mode of the XU resource adapter, you should enable \"Isolate this resource provider\" on the JDBC Provider. This setting ensures that only the specified jar in the classpath is used for all datasources under that JDBC provider, preventing conflicts between multiple versions of driver jars.\n\nHowever, when \"Isolate this resource provider\" is enabled, the resource adapter will not be able to see shared library classes from other classloaders. This is the expected behavior, as the isolation is designed to prevent conflicts between different versions of driver jars.\n\nTo use shared libraries with isolated resource providers, you will need to configure the shared library at the same scope as the JDBC provider, and ensure that the datasource using the shared library is referenced from the application using a resource reference.\n\nIn summary, to define shared libraries for ODM ruleApps on WAS traditional while maintaining isolated mode:\n\n1. Enable \"Isolate this resource provider\" on the JDBC Provider.\n2. Configure the shared library at the same scope as the JDBC provider.\n3. Reference the datasource using the shared library from the application using a resource reference.\n\nNote: This solution is based on the provided context, which focuses on JDBC providers and resource adapters. If your specific use case involves other components or configurations, additional steps or considerations may be necessary.",
    "id": "TECHQA_TRAIN_Q478_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q483",
    "question": "How do I tell when there are mismatched MQ jars in my application server?\nMismatched jar files can cause strange and unpredictable errors when using the MQ JMS classes.",
    "ground_truth": "1. Use the **mqjavalist.sh** script.\n   This script simplifies the process of finding and eliminating duplicate copies of the **MQ** jar files on Linux and UNIX systems.",
    "answer": "To determine if there are mismatched MQ jars in your application server, you can use the `mqjavalist.sh` script. Here's how:\n\n1. Run the `mqjavalist.sh` script and review its output to see where copies of the MQ jar files have been found.\n2. Check the implementation version of the `com.ibm.mqjms.jar` file in the output. If the versions are not in sync, it may indicate a mismatch.\n3. Look for duplicate copies of the MQ jar files in the Java CLASSPATH or bundled in Java applications (.ear,.war, and.jar files).\n4. If you find any mismatched or duplicate jar files, remove them and rely on the ones from the installed MQ Resource Adapter instead.\n\nBy following these steps, you should be able to identify and resolve any issues related to mismatched MQ jars in your application server.",
    "id": "TECHQA_TRAIN_Q483_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q489",
    "question": "Recurrent RES StaleConnectionException\nHow to prevent rule execution failing because of recurrent StaleConnectionException on ODM 8.8 Rule Execution Server?",
    "ground_truth": "1. Set the Minimum connections to **0**.\n\n2. Set the values for **Unused timeout** and **Reap timeout** so that the sum does not exceed any network level idle connection timeout.\n",
    "answer": "To prevent recurrent StaleConnectionException on ODM 8.8 Rule Execution Server, you can configure the WebSphere Application Server data source connection pool as follows:\n\n1. Set the Minimum connections to 0. This will prevent connections from being kept in the pool to meet the minimum requirement, even if they have been idle for longer than the Unused timeout.\n2. Set the values for Unused timeout and Reap timeout such that their sum does not exceed any network level idle connection timeout.\n\nBy making these changes, you can help eliminate occurrences of StaleConnectionException and prevent rule execution from failing due to this issue. For more detailed information, you can refer to the WebSphere Application Server documentation on configuring data source connection pools.",
    "id": "TECHQA_TRAIN_Q489_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q490",
    "question": "TWS / DWC and WebSphere 8.5.5.4+\nWebSphere for TWS & DWC were upgraded to 8.5.5.4 on most servers in a particular environment. However, any TWS servers that still had 8.5.5.2, could no longer be seen by the new DWC / WAS 8.5.5.4 servers. Those lower WAS version engines could not be added to the DWC.\n\nErrors seen are:\n\n     AWSUI0833E The operation could not be completed. There has been a communication failure. \n     The internal message is: AWSJCO005E WebSphere Application Server has given the following error: Error getting WsnNameService properties.",
    "ground_truth": "1. Configure your **TWS** engines to use **TLS** instead of SSL",
    "answer": "To resolve the issue of TWS servers with WebSphere 8.5.5.2 not being visible to the new DWC/WAS 8.5.5.4 servers, you need to configure your TWS engines to use TLS instead of SSL. \n\nHere are the steps to follow:\n\n1. Backup and edit the following files:\n   - `TWA_HOME/WAS/TWSProfile/config/cells/TWSNodeCell/security.xml`\n   - `TWA_HOME/WAS/TWSProfile/properties/ssl.client.props`\n   - `TWA_HOME/WAS/TWSProfile/temp/ssl.client.props`\n\n2. In `security.xml`, find `sslProtocol` and change `\"SSL_TLS\"` to `\"TLS\"`. Also, find `ssl.protocol` and change `value=\"SSL\"` to `value=\"TLS\"`.\n\n3. In `ssl.client.props` files, find `com.ibm.ssl.protocol=SSL` and change it to `com.ibm.ssl.protocol=TLS`.\n\n4. Stop and restart WAS.\n\nNote: After making these changes, your TWS engines will be using TLS. If you have any DWC 9.2 or 9.1 installations that need to connect to these engines, you will also need to reconfigure them to use TLS by making the same changes in their respective `security.xml` and `ssl.client.props` files.\n\nAdditionally, be aware that configuring TWS engines to use TLS may impact the Dynamic Agent, so it's recommended to review technote 1689332 for further information.",
    "id": "TECHQA_TRAIN_Q490_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q494",
    "question": "Why do we observe the transaction rollback errors J2CA0024E and DSRA0080E with Oracle 12c and how can we fix it?\nWe are using BPM Advanced v8.5.6 in connection with the Oracle JDBC Driver 12.1.0.1.0. We observe many database transaction rollback exceptions:\n\n     J2CA0024E: Method rollback, within transaction branch ID <null> of resource pool jdbc/BPEDB, caught com.ibm.ws.exception.WsException: DSRA0080E: An exception was received by the Data Store Adapter. See original exception message: Could not rollback with auto-commit set on. with SQL State : 99999 SQL Code : 17274\n\nDue to the technote \"Advanced database support for IBM BPM Standard, IBM BPM Advanced, and IBM Business Monitor on distributed platforms\" this is a supported configuration.\n\nWhy do we observe these errors and how can we fix it?",
    "ground_truth": "1. Add the following JVM property to the Monitor server JVM: **oracle.jdbc.autoCommitSpecCompliant=false**",
    "answer": "The transaction rollback errors J2CA0024E and DSRA0080E are observed because the Oracle 12c JDBC driver has a different behavior regarding auto-commit compared to earlier versions. To fix this issue, you need to add a JVM property to make the Oracle 12c JDBC driver behave in a way that is compatible with IBM BPM Advanced v8.5.6.\n\nAdd the following JVM property to your server:\n\n`oracle.jdbc.autoCommitSpecCompliant=false`\n\nThis property will ensure that the Oracle 12c JDBC driver behaves correctly with regards to auto-commit, preventing the transaction rollback errors.",
    "id": "TECHQA_TRAIN_Q494_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q497",
    "question": "Login to DASH  returned  \"Page cannot be displayed\" error\nLogin to DASH  returned  \"Page cannot be displayed\" error",
    "ground_truth": "1. Change the directory to **<JazzSM Home>/ui/bin**\n\n2. Run the following command: ./consoleLogCollector.sh or .bat\n\n3. Send us the console_logs.zip file located in **<JazzSM Home>/ui** directory\n\n4. Attach the console_logs.zip file to the associated Problem Management Record (PMR)\n\n5. Include the time the issue was reproduced in the PMR update\n\n6. Provide the DASH version info using the command: **<JazzSM Home>/ui/bin/consolecli.sh Version**\n\n7. Upload the resulting output file to the PMR",
    "answer": "To resolve the \"Page cannot be displayed\" error when logging into DASH, I recommend the following steps:\n\n1. Enable tracing for the DASH service by following these steps:\n\t* Log into the DASH and navigate to Console Settings > Websphere Administrative Console.\n\t* Go to Troubleshooting -> Logs & Trace.\n\t* Click on Server1 -> Select Diagnostic Trace Service and increase the Maximum Number of Historical Files from 1 to 10.\n\t* Click Apply, then select Change Log Detail Levels.\n\t* Enable tracing for the DASH process by clicking on the Runtime tab or Configuration tab (for persistent tracing).\n\t* Replace the trace string with the recommended settings: *=info: com.ibm.isc.*=all: com.ibm.isclite.*=all: com.ibm.iscportal.*=all: com.ibm.isclite.service.datastore.consoleproperties.*=INFO\n2. Reproduce the issue and note the time it occurs.\n3. Run the log collector program by changing the directory to <JazzSM Home>/ui/bin and running the command./consoleLogCollector.sh or.bat.\n4. Send the console_logs.zip file located in <JazzSM Home>/ui directory to the support team along with the time the issue was reproduced and the DASH version info obtained by running <JazzSM Home>/ui/bin/consolecli.sh Version.\n\nBy following these steps, you should be able to collect the necessary logs to troubleshoot the issue and provide more information to the support team to assist with resolving the problem.",
    "id": "TECHQA_TRAIN_Q497_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q503",
    "question": "Can I remove the write permissions for \"other\" in ../ibm/common/acsi?\nCan I remove \"write\" permission for \"other\" for all the sub-directories and files under the following directory,\n\n    /usr/ibm/common/acsi  \n    /var/ibm/common/acsi  \n\nWill it cause any problem?",
    "ground_truth": "1. Remove world **writable** permissions from DE directories.",
    "answer": "Yes, you can remove the write permissions for \"other\" in the specified directories and their sub-directories and files. According to the context, it is safe to remove world-writable permissions from these directories and files, and it will not impact functionality. You can use the command `chmod o-w` to remove the write permissions for \"other\". \n\nFor the directories `/usr/ibm/common/acsi` and `/var/ibm/common/acsi`, you can use the following commands to remove the write permissions for \"other\" recursively:\n\n```bash\nchmod -R o-w /usr/ibm/common/acsi\nchmod -R o-w /var/ibm/common/acsi\n```\n\nThis will remove the write permissions for \"other\" for all the sub-directories and files under these directories.",
    "id": "TECHQA_TRAIN_Q503_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q504",
    "question": "OMNIBUS   nco_p_mttrapd : Malformed traps\nHow can you determine why the MTTrapd [SNMP] probe drops traps?",
    "ground_truth": "1. Ensure that the traps are being dropped from specific devices under normal load.\n2. Use **snoop**, **tcpdump** or **Wireshark** to capture the traps that are being dropped on the probe servers port.",
    "answer": "To determine why the MTTrapd [SNMP] probe drops traps, you can follow these steps:\n\n1. **Verify the load**: Ensure that the traps are being dropped from specific devices under normal load, as high loading can cause traps to be dropped.\n2. **Capture the traps**: Use tools like snoop, tcpdump, or Wireshark to capture the traps on the probe server's port (usually port 162).\n3. **Analyze the captured traps**: Load the captured PCAP file into Wireshark and review the traps visually to check for any issues.\n4. **Check for required fields**: Ensure that the traps have the required fields, including enterprise-oid and uptime, as traps without these fields will be dropped during probe processing.\n5. **Check the protocol**: Try setting the Protocol to 'ALL' in case the trap is being sent as TCP or UDP.\n6. **Verify SNMPv3 configuration**: If using SNMPv3, ensure that each device has a unique creatruser entry in the mttrapd.conf file, including the device's unique engine-id.\n7. **Send logs to support (if necessary)**: If the trap appears to be RFC compliant and the MTTrapd probe is correctly configured, send the PCAP file, debug log, and property file to IBM Tivoli Netcool support for further analysis.\n\nAdditionally, ensure that you have the latest MTTrapd probe and Netcool/OMNIbus fix pack installed before contacting support.",
    "id": "TECHQA_TRAIN_Q504_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q505",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM\u00ae SPSS\u00ae Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message:\n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction.\nNo additional authorizations are permitted on this code.\nWhat should I do?",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To transfer your SPSS 24 license key to a new computer, you should contact the vendor from which you originally purchased the software. According to the provided context, for installation and licensing issues related to the Student Version and Graduate Pack, you need to reach out to your vendor for support. The vendors listed include:\n\n- Hearne\n- On the Hub\n- StudentDiscounts.com\n- JourneyEd\n- thinkEDU\n- Studica\n\nYou are receiving the error message \"Authorization failed.: You are not allowed to generate any more new licenses.\" because your license key has likely reached its maximum number of activations. Your vendor can assist you in resolving this issue, potentially by resetting or reissuing your license key.",
    "id": "TECHQA_TRAIN_Q505_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q507",
    "question": "Why are the users unable to login to Web GUI 8.1 after I modify timeout to 2147483647 in security.xml file ?\nI followed the Web GUI 8.1 reference guide here to switching off the session timeout\n\nhttp://www-01.ibm.com/support/knowledgecenter/SSSHTQ_8.1.0/com.ibm.netcool_OMNIbus.doc_8.1.0/webtop/wip/task/web_adm_settimeout.html\n\nAfter I edited /config/cells/JazzSMNode01Cell/security.xml file, modified timeout setting to 2147483647, users are not able to login anymore.",
    "ground_truth": "1. Navigate to the **<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF** on DASH server.\n\n2. Take a backup of **consoleProperties.xml**.\n\n3. Open **consoleProperties.xml** in edit-mode.\n\n4. Change the value of **LTPAFIX** from true to false.\n\n5. Save the file.\n\n6. Restart the DASH server.",
    "answer": "The issue you're experiencing with users being unable to log in to Web GUI 8.1 after modifying the timeout to 2147483647 in the security.xml file is due to a known condition where setting a very large timeout value causes a login prevention issue. This is because the timeout parameter used in the security.xml file is a WAS setting, but DASH uses a JavaScript call (settimeout) which is affected by very large timeout values.\n\nTo resolve this issue, you need to set the custom property LTPAFIX in the consoleProperties.xml to \"false\". Here are the steps to follow:\n\n1. Navigate to `<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF` on your DASH server.\n2. Take a backup of `consoleProperties.xml`.\n3. Open `consoleProperties.xml` in edit mode.\n4. Search for \"LTPAFIX\" and change the value from \"true\" to \"false\".\n\nExample:\nBefore:\n```xml\n<consoleproperties:console-property id=\"LTPAFIX\" value=\"true\"/>\n```\nAfter:\n```xml\n<consoleproperties:console-property id=\"LTPAFIX\" value=\"false\"/>\n```\n5. Save the file.\n6. Restart the DASH server.\n\nThis should resolve the issue and allow users to log in again.",
    "id": "TECHQA_TRAIN_Q507_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q512",
    "question": "Installing RAA plugin in RDz\nHi,\n\nI'm trying to install the RAA plugin in RDz.\n\nBut the installation manager mentions that it is not compatibble with an other package, in casu the IBM CICS Explorer SDK. But I would like to install both, is this not possible?",
    "ground_truth": "1. Find the jar files by opening the **RAAiInstallRepository.zip** file and looking in thepluginsfolder for these two files: **com.ibm.dmh.raai_*.jar**, **com.ibm.raa.integrate.doc_*.jar**\n\n2. Right click on the properties to find the shortcut used to start RDz.\n\n3. Look at the Target property to see where **eclipse.exe** resides.\n   For example: C:\\Program Files\\IBM\\SDP.\n\n4. Find the dropinssubdirectory.\n\n5. Create a dropinssubdirectory if one does not exist.\n\n6. Copy the two jar files above to thedropinssubdirectory.\n\n7. Restart RDz (Run as administrator).\n\n8. Verify you have an **Asset Analyzer** entry in the left pane after RDz restarts by clicking on Window > Preferences from the menu.",
    "answer": "To install the RAA plugin in RDz, you can manually copy the plug-in jar files to the Eclipse dropins folder. This is because the RAAi installation program does not yet support RDz 9.0, and there is a compatibility issue with the IBM CICS Explorer SDK.\n\nHere are the steps to follow:\n\n1. Extract the RAAiInstallRepository.zip file and find the two jar files: com.ibm.dmh.raai_*.jar and com.ibm.raa.integrate.doc_*.jar.\n2. Find the Eclipse dropins subdirectory by checking the Target property of the RDz shortcut.\n3. Create a dropins subdirectory if it does not exist.\n4. Copy the two jar files to the dropins subdirectory.\n5. Restart RDz as an administrator.\n6. Verify that the Asset Analyzer entry appears in the left pane after restarting RDz.\n\nNote that this manual installation method allows you to install both the RAA plugin and the IBM CICS Explorer SDK, despite the compatibility issue reported by the installation manager.",
    "id": "TECHQA_TRAIN_Q512_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q514",
    "question": "Why is WAS sending duplicate requests though our Portal application user clicks submit button only once?\nIs there any setting in WAS,Portal or IHS that can help prevent duplicate requests?",
    "ground_truth": "1. Use **ServerIOTimeoutRetry** to decrease the number of retries.",
    "answer": "To prevent duplicate requests in your Portal application, you can try adjusting the `ServerIOTimeoutRetry` setting in the web server plug-in configuration. This setting, introduced by the plug-in APAR PM70559, controls the number of retries due to ServerIOTimeout. By setting this value to a lower number or to 0, you can limit the number of retries and potentially prevent duplicate requests.\n\nAdditionally, you can also review the `GetDWLMTable` setting in the plug-in config. If Memory-to-Memory (M2M) session replication is enabled in WebSphere Application Server, it is recommended to set `GetDWLMTable` to \"true\" to maintain session affinity.\n\nTo modify these settings, you can refer to the following resources:\n\n* Modifying plug-in properties from the WebSphere Application Server administrative console: http://www.ibm.com/support/docview.wss?uid=swg21460889\n* Web server plug-in configuration: http://www.ibm.com/support/docview.wss?uid=swg21450051\n\nIt's also a good idea to review the tuning recommendations for IBM HTTP Server processes and threads to ensure optimal performance: http://www.ibm.com/support/docview.wss?uid=swg21167658\n\nIf you're still experiencing issues after trying these suggestions, you may want to investigate further to determine the root cause of the duplicate requests.",
    "id": "TECHQA_TRAIN_Q514_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q515",
    "question": "SPSS will not start on Mac\nI downloaded SPSS about 3 weeks ago. On the day when I downloaded it, it was working fine. Last week, I tried starting SPSS but it did not start. I tried reinstalling it, it still would not open. I've updated JAVA (thought this would be a problem), it slowly opened the program but then now that I have reinstalled it and entered in my code, I've used up my code and I have no authorization. But just now, I started SPSS and the same problem is happening. The IBM SPSS name screen appears but nothing happens.\n\n    SPSS would not start.\n\n    Even if it does start, I have licensing problems.",
    "ground_truth": "1. Delete the file: **com.ibm.spss.plist** on your Macintosh.",
    "answer": "To resolve the issue of SPSS not starting on your Mac, try the following steps:\n\n1. Delete the `com.ibm.spss.plist` file on your Macintosh. You can do this by:\n\t* Restarting your Mac\n\t* Opening Finder\n\t* Selecting the 'Home' (house) icon (folder) in the left-hand pane\n\t* Selecting the 'Go' menu at the top of the screen\n\t* Pressing the 'Option' key to reveal the 'Library' option\n\t* Selecting the 'Library' menu option\n\t* Opening the 'Preferences' folder\n\t* Renaming the `com.ibm.spss.plist` file to `old_com.ibm.spss.plist`\n2. Alternatively, you can use the Terminal application to delete the file by running the command: `rm -fR ~/Library/Preferences/com.ibm.spss.plist`\n\nAfter deleting the file, test SPSS by:\n\n1. Launching Statistics\n2. Working with the program for a bit\n3. Closing the software (without force-quitting)\n4. Re-launching Statistics\n5. Working with the program for a bit\n6. Closing the software (without force-quitting)\n7. Launching the software again\n\nNote: The first launch after deleting the file may take a little longer due to Java initialization routines. If you're using Mac OS X Mavericks 10.9.x, you may need to stop the process that protects and restores the deleted file.\n\nRegarding the licensing issue, you may want to contact IBM support or check their website for instructions on how to resolve authorization problems, as this is not directly related to the technical issue of SPSS not starting.",
    "id": "TECHQA_TRAIN_Q515_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q516",
    "question": "RecognizePageFieldsICR_C aborts with Page Type change\nI have an DeveloperWorks application that runs: Survey. In the application PageID Task there is a function that sets the Page Type to ReliefForm (based on a barcode)\n\nDoes anyone know why when I change the SetPageType to set another name, the RecognizePageFieldsICR_C in the Profiler Task aborts? If I put the name back the action runs fine.",
    "ground_truth": "1. Set the **c_cr** variable to USA prior to the call to recognition.",
    "answer": "The issue you're experiencing with RecognizePageFieldsICR_C aborting when you change the Page Type is likely due to the fact that the `c_cr` variable for ICR_C recognition is not set for the new page type. \n\nTo resolve this, you need to set the `c_cr` variable to the appropriate value (e.g., \"USA\") before calling the RecognizePageFieldsICR_C action. You can do this by adding the following line of code before the RecognizePageFieldsICR_C action:\n\n`SaveAsCurrentObjVariable(\"c_cr\", \"USA\")`\n\nThis will ensure that the ICR_C engine is properly configured for the new page type, and the RecognizePageFieldsICR_C action should run without aborting.",
    "id": "TECHQA_TRAIN_Q516_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q517",
    "question": "Installed an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\nInstalled an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\n\nI get the following messages in the logs:-\n\n/tmp/guard_stap.stderr.txt on the DB Server :- \"Server wasn't heard from for nn sec during this attempt nnn sec total), closing and re-opening\"\n\nand from the Guardium Appliance - via fileserver in the /log/opt-ibm-guardium-log/snif/snif.log \"Unauthorized client connecting from ,rejecting\".\n\nHow do I correct the problem?",
    "ground_truth": "1. Uncheck the **Approval** box",
    "answer": "To correct the problem, you need to uncheck the \"S-TAP Approval Needed\" box in the S-TAP Certification screen on the Guardium Appliance. This should allow the STAP to connect properly and appear in the S-TAP Control. The error messages you're seeing in the logs, including \"Server wasn't heard from for nn sec during this attempt\" and \"Unauthorized client connecting from,rejecting\", are likely caused by this setting. Unchecking the approval box should resolve the issue and enable the STAP to connect.",
    "id": "TECHQA_TRAIN_Q517_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q520",
    "question": "OCR Results for Bold fonts\nHi all,\n\nI am having issue with extracting front that are bold, big front. May I know if Datacap have limitation on capturing metadata with big, bold front such as title of the document. I am using RecognizePageOCR_A for extraction of meta data and every other words were being extracted fine except those that are big. The attachment are the sample of front that could not be captured.",
    "ground_truth": "1. Verify that the newest recognition engine is being used.\n   Currently this can be achieved by using the **RecognizePageOCR_S** action from the **ocr_sr** library.",
    "answer": "The issue you're experiencing with extracting bold fonts, specifically big fonts such as titles, using RecognizePageOCR_A in IBM Datacap, is likely due to the \"Word too tall\" error. This error occurs when the height of the word in pixels exceeds the configured limit or when the recognition engine cannot identify the word boundaries.\n\nTo resolve this issue, you can try the following:\n\n1. **Update your recognition engine**: Switch to using the RecognizePageOCR_S action from the ocr_sr library, as it is the newest recognition engine and might handle large fonts better.\n2. **Increase the height limit**: Use the SetMaxCharacterHeightTMM(x) action to increase the height limit in pixels. The default limit depends on the DPI (dots per inch); for 300 DPI, the default is 64 pixels. Adjust this value according to your document's DPI and the size of the fonts you're trying to extract.\n3. **Adjust the document's DPI or font size**: If possible, reduce the height of the word in pixels either by making the font smaller in the original document or by reducing the DPI of the TIFF image. This can help the recognition engine process the text more effectively.\n\nBy implementing one or more of these solutions, you should be able to improve the extraction of metadata from documents with large, bold fonts using IBM Datacap.",
    "id": "TECHQA_TRAIN_Q520_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q521",
    "question": "Cannot open module in exclusive edit - (no such file or directory)\nHello.\n\nI have a module, that I can open normally, but when I try to open it in Exclusive Edit it tells me that \"no such file or directory\"\n\nWhat does this mean?",
    "ground_truth": "1. Upgrade to IBM Rational DOORS Version **9.4.0.1**",
    "answer": "The issue you're experiencing, where you cannot open a module in exclusive edit mode and receive the error \"no such file or directory,\" is due to a corrupted user session file on the database server. This is a known product defect under APAR PM50525.\n\nTo resolve this problem, you have a few options:\n\n1. **Upgrade to IBM Rational DOORS Version 9.4.0.1 or later**, where this defect is resolved.\n2. **Retrieve the missing session file from a system backup** and insert it into the module's current.ver directory. This can be done without restarting the database server.\n3. **Contact Rational Support** to repair the session index file. This requires all users to log out and the DOORS database server to be shut down until the repaired file is returned and inserted.\n\n**Important:** Any modifications to the files in your DOORS database should only be performed by Rational Support, as they could result in data corruption and jeopardize your DOORS database.\n\nBefore proceeding, ensure you have the necessary support and follow the recommended steps carefully to avoid any further issues.",
    "id": "TECHQA_TRAIN_Q521_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q524",
    "question": "I have an issues with V701 SCSQAUTH/SCSQANLE and MQ V8, my batch jobs receiving an ABEND (ABN=102-00000000).\nI have an issues with V701 SCSQAUTH/SCSQANLE and MQ V8, my batch jobs receiving an ABEND (ABN=102-00000000).",
    "ground_truth": "1. Correct the **STEPLIB** for the batch job to point to the V7.1.0 libraries.",
    "answer": "To resolve the ABEND 102-00000000 issue with your batch jobs, you need to correct the STEPLIB for the batch job to point to the V7.1.0 (V710) libraries, as the current setup is using V7.0.1 (V701) libraries against a V710 queue manager. This mismatch in code levels between the WMQ MSTR (Queue Manager) and the batch job is causing the error. Update the STEPLIB to reference the V710 libraries, which will allow your batch jobs to connect to the V710 queue manager. This change will ensure compatibility and resolve the ABEND issue.",
    "id": "TECHQA_TRAIN_Q524_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q525",
    "question": "Can I change the ITCAM J2EE Agent Monitoring Level via the TEPS in version 7.1.1?\nIn the 7.1 version of the J2EE agent I could use the Agent Configuration to change the Monitoring Level for the agent- https://www.ibm.com/support/knowledgecenter/en/SS3JRN_7.2.0/com.ibm.itcamfapps_ad.doc_72/J2EE_agent_tema_install_guide/step10.html\n\nSo how can I change the Monitoring Level in the 7.1.1 agent?",
    "ground_truth": "1. Make a copy of the <hostname>_yj.xml file.\n   In the **$ITM_HOME/config** (Unix) directory or **%ITM_HOME%\\TMAITM6** (Windows), locate the <hostname>_yj.xml file and create a duplicate of this file.\n2. Stop the agent.\n\n3. Make changes to the parameters in the <hostname>_yj.xml file.\n\n4. Save the file.\n\n5. Restart the agent.",
    "answer": "No, you cannot change the ITCAM J2EE Agent Monitoring Level via the TEPS in version 7.1.1. According to the provided context, the option to specify the Monitoring Level is not available in the new J2EE agent v7.1.1.0.0 configuration panels. \n\nTo modify the default Monitoring Level, you need to manually edit the `<hostname>_yj.xml` file (or `<hostname>_yj_<wls_instance>.xml` file for a new Weblogic application) located in the `$ITM_HOME/config` (Unix) directory or `%ITM_HOME%\\TMAITM6` (Windows) directory. \n\nHere are the steps:\n1. Make a copy of the file.\n2. Stop the agent.\n3. Modify the parameters (Monitoring Level and Sampling Rate) in the file.\n4. Save the file.\n5. Restart the agent.\n\nThe new values will now be accepted by the agent.",
    "id": "TECHQA_TRAIN_Q525_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q528",
    "question": "We have configured a new LDAP server in Atlas but why does authentication work for only some users ?\nWe have configured a new LDAP server in Atlas but why does authentication work for only some users ?",
    "ground_truth": "1. Ensure the user who failed to login exists in **Atlas** and is active.\n   \n2. If the user does not exist or is not active, create the corresponding user manually.\n",
    "answer": "To resolve the issue of authentication working for only some users after configuring a new LDAP server in Atlas, ensure that the users who failed to log in exist in Atlas and are active. If they don't, you have two options: \n\n1. Create the corresponding users manually in Atlas.\n2. Use the HR Loader to import those users who are part of the new LDAP server.\n\nThis should resolve the authentication issue for all users.",
    "id": "TECHQA_TRAIN_Q528_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q537",
    "question": "Netcool/Impact 6.1.0: How to change the HSQLDB password?\nNetcool/Impact 6.1.0: How to change the HSQLDB password?",
    "ground_truth": "1. Run command: **SET PASSWORD <password>;** Replace `<password>` with your desired password.",
    "answer": "To change the HSQLDB password in Netcool/Impact 6.1.0, follow these steps:\n\n1. Connect to the HSQLDB database using the default ImpactServer name (NCI) and HSQLDB port number (5435).\n2. Issue the command `SET PASSWORD \"<new_password>\";` to change the password. The password must be double-quoted.\n3. Quit and log back in with the new password.\n4. Edit the HSQLDB DataSource to enable it to connect to the database with the new password. You can do this in two ways:\n   - A) Encrypt the password using `nci_crypt` and edit the `datasource.properties` file to update the password property. This requires an ImpactServer restart.\n   - B) Edit the DataSource via the normal Impact configuration GUI and provide the new password. This method does not require encryption, manual file editing, or an ImpactServer restart.\n\nNote: Replace `<new_password>` with your desired password.",
    "id": "TECHQA_TRAIN_Q537_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q538",
    "question": "Is ITCAM Data Collector for WebSphere 7.2.0.0.14 available?\nIs ITCAM Data Collector for WebSphere 7.2.0.0.14 available?",
    "ground_truth": "1. Go to the following URL: **http://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAM_DC-IF0014&includeSupersedes=0&source=fc**",
    "answer": "The provided context does not mention ITCAM Data Collector for WebSphere version 7.2.0.0.14. The context only lists versions up to 7.2.0.0.11, and there is no information about the availability of version 7.2.0.0.14. Therefore, I don't know if ITCAM Data Collector for WebSphere 7.2.0.0.14 is available.",
    "id": "TECHQA_TRAIN_Q538_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q543",
    "question": "RHEL7.2: CF servers crashed when db2cluster -cm -list -alert command issued\nEnvironment: DB2 11.1 GA / RHEL7.2\n\nWhenever I execute \"db2cluster -cm -list -alert\", 0x80090030 logged in db2diag.log on member nodes. Finally CF servers become STOPPED status with high probability.\n\n  2016-09-12-15.51.35.731323+540 I362836576E602       LEVEL: Severe  \n  PID     : 22991                TID : 70366596624816 PROC : db2sysc 0  \n  INSTANCE: db2inst1             NODE : 000           DB   : SAMPLE\n  HOSTNAME: pscale00.ibm.com  \n  EDUID   : 112                  EDUNAME: db2LLMn2 (SAMPLE) 0  \n  FUNCTION: DB2 UDB, RAS/PD component, pdLogCaPrintf, probe:876  \n  DATA #1 : <preformatted>  \n  NotifyConn_t.wait (PsGetNotification:) failed: 0x80090030  \n  DATA #1 : <preformatted>  \n  If a CF return code is displayed above and you wish to get  \n  more information then please run the following command:  \n    \n  db2diag -cfrc <CF_errcode>",
    "ground_truth": "1. Add the setting **RemoveIPC=no** to file **/etc/systemd/logind.conf**",
    "answer": "To resolve the issue of CF servers crashing when running the `db2cluster -cm -list -alert` command on RHEL 7.2 with DB2 11.1 GA, you can apply a local fix by adding the following setting to the `/etc/systemd/logind.conf` file:\n\n```\nRemoveIPC=no\n```\n\nThis fix addresses the problem caused by `logind` removing IPC resources owned by a user when the user logs off, which is described in the Red Hat bug report https://bugzilla.redhat.com/show_bug.cgi?id=1264533. \n\nAfter making this change, you should restart the `systemd-logind` service to apply the new configuration. This can typically be done by running the command:\n\n```\nsudo systemctl restart systemd-logind\n```\n\nor\n\n```\nsudo service systemd-logind restart\n```\n\ndepending on your system's configuration. This should prevent the CF servers from crashing when the `db2cluster -cm -list -alert` command is issued.",
    "id": "TECHQA_TRAIN_Q543_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q544",
    "question": "Unable to login to TEP with TEPS LDAP authentication\nTEPS LDAP has been configured correctly. User id can be searched successfully in eWAS.\n\nThe login appears to be attempting to authenticate with the HUB TEMS rather than going through Websphere to contact the LDAP server.",
    "ground_truth": "1. Remove the TEPS variable **KFW_AUTHORIZATION_USE_EWAS** from the **KFWENV**.\n\n2. Restart the TEPS.\n\n3. Verify that all users can log in.",
    "answer": "To resolve the issue of being unable to login to TEP with TEPS LDAP authentication, you should remove the TEPS variable 'KFW_AUTHORIZATION_USE_EWAS' from the KFWENV. After removing this variable, restart the TEPS. This should allow all users to log in successfully, as the issue seems to be related to the authentication path not going through Websphere to contact the LDAP server as intended.",
    "id": "TECHQA_TRAIN_Q544_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q545",
    "question": "Netcool/Impact 6.1.0: SelfMonitoring events are being incorrectly cleared by OMNIbus GenericClear Automation\nNetcool/Impact 6.1.0: SelfMonitoring events are being incorrectly cleared by OMNIbus GenericClear Automation\n\nWhen there are multiple SelfMonitoring events reporting stopped Impact Services and one of those Impact Services is restarted the resolution event is used by the OMNIbus GenericClear (and DeleteClears) Automations to delete ALL the events.",
    "ground_truth": "1. Upgrade to **Fix Pack 1** or higher.\n",
    "answer": "To resolve the issue of Netcool/Impact 6.1.0 SelfMonitoring events being incorrectly cleared by OMNIbus GenericClear Automation, you have two possible solutions:\n\n1. **Upgrade to Fix Pack 1 or higher**: This is the recommended and easiest solution. Upgrading to Fix Pack 1 or a higher version will resolve the issue as it is fixed in IBM Tivoli Netcool/Impact V6.1.0 Fix Pack 1 (6.1.0-TIV-NCI-FP0001) and above.\n\n2. **Create a custom PolicyActivator**: As a workaround, you can create a PolicyActivator that polls at a higher rate than the GenericClear Automation. This PolicyActivator should run a policy that picks up the SelfMonitoring Service events, extracts the Service name from the Summary field, and appends it to the Agent field of the events. This modification allows the GenericClear Automation to uniquely identify and correlate Problem and Resolution events, thus preventing it from clearing all SelfMonitoring Service events when a single resolution event is created.\n\nPlease refer to the APAR IV13297 and the Fix Pack 1 documentation for more detailed information and instructions.",
    "id": "TECHQA_TRAIN_Q545_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q547",
    "question": "Do I need to manually apply SDA function for ITCAM for SOA 7.2 FP1 ifix 5?\nThe SDA function for ITCAM for SOA 7.2 FP1 ifix 5 works for TEMS but IS NOT coded to work for TEPS. User is required to manually apply the support files on TEPS for this version (ifix 5).\n\ndoes this need a manual apply for TEPS only for SOA 7.2, FP1 and ifix 5 ?\"",
    "ground_truth": "1. User has to manually apply SOA **7.2 FP1 ifix 5** support files on TEPS.",
    "answer": "Yes, you need to manually apply the SDA function for ITCAM for SOA 7.2 FP1 ifix 5 on TEPS, as the SDA package is only coded to work for TEMS, not TEPS. This manual application is required for all versions of ITCAM for SOA 7.2 on TEPS, not just ifix 5.",
    "id": "TECHQA_TRAIN_Q547_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q549",
    "question": "What does the end-file-message mean while doing a launchpad.sh in the MS\"\nI am getting an end-file-message means while doing a launchpad.sh in the MS. How do I solve the problem?",
    "ground_truth": "1. Use the commands shown below to verify you have them installed.\n   \n2. If not installed, contact your **Linux system administrator** and install these required libraries.\n   ",
    "answer": "The \"end-of-file\" message you're seeing while running `launchpad.sh` is due to missing Linux system libraries, specifically the `compat-libstdc++` or `libstdc++` libraries, usually the 32-bit version. To resolve the issue, you need to install these required libraries. \n\n1. Verify if the libraries are installed by checking with your Linux system administrator.\n2. If they are not installed, install the `compat-libstdc++` and `libstdc++` libraries, ensuring you get the 32-bit versions.\n3. After installing the libraries, try running `launchpad.sh` again.\n\nAlternatively, you can try running the installer with the `-console` or `-silent` flag as suggested in the error message. This might allow the installation to proceed without requiring the graphical mode.",
    "id": "TECHQA_TRAIN_Q549_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q552",
    "question": "How to export key from SSL certificate in IBM HTTP Server 7; getting restricted policy error\nWe're trying to export our IHS 7 SSL key to PKCS12 format so we can use it on our Load Balancer, but it fails with some policy error:\n\n     $/usr/IBM/HTTPServer/bin/gsk7cmd -cert -export -db /usr/IBM/HTTPServer/ssl/key.kdb -pw #### -label \"domain1\" -type cms -target /tmp/domain1.p12 -target_type PKCS12 -target_pw ####\n     \n     The command cannot complete because your JRE is using restricted policy files.\n\nSame error happens in Ikeyman tool. Any ideas?",
    "ground_truth": "1. Download and install a later Java 32-bit x86 AMD/Intel Java SDK.\n   Access the WebSphere Support web site at **http://www-01.ibm.com/support/docview.wss?rs=180&uid=swg24023707** and download the Java SDK. Then, install the SDK into the IBM HTTP Server java and plug-ins java folder.",
    "answer": "To resolve the issue of exporting a key from an SSL certificate in IBM HTTP Server 7 and encountering a restricted policy error, follow these steps:\n\n1. **Identify the Java Version**: Run the command `java -version` from the `<ihsinst>/java/jre/bin` directory to determine your Java SR version.\n\n2. **Download Unrestricted JCE Policy Files**: Go to the [Unrestricted JCE policy files download site](https://www14.software.ibm.com/webapp/iwm/web/preLogin.do?source=jcesdk) and download the appropriate unrestricted JCE policy files for your Java version. Ensure you select the correct version based on your Java SR version.\n\n3. **Rename and Move Restricted Policy Files**: Move the restricted policy files (`local_policy.jar` and `US_export_policy.jar`) from the `<ihsinst>/java/jre/lib/security/` directory to a location outside the JDK class path, extdirs, or bootclasspath.\n\n4. **Install Unrestricted Policy Files**: Place the downloaded unrestricted JCE policy files (`local_policy.jar` and `US_export_policy.jar`) in the `<ihsinst>/java/jre/lib/security/` directory.\n\n5. **Restart ikeyman Utility**: After replacing the policy files, restart the ikeyman utility. This should allow you to export your SSL key to PKCS12 format without encountering the restricted policy error.\n\nAlternatively, you can also resolve the issue by downloading and installing a later Java 32-bit x86 AMD/Intel Java SDK from the [WebSphere Support web site](http://www-01.ibm.com/support/docview.wss?rs=180&uid=swg24023707) to the IBM HTTP Server java and plug-ins java folder.\n\nAfter completing these steps, you should be able to successfully export your key to a PKCS12 file using the command:\n```bash\n/usr/IBM/HTTPServer/bin/gsk7cmd -cert -export -db /usr/IBM/HTTPServer/ssl/key.kdb -pw #### -label \"domain1\" -type cms -target /tmp/domain1.p12 -target_type PKCS12 -target_pw ####\n```",
    "id": "TECHQA_TRAIN_Q552_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q555",
    "question": "SPSS free trial not working on MAC - gets stuck in when it should be launching and goes nowhere\nI downloaded the SPSS software on my mac running Yosemite 10.10.5. The trial was activated by IBM, they sent me several emails stating this.\n\nSo I tried to launch the app and get stuck here alt text There is no progress after an hour; and I tried to launch several times, it never gets out of this screen.",
    "ground_truth": "1. Install Statistics 22 **Fixpack 2**.",
    "answer": "To resolve the issue with the SPSS free trial not working on your Mac running Yosemite 10.10.5, I recommend the following steps:\n\n1. **Check the supported version**: Since you are running Yosemite 10.10.5, you should be able to run IBM SPSS Statistics 24, 23, or 22. Ensure that you have downloaded and installed one of these supported versions.\n2. **Install Statistics 22 FixPack 2 (if applicable)**: If you are using Statistics 22, you need to install FixPack 2 to ensure compatibility with Yosemite. You can find the FixPack 2 installation instructions on the IBM website.\n3. **Re-install Apple Java 6**: In some cases, re-installing Apple Java 6 may be necessary to resolve the issue. You can download and re-install Apple Java 6 from the Apple support website.\n4. **Try launching the application again**: After completing the above steps, try launching the SPSS application again to see if it resolves the issue.\n\nIf none of these steps resolve the issue, you may want to consider contacting IBM support for further assistance or checking the IBM website for any additional troubleshooting guides or patches specific to your version of SPSS and Yosemite.",
    "id": "TECHQA_TRAIN_Q555_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q557",
    "question": "How do I resolve a performance issue with my applicaiton running on a DB2 client as a result of low level segement calls issued by DB2?\nCurrently experiencing a performance issue with an application running on a DB2 client, the stack traces reveals that multiple segment() calls are being issued by DB2 and they are failing. What can be done to resolve this issue?",
    "ground_truth": "1. Issue the command at the DB2 client.\n   Type and execute the command **db2trc alloc** in the DB2 client terminal. The command will allocate the necessary IPC resources to prevent failures of **semget()** calls.\n",
    "answer": "To resolve the performance issue with your application running on a DB2 client due to low-level semget calls issued by DB2, you can issue the following command at the DB2 client:\n\n`db2trc alloc`\n\nThis command will create the necessary IPC resources, preventing the semget() calls from failing and avoiding potential performance problems. It is recommended to add this command to a startup script, so it is invoked every time the client is restarted. \n\nNote: This solution is particularly relevant for Solaris, Linux, HP-UX, and AIX operating systems, as Windows does not experience this issue due to its architecture. If you're unsure about the semget() calls, consider taking a \"truss\" to verify the issue, following the instructions in your operating system manuals.",
    "id": "TECHQA_TRAIN_Q557_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q561",
    "question": "I am getting an error when attempting to apply CF09 on Portal 8001 on a secondary cluster node\nThe ConfigTrace.log shows the following....\n\n     [wsadmin] com.ibm.websphere.management.exception.AdminException:\n     ADMA5026E: No valid target is specified in ObjectName\n     WebSphere:cell=<cellname>,node=<nodename>,server=webserver1 for\n     module ilwwcm-authoring.war+WEB-INF/web.xml.\n       [wsadmin] ADMA5026E: No valid target is specified in ObjectName\n     WebSphere:cell=<cellname>,node=<nodename>,server=webserver1 for\n     module ilwwcm-authoring.war+WEB-INF/web.xml.",
    "ground_truth": "1. Ensure the remote Dmgr is started prior to the upgrade.\n   \n2. Verify the Dmgr profile name.\n   Navigate to the Dmgr's **AppServer/bin** folder and execute the command: **./manageprofiles.sh|bat -listProfiles**.\n3. Pass in the correct Dmgr profile name according to the installation option.",
    "answer": "To resolve the issue of getting an error when attempting to apply CF09 on Portal 8001 on a secondary cluster node, follow these steps:\n\n1. Ensure the Deployment Manager (Dmgr) is started before attempting the upgrade. If you're using a remote Dmgr, verify it's running.\n2. If you're using a local Dmgr and Installation Manager requires you to stop it, follow these sub-steps:\n   a. Verify the Dmgr profile name by navigating to the Dmgr's AppServer/bin folder and executing the command `./manageprofiles.sh|bat -listProfiles`.\n   b. Pass in the correct Dmgr profile name according to the installation option you're using. Refer to the provided link for upgrade instructions for WebSphere Portal and Web Content Manager V8.0.0.1 clustered servers.\n\nBy following these steps, you should be able to resolve the ADMA5026E error and successfully apply the CF09 fix pack on your Portal 8001 secondary cluster node.",
    "id": "TECHQA_TRAIN_Q561_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q569",
    "question": "Authorization failed.: The Authorization Code entered is not for this product/version.\nIf you have multiple Authorization Codes, please check you have entered the correct one.",
    "ground_truth": "1. Check that your authorization code matches the version and software product you are trying to license.\n\n2. Visit the Predictive Analytics Community Get Help page.\n   Access the webpage at **https://developer.ibm.com/predictiveanalytics/get-help/** for assistance with your authorization codes, including direct links to the **License Key Center** and information about Support options.",
    "answer": "To correct the \"Authorization failed\" issue, please ensure that the authorization code you entered matches the version and software product you are trying to license. Verify that the product and version of the authorization code match that of the installed product. If you have multiple authorization codes, double-check that you are using the correct one. For further assistance, you can visit the Predictive Analytics Community Get Help page at https://developer.ibm.com/predictiveanalytics/get-help/ or seek help from the Statistics forum at https://developer.ibm.com/answers/topics/statistics.html.",
    "id": "TECHQA_TRAIN_Q569_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q577",
    "question": "My SystemOut.log is overfilled by messages SECJ0371W (LTPA token expired). I am sick and tired of them. Can I disable them?\nMy SystemOut.log is overfilled by messages SECJ0371W (LTPA token expired). I am sick and tired of them. Can I disable them?",
    "ground_truth": "1. Set the security custom property **com.ibm.websphere.security.ltpa.disableSECJ0371W** to **true** in order to disable future logging of the **SECJ0371W** message.",
    "answer": "To disable the SECJ0371W (LTPA token expired) messages in your SystemOut.log, you can set a security custom property. Add the following property to your WebSphere Application Server configuration:\n\n`com.ibm.websphere.security.ltpa.disableSECJ0371W=true`\n\nThis will disable future logging of the SECJ0371W message. Alternatively, you can also apply one of the available fix packs (such as 8.0.0.13 or 8.5.5.10) that include the fix for this issue.",
    "id": "TECHQA_TRAIN_Q577_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q580",
    "question": "WebSphere MQ Hypervisor Edition requires customer action for the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423)\nWebSphere MQ Hypervisor Edition requires customer action for the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423)\nWhere can I find additional information on what action is required?",
    "ground_truth": "1. Contact **Red Hat** to obtain fixes.\n\n2. Install fixes for Red Hat Enterprise Linux (RHEL).",
    "answer": "To find additional information on the required action for the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423) in WebSphere MQ Hypervisor Edition, you can visit the Red Hat website to obtain fixes and install them for Red Hat Enterprise Linux (RHEL). Specifically, you can check the Red Hat vulnerabilities by CVE name at https://access.redhat.com/security/cve/. Additionally, a Japanese translation of the information is available at http://www.ibm.com/support/docview.wss?uid=swg21903158.",
    "id": "TECHQA_TRAIN_Q580_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q581",
    "question": "OOM exception thrown when trying to configure an ITCAM for WAS 7.2 Data Collector\nI am trying to configure an ITCAM for WAS 7.2.0.0.x DC using config.sh, but getting OOM exceptions, as following:\n\n./config.sh\n\nLog file name: /opt/IBM/ITM/dchome/7.2.0.0.10/data/config-trace.log.\n\nList of TCP/IP interfaces discovered:\n\n       1. ...\n     Enter a number [default is: 1]:\n     1\n     JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2017/08/22 12:27:03 - please wait.\n....\n     java.lang.OutOfMemoryError: java.lang.OutOfMemoryError: Java heap space\n\nLooking at the javacore.txt files, I can see that this is the command throwing an OOM\n\n1CICMDLINE /opt/IBM/ITM/JRE/aix526/bin/java -classpath /opt/IBM/ITM/dchome/7.2.0.0.10/bin/jython/jython.jar:/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib/installbundle.jar -Xms256m -Xmx256m -Dpython.path=/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib:/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib org.python.util.jython /opt/IBM/ITM/dchome/7.2.0.0.10/bin/config.py\n\nHow could I solve this?",
    "ground_truth": "1. Make a backup of the config.sh file.\n\n2. Edit the config.sh file.\n\n3. Search for the following line **JAVA_OPTS** in the config.sh file.\n\n4. Change the JAVA_OPTS=\"-Xms256m -Xmx256m\" to a higher value.\n\n5. Save the file.\n\n6. Restart the config.",
    "answer": "To solve the OOM exception issue when trying to configure an ITCAM for WAS 7.2 Data Collector, you need to increase the Java heap settings in the `config.sh` script. \n\nHere are the steps:\n1. Make a backup of the `config.sh` file.\n2. Edit the `config.sh` file and search for the line containing `JAVA_OPTS`.\n3. Change the `JAVA_OPTS` line from `-Xms256m -Xmx256m` to a higher value, such as `-Xms512m -Xmx512m`.\n4. Save the changes to the `config.sh` file.\n5. Restart the configuration process using `config.sh`.\n\nThis should resolve the Java heap space issue and allow you to complete the configuration without encountering OOM exceptions.",
    "id": "TECHQA_TRAIN_Q581_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q582",
    "question": "Problems downloading SPSS Statistics Premium Grad Pack v.24- Mac\nPurchased SPSS Statistics Premium Grad Pack v.24. for Mac from THINKedu.com. Have tried a dozen times to download it but fails. Tried using wifi, direct ethernet connection, Firefox, Safari, and Chrome incognito, with no other programs running in background. Have purchased previous versions from another vendor multiple times without an issue. THINKedu would not offer additional support, directing me to contact IBM instead. IBM Software Support @ (919) 864-3512 said \"there is no phone support for students for SPSS\" and directed me to ask a question here instead. Saw a suggestion for an installer on another post; seems to lead to a trial version- is that the best idea?",
    "ground_truth": "1. Go to the **Free Trial** Version.",
    "answer": "To resolve the issue with downloading SPSS Statistics Premium Grad Pack v.24 for Mac, I recommend the following steps:\n\n1. Go to the IBM Passport Advantage Web Site ([http://www.ibm.com/software/howtobuy/passportadvantage/paocustomer/sdma/SDMA?PO=DOWNLOAD_FIND_BY_PART_NUMBER](http://www.ibm.com/software/howtobuy/passportadvantage/paocustomer/sdma/SDMA?PO=DOWNLOAD_FIND_BY_PART_NUMBER)) and search for the download using the part number.\n2. Look for the \"IBM SPSS Statistics Desktop 24.0 for Base and all Modules Mac OS Multilingual eAssembly CRZ10ML\" and download the required files, including \"IBM SPSS Statistics Client 24.0 Mac OS Multilingual CN98UML\" and \"IBM SPSS Statistics Client 24.0 Mac OS Silent Multilingual CN98VML\".\n3. Follow the installation instructions provided in the IBM SPSS Statistics 24 Documentation ([http://www.ibm.com/support/docview.wss?uid=swg27047033](http://www.ibm.com/support/docview.wss?uid=swg27047033)) or the GetSPSS page ([http://www.ibm.com/software/analytics/spss/support/get_spss.html](http://www.ibm.com/software/analytics/spss/support/get_spss.html)).\n\nAvoid downloading the trial version, as it may not be the full version you purchased. If you continue to experience issues, you can try contacting THINKedu.com for further assistance, as they are the vendor you purchased from.",
    "id": "TECHQA_TRAIN_Q582_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q584",
    "question": "Help with Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with WSRR (CVE-2017-1741)\nI need to understand details regarding Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with IBM WebSphere Service Registry and Repository (CVE-2017-1741). We are running WAS traditional V9.0.0.0.  What is the recommended fix?",
    "ground_truth": "1. Upgrade to a minimal fix pack levels as required by interim fix and then apply Interim Fix **PI89498**.\n",
    "answer": "The provided context does not specifically address the vulnerability identified in IBM WebSphere Application Server shipped with IBM WebSphere Service Registry and Repository (CVE-2017-1741) for WAS traditional V9.0.0.0. The context provided is for a different CVE (CVE-2017-1731) and does not offer a solution for CVE-2017-1741. Therefore, I don't know the recommended fix for the specified vulnerability based on the given context.",
    "id": "TECHQA_TRAIN_Q584_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q585",
    "question": "Minimum Size of QR Code for Datacap to identify correctly\nWhat is the recommended minimum size of the barcode for the Datacap to identify it properly.",
    "ground_truth": "1. Ensure the width of the thinnest bar (X-dimension) is at least one pixel, and two pixels are recommended for best results.\n   At **200** DPI, each bar must be at least .01 inch wide, which typically translates to about 4 to 5 characters per inch.\n2. Set the X-dimension or width of the narrowest black bar and white space between bars to at least 20 mils.\n   This is equivalent to 1/50 inch or 1/2 mm. When scanned perfectly, this would result in 4 pixels at 200 DPI and 6 pixels at 300 DPI.\n3. For Code 39 symbols, use a **20** mil X-dimension for a density of approximately **3.6** characters per inch.\n   The optimal height should be at least 1/4 inch or 15% of the width, whichever is greater, though this is not an absolute requirement. The minimum quiet zone (white space before and after the bar code) specified by the standard is 1/5 inch.",
    "answer": "The recommended minimum size of the barcode for Datacap to identify it properly is:\n\n* The width of the thinnest bar (X-dimension) must be at least 1 pixel, and 2 pixels are recommended for best results. At 200 DPI, this means each bar must be at least 0.01 inch.\n* The X-dimension or width of the narrowest black bar and white space between bars must be at least 20 mils (1/50 inch, 1/2 mm).\n* For Code 39 symbols, a 20 mil X-dimension results in a density of approximately 3.6 characters per inch.\n* The minimum quiet zone (white space before and after the bar code) is 1/5 inch.\n* The height of the barcode should be at least 1/4 inch or 15% of the width, whichever is greater.\n\nIt's also recommended to print barcodes perpendicular to the direction of scanning to avoid issues with white or black stripes on the image.",
    "id": "TECHQA_TRAIN_Q585_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q587",
    "question": "Why can't I connect to HTTPS server using Installation Manager 1.7.2?\nWhen using IBM Installation Manager 1.7.2 to connect to a HTTPS server, I get the following message:\n\nThe following repositories are not connected: https://www.ibm.com/software/repositorymanager/service/com.ibm. websphere.ND.v85/8.5.5.2.\n\nWhen I try to hit the URL, I get a 404 error.",
    "ground_truth": "1. Update IBM Installation Manager to version **1.7.4**, **1.8** or newer.",
    "answer": "The issue you're experiencing with IBM Installation Manager 1.7.2 not being able to connect to the HTTPS server is due to the server having SSL security protocol disabled. IBM Installation Manager versions 1.7.3.1 or older, including your version 1.7.2, require SSL to connect to HTTPS servers and do not support TLS, which is likely being used by the server instead.\n\nTo resolve this issue, you need to update your IBM Installation Manager to version 1.7.4, 1.8, or newer, as these versions have added support for the TLS protocol. You can find the downloads for the updated versions of Installation Manager at the provided link: http://www-01.ibm.com/support/docview.wss?uid=swg27025142.",
    "id": "TECHQA_TRAIN_Q587_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q589",
    "question": "How to have IBM HTTP Server re-direct an application URL from HTTPS to HTTP?\nWe have an application which uses SSL, but we need to make this http only. We disabled all the SSL, but many clients URLs are still pointing to https. So we need a HTTP Server redirect to change these URLs from https to http. Is this possible?",
    "ground_truth": "1. Make sure the LoadModule line for mod_rewrite is uncommented in the httpd.conf\n   Check the httpd.conf file and ensure that the following line is not commented out: **LoadModule rewrite_module modules/mod_rewrite.so**\n2. Add the specified lines to the global scope or any port 80 VirtualHost stanzas in the httpd.conf\nInclude the following lines in the global scope or in any defined port 80 VirtualHost sections of the httpd.conf:\n   - **RewriteEngine on**\n   - **RewriteCond %{SERVER_PORT} =80**\n   - **RewriteRule ^(.*) https://%{SERVER_NAME}%{REQUEST_URI} [R,L]**\n3. Restart the IBM HTTP Server after making the preceding changes",
    "answer": "To redirect an application URL from HTTPS to HTTP in IBM HTTP Server, you can use the rewrite module (mod_rewrite.c). You will need to modify the httpd.conf configuration file as follows:\n\n1. Ensure the LoadModule line for mod_rewrite is uncommented:\n```\nLoadModule rewrite_module modules/mod_rewrite.so\n```\n2. Add the following lines to the global scope or any port 443 VirtualHost stanzas defined within the httpd.conf configuration file:\n```\nRewriteEngine on\nRewriteCond %{SERVER_PORT} =443\nRewriteRule ^(.*) http://%{SERVER_NAME}%{REQUEST_URI} [R,L]\n```\n3. Restart the IBM HTTP Server after making the preceding changes.\n\nThis will redirect all HTTPS requests to HTTP. Note that you should ensure that SSL is properly disabled and configured for HTTP-only access before implementing this redirect.",
    "id": "TECHQA_TRAIN_Q589_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q595",
    "question": "How can I configure a DataPower MQ client to use mutual authentication with SSL?\nI am looking to setup a DataPower MQ Client to use SSL in mutual authentication mode with a Remote WebSphere MQ Manager.",
    "ground_truth": "1. Configure WebSphere MQ **Queue Manager** (Remote MQ Server) to use SSL authentication.\n\n2. Configure WebSphere MQ Client to use SSL authentication.\n   \n3. Verify that WebSphere MQ Client can PUT/GET message(s).\n   Use application programs such as **amqsputc** and **amqsgetc** with the MQ Queue Manager to test the SSL mutual authentication mode.",
    "answer": "To configure a DataPower MQ client to use mutual authentication with SSL, follow these steps:\n\n1. **Configure WebSphere MQ Queue Manager (Remote MQ Server) to use SSL authentication**: Set SSLCAUTH to \"required\" using the instructions at http://publib.boulder.ibm.com/infocenter/wmqv7/v7r0/topic/com.ibm.mq.explorer.doc/e_ssl.htm.\n2. **Configure WebSphere MQ Client to use SSL authentication**.\n3. **Verify that WebSphere MQ Client can PUT/GET messages using application programs** such as amqsputc and amqsgetc with MQ Queue Manager in SSL mutual authentication mode.\n4. **Create an SSL Proxy Profile** on DataPower using a Crypto profile with Identification Credential, as described in the DataPower InfoCenter: https://www.ibm.com/support/knowledgecenter/SS9H2Y_7.1.0/com.ibm.dp.doc/mq_securingwithansslproxyprofileobject.html (for Fixpack V7.1.0.x) or https://www.ibm.com/support/knowledgecenter/SS9H2Y_7.2.0/com.ibm.dp.doc/mq_securingwithansslproxyprofileobject.html (for Fixpack V7.2.0.x).\n5. **Upload the \"key.kdb\" and \"key.sth\" files** to the \"cert:\" directory of the DataPower box.\n6. **Configure the MQ client object** in the DataPower box to use the uploaded key database and connect in SSL mutual authentication mode with the MQ Manager.\n\nNote: Ensure you have a working knowledge of setting up and administering MQ Server and configuring DataPower MQ Manager Object. Additionally, refer to the provided URLs for detailed instructions on each step.",
    "id": "TECHQA_TRAIN_Q595_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_TRAIN_Q597",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator v2.0.2, to fit content by height or width?",
    "ground_truth": "1. Set the value of the parameter 'scale' in the **..navigator.war/applets/filenetViewer_properties.jsp** file.\n   To fit content by width, specify - **scale: \"ftow\"**, To fit content by height, specify - **scale: \"ftoh\"**.\n2. Save the changes.\n   The changes should be picked up when the viewer is re-launched.",
    "answer": "To change the default 'fit content by' behavior of Daeja viewer in IBM Content Navigator v2.0.2 to fit content by height or width, follow these steps:\n\n1. Locate the `filenetViewer_properties.jsp` file in the `navigator.war/applets` directory.\n2. Set the value of the `scale` parameter as follows:\n   - To fit content by width, specify: `scale: \"ftow\"`\n   - To fit content by height, specify: `scale: \"ftoh\"`\n3. Save the changes.\n4. Alternatively, you can also make the same changes to the `filenetViewer_properties.jsp` file under the `ECMClient\\configure\\explodedformat\\navigator\\applets` folder, then rebuild and redeploy the ear file, and restart the application server.\n\nFor IBM Content Navigator v2.0.3, you can add the parameter-value pair to the Additional Settings section of the Daeja ViewONE panel in the admin desktop:\n1. Go to the Professional tab for the Daeja Professional viewer or the Virtual tab for the Daeja Virtual viewer.\n2. Click New in the Additional Settings section to add the parameter-value pair.\n3. Save the changes.\n\nIn both cases, the changes should take effect when the viewer is re-launched.",
    "id": "TECHQA_TRAIN_Q597_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q002",
    "question": "Unable to open profile from P8 Content Engine Configuration manager (CMUI) on Redhat Linux 7.2, getting GPF and javacore dump.\nLaunch configmgr then try to open an existing profile. Once I click ok on the dialog box to\n\"Verify your application server setting before proceeding...\" Configuration manager would crash and GPF. I can see the javacore.txt and dmp file created.\nThe javacore.txt contains the following:\n\n0SECTION TITLE subcomponent dump routine NULL =============================== 1TICHARSET UTF-8 1TISIGINFO Dump Event \"gpf\" (00002000) received 1TIDATETIME Date: 2016/05/05 at 04:53:30 1TIFILENAME Javacore filename: /opt/IBM/FileNet/ContentEngine/tools/configure/javacore.20160505.045330.25035.0002.txt 1TIREQFLAGS Request Flags: 0x81 (exclusive+preempt) 1TIPREPSTATE Prep State: 0x100 (trace_disabled) 1TIPREPINFO Exclusive VM access not taken: data may not be consistent across javacore sections NULL ------------------------------------------------------------------------ 0SECTION GPINFO subcomponent dump routine NULL ================================ 2XHOSLEVEL OS Level : Linux 3.10.0-327.13.1.el7.x86_64 2XHCPUS Processors - 3XHCPUARCH Architecture : x86 3XHNUMCPUS How Many : 1 3XHNUMASUP NUMA is either not supported or has been disabled by user NULL\n1XHEXCPCODE J9Generic_Signal_Number: 00000004 1XHEXCPCODE Signal_Number: 0000000B 1XHEXCPCODE Error_Value: 00000000 1XHEXCPCODE Signal_Code: 00000080 1XHEXCPCODE Handler1: F72A2E6A 1XHEXCPCODE Handler2: F724D00A 1XHEXCPCODE InaccessibleAddress: 00000000 NULL\n1XHEXCPMODULE Module: /lib/libcairo.so.2 1XHEXCPMODULE Module_base_address: D55FC000\n\nThis is a Redhat Linux 7.2 environment with Content Platform Engine CPE 5.2.1.4.",
    "ground_truth": "1. Please contact **RedHat** to obtain the missing libraries.\n\n2. Install the missing libraries **adwaita-gtk2-theme** (32 and 64 bit) and **adwaita-gtk3-theme** 64 bit.\n\n",
    "answer": "To resolve the issue of being unable to open a profile in FileNet Content Engine Configuration Manager User Interface (CMUI) on Redhat Linux 7.2, which results in a GPF and javacore dump, you should install the missing libraries \"adwaita-gtk2-theme\" (both 32 and 64 bit) and \"adwaita-gtk3-theme\" (64 bit). Please contact RedHat to obtain these missing libraries. This should fix the problem causing the CMUI to crash when attempting to open an existing profile.",
    "id": "TECHQA_DEV_Q002_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q008",
    "question": "How can I export a private key from DataPower Gateway Appliance?\nHow can I export a private key from DataPower Gateway appliance?",
    "ground_truth": "1. Using the **crypto-export** command.\n   HSM-enabled DataPower appliances provide the capability to export private keys by utilizing the **crypto-export** command.",
    "answer": "To export a private key from a DataPower Gateway Appliance, you can use the `crypto-export` command. However, several conditions must be met:\n\n1. The HSMs (Hardware Security Modules) must be initialized and in the same key sharing domain on the exporting and importing machines.\n2. The private key must be marked as exportable at keygen time using the `exportable` option.\n3. The HSMs on the exporting and importing machines must share internal key-wrapping keys, which can be synchronized using the `hsm-clone-kwk` command.\n\nTo export the private key, follow these steps:\n\n1. Ensure the HSMs are initialized and in the same key sharing domain.\n2. Verify that the private key is marked as exportable.\n3. Synchronize the key-wrapping keys using the `hsm-clone-kwk` command, running it four times: twice on the source HSM appliance and twice on the destination HSM appliance, moving the output file manually between each step.\n4. Use the `crypto-export` command to export the private key.\n\nNote that if you are exporting the key to the same appliance, you don't need to worry about synchronizing the key-wrapping keys. For more information, refer to the IBM Info Center documentation.",
    "id": "TECHQA_DEV_Q008_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q010",
    "question": "We transferred the database to an external database on our Portal 8.5 environment and now seeing errors, EJPDB0085W and EJPFD0016E in the logs\nAfter transferring the Portal database we seeing the following....\n\n     [3/1/16 6:22:19:481 CST] 00000071 DataStoreServ W com.ibm.wps.services.\n     datastore.DataStoreServiceImpl checkCorrectSetup EJPDB0085W: The\n     character encoding of the database is not UTF-8.\n     [3/1/16 6:22:19:528 CST] 00000071 Servlet       E com.ibm.wps.engine.\n     Servlet init EJPFD0016E: Initialization of service failed.\n                                      com.ibm.wps.util.DataBackendException:\n     EJPDB0160E: The sanity checks of the database layer failed.\n                     at com.ibm.wps.services.datastore.DataStoreServiceImpl.\n     checkCorrectSetup(DataStoreServiceImpl.java:712)\n                     at com.ibm.wps.services.datastore.DataStoreServiceImpl.\n     init(DataStoreServiceImpl.java:288)\n\n...\n\n     [3/1/16 6:22:19:824 CST] 00000071 DatabaseInsig W com.ibm.wps.datastore.\n     dbinsight.DatabaseInsight checkCharacterEncodingForOracle EJPDB0166W:\n     The character encoding of database domain [[Domain: jcr]] is not\n     correct. The value [WE8MSWIN1252] is set for key [NLS_CHARACTERSET] in\n     parameter section [NLS_DATABASE_PARAMETERS] where expected values only\n     can contain one of [[UTF8, AL16UTF16, AL32UTF8, UTFE]].\n\\",
    "ground_truth": "1. Drop the entire Portal database.\n\n2. Recreate the Portal database using specifications provided in the **InfoCenter**.",
    "answer": "The issue you're experiencing is due to the character encoding of the database not being set to UTF-8, which is a requirement for IBM WebSphere Portal. The error messages EJPDB0085W and EJPFD0016E indicate that the database character encoding is not correct.\n\nTo resolve this issue, you'll need to drop and recreate the Portal database using the specifications provided in the IBM InfoCenter, which can be found at the link provided in the context. Specifically, you need to ensure that the database is created using a UNICODE database and national character sets such as UTF8, AL32UTF8, or AL16UTF16.\n\nYou can verify the current character sets used by your database by running the following SQL statements:\n\n```sql\nSELECT VALUE FROM NLS_DATABASE_PARAMETERS WHERE PARAMETER IN ('NLS_CHARACTERSET', 'NLS_NCHAR_CHARACTERSET');\nSELECT PROPERTY_VALUE FROM DATABASE_PROPERTIES WHERE PROPERTY_NAME IN ('NLS_CHARACTERSET', 'NLS_NCHAR_CHARACTERSET');\n```\n\nIf the results show that the character sets are not set to a supported format (such as UTF8, AL32UTF8, or AL16UTF16), you'll need to recreate the database with the correct character encoding.\n\nPlease follow the instructions in the IBM InfoCenter to recreate the database with the correct character encoding, and then try to start WebSphere Portal again.",
    "id": "TECHQA_DEV_Q010_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q011",
    "question": "How to proceed when jextract utility is throwing an OutOfMemory error ?\nI was getting a crash and was told to provide a \"jextracted core dump\". I ran the jextract command as instructed:\n\n/java/jre/bin/jextract [CORE_PATH]\n\nbut I am getting now an OutOfMemory error when jextract itself is running so I cannot proceed with the original crash investigation.",
    "ground_truth": "1. Increase the heap size using the **-J-Xmx** option.\n   ",
    "answer": "To resolve the OutOfMemory error when running the jextract utility, you can try increasing the heap size using the -J-Xmx option. For example, you can run the command as follows:\n\n`/java/jre/bin/jextract -J-Xmx1024m [CORE_PATH]`\n\nThis will increase the maximum heap size to 1024 MB. You can adjust the value as needed to accommodate the size of your core dump. If you're still encountering issues, you may want to try increasing the heap size further or checking if compressed references are enabled, which may require additional options when running jextract.",
    "id": "TECHQA_DEV_Q011_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q016",
    "question": "How to configure DC to look on a different App server for the SSP?\nI have a single Application server with the RES console installed, and then a separate application server with the XU, the ssp ear, etc. on that one. Each app server is configured separately with respective ports. for example, mgmt server (with the RES console only) has port 8000, and the runtime server (with all of the runtime components) has port 9000.\n\nThe problem I am running into is the following:\n\nWhen I am trying to run a DVS test suite from Decision Center against RES, (my server endpoint in Decision Center is configured as http://hostname:port/res)\n\nI am getting a \"the host and port are responsive but the \"/testing/sspService\" cannot be found. This is expected if it is looking on the same server as the RES console since the application (ssp) is not deployed there.\n\nHowever, I cannot seem to configure the RES console to not assume that the ssp is running on the same port.",
    "ground_truth": "1. Implement the method **IlrSSPResolver.getSSPURL(String serverName,URL url)**.\n\n2. Create your own SSP resolver and add it to the **teamserver.war** file and set the teamserver.defaultSSPResolver.class property to this class.\n\n3. Deploy the SSP on each server.\n   Ensure that the ssp.war is deployed on each server along with a **XU** connection factory and the appropriate datasource definition.",
    "answer": "To configure Decision Center (DC) to look for the SSP on a different App server, you need to create a custom SSP resolver. Here's a step-by-step solution:\n\n1. **Create a custom SSP resolver class**: Implement the `IlrSSPResolver` interface and override the `getSSPURL(String serverName, URL url)` method. This method should return the URL of the SSP server based on the server name.\n2. **Add the custom SSP resolver to the teamserver.war**: Package the custom SSP resolver class into the teamserver.war file.\n3. **Set the teamserver.defaultSSPResolver.class property**: Configure the `teamserver.defaultSSPResolver.class` property to point to your custom SSP resolver class.\n4. **Define multiple servers in RTS**: Define multiple servers in Rule Team Server (RTS) with different URLs, such as `testingServer1` and `testingServer2`.\n5. **Implement the getSSPURL method**: In the `getSSPURL` method, use the server name to return the specific SSP URL. For example:\n```java\nif (serverName.equals(\"testingServer1\")) {\n    return new URL(\"http://server1:9000/testing\");\n} else if (serverName.equals(\"testingServer2\")) {\n    return new URL(\"http://server2:9000/testing\");\n} else {\n    return new URL(\"http://defaultServer:9000/testing\");\n}\n```\nBy following these steps, you can configure Decision Center to look for the SSP on a different App server based on the server name.\n\nNote: Make sure to deploy the SSP (ssp.war) on each server along with a XU connection factory and the appropriate datasource definition, as mentioned in the context.",
    "id": "TECHQA_DEV_Q016_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q021",
    "question": "How to refresh a DataPower WebService Proxy which WSDL got changed?\nI have made changes to a WSDL stored in DP local filesystem.\n\nHow can I make the WSP reflect this change since DataPower Gateway 7.1.0 WebService Proxy WebGUI doesn't offer the \"Refresh\" button anymore?\n\nIs there a best practice to refresh the WSP if I modified my WSDL?",
    "ground_truth": "1. Disable and re-enable the service.\n",
    "answer": "To refresh a DataPower WebService Proxy (WSP) after changing a WSDL stored in the local filesystem, you need to disable and then re-enable the service. The WSDL Cache policy does not work with local WSDL files (those stored in the `local:///` directory), so simply updating the WSDL file does not automatically refresh the WSP. Disabling and re-enabling the service is the recommended approach to ensure the WSP reflects the changes made to the WSDL.",
    "id": "TECHQA_DEV_Q021_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q025",
    "question": "How to import a certificate in ITCAM for Data Power ?\nHow can I import a certificate in ITCAM for Data Power?",
    "ground_truth": "1. Import the certification file into the agent.\n   Use the command: **/usr/ITM/JRE/aix526/jre/bin/keytool -import -trustcacerts -alias\nligitalsso -keystore /usr/ITM/JRE/aix526/jre/bin/lib/security/cacerts\n-storepass <fileName> -file /NEWSSL-sscert.cer**\n",
    "answer": "To import a certificate in ITCAM for Data Power, you can use the following command:\n\n`/usr/ITM/JRE/aix526/jre/bin/keytool -import -trustcacerts -alias ligitalsso -keystore /usr/ITM/JRE/aix526/jre/bin/lib/security/cacerts -storepass <password> -file <fileName>.cer`\n\nReplace `<password>` with the actual store password and `<fileName>` with the name of your certificate file (either `.cer` or `.pem` format). Make sure the file is in ASCII format, not binary. \n\nNote: The Java location `/usr/ITM/JRE` may vary depending on your system configuration. Ensure you use the correct path to the Java location on your system.",
    "id": "TECHQA_DEV_Q025_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q027",
    "question": "How to create batches for bulk upload\nI am new in datacap 9.0 .I just started developing with datacap studio and currently I have learned  to recognize, capture and export the data into filenet.\n\nNow I want to Create batches of image or pdf files so that I can process images and pdf .\n\n \n\nAs per requirement client is sharing document at one shared location.I need to pickup all the documnets from shared location. For creating batches which tool I should use? how it works?\n\n \n\nCan anyone help how I proceed with this.\n\n \n\nRegards,\n\nChhaya Sahu",
    "ground_truth": "1. Run Rulerunner Manager.\n   \n2. On the Rulerunner tab, stop the service.\n   \n3. On the Rulerunner Login tab, click **Connect**.\n   \n4. On the **Workflow** tab, expand the hierarchy on the right and highlight **VScan**.\n   \n5. In the Settings section in the lower right, set skipsamebatch to **1**.\n   \n6. Highlight the line labeled <dbs> above VScan in the thread hierarchy.\n   \n7. Set skipsamebatch to **1** there also.\n   \n8. Click Save, then go back to the Rulerunner tab and start the service.\n   ",
    "answer": "To create batches for bulk upload in Datacap 9.0, you should use the Rulerunner tool. Here's a step-by-step guide to get you started:\n\n1. Run Rulerunner Manager.\n2. On the Rulerunner tab, stop the service.\n3. On the Rulerunner Login tab, click Connect.\n4. Select the Workflow tab.\n5. Expand the hierarchy on the right and highlight the task you want to use for batch creation (e.g., VScan).\n6. Configure the task settings as needed.\n7. To pick up documents from a shared location, you'll need to set up a Datacap application that uses a \"Folder\" or \"File\" input method. This will allow you to import files from the shared location into Datacap.\n8. Once you've set up the input method, you can create batches by running the VScan task or other batch creation tasks.\n\nNote: Make sure to turn off Mixed Queuing in Rulerunner Settings to avoid creating multiple batches and/or leaving them in the running state.\n\nAdditionally, you can refer to the IBM Datacap documentation and tutorials for more detailed information on creating batches and configuring Rulerunner. If you're still experiencing issues, you may want to check the Datacap Object (DCO) for any errors or inconsistencies.",
    "id": "TECHQA_DEV_Q027_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q029",
    "question": "Recurrent RES StaleConnectionException\nHow to prevent rule execution failing because of recurrent StaleConnectionException on ODM 8.8 Rule Execution Server?",
    "ground_truth": "1. Set the Minimum connections to **0**\n\n2. Set the values for **Unused timeout** and **Reap timeout** so that the sum does not exceed any network level idle connection timeout",
    "answer": "To prevent the Rule Execution Server (RES) from failing due to recurrent StaleConnectionException on ODM 8.8, you can configure the WebSphere Application Server data source connection pool as follows:\n\n1. Set the Minimum connections to 0. This will prevent connections from being kept in the pool even if they have been idle for longer than the Unused timeout.\n2. Set the values for Unused timeout and Reap timeout so that their sum does not exceed any network level idle connection timeout.\n\nBy making these changes, you can eliminate occurrences of StaleConnectionException and prevent rule execution from failing due to this issue. \n\nAdditionally, you can refer to the following resources for further information:\n- Troubleshooting stale connection problems: http://www-01.ibm.com/support/docview.wss?uid=swg21247168#SCETroubleshooting\n- Configuring the WebSphere Application Server data source connection pool: http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/index.jsp?topic=/com.ibm.websphere.nd.multiplatform.doc/info/ae/ae/udat_conpoolset.html\n\nPlease note that these changes should be made by an administrator with the necessary permissions and expertise, as they may impact the performance and behavior of your WebSphere Application Server and RES.",
    "id": "TECHQA_DEV_Q029_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q030",
    "question": "For HP-UX how to write verbose gc output to a log file other than the native_stdout?\nA customer asked why no gc logs generated even if they use the -Xverbosegc option. So How can I write verbose gc output to a log file other than the native_stdout for HP-UX?",
    "ground_truth": "1. Add the following parameters to the generic JVM arguments:\n   **-XX:+PrintGCDetails**\n   **-XX:+PrintGCDateStamps**\n   **-XX:+PrintHeapAtGC**\n   **-Xverbosegc:file=/tmp/gc_pid$$.vgc**",
    "answer": "To write verbose GC output to a log file other than the native_stdout for HP-UX, you need to add the following parameters to the generic JVM arguments:\n\n-XX:+PrintGCDetails \n-XX:+PrintGCDateStamps \n-XX:+PrintHeapAtGC \n-Xverbosegc:file=/tmp/gc_pid$$.vgc\n\nThe `-Xverbosegc:file=/tmp/gc_pid$$.vgc` option specifies the log file where the verbose GC output will be written. The `$$` in the file name maps to the PID of the Java process.\n\nIf you want to enable log file rotation, you can add the following parameters:\n\n-XX:+UseGCLogFileRotation \n-XX:NumberOfGCLogFiles=10\n-XX:GCLogFileSize=10M\n\nThis will rotate the log file when it reaches 10M in size, keeping up to 10 rotated log files.",
    "id": "TECHQA_DEV_Q030_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q033",
    "question": "Limitations of sylog-TCP log target using DataPower Gateways\nI am trying to configure a log target using type syslog-TCP. It seems that the payload is getting truncated when I try to record custom logs to it using log-action. Why is this? How can I workaround it.",
    "ground_truth": "1. Configure a server daemon to listen and capture the DataPower devices events.",
    "answer": "The issue you're experiencing with payload truncation when using a syslog-TCP log target with DataPower Gateways is likely due to the finite amount of space available on the device for holding larger-than-average log files. \n\nTo work around this limitation, consider the following options:\n\n1. **Configure a server daemon to listen and capture the DataPower device's events**: This approach allows for more reliable logging and can help prevent log events from being dropped.\n\n2. **Use syslog-ng**: This operates over TCP, ensuring packet delivery to the destination. However, be aware that under high load, log events could still be dropped if they cannot be written out to the network in time.\n\n3. **NFS (Network File System)**: This method involves using an NFS static mount to capture log targets. It can provide slightly more reliable message logging but is limited by network speed and NFS server response time.\n\n4. **File type with backup method**: This involves writing log events to a local file on the device's file system and then uploading the file to a destination once it reaches a set size. This method is useful for capturing sporadic problems or long-running transactions.\n\n5. **HTTP service**: Configuring an HTTP service on the device can also be a viable method for logging, depending on your specific scenario.\n\nEach of these methods has its own strengths and considerations, so choose the one that best fits your needs and environment.",
    "id": "TECHQA_DEV_Q033_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q038",
    "question": "ODM 8.7 TeamServer users active authoring rules and they get kicked out - transaction timeout or session timeout?\nSome of my users are being kicked out of TeamServer while actively authoring rules. What value would be controlling this behavior? Session timeout is at it's default 30 minutes. Does transaction timeout come in to play here or is there a different setting that might be causing this. Thanks.",
    "ground_truth": "1. Increase the timeout value in the web.xml file of the RTS/DC EAR file.\n   Locate the web.xml file in the path **jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF**.\n2. Change the value of the property **ilog.rules.teamserver.transaction.timeout**.",
    "answer": "The issue you're experiencing with users being kicked out of TeamServer while actively authoring rules is likely due to the transaction timeout, not the session timeout. The default transaction timeout is 10 minutes (600 seconds), which is set in the `web.xml` file of the TeamServer EAR file. If the transactional operation takes longer than this timeout to complete, the transaction is rolled back and the operation is not completed, resulting in the user being kicked out.\n\nTo resolve this issue, you can try increasing the transaction timeout value in the `web.xml` file by changing the value of the `ilog.rules.teamserver.transaction.timeout` property. For example, you can increase the value to 1200 seconds (20 minutes) or more, depending on the complexity of the operations being performed.\n\nAdditionally, you should also check the application server-specific transaction timeout configurations, such as the \"Maximum transaction timeout\" in WebSphere Application Server, and increase it as needed.\n\nIt's worth noting that the session timeout, which is set to 30 minutes in your case, is not directly related to this issue, as it controls the duration of the user's session, whereas the transaction timeout controls the duration of a specific transactional operation.",
    "id": "TECHQA_DEV_Q038_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q039",
    "question": "How do I upgrade my virtual DataPower Appliance from 5.0 firmware to 6.0+ firmware?\nWhen attempting to upgrade my Virtual DataPower Appliance from 5.0.0.8 firmware version to 6.0+ firmware versions, I receive a failure message.",
    "ground_truth": "1. Install the **5.0.0.8** or later fix pack to upgrade to **6.0.0.0** or later.\n   The fix pack contains a required fix to allow the larger sized firmware image to fit.",
    "answer": "To upgrade your Virtual DataPower Appliance from 5.0.0.8 firmware to 6.0+ firmware, you must first ensure that you have the 5.0.0.8 fix pack installed, as it contains a required fix to allow the larger sized firmware image to fit. Since your current firmware version is 5.0.0.8, you can proceed with the upgrade to 6.0.0.0 or later. \n\nPlease follow these steps:\n1. Go to Fix Central and download the 6.0.0.0 or later fix pack compatible with your virtual deployment.\n2. Install the downloaded fix pack on your Virtual DataPower Appliance.\n3. Follow the standard upgrade procedure for your appliance to complete the upgrade to 6.0+ firmware.\n\nNote: Make sure to only install fix packs that are compatible with your virtual deployment to avoid unexpected errors. You can use the provided links in the context to determine which fix packs are compatible with your version.",
    "id": "TECHQA_DEV_Q039_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q040",
    "question": "Why Plug-in log file reports an error message after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver.\nDuring web server start-up, errors like the following will be logged into the Plug-in log file (http_plugin.log):\n\nERROR: lib_security: loadSecurityLibrary: Failed to load gsk library from /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64 ERROR: ws_transport: transportInitializeSecurity: Unable to load security library ERROR: ws_server: serverAddTransport: Failed to initialize security ERROR: ws_server: serverAddTransport: HTTPS Transport is skipped\n\nNote: This is after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver  on a Linux platform",
    "ground_truth": "1. Set the **LD_LIBRARY_PATH** environment variable to point to the library directory of the **GSKit** that comes with the IBM web server Plug-in.",
    "answer": "To resolve the error message in the Plug-in log file after installing and configuring the WebSphere Plugin 8.5 version on an Apache 2.4 web server on a Linux platform, you need to set the LD_LIBRARY_PATH environment variable to point to the library directory of the GSKit that comes with the IBM web server Plug-in.\n\nSince you are using a 64-bit Plug-in v8.x with Apache 2.4, you should use the following command:\n\n```\nexport LD_LIBRARY_PATH=/opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n```\n\nHowever, simply setting the LD_LIBRARY_PATH environment variable from the command line may not work. You need to set this variable in a way that it is applied when the web server is started.\n\nFor Linux platforms, you can add the export command to the following files:\n\n- For SLES and SUSE Linux, add the export command to the `/usr/sbin/envvars` file.\n- For RHEL Linux, add the export command to the `/etc/sysconfig/httpd` file.\n\nBy adding the export command to these files, the environment variable will be set when the web server is started, allowing the Plug-in to locate the GSKit libraries and initialize SSL transports.",
    "id": "TECHQA_DEV_Q040_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q043",
    "question": "Where I can get ITNM 4.2.0.1 GA version download details with Part number?.\nHow to download and install IBM Tivoli Network Manager IP Edition Version 4.2 Fix Pack 1 (GA) using the Passport Advantage Web site?.",
    "ground_truth": "1. Download all of the parts that you need, both required and optional.\n\n2. Unpack each of the parts into a single temporary directory on your system.\n   \n3. Follow the instructions in the **Installing** section of the **IBM Knowledge Center** to install the product.",
    "answer": "To get the ITNM 4.2.0.1 GA version download details with Part number, follow these steps:\n\n1. Log in to the IBM Passport Advantage Online Web site at https://www.ibm.com/software/howtobuy/passportadvantage/pao_customers.htm.\n2. Click on \"Software download & media access\", then click on \"Download finder\".\n3. Select \"Find by product description\" and type in \"Tivoli Network Manager\".\n4. Expand the \"Tivoli Software eAssembly\" and select the images you wish to download from the list.\n\nThe Part number for IBM Tivoli Network Manager IP Edition 4.2.0.1 for Linux is CNE9VEN. This part includes the base product, core components, GUI components, and topology database scripts, and supports multiple languages.\n\nTo download and install IBM Tivoli Network Manager IP Edition Version 4.2 Fix Pack 1 (GA), follow the instructions in the IBM Tivoli Network Manager IP Edition V4.2 Quick Start Guide, which can be found at https://www-01.ibm.com/support/docview.wss?uid=swg27048605.",
    "id": "TECHQA_DEV_Q043_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q047",
    "question": "I need to move my perpetual license of SPSS v24 to my new machine.\nI have my authorization code first given to me, but since we did not renew our support contract we can't seem to download the software. I was originally told that I could download the trial version and it would have the authorization wizard where I could input the code and move forward. But the only downloadable version is subscription version with no authorization wizard. How do I move forward?",
    "ground_truth": "1. **Renew** your software Subscription and Maintenance.\nYou can order the Media CD copy of the software that your company purchased. The software version on the Media CD will be the version available up to the time your subscription has expired.",
    "answer": "To move your perpetual license of SPSS v24 to your new machine, you have a couple of options since you cannot download the software due to your expired support contract. \n\n1. **Renew Your Subscription and Maintenance**: The most straightforward way to access the software download is by renewing your Subscription and Maintenance. This will grant you access to download the software from Passport Advantage Online.\n\n2. **Order a Media CD Copy**: If renewing the subscription is not feasible at this time, you can order a Media CD copy of the software. This copy will be the version of the software that was current up to the time your subscription expired. You can contact the IBM Sales Department to inquire about the availability of the Media CD and to place an order. You can find your local IBM Sales Department contact at https://www.ibm.com/planetwide/.\n\nOnce you obtain the software through either of these methods, you can install it on your new machine and use your authorization code to activate it.",
    "id": "TECHQA_DEV_Q047_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q048",
    "question": "Need to understand what exact counters are needed for the ITM IIS agent?\nNeed to understand what exact counters are needed for the ITM IIS agent to collect website details and web site status. unable to find what \ncounters are required in the IIS doc.",
    "ground_truth": "1. Install IIS 6.0 **management compatibility pack** on your Windows Server.\n   ",
    "answer": "\n\nTo collect website details and website status for the ITM IIS agent, you need to ensure that the following IIS Role Services are installed:\n\n1. IIS 6 Management Compatibility\n2. IIS 6 Metabase Compatibility\n3. IIS 6 WMI Compatibility\n4. IIS 6 Scripting Tools\n5. IIS 6 Management Console\n\nAdditionally, you need to install the IIS v6.0 Management Compatibility pack. \n\nThe exact counters required for the ITM IIS agent are not specified in the provided context. However, installing the above-mentioned IIS Role Services and the IIS v6.0 Management Compatibility pack should enable the agent to collect the necessary data for website details and website status. If you are still unable to find the required counters, you may need to refer to additional documentation or contact IBM support for further assistance.",
    "id": "TECHQA_DEV_Q048_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q051",
    "question": "We got a NullPointerException when bootstrapping the object store or accessing Site Preferences/Access Role on WorkplaceXT\nAfter logging into FileNet Workplace XT, a java.lang.NullPointerException error is logged when bootstrapping the object store or when accessing Site Preferences/Access Role.\n\nHere's the error stack,\n\nError Stack Trace extracted from the J2EE Application Server error log:\n\njava.lang.NullPointerException\n\nat org.apache.jasper.runtime.JspWriterImpl.write(JspWriterImpl.java:421)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefAccessRolesInfoPage.renderRoleMembers(PrefAccessRolesInfoPage.java:254)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefAccessRolesInfoPage.renderRole(PrefAccessRolesInfoPage.java:220)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefBootstrapInfoPage.renderAdminRole(PrefBootstrapInfoPage.java:131)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefBootstrapInfoPage.render(PrefBootstrapInfoPage.java:303)",
    "ground_truth": "1. Change the **User Display Name** Attribute or **Group Display Name** Attribute to a valid LDAP entry such as cn, displayName or uid.\n\n2. Restart the FileNet Content Engine and **Workplace XT** instances.",
    "answer": "To resolve the NullPointerException error when bootstrapping the object store or accessing Site Preferences/Access Role on WorkplaceXT, follow these steps:\n\n1. Log in to FileNet Enterprise Manager (FEM).\n2. Check the Directory Services Configuration.\n3. Verify that the User Display Name Attribute and Group Display Name Attribute settings are valid.\n4. Change these settings to valid LDAP entries, such as cn, displayName, or uid, if they are currently set to invalid values.\n5. Restart the FileNet Content Engine and Workplace XT instances.\n\nThis should resolve the NullPointerException error and allow you to successfully bootstrap the object store or access Site Preferences/Access Role on WorkplaceXT.",
    "id": "TECHQA_DEV_Q051_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q052",
    "question": "Why do I still get \"certificate expired\" error after adding new certificate?\nThe remote SSL vendor has provided us a new certificate to replace an expiring one. We have added the new certificate to the appropriate Datapower validation credential, however, connections are still failing with \"certificate expired\":\n\nmpgw(Inbound_MPG): tid(51005)[request][10.20xx.xx] gtid(51345): certificate validation failed for '/C=US/O=People Services/OU=IT/CN=test.site.com' against 'My_ValCred': certificate has expired",
    "ground_truth": "1. Disable/enable the certificate object.\n   If the replacement certificate has the same file name of the expired certificate, you **MUST** disable the certificate object in order to clear all cached references to the expired certificate.",
    "answer": "The \"certificate expired\" error persists after adding the new certificate because the DataPower appliance may still be referencing the old certificate files or have cached references to the expired certificate. To resolve this issue, ensure you have the full certificate chain, including personal, intermediate, and root certificates, and update the Crypto Configuration objects to reference the new certificate files. If the replacement certificate has the same file name as the expired certificate, disable and then enable the certificate object to clear cached references. Verify that the configuration is referencing the new certificate files by checking the SSL Proxy Profile, Crypto Profile, and Crypto Key and Certificate objects.",
    "id": "TECHQA_DEV_Q052_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q053",
    "question": "After uninstalling Portal 8.0 only from my WAS environment my subsequent attempts to install Portal 8.0 into that same existing WAS fails.\nI installed Portal 8.0.0.1 CF12 with an existing WAS 8.0.0.8 application server and everything was successful. I want to script my install so I uninstalled Portal 8.0.0.1 only and was left with an existing WAS 8.0.0.8...as before. However, when I attempt to reinstall Portal 8.0.0.1 into that same existing WAS 8.0.0.8 to test my scripting I get the following error immediately:\n\nERROR: The required version 8.0.0.5 or later of WebSphere Application Server has not been detected on this system. Select the WebSphere Application Server Package to install WebSphere Application Server and WebSphere Portal.\n\nIIM shows WAS as installed, so I am not sure what is causing this behavior when it installed fine just a few hours ago.",
    "ground_truth": "1. Navigate to the **AppServer** folder and remove the following files.\n   - **lib/ext/commons-codec-1.3.jar**\n   - lib/ext/commons-httpclient-3.0.1.jar\n   - lib/ext/openid4java-full-0.9.5.jar\n   - lib/ext/wp.auth.base.sua_RedirectServletFilter.jar\n   - lib/ext/wp.auth.base.sua_loginmodule.jar\n   - lib/ext/wp.auth.tai.jar\n   - lib/wp.user.connections.jar\n   - lib/wp.wire.jar\n   - **plugins/com.ibm.patch.was.plugin.jar**\n- plugins/com.ibm.wp.was.plugin.jar\n- plugins/wp.ext.jar\n- properties/jndi.properties",
    "answer": "To resolve the issue, you need to manually remove the remaining Portal files from the AppServer folder structure. Navigate to the AppServer folder and delete the following files:\n\n1. lib/ext/commons-codec-1.3.jar\n2. lib/ext/commons-httpclient-3.0.1.jar\n3. lib/ext/openid4java-full-0.9.5.jar\n4. lib/ext/wp.auth.base.sua_RedirectServletFilter.jar\n5. lib/ext/wp.auth.base.sua_loginmodule.jar\n6. lib/ext/wp.auth.tai.jar\n7. lib/wp.user.connections.jar\n8. lib/wp.wire.jar\n9. plugins/com.ibm.patch.was.plugin.jar\n10. plugins/com.ibm.wp.was.plugin.jar\n11. plugins/wp.ext.jar\n12. properties/jndi.properties\n\nAfter removing these files, go back to the Installation Manager and select the \"Recheck Status\" button. It should now indicate that \"All prerequisites are met,\" and you should be able to proceed with the reinstall of Portal 8.0.0.1 into the existing WAS 8.0.0.8.",
    "id": "TECHQA_DEV_Q053_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q055",
    "question": "Table \"\".\"\" could not be found\nWhen doing a table mapping with DB2 as source, selecting a table which contains special characters on column comments like:\n\nCOMMENT ON COLUMN .. IS 'Test comment \u20181\u2019 complete';\n\nMapping fails with following error message: Table . could not be found in the database.",
    "ground_truth": "1. **Reinsert**  data with codepage conversion enforced by setting the operation system codepage matching to the codepage of data to be inserted",
    "answer": "The issue you're experiencing, \"Table \"\".\"\" could not be found,\" when doing a table mapping with DB2 as the source, is likely due to the presence of special characters in column comments that are not properly encoded in UTF-8. The error message \"Table. could not be found in the database\" suggests that the database is unable to correctly interpret the table name due to these encoding issues.\n\nTo resolve this issue, follow these steps:\n\n1. **Delete Rows with Incorrect Unicode Codepoints**: First, delete all rows with incorrect Unicode codepoints from your table using the command `DELETE * from test`. This will remove any data that could be causing the encoding issues.\n\n2. **Change the Locale**: Change the locale to one that matches the codepage of the data to be inserted. You can do this by running `export locale=en_us` (or the appropriate locale for your data). This ensures that the data is inserted with the correct encoding.\n\n3. **Insert Data with Correct Encoding**: After setting the correct locale, insert your data into the table. For example, `INSERT INTO test VALUES ('\u00c3')`, `INSERT INTO test VALUES ('\u00b3')`, and `INSERT INTO test VALUES ('\u00a9')`.\n\n4. **Verify UTF-8 Conversion**: To ensure that the inserted data was correctly converted to UTF-8, run the query `SELECT col, HEX(col) FROM test`. The results should show the correct UTF-8 representations for the characters, such as `\u00c3` being represented as `C383`, `\u00b3` as `C2B3`, and `\u00a9` as `C2A9`.\n\nBy following these steps, you should be able to resolve the encoding issues that are preventing the table from being found. Remember, it's crucial to ensure that the data you insert into your database is correctly encoded to avoid such problems.",
    "id": "TECHQA_DEV_Q055_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q063",
    "question": "Hide a page in dotedit step\nI am working on datacap 8.1 version. I have 2 pages in a batch. Page 1 with status as 1, Page 2 with status as 20. Both are of same page type. In verification step (dotedit) I want to hide the page which is with status 20. I have given status 20 in ignored page status in web administrator for verify. But still when I navigate through pages in dotedit batch view the respective panel is loading. I am able to submit the batch even if I have one page in a batch with 20 as status.\n\nIs there any way to delete the page (we have multiple same type of pages in a batch) from dotedit based on the page status?",
    "ground_truth": "1. Create a special page type attached at the batch level called something like DeleteMe.",
    "answer": "To hide a page in the dotedit step based on the page status, you can create a custom rule using the DeleteChildType action from the Validations library. Here's a step-by-step solution:\n\n1. Create a new page type, e.g., \"HidePage\", and attach it to the batch level.\n2. Use an action to identify the pages with status 20, e.g., `PageStatusIDByValue(20, HidePage)`.\n3. Create a rule with the action `DeleteChildType(HidePage)` and attach it to the batch level. This will remove all pages with page type \"HidePage\" (i.e., pages with status 20).\n\nBy doing this, the pages with status 20 will be hidden from the dotedit batch view, and you won't be able to submit the batch if it contains only pages with status 20.\n\nNote that this approach doesn't actually delete the pages from the batch, but rather hides them from the dotedit view. If you want to permanently delete the pages, you'll need to use a different approach, such as using the `DeleteChild` API method in a custom action.",
    "id": "TECHQA_DEV_Q063_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q067",
    "question": "BPM AppTarget startup hangs during startup\nDuring startup of the apptarget, JVM hangs with the following messages\n\n[9/8/14 14:11:01:709 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W - The system has been waiting for the group replication lock to be released for the last 10 minutes. [9/8/14 14:11:32:810 CDT] 00000022 ThreadMonitor W WSVR0605W: Thread \"server.startup : 0\" (0000001f) has been active for 654582 milliseconds and may be hung. There is/are 1 thread(s) in total in the server that may be hung. at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:896) at com.lombardisoftware.server.core.GroupCore.getAllGroups(GroupCore.java:545) at com.lombardisoftware.server.ejb.security.SecurityCore.listAllGroups(SecurityCore.java:566) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37) at java.lang.reflect.Method.invoke(Method.java:611) ... [9/8/14 14:21:02:662 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W - The system has been waiting for the group replication lock to be released for the last 20 minutes. [9/8/14 14:31:03:193 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W -The system has been waiting for the group replication lock to be released for the last 30 minutes. [9/8/14 14:41:03:749 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W -The system has been waiting for the group replication lock to be released for the last 40 minutes.",
    "ground_truth": "1. Make a backup copy of the wimconfig.xml file.\n\n2. Edit the wimconfig.xml file.\n\n3. Change the connectTimeout value.\n   Search for the line containing connectTimeout in the wimconfig.xml file and change the value from connectTimeout=\"20\" to **connectTimeout=\"0\"**.\n\n4. Save the wimconfig.xml file.\n\n5. Restart the WebSphere Application Server / **IBM Business Process Manager** environment.",
    "answer": "To resolve the BPM AppTarget startup hang issue, you need to update the LDAP connection timeout setting. You can do this in one of two ways:\n\n**Option 1: Using the wsadmin command**\n\n1. Run the following command: `$AdminTask updateIdMgrLDAPServer {-id AD -connectTimeout 0}`\n2. Save the changes using `$AdminConfig save`\n3. Verify that the `wimconfig.xml` file has been updated with `connectTimeout=\"0\"`\n\n**Option 2: Editing the wimconfig.xml file directly**\n\n1. Make a backup copy of the `wimconfig.xml` file\n2. Edit the file and search for `connectTimeout`\n3. Change the value from `connectTimeout=\"20\"` to `connectTimeout=\"0\"`\n4. Save the file\n\nAfter making these changes, a complete restart of the WebSphere Application Server / IBM Business Process Manager environment is required for the changes to take effect. This should resolve the startup hang issue caused by the group replication lock waiting for the LDAP connection timeout.",
    "id": "TECHQA_DEV_Q067_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q071",
    "question": "Why is Connection Refused on the ITCAM Managing Server?\nITCAM Data Collector connection to the Managing Server fails with Connection Refused.",
    "ground_truth": "1. Specify a 'valid' IP address for the MS in the **<MS_HOME>/bin/setenv.sh** file,  and in ITCAM 6.1, the **ms.properties** file.",
    "answer": "The \"Connection Refused\" error on the ITCAM Managing Server occurs when the Data Collector (DC) tries to connect to the Managing Server (MS) using an IP address that cannot reach the MS. To resolve this issue, you should specify a valid IP address for the MS in the configuration files instead of using the host name.\n\nFor ITCAM 6.0 or earlier, update the `setenv.sh` file in `MS_HOME/bin` with the following:\n```\nKERNEL_HOST01=<ip addr of MS>\nKERNEL_HOST02=<ip addr of MS>\n```\nFor ITCAM 6.1, update the `setenv.sh` file in `MS_HOME/bin` with the following:\n```\nKERNEL_HOST01=<ip addr of MS>\nam_socket_bindip=<ip addr of MS>\nam_socket_exportip=<ip addr of MS>\n```\nAdditionally, update the `ms.properties` file in `MS_HOME/etc` with the following:\n```\nkernel.hosts=<ip addr of MS>:9122:9120:9118\n```\nReplace `<ip addr of MS>` with the actual IP address of the Managing Server.\n\nTo determine the IP addresses for a given MS host name, use the `nslookup` command on the Data Collector:\n```\nnslookup <MS_host_name>\n```\nThen, test basic connectivity for each IP address listed by using the `ping` command:\n```\nping <ip_address>\n```\nBy specifying a valid IP address for the MS and ensuring network connectivity, you should be able to resolve the \"Connection Refused\" error.",
    "id": "TECHQA_DEV_Q071_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q072",
    "question": "Help with Security Bulletin: Multiple vulnerabilities in IBM Java Runtime affect WMB and IIB\nI need to understand details regarding Security Bulletin: Multiple vulnerabilities in IBM Java Runtime affect WebSphere Message Broker and IBM Integration Bus. Where can I find this information?",
    "ground_truth": "1. Refer to the IBM Java SDK Security Bulletin for a complete list of vulnerabilities.\n\n2. Evaluate your code to determine whether the complete list of vulnerabilities are applicable to your code.",
    "answer": "To find information regarding the Security Bulletin: Multiple vulnerabilities in IBM Java Runtime that affect WebSphere Message Broker and IBM Integration Bus, you can visit the IBM Support website. Specifically, you can check the following resources:\n\n1. **IBM Security Bulletin**: The bulletin provides a summary of the vulnerabilities, affected products and versions, and remediation/fixes. You can find it by searching for \"IBM Security Bulletin: Multiple vulnerabilities in IBM Java Runtime affect WebSphere Message Broker and IBM Integration Bus\" on the IBM Support website.\n\n2. **Planned Maintenance Release Dates**: For the planned maintenance release dates for WebSphere Message Broker and IBM Integration Bus, visit http://www.ibm.com/support/docview.wss?uid=swg27006308.\n\n3. **My Notifications**: To be notified of important product support alerts like this, subscribe to My Notifications at http://www-01.ibm.com/software/support/einfo.html.\n\n4. **System z Security Portal**: If you are a System z customer, IBM recommends subscribing to the System z Security Portal to receive the latest critical System z security and integrity service. You can find instructions on how to subscribe on the System z Security website at http://www.ibm.com/systems/z/solutions/security_subintegrity.html.\n\n5. **Fix Packs**: For specific remediation/fixes, you can find the APARs and fix packs for your version of IBM Integration Bus or WebSphere Message Broker in the \"REMEDIATION/FIXES\" section of the security bulletin. The fix packs are available on the IBM Support website, with links provided in the bulletin.\n\nBy following these steps, you should be able to find the necessary information to address the security vulnerabilities in your IBM Java Runtime environment used by WebSphere Message Broker and IBM Integration Bus.",
    "id": "TECHQA_DEV_Q072_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q077",
    "question": "I need to transfer my SPSS 24 licence to a new computer\nI need to transfer my SPSS 24 license to a new machine. I have only used my activation code on one computer so far, and that computer was found to be defective which has led me to get a new computer. I was able to download SPSS 24 Gradpack onto the new computer, but every time I put in the activation code, the program gives me an error message saying that I am not allowed to generate any new licenses.",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To transfer your SPSS 24 license to a new computer, you should contact the vendor from whom you originally purchased the software. Since you've only used the activation code on one computer and that computer was defective, they should be able to assist you with reactivating the license on your new machine. \n\nHere are some possible vendors you can contact for support:\n- Hearne: http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ\n- On the Hub: http://onthehub.com/\n- StudentDiscounts.com: http://studentdiscounts.com/contact-us.aspx\n- JourneyEd: https://www.journeyed.com/contact\n- thinkEDU: https://thinkedu.desk.com/\n- Studica: http://www.studica.com/technical-support\n\nExplain your situation to them, and they should be able to guide you through the process of transferring your license to the new computer.",
    "id": "TECHQA_DEV_Q077_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q090",
    "question": "RTW eclipse license error\nI get a RTW eclipse license error on IM stating server is available, but license is not available. License is imported fine on license key admin and RPT floating license and RIT floating license shows on the  pc end on license key admin 8.1.3, but not showing on IM. \n\nRTW 8.5\n\nWhat to do?",
    "ground_truth": "1. Navigate to IBM Rational License Key Center website.\n   Access the IBM Rational License Key Center by visiting the URL: **http://www-01.ibm.com/software/rational/support/licensing/**.\n2. Return and generate the license file for IBM Rational Test Workbench Floating License.\n\n3. Download and Import the license file again.\n   \n4. Click on Start > IBM Rational > LMTools > Start/Stop/Reread tab to stop and start the license server.\n   \n5. Click on Start > IBM Rational > LMTools > Server Status to perform status enquiry.\n\n6. Reactivate the floating license for Rational Integration Tester using **Rational Installation Manager**.",
    "answer": "To resolve the RTW Eclipse license error, follow these steps:\n\n1. **Verify the license server configuration**: Ensure that the PACKAGE ibmrtw block is present in the license server configuration, which displays the components of IBM Rational Test Workbench Suite.\n2. **Regenerate and re-import the license file**: Go to the IBM Rational License Key Center website, generate a new license file for IBM Rational Test Workbench Floating License, and import it into the license server.\n3. **Restart the license server**: Stop and start the license server using the LMTools utility.\n4. **Check the server status**: Perform a status enquiry using LMTools to verify that the 'Users of ibmrit' line is present.\n5. **Reactivate the floating license**: Use Rational Installation Manager to reactivate the floating license for Rational Integration Tester.\n\nIf you have already imported the license file and it is showing on the License Key Administrator, but not on IM, try stopping and starting the license server, and then reactivate the floating license for Rational Integration Tester using Rational Installation Manager.",
    "id": "TECHQA_DEV_Q090_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q099",
    "question": "Is ITCAM Agent for WebSphere Applications 7.2.0.0.7 available?\nIs ITCAM Agent for WebSphere Applications 7.2.0.0.7 available?",
    "ground_truth": "1. Go to the link: **http://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAMAD_WS-IF0007&includeSupersedes=0&source=fc**.",
    "answer": "Yes, ITCAM Agent for WebSphere Applications 7.2.0.0.7 is available. You can download it from Fix Central using the following link: \n\nhttp://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAMAD_WS-IF0007&includeSupersedes=0&source=fc\n\nIt was released on August 23, 2013.",
    "id": "TECHQA_DEV_Q099_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q106",
    "question": "Why does WebSphere DataPower spike with a high CPU rate when a WebSphere MQ connection is unavailable?\nI have noticed when my MQ backends go down unexpectedly it can result in a high CPU rate on DataPower. And how can I resolve this?",
    "ground_truth": "1. Change the **Retry Attempts** parameter on the **Configure MQ Queue Manager** window from 0 to some number.",
    "answer": "The high CPU rate on WebSphere DataPower when a WebSphere MQ connection is unavailable is caused by the default settings of Retry Attempts (0) and Retry Interval (1 second) on the DataPower MQ Queue Manager object. To resolve this issue, you should change the Retry Attempts parameter to a non-zero value (e.g., 6) and adjust the Retry Interval (e.g., 10 seconds) and Long Retry Interval (e.g., 600 seconds) accordingly. This will allow DataPower to retry the connection a limited number of times with increasing intervals, reducing the CPU usage when the MQ connection is down. \n\nFor example, you can change the parameters as follows:\n* Retry Attempts: 6\n* Retry Interval: 10 seconds\n* Long Retry Interval: 600 seconds (10 minutes)\n\nThis configuration will allow the MQ QM Object to retry 6 times with 10-second intervals, and then retry every 10 minutes, reducing the CPU usage when the Queue Manager is down or a connection is not established.",
    "id": "TECHQA_DEV_Q106_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q108",
    "question": "Why do I get \"OSS version is not suitable for installation\" when attempting to install the MQ 5.3.1 base version on a HP Integrity NonStop Server BladeSystem?\nI am trying to install the MQ 5.3.1 base version on a HP Integrity NonStop Server BladeSystem, but it complains saying that the \"OSS version is not suitable for installation\". My OSS version is J06.14 and it looks to be a supported version according to the System Requirements site:\n\nhttp://www-01.ibm.com/support/docview.wss?uid=swg27006797\n\nWhy am I getting this error message?",
    "ground_truth": "1. Ensure the HP Integrity NonStop Server H-Series system runs on **H06.23.01** or later.",
    "answer": "The error message \"OSS version is not suitable for installation\" is occurring because the minimum mandatory OSS version for installing WebSphere MQ V5.3.1 on an HP Integrity NonStop Server BladeSystem (J-Series) is J06.14.00 or later. However, the provided context does not explicitly state that J06.14 is not suitable, but rather that J06.14.00 or later is the minimum required version.\n\nTo resolve the issue, ensure that your OSS version is at least J06.14.00. Since your current OSS version is J06.14, it is likely that the issue is due to the missing patch level (.00). You should update your OSS version to J06.14.00 or later to meet the minimum requirements for installing WebSphere MQ V5.3.1. \n\nIt is recommended to review the IBM documentation and HP support resources to confirm the exact requirements and to obtain the necessary updates for your OSS version.",
    "id": "TECHQA_DEV_Q108_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q110",
    "question": "Why does our Websphere application server hang when we apply Microsoft patch on our database server?\nWhy does our Websphere application server hang when we apply Microsoft patch on our database server?",
    "ground_truth": "1. Immediately purge the pool by invoking the purgePoolContents operation of the data source MBean with the immediate option using Jacl or Jython.\n   - Jacl: **$AdminControl invoke $ds purgePoolContents immediate**\n   - Jython: **AdminControl.invoke(ds, \"purgePoolContents\", \"immediate\")**",
    "answer": "The Websphere application server may hang when applying a Microsoft patch on the database server because the patch may invalidate cached connections in the Connection Manager pool. To resolve this issue, you can try purging the connection pool of the WebSphere Application Server data source using the `purgePoolContents` operation on the data source MBean. This can be done via the wsadmin console.\n\nHere are the steps to follow:\n\n1. List all data sources using the command: `$AdminControl queryNames *:type=DataSource,*` (in Jacl) or `AdminControl.queryNames(\"*:type=DataSource,*\")` (in Jython)\n2. Initialize a variable to specify the data source you want to purge, for example: `set name \"Default Datasource\"` (in Jacl) or `name = \"Default Datasource\"` (in Jython)\n3. Purge the pool contents by invoking the `purgePoolContents` operation with the `immediate` option: `$AdminControl invoke $ds purgePoolContents immediate` (in Jacl) or `AdminControl.invoke(ds, \"purgePoolContents\", \"immediate\")` (in Jython)\n\nThis should help resolve the issue and prevent the application server from hanging.",
    "id": "TECHQA_DEV_Q110_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q112",
    "question": "Why does nco_confpack -export fail with the message \"Tool in menu but not found\"?\nI tried to export OMNIbus configuration using nco_confpack command and I get the following message:\r\nTool in menu but not found, menu: AlertsMenu, tool: Close\r\nI've also tried using it with -list command and I get the same error.",
    "ground_truth": "1. Recreate the tool\n   \n2. Associate it with the **menu**\n   \n3. Try to run the command again\n   ",
    "answer": "The `nco_confpack -export` command fails with the message \"Tool in menu but not found\" because the tool referenced in the menu (in this case, \"Close\" in the \"AlertsMenu\") no longer exists. To resolve this issue, you need to recreate the missing tool and associate it with the menu. After recreating the tool, try running the `nco_confpack` command again.",
    "id": "TECHQA_DEV_Q112_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q122",
    "question": "Importing Asset GL Errors\nWhen importing or syncing with assets, I receive the following error for the glaccount.\n\nInternal Server Error\nError 500: nested exception is: psdi.util.MXAccessException: BMXAA4198E - The GL attribute TLOAMNEWGLACCOUNT on object {1} requires an organization. Specify a value in the Organization field.",
    "ground_truth": "1. Add the following field or tag to your inbound message.\n   Include the tag <NEWORGID>xxx</NEWORGID> in the XML message, where xxx is the **ORGID** value.",
    "answer": "To resolve the \"BMXAA4198E - The GL attribute TLOAMNEWGLACCOUNT on object {1} requires an organization\" error when importing or syncing assets, you need to add the `NEWORGID` field to your inbound message. For example, if you're sending XML, include the tag `<NEWORGID>xxx</NEWORGID>` where `xxx` is the actual `ORGID` value.\n\nAdditionally, ensure that `NEWORGID` is included in the object structure by following these steps:\n1. Go to **Integration** > **Object Structures**.\n2. Query the object structure.\n3. From the **Select Action** menu dropdown, choose **Exclude/Include Fields**.\n4. Select the **Non-Persistent Fields** tab.\n5. Include `NEWORGID` in the fields.\n\nBy adding the `NEWORGID` field to your inbound message and ensuring it's included in the object structure, you should be able to resolve the error related to the GL attribute requiring an organization.",
    "id": "TECHQA_DEV_Q122_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q132",
    "question": "What is the meaning of value \"unknown\" for ITCAM WAS Application Status attribute?\nWhat is the meaning of value \"unknown\" for ITCAM WAS Application Status attribute?",
    "ground_truth": "1. Enable the situation **WasAppDiscovered**.\n   If this situation is not enabled, then the user should enable it.\n2. Assign the situation to the **ITCAM App Server** managing system list.",
    "answer": "The value \"unknown\" for the ITCAM WAS Application Status attribute means that baselining has not started or has not been calculated for the application. This is indicated when you select Application Health, right-click on it, go to Workspace, and select Application Health status, and you see \"Unknown\". It suggests that the application's health status cannot be determined because baselining, which is the process of calculating a threshold based on response time information, has not been initiated or completed. To resolve this, you need to start the baselining process by following the steps outlined in the provided context.",
    "id": "TECHQA_DEV_Q132_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q141",
    "question": "Why is OCR is putting multiple lines on one line?\nI am running an APT application, and multiple detail lines are getting put on a single line within my .TXT file.  Is there something I can do about this?",
    "ground_truth": "1. Add the following action prior to **NormalizeCCO**.\n   ",
    "answer": "The issue you're experiencing with OCR putting multiple lines on one line is likely due to the NormalizeCCO function in IBM Datacap Taskmaster Capture. This function is merging lines because it's having trouble determining where to separate them, possibly due to varying font sizes or vertically offset text.\n\nTo resolve this issue, you can add an action prior to running NormalizeCCO with a parameter that specifies the percentage of a line that two words must be offset to be considered as separate lines. For example, you can set this value to 35, which means that if two words are vertically offset by more than 35% of the height of the words, they will be considered to be on separate lines.\n\nTry adding the following action before NormalizeCCO: `* *` with the desired percentage value. A lower value will be more likely to split words into separate lines, while a higher value will be more likely to merge words into a single line.",
    "id": "TECHQA_DEV_Q141_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q145",
    "question": "Why is the reload() not clearing the attribute cache so I can see my newly updated LDAP data in real time?\nWhy is the reload() not clearing the attribute cache so I can see my newly updated LDAP data in real time?",
    "ground_truth": "1. Please refer to the Recommended Updates page for delivery information.\n   Visit the URL **http://www.ibm.com/support/docview.wss?rs=180&uid=swg27004980** to get information about the delivery of the fix, which is targeted for inclusion in fix packs **8.0.0.13** and **8.5.5.9**.",
    "answer": "The `reload()` function is not clearing the attribute cache because you are using the `clearEntity` mode, which is known to cause issues with cache clearance when the base entry and name in the repository are different. This is a documented problem (APAR PI47826) that has been fixed in later fix packs of IBM WebSphere Application Server (starting from 8.0.0.13 and 8.5.5.9). To resolve the issue, you can either upgrade to a fix pack that includes the fix or try using a different mode. If you are already on a compatible fix pack, ensure that your configuration is correct and the base entry matches the name in the repository. If the issue persists, consider reaching out to IBM support for further assistance.",
    "id": "TECHQA_DEV_Q145_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q153",
    "question": "Can we create Match design specification db in xmeta\nCould you please let me know if we can create schema for Match design\nspecification database in xmeta db.",
    "ground_truth": "1. Start from an empty **Database**.",
    "answer": "Yes, you can create a schema for the Match design specification database in xmeta db. However, it is not recommended to use the default XMETA Database as it can become corrupt. Instead, create a new database following the requirements outlined in the context, such as setting the character set to AL32UTF for Oracle, using the default settings for SQL, and creating the database with a codepage of UTF-8 and page size of 32K for DB2. Additionally, ensure that each user has the necessary permissions to create tables, write, and read rights in the database. \n\nTo configure the Match Designer for use with the database, follow the steps outlined in the context, including creating a DSN, selecting the test environment, and filling in the required information for the test results database. \n\nIt's also important to note that the Match Database is used to test match specifications, store statistics and match results, and allow developers to change matching logic and retest quickly. Each user should have their own respective database to avoid overwriting previous results.",
    "id": "TECHQA_DEV_Q153_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q154",
    "question": "Why are some Datatypes corrupt after Impact cluster failover/failback ?\nRunning Impact 7.1.0.11. The symptom is whenever Impact does a failover, a couple DataTypes\nturn out empty.\n\nI've checked the type files before and after Impact failover and the difference happens in the property\n\n*.SQL.USERPARAMETERS\n\nThis property no longer exists for the corrupted datatypes\".",
    "ground_truth": "1. Add the property to $NCHOME/impact/etc/<SERVERNAME>_server.props file\n   This property should be set with a size limit that can be 8192, 16384, 32768, etc.\n2. Add the property to all ImpactServers in the Cluster\n\n3. Restart the ImpactServer to enable the property\n   Ensure that the ImpactServer started as **Primary** has the correct, uncorrupted **.type** file to be replicated across the Cluster.",
    "answer": "The issue you're experiencing with some DataTypes becoming corrupt after Impact cluster failover/failback is likely due to the APAR IZ81446. This APAR states that Impact 7.1.0.11 has a limitation where it cannot replicate DataTypes with USERPARAMETERS values exceeding 16,000 characters.\n\nTo resolve this issue, you need to add a new property to the `$NCHOME/impact/etc/<SERVERNAME>_server.props` file to increase the file size limit. For example, you can add the property `datatype.replication.maxlinesize=32768` to allow for larger USERPARAMETERS values.\n\nMake sure to add this property to all ImpactServers in the Cluster and restart them to enable the change. Also, ensure that there are no trailing white-space characters on the property, as these can invalidate properties in lower versions of Impact.\n\nBy adding this property, you should be able to prevent the corruption of DataTypes during failover/failback and ensure that the USERPARAMETERS property is correctly replicated across the Cluster.",
    "id": "TECHQA_DEV_Q154_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q161",
    "question": "Netcool/Impact 7.1.0: The StateChange value being used by the OMNIbusEventReader is too high\nThe value being used is a date and time in the future and as such is preventing the EventReader from capturing the current events.",
    "ground_truth": "1. Stop the EventReader.\n\n2. Open the EventReader for edit.\n   \n3. Click the **Clear State** button.\n   \n4. Exit the editor.\n   \n5. Restart the EventReader.\n   ",
    "answer": "To resolve the issue with the OMNIbusEventReader using a StateChange value that is too high and preventing it from capturing current events, you can follow one of these two solutions:\n\n1. **Manual Reset via GUI**:\n   - Stop the EventReader.\n   - Open it for edit.\n   - Click the \"Clear State\" button.\n   - Exit the editor and restart the EventReader.\n\n2. **Reset via Command Line Interface**:\n   - Use a script (like ClearState.sh) that stops the EventReader, clears the StateChange value, and restarts the EventReader.\n   - This can be automated using a PolicyActivator that checks for events with future-dated StateChange values and corrects them.\n\nBoth methods will reset the StateChange value used by the EventReader, allowing it to capture current events again.",
    "id": "TECHQA_DEV_Q161_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q162",
    "question": "Is there a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager?\nIs there a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager?",
    "ground_truth": "1. Consult the security bulletin Vulnerability in **Apache Commons** affects IBM WebSphere Application Server",
    "answer": "Yes, there is a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager. The vulnerability is identified as CVE-2015-7450 and affects ITNCM versions 6.4.1.3 and 6.3.0.6. It allows a remote attacker to execute arbitrary code on the system by sending specially crafted data. To remediate this vulnerability, you can download and apply the fixes from the IBM Fix Central website, or upgrade to a fixed, supported version of the product if you are using ITNCM 6.2.x.",
    "id": "TECHQA_DEV_Q162_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q167",
    "question": "How do I recreate all the Oracle Text indexes for the Atlas database\nHow do I recreate all the Oracle Text indexes for the Atlas database ?",
    "ground_truth": "1. Shutdown the application server running the Atlas applications.\n   \n2. Locate the script drop_ctxsys_indexes.sql to drop the Oracle Text indexes.\n   Locate the script drop_ctxsys_indexes.sql to drop the Oracle Text indexes from the following folder in the Atlas release: **Atlas\\Schema\\Deploy\\smf\\db\\etc\\oracle**\n3. Open up a command window to that directory and execute the script using SQL Plus.\n   Open up a command window to that directory and execute the script using SQL Plus: **sqlplus <user>/<password>@<database> @drop_ctxsys_indexes.sql**\n4. Locate the scripts, setup_ctxsys_objects.sql and create_ctxsys_indexes.sql.\n   Locate the scripts, setup_ctxsys_objects.sql and create_ctxsys_indexes.sql, used to create the Oracle Text preferences and indexes from the following folder in the Atlas release. The <version> folder will differ depending on which version you are currently running: **Atlas\\Schema\\Deploy\\smf\\db\\release\\<version>\\oracle\\create\\schema**\n5. Open up a command window to that directory and execute the scripts using SQL Plus.\n   Open up a command window to that directory and execute the scripts using SQL Plus: **sqlplus <user>/<password>@<database> @setup_ctxsys_objects.sql**, **sqlplus <user>/<password>@<database> @create_ctxsys_indexes.sql**\n6. Start the application server running the Atlas applications.\n   ",
    "answer": "To recreate all the Oracle Text indexes for the Atlas database, follow these steps:\n\n1. Shutdown the application server running the Atlas applications.\n2. Locate the script `drop_ctxsys_indexes.sql` in the `Atlas\\Schema\\Deploy\\smf\\db\\etc\\oracle` folder and execute it using SQL Plus: `sqlplus <user>/<password>@<database> @drop_ctxsys_indexes.sql`\n3. Locate the scripts `setup_ctxsys_objects.sql` and `create_ctxsys_indexes.sql` in the `Atlas\\Schema\\Deploy\\smf\\db\\release\\<version>\\oracle\\create\\schema` folder and execute them using SQL Plus:\n   - `sqlplus <user>/<password>@<database> @setup_ctxsys_objects.sql`\n   - `sqlplus <user>/<password>@<database> @create_ctxsys_indexes.sql`\n4. Start the application server running the Atlas applications.\n\nNote: Replace `<user>`, `<password>`, `<database>`, and `<version>` with the actual values for your Atlas database and version.",
    "id": "TECHQA_DEV_Q167_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q171",
    "question": "Error: \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" occurs at portal startup\nWe are using Portal Server 8.5 and when starting the Portal server we see following error:\n\n0000005e MBeanStarter E com.ibm.wps.scripting.server.MBeanStarter loadExtensions failed to load extension: key: ServerExt.applications / value: com.ibm.wps.scripting.server.ApplicationServerExtensions\n\nHow can we resolve this error?",
    "ground_truth": "1. Use the WebSphere Portal & WCM Combined Cumulative Fix 05 (PI31198) that is available for Portal version **8.5.0.0** from **Fix Central**.",
    "answer": "To resolve the \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" error at portal startup, you can try the following steps:\n\n1. Open the WebSphere Application Server (WAS) admin console.\n2. Navigate to Resources > Resource environment providers > WP ScriptingService > Custom properties.\n3. Look for an entry with the name \"ServerExt.applications\" and value \"com.ibm.wps.scripting.server.ApplicationServerExtensions\".\n4. Delete this entry, save, and restart the server.\n\nAlternatively, you can also apply the Combined Cumulative Fix 05 (PI31198) for Portal 8.5.0.0, which includes a code fix for this issue. The fix is available from Fix Central.\n\nBy following these steps, you should be able to resolve the error and successfully start the Portal server.",
    "id": "TECHQA_DEV_Q171_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q181",
    "question": "Get all data that\\'s registred today\nVersion: \nMxLoader 4.7.4\n                        \n\nProblem:\nIs it possible to do something like this:\nreportdate >= TODAY()?\n\nI cant get it to work but i would like to get all the data that has been registred today today.",
    "ground_truth": "1. Replace getdate() MSSQL function by **DB2 CURRENT DATE** special register.\n",
    "answer": "To get all data that's registered today in MxLoader 4.7.4, you can use the following syntax:\n\nFor DB2: `reportdate >= CURRENT DATE`\nFor Oracle: `reportdate >= sysdate`\nFor SQL Server: `reportdate >= getdate()`\n\nThis will retrieve all data where the `reportdate` is today's date. Note that the exact syntax may vary depending on the specific database management system you are using. \n\nTry using one of the above conditions in your query to achieve the desired result. If you're still having trouble, please provide more details about your query and the error message you're receiving.",
    "id": "TECHQA_DEV_Q181_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q186",
    "question": "Silent uninstall of ITCAM for MQ agent fails\nRunning silent uninstall of the ITCAM for MQ agent with this command: start /wait setup /z\"/sfMQ_Silent_Uninstall.txt\" /s /f2\"C:\\temp\\silent_setup.log\" fails with this message in the Abort_*.trc file: SEVERE: You must agree to the License Agreement.\n\nThe MQ_Silent_Uninstall.txt does contain this line: License Agreement=I agree to use the software only in accordance with the installed license.",
    "ground_truth": "1. Specify the complete path to the silent response file while launching the silent install.",
    "answer": "The issue with the silent uninstall of the ITCAM for MQ agent failing is due to the incomplete path to the silent response file not being specified in the command. \n\nTo resolve this issue, specify the complete path to the silent response file (MQ_Silent_Uninstall.txt) in the command. For example:\n\n`start /wait setup /z\"/sfC:\\complete\\path\\to\\MQ_Silent_Uninstall.txt\" /s /f2\"C:\\temp\\silent_setup.log\"`\n\nEnsure that the path to the MQ_Silent_Uninstall.txt file is correct and the file contains the necessary line: `License Agreement=I agree to use the software only in accordance with the installed license.` \n\nThis should allow the silent uninstall to proceed without prompting for the license agreement.",
    "id": "TECHQA_DEV_Q186_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q196",
    "question": "Error while installing SpSS modeler trial version\nI have downloaded the SPSS modeller trial version (18.1) (64 bit) and trying to install the same. I get the following error 1152: Error extracting modelerClient64.msi to the temporary location",
    "ground_truth": "1. Transfer the **files** again.",
    "answer": "To resolve the error 1152 while installing the SPSS Modeler trial version, try the following steps:\n\n1. **Verify the download integrity**: Use a tool like MD5 to check if the downloaded file is corrupted. Alternatively, try downloading the trial version again to ensure you have a complete and uncorrupted file.\n2. **Check available space in the temporary location**: Ensure that there is sufficient disk space in the temporary location where the installer is trying to extract the files. Free up some space if necessary.\n3. **Check write permissions in the temporary location**: Make sure that the installer has the necessary permissions to write to the temporary location.\n\nIf none of these steps resolve the issue, you can visit the IBM Modeler forum (https://developer.ibm.com/answers/topics/modeler/?smartspace=predictive-analytics) for further assistance.",
    "id": "TECHQA_DEV_Q196_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q201",
    "question": "Why are HTML documents not rendering  and just shown as plain text after upgrading and installing ifixes to BPM?\nAfter upgrading BPM, my HTML documents that were once rendering are no longer being displayed correctly and are being shown as plain text. This is happening in multiple web browses.",
    "ground_truth": "1. Install IBM Business Process Manager interim fix **JR50092**.",
    "answer": "The issue you're experiencing with HTML documents being displayed as plain text after upgrading and installing iFixes to BPM is due to a security feature that maps the `text/html` MIME type to `text/plain` by default. This is a result of the CVE-2014-3075 vulnerability fix, which aims to prevent potentially malicious files from being uploaded and executed.\n\nTo resolve this issue, you need to explicitly add the `text/html` MIME type to the `100Custom.xml` file to override the default configuration. This will allow HTML documents to be rendered correctly again.\n\nHere's an example of how to configure the `100Custom.xml` file:\n```xml\n<document-attachment-download-mime-types>\n  <!-- will map text/html mime type to text/html mime type -->\n  <mime-type-map>\n    <from>text/html</from>\n    <to>text/html</to>\n  </mime-type-map>\n</document-attachment-download-mime-types>\n```\nBy adding this configuration, you're allowing HTML documents to be rendered correctly, while still maintaining the security benefits of the vulnerability fix.",
    "id": "TECHQA_DEV_Q201_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q202",
    "question": "Why is installation manager cores when try to install netcool using GUI mode in AIX 7.1?\nIBM Installation Manager Cores when running in GUI mode on AIX 7.1",
    "ground_truth": "1. Install the **gtk+** RPM and dependencies on **AIX**\n   ",
    "answer": "\n\nThe IBM Installation Manager is crashing (cores) when trying to install Netcool using GUI mode on AIX 7.1 because the required gtk libraries are not installed. To resolve this issue, you need to install the gtk+ RPM and its dependencies on AIX. This will allow the Installation Manager to support the graphical user interface (GUI) mode. Alternatively, you can use the Installation Manager in console mode, command-line mode, or silent mode, which do not require the gtk libraries.",
    "id": "TECHQA_DEV_Q202_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q209",
    "question": "How to change the maximum string length for properties in FileNet Administration Console for Content Engine (ACCE)\nI am trying to change the maximum string length in ACCE like we do in FileNet Enterprise Manager, but in the more Tab, I am not seeing the option. In this case, how can I change it?",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open **Document Class** tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the **Class Definition** tab and click Save\n   ",
    "answer": "To change the maximum string length for properties in FileNet Administration Console for Content Engine (ACCE), follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click the object store to open the Object store tab.\n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab.\n4. From Properties tab, open Property Definitions drop down and select the property definition you want to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the property definition as required, including changing the maximum string length.\n7. Go back to the Class Definition tab and click Save.\n\nNote: The specific step to change the maximum string length is not explicitly mentioned in the provided context, but it is implied that you can modify the property definition as required in step 6. If the maximum string length option is not available in the property definition, you may need to refer to additional documentation or contact IBM support for further assistance.",
    "id": "TECHQA_DEV_Q209_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q216",
    "question": "Error message 1311 when attempting to install SPSS 23 on Windows 10.\nI have downloaded SPSS 23 onto a Windows 10 operating system. The computer previously had SPSS, however the computer crashed and SPSS needs be installed on the new operating system. When trying to install the program the following error message appears Error 1311. Source file not found.\n\nScreenshot attached.\nerror-messg.png (50.7 kB)",
    "ground_truth": "1. Stop the installation.\n   \n2. Extract all of the files in the compressed (.zip file) to a new folder.\n   \n3. Run the installer executable (**setup.exe**) from that new folder.\n   ",
    "answer": "To resolve the Error 1311 issue when attempting to install SPSS 23 on Windows 10, follow these steps:\n\n1. Stop the current installation process.\n2. Right-click on the downloaded compressed file (.zip).\n3. Select the 'Extract All' option from the drop-down menu.\n4. Click the 'Extract' button to extract all files to a new folder.\n5. Once the extraction is complete, navigate to the new folder containing the extracted files.\n6. Run the installer executable ('setup.exe') from this new folder to proceed with the installation.\n\nThis should resolve the \"Error 1311. Source file not found\" issue and allow you to successfully install SPSS 23 on your Windows 10 operating system.",
    "id": "TECHQA_DEV_Q216_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q221",
    "question": "App Connect Professional (formerly Cast Iron) Studio not launching\nWhen trying to start App Connect Professional (formerly Cast Iron) Studio tool, the application appears but after few seconds it crashes with no error message or warning.",
    "ground_truth": "1. Start the Studio through the command line interface using the following command: **CastIronStudio.exe -J-Xmx1024m**\n   This command starts the Studio by executing the 'CastIronStudio.exe' file and allocates a memory size of '1024' MB to the Studio instead of the default value of 512 MB.",
    "answer": "To resolve the issue with App Connect Professional (formerly Cast Iron) Studio not launching, try increasing the size of the heap memory allocated to the Studio. You can do this by starting the Studio through the command line interface using the following command:\n\n`CastIronStudio.exe -J-Xmx1024m`\n\nThis command allocates 1024MB of memory to the Studio, which may help prevent it from crashing. You can adjust the numeric value (in this case, 1024) to a higher or lower value depending on your system's configuration and available memory. If the issue persists, you may want to try using garbage collection from Studio to free up unused space or adjusting the XML Schema preference settings. If you need further assistance, consider opening a service request with IBM Cast Iron Support.",
    "id": "TECHQA_DEV_Q221_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q224",
    "question": "How do we set HttpOnly and secure flag in Oracle Weblogic 12c to secure IBM Atlas?\nHow do we set HttpOnly and secure flag in Oracle Weblogic 12c to secure IBM Atlas?",
    "ground_truth": "1. Undeploy any existing PolicyAtlas deployments using Oracle Weblogic console\n   \n2. Open the **PolicyAtlas.ear** file using a tool like 7zip or similar and update weblogic.xml file with the changes below\n   Update the weblogic.xml file to include the following session descriptor changes: **<wls:session-descriptor><wls:cookie-secure>true</wls:cookie-secure><wls:cookie-http-only>true</wls:cookie-http-only><wls:url-rewriting-enabled>false</wls:url-rewriting-enabled></wls:session-descriptor>**\n3. Save the changes by updating the ear file\n   \n4. Redeploy the updated ear file using Oracle Weblogic console\n   ",
    "answer": "To set the HttpOnly and secure flag in Oracle Weblogic 12c to secure IBM Atlas, follow these steps:\n\n1. Undeploy any existing PolicyAtlas deployments using the Oracle Weblogic console.\n2. Open the PolicyAtlas.ear file using a tool like 7zip, and update the `weblogic.xml` file with the following changes:\n```\n<wls:session-descriptor>\n  <wls:cookie-secure>true</wls:cookie-secure>\n  <wls:cookie-http-only>true</wls:cookie-http-only>\n  <wls:url-rewriting-enabled>false</wls:url-rewriting-enabled>\n</wls:session-descriptor>\n```\n3. Save the changes by updating the ear file.\n4. Redeploy the updated ear file using the Oracle Weblogic console.\n\nThis will set the HttpOnly and secure flags, helping to prevent session hijacking and secure the cookie for IBM Atlas in Oracle Weblogic 12c.",
    "id": "TECHQA_DEV_Q224_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q229",
    "question": "Can I hide left menu pane for specific application?\nIs it possible to disable the left navigation pane menu for certain application?",
    "ground_truth": "1. Edit the **incident.xml**.\n\n2. Import back the **incident.xml** and save.",
    "answer": "Yes, it is possible to disable the left navigation pane menu for a specific application. To do this, you need to include `systemnav=\"false\"` in the application presentation XML. For example, you can edit the `incident.xml` file by adding `systemnav=\"false\"` to the `<presentation>` tag, then import the updated file and save. This will hide the left navigation pane menu for the specified application.",
    "id": "TECHQA_DEV_Q229_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q234",
    "question": "TCR 2.1.1 Fixpack 2 installation failed\nI need to install Fixpack 2 on my TCR 2.1.1 environment, but the installation keeps failing with error:\n\n     ACUOSI0050E External command action failed with return code 1.\n\nI was not able to understand why it is failing. Can you please help providing suggestion to perform a correct troubleshooting ?\n\nThanks",
    "ground_truth": "1. Double check the permission bit for the involved directory tree.\n\n2. In case, temporarily set them to give **write** authorization to the user account.\n\n3. Run again the installation program.",
    "answer": "To troubleshoot the failed installation of TCR 2.1.1 FixPack 2, follow these steps:\n\n1. **Check the log file**: Look at the `IBM_Tivoli_Common_Reporting_2.1_1_FP2.log` file for additional details about the failure.\n2. **Verify permissions**: The error message `ACUOSI0050E External command action failed with return code 1` and the `Permission denied` message in the `tcr211_Embedded_FP2_run_cognos_copy_ear_update.err` file indicate a lack of permission for the user account used to run the installation. Check the permission bits for the involved directory tree and temporarily set them to give write authorization to the user account you are installing the FixPack with.\n3. **Check the `tcr211_Embedded_FP2_run_cognos_copy_ear_update.err` file**: This file may contain more detailed information about the installation failure, such as the specific file that cannot be copied due to permission issues.\n4. **Run the installation again**: After verifying and adjusting the permissions, run the installation program again.\n\nBy following these steps, you should be able to identify and resolve the permission issues causing the installation failure. If you continue to experience issues, you may want to consider running the installation with a root user or seeking further assistance from IBM support.",
    "id": "TECHQA_DEV_Q234_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q239",
    "question": "Cannot launch RFT 8.2\nHello.\n\nCould anyone can help to see why I cannot launch RFT 8.2? When I launch RFT. I get an error message--\"An error has occurred. See the log file...\" I check the log file. It shows\n\n!SESSION Mon Nov 04 12:46:16 CST 2013 ------------------------------------------\n!ENTRY org.eclipse.equinox.launcher 4 0 2013-11-04 12:46:16.359\n!MESSAGE Exception launching the Eclipse Platform:\n!STACK\njava.lang.ClassNotFoundException: org.eclipse.core.runtime.adaptor.EclipseStarter\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:423)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:653)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:619)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:616)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1407)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1383)\n\nIf I launch RFT with -clean or -vm option, the same phenomenon occurs.",
    "ground_truth": "1. Delete the user's .eclipse/ibm.software.delivery.platform_7.5.0_???? directory.\nFor example, run command rm -rf /home/joe/.eclipse/ibm.software.delivery.platform_7.5.0_1529064711 to delete the specified directory.\n2. Relaunch the package.",
    "answer": "To resolve the issue with launching RFT 8.2, you need to delete the `.eclipse/ibm.software.delivery.platform_7.5.0_????` directory. This directory is likely located in your user directory. For example, if your username is \"joe\", you would delete the following directory:\n\n`/home/joe/.eclipse/ibm.software.delivery.platform_7.5.0_????`\n\nReplace `joe` with your actual username and `????` with the actual numbers in the directory name. After deleting this directory, relaunch RFT 8.2. This should resolve the `java.lang.ClassNotFoundException: org.eclipse.core.runtime.adaptor.EclipseStarter` error and allow you to launch RFT 8.2 successfully.",
    "id": "TECHQA_DEV_Q239_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q240",
    "question": "Port number error starting 9.0 Launcher\nI'm attempting to start up v9.0 for the first time with one .msl file on a Windows server and get the following error.  I also have v8.4 on this server and it starts fine.  I do not have v8.4 running when I attempt to start v9.0.\n\nCannot recognize if the system RecordChangeSystem.msl; has started. Reason: Server is unable to get the status of the system on port number 6,002.\n\nI have the port range set to 7000/8000.  I've never seen this error before.\n\nAny help?  Thanks.",
    "ground_truth": "1. Obtain patch for APAR **PI64816**.\n   ",
    "answer": "The provided context does not seem to relate directly to the issue of a port number error when starting the 9.0 Launcher. The context discusses an issue with the IBM Transformation Extender (ITX) Launcher failing when specific settings are used, which does not appear to be relevant to the port number error described in the question.\n\nGiven the information provided in the question, it seems that the issue might be related to the port range settings or a conflict with another application. However, without more specific information about the configuration, environment, or how the port range is set, it's difficult to provide a precise solution.\n\nTo troubleshoot the issue, you might want to try adjusting the port range settings to ensure that port 6002 is included within the range, or check if another application is using this port. Additionally, verifying that there are no firewall rules blocking the port and ensuring that the server is configured to allow communication on the specified port range could be helpful.\n\nUnfortunately, based on the provided context, I don't know the exact solution to the port number error when starting the 9.0 Launcher. Further investigation into the specific configuration and environment of the server and the application would be necessary to resolve the issue.",
    "id": "TECHQA_DEV_Q240_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q244",
    "question": "How to clear Errors Found in crm_mon\nHow to clear Errors Found in crm_mon",
    "ground_truth": "1. Run the cib_tools.pl script.\n   Execute the command **/opt/nz-hwsupport/pts/cib_tools.pl** in the terminal.",
    "answer": "To clear errors found in `crm_mon`, follow these steps:\n\n1. Run the command `/opt/nz-hwsupport/pts/cib_tools.pl` as the root user.\n2. The tool will display a list of failed resources that can be cleared. Select the resource you want to clear by inputting the corresponding number.\n3. Confirm that the resource has been cleared successfully.\n4. Repeat the process for each failed resource until all errors have been cleared.\n\nNote: The `cib_tools.pl` script is used to manage and clear failed resources in the cluster. The `crm_mon` command is used to monitor the cluster status, and the `cib_tools.pl` script is used to take corrective actions to clear errors.",
    "id": "TECHQA_DEV_Q244_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q245",
    "question": "Problem with XMLLIB->VALIDATEEX during XML Validation\nI am using XMLLIB VALIDATEXX in WTX 8.3.0.5 for XML Validations and it is running fine on Windows.\nWhen deployed same code on zos map is executing in loop(output card having rule with xmllib method call is not completing) \nPlease suggest.Thanks",
    "ground_truth": "1. Add the XML toolkit **xml4c** library directory to the **LIBPATH** environment variable.\n   Execute the command: **export LIBPATH=$LIBPATH:/usr/lpp/ixm/xslt4c-1_11/lib/** (example)",
    "answer": "To resolve the issue with XMLLIB->VALIDATEEX during XML validation on z/OS, you need to add the XML toolkit xml4c library directory to the LIBPATH environment variable. This is because the library directory is missing from the LIBPATH, causing the map execution to loop indefinitely.\n\nTo fix this, you can use the following example command:\n\n`export LIBPATH=$LIBPATH:/usr/lpp/ixm/xslt4c-1_11/lib/`\n\nThis will add the necessary library directory to the LIBPATH environment variable, allowing the XML validation to complete successfully.",
    "id": "TECHQA_DEV_Q245_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q254",
    "question": "Why do I receive the message, \"IKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION. \" for a TSO SEND command?\nIf you issue the TSO SEND command in a batch job and receive this message:\n\nIKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION.\nIKJ79154I REASON CODE X'00000004'.",
    "ground_truth": "1. Code a facility class for the **FEK.CMD.SEND** and **FEK.CMD.SEND.CLEAR**\n   ",
    "answer": "The message \"IKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION\" with reason code X'00000004' is received because the RDz TSO Send command is invoking the TSO exit IKJEESX0, which terminates with a reason code of 4 when no facility class is coded for FEK.CMD.SEND and FEK.CMD.SEND.CLEAR.\n\nTo resolve the problem, you need to code the appropriate security definitions for FEK.CMD.SEND and FEK.CMD.SEND.CLEAR. You can do this by running the following TSO commands:\n\n1. RDEFINE FACILITY (FEK.CMD.SEND.**) UACC(READ) - DATA('z/OS EXPLORER - SEND COMMAND')\n2. RDEFINE FACILITY (FEK.CMD.SEND.CLEAR.**) UACC(NONE) - DATA('z/OS EXPLORER - CLEAR SEND BUFFER')\n3. PERMIT FEK.CMD.SEND.CLEAR.** CLASS(FACILITY) - ID(STCRSE) ACCESS(READ)\n4. SETROPTS RACLIST(FACILITY) REFRESH\n\nThese commands will allow everyone to send messages and only users with the ID STCRSE to clear the message buffer. After running these commands, the issue should be resolved.",
    "id": "TECHQA_DEV_Q254_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q257",
    "question": "How to control SDMS database size?\nHi,\n\nITCAM for SOA 7.1.1 was installed about 3 years ago. I already know that SDMS database size may increase with no limit. Has anyone found a way to keep under control this behavior?\n\nThanks",
    "ground_truth": "1. Schedule a daily job to run the **kd4TrimDB2db** utility.\n   This step involves setting up a regular task that executes the **kd4TrimDB2db** utility every day to maintain only the latest 24 hours of data.",
    "answer": "To control the SDMS database size in ITCAM for SOA 7.1.1, you can schedule a daily job to run the `kd4TrimDB2db` utility. This will allow you to regularly prune the database and keep only the latest 24 hours of data. You can refer to the provided Wiki page for more information: https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Tivoli+Composite+Application+Manager/page/Pruning+SDMS+Relationship+Metrics+Tables. Note that this version is out-of-support since 2015, and upgrading to a newer version like 7.2 may provide a built-in cleanup task that automatically manages database size.",
    "id": "TECHQA_DEV_Q257_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q260",
    "question": "Crash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\nCrash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\n\nDetails of gpf crash events: A VerifyError was thrown due to \"Inaccessible class\" at offset 39(0x27) of the method executeInternal(Lorg/springframework/http/HttpHeaders;[B)Lorg/springfram ework/http/client/ClientHttpResponse of the above class org/springframework/http/client/HttpComponentsClientHttpRequest.\n\nLooking at method the bytecodes :\n\n31 invokespecial 15 org/apache/http/entity/ByteArrayEntity.([B)V 34 astore 4 36 aload3 37 aload 4 39 invokeinterface2 41 invokeinterface 16 org/apache/http/HttpEntityEnclosingRequest.setEntity(Lorg/apache/http/Ht tpEntity;)V\n\nThe above sequence of bytecodes indicates it created an instance of org/apache/http/entity/ByteArrayEntity, trying to cast it to type Lorg/apache/http/HttpEntity; which in turns led to the \"Inaccessible class\" VerifyError message.\n\nIt is clear that class org/apache/http/HttpEntity was not loaded at all:\n\n    allclasses | grep org/apache/http/HttpEntity",
    "ground_truth": "1. Update the application with **HTTPCore** and **HTTPClient** libraries bundled.",
    "answer": "To resolve the crash issue caused by the \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\", you should download and apply the fix provided by IBM. The fix is available for different versions of WebSphere Application Server, including 8.0.0.11 and 8.5.5.7. \n\nHere are the steps to follow:\n1. Go to the IBM Fix Central website and download the appropriate fix package for your WebSphere Application Server version.\n2. Review the readme.txt file included in the fix package for detailed installation instructions.\n3. Apply the fix according to the instructions provided.\n\nNote: After applying the fix, you may encounter a NoClassDefFoundError because the API in HTTPCore and HTTPClient libraries are no longer visible to the application. To resolve this error, you may need to update your application with the HTTPCore and HTTPClient libraries bundled.\n\nIf you need further assistance, you can contact IBM Support using the Service Request (SR) tool or visit the WebSphere Application Server support website.",
    "id": "TECHQA_DEV_Q260_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q263",
    "question": "How can I check the health of my IBM PureApplication System?\nHow can I check the health of my IBM PureApplication System?\nAre there steps to verify that my system is healthy? Is this something I can do, or does IBM have to verify the health of my system?",
    "ground_truth": "1. Consider forwarding the **PureApplication System Events** to an external monitoring system, such as IBM Netcool/OMIbus.\n\n2. Enable the call home feature.",
    "answer": "To check the health of your IBM PureApplication System, you can follow these steps:\n\n1. **Use the System Health Check report**: If your system has firmware version 2.1.0.1 or newer, go to **System** > **System Troubleshooting**, and click on **System Health Check**.\n2. **Perform a Lite Health Check**:\n\t* Check the High Availability Status: **System Console** > **Troubleshooting**, expand the **High Availability** section, and verify that the overall status is \"Online\".\n\t* Check for Problems: **System Console** > **System** > **Problems**, which should be empty.\n3. **Perform a Full Health Check** (recommended weekly):\n\t* Check the High Availability Status (as above).\n\t* Check Temperature: **System Console** > **Hardware** > **Infrastructure Map**, and click on \"Temperature\" in the top menu bar.\n\t* Check Storage Nodes: **System Console** > **Hardware** > **Storage Devices**, and verify that Disk Drives, LUNs, and Storage Controller Ports are available for each node.\n4. Consider forwarding PureApplication System Events to an external monitoring system, such as IBM Netcool/OMNIbus, and enabling the call home feature.\n\nIf you encounter any issues or unexpected results during these checks, you can copy the relevant web pages to a word processing document and proceed to contact IBM Support for further assistance.",
    "id": "TECHQA_DEV_Q263_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q266",
    "question": "How to install Packaging utility?\nHow to install Packaging utility?",
    "ground_truth": "1. Use **Installation Manager** to install and update **Packaging Utility**.\n   ",
    "answer": "To install the Packaging Utility, follow these steps:\n\n1. **Check if Installation Manager is installed**: If it is, you can use the Packaging Utility repository on www.ibm.com to install or update Packaging Utility without downloading files.\n2. **If Installation Manager is not installed**, download the Packaging Utility files. The installer package is `pu.offering.disk.platform_version.zip`, where `platform` indicates the operating system and `version` indicates the version of Packaging Utility.\n3. **Run the install command** using the downloaded package to install Packaging Utility and Installation Manager.\n4. **Alternatively**, add the package as a repository in Installation Manager and use it to update Packaging Utility.\n\nNote: You can also install or update Packaging Utility without downloading files by accessing the Packaging Utility repository on www.ibm.com, but you need to have an IBM user name and password.",
    "id": "TECHQA_DEV_Q266_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q271",
    "question": "Problem with Postal database in Parascript\nHi\n\ni am working with Parascript and i have installed successfully in my local system by folloing this guide [ Parascript FieldScript for Taskmaster Guide ]\n\nhere i can able to create vocabulary file, but storing multiple values into this the values are overridden and i do not understand how to create a postal database and access it\n\nis that postal database is separate component ,,?? do we need to get somewhere and install ,,? they just mention in Guide the use of actions only\n\nand does this parascript really helps to get better recognize.",
    "ground_truth": "1. Obtain refreshed data from Passport Advantage on a regular schedule so that you avoid issues that are associated with disabled address information.",
    "answer": "To resolve the issue with the Postal database in Parascript, it appears that the database is a separate component that comes with the data disk, which is available for download through Passport Advantage. The guide you followed, \"Parascript FieldScript for Taskmaster Guide,\" only mentions the use of actions, but it does not provide information on how to create and access the postal database.\n\nTo obtain the postal database, you need to download the data disk from Passport Advantage, which contains the United States Postal Service (USPS) database. Please note that the address information in the USPS database is automatically disabled 105 days after the date of issue, so you will need to ensure that you obtain the refreshed data from Passport Advantage on a regular schedule.\n\nTo access the postal database, you may need to refer to additional documentation or contact technical support for assistance. You can find technical support resources at the following links:\n\n* Passport Advantage Online support: https://www.ibm.com/software/howtobuy/passportadvantage/paocustomer/docs/en_US/ecare.html\n* IBM Datacap Taskmaster Capture V8.0.1 and V8.1.0 support: http://www.ibm.com/support/entry/portal/Overview/Software/Information_Management/Datacap_Taskmaster_Capture\n\nRegarding your question about whether Parascript helps to get better recognition, the answer is yes. Parascript is designed to improve the accuracy of data recognition and extraction, but the effectiveness of the software depends on various factors, including the quality of the input data and the configuration of the software.",
    "id": "TECHQA_DEV_Q271_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q275",
    "question": "Jobtask long description\nHow do I modify the JP sheet to include the JOBTASK Long description in the query.  I have tried JOBTASK.DESCRIPTION.DESCRIPTION_LONGDESCRITION and other combinations but they do not seem to work.",
    "ground_truth": "1. Go To Integration -> Integration Object\n   \n2. Click Select Action -> Exclude/Include Fields\n\n3. On the Persistent Fields tab, exclude **HASLD**\n   \n4. On the Non-Persistent Fields tab, include **DESCRIPTION_LONGDESCRIPTION**",
    "answer": "To modify the JP sheet to include the JOBTASK Long description in the query, you should use `DESCRIPTION_LONGDESCRIPTION` instead of `JOBTASK.DESCRIPTION.DESCRIPTION_LONGDESCRITION`. \n\nIn the Integration Object or Object Structures, go to the Non-Persistent Fields tab and include `DESCRIPTION_LONGDESCRIPTION`. Make sure to exclude `HASLD` from the Persistent Fields tab. \n\nAlternatively, you can add the long description tag to the inbound XML: `<DESCRIPTION_LONGDESCRIPTION>xxxxx</DESCRIPTION_LONGDESCRIPTION>`. Do not include the `HASLD` tag, as it will be set automatically. \n\nNote that if you are using DB2 or SQL Server, you may need to use an alias for `DESCRIPTION_LONGDESCRIPTION` since the column name is longer than 18 characters.",
    "id": "TECHQA_DEV_Q275_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q283",
    "question": "Hello - I recently installed SPSS 20, my temporary period for running spss has expired, I am in need of the actual license code to fully install. my Lock code is: 4-20C30\nHello - I recently installed SPSS 20, my temporary period for running spss has expired, I am in need of the actual license code to fully install. my Lock code is: 4-20C30 . please help!",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To obtain the actual license code for your SPSS 20 installation, you will need to contact the vendor from whom you purchased the software. Since your temporary period has expired and you have a Lock code (4-20C30), you should reach out to one of the authorized vendors listed, such as Hearne, On the Hub, StudentDiscounts.com, JourneyEd, thinkEDU, or Studica, for assistance with licensing issues. They should be able to provide you with the necessary license code to fully install and use your SPSS 20 software.",
    "id": "TECHQA_DEV_Q283_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q292",
    "question": "Content Engine System Health Page page doesn't reflect correctly, Fixed Content Advise and Storage Area showing unavailable.\nContent Engine System Health Page page doesn't reflect correctly, Fixed Content Advise and Storage Area showing unavailable.",
    "ground_truth": "1. Verify the Content Engine Bootstrap User has **Full Control** on the Object Store and all associated Storage Areas.\n   \n2. Inspect Storage Area security by right-clicking on the **Object Store**.\n   \n3. Choose Properties.\n   \n4. Select the **All Properties** radio button and view the Storage Area property name.\n   \n5. Click on the drop down list to select the Storage Area.\n   \n6. The Storage Area properties screen will appear.\n   \n7. Verify the Security tab allows the Content Engine Bootstrap User has Full Control.\n   ",
    "answer": "To resolve the issue where the Content Engine System Health Page doesn't reflect correctly and Fixed Content Advise and Storage Area show as unavailable, follow these steps:\n\n1. **Verify Content Engine Bootstrap User Permissions**: Ensure the Content Engine Bootstrap User has Full Control on the Object Store and all associated Storage Areas.\n2. **Inspect Storage Area Security**:\n   - Right-click on the Object Store.\n   - Choose Properties.\n   - Select the \"All Properties\" radio button and view the Storage Area property name.\n   - Click on the drop-down list to select the Storage Area.\n   - In the Storage Area properties screen, verify the Security tab allows the Content Engine Bootstrap User to have Full Control.\n\nIf after following these steps the issue persists, check the `p8_server_error` log for an `E_ACCESS_DENIED` error, which may indicate insufficient access rights for the requester to perform the requested operation. Adjusting the permissions accordingly should resolve the issue.",
    "id": "TECHQA_DEV_Q292_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q296",
    "question": "Does the BPM internal Document Store work with IBM DB2 pureScale?\nI use IBM DB2 pureScale with my BPM installation. During startup of the server and initialization of the internal document store I see hanging threads in the systemOut.log and the process will not finish. How can this be solved?",
    "ground_truth": "1. Have a single DB2 **pureScale** member active during FileNet CM addon installation.\n",
    "answer": "To solve the issue of hanging threads during the initialization of the internal document store with IBM DB2 pureScale, ensure that only a single DB2 pureScale member is active during the startup of the BPM server and the initialization of the internal document store. After the initialization has completed successfully, you can bring the other DB2 pureScale members back online. This approach should prevent the excessive SQL locking and subsequent lock timeouts that are causing the hanging threads and process failures.",
    "id": "TECHQA_DEV_Q296_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q298",
    "question": "can Datacap support to Arabic language?\ncan Datacap support to Arabic language?",
    "ground_truth": "1. License NovoDynamics NovoVarus separately.\n\n2. Install it on the **Rulerunner** machine where the \n   Datacap Studio actions for Arabic (Datacap.Libraries.NovoDynamics) will be running.",
    "answer": "Yes, Datacap supports the Arabic language. However, support for Arabic requires that customers license NovoDynamics NovoVarus separately and install it on the Rulerunner machine where the Datacap Studio actions for Arabic (Datacap.Libraries.NovoDynamics) will be running.",
    "id": "TECHQA_DEV_Q298_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q299",
    "question": "Netcool/Impact 6.1.1: Policy Custom Function not getting variable value\nNetcool/Impact 6.1.1: Policy Custom Function not getting variable value\n\nCustom Function call:\n\n     ProcessFunction(GotNodes[0].AlertKey); \n\nof a result set acquired by GetByFilter:\n\n     GotNodes=GetByFilter(ObjServ_Alerts_DT, Node=\"'\"+@Node+\"'\", False); \n\nstill fails to use the acquired variable even when there is a value for both GotNodes and GotNodes[0].AlertKey",
    "ground_truth": "1. Assign the variable prior to the function call.\n   This ensures that the value is passed to the **User Defined Function**.",
    "answer": "To resolve the issue of the Custom Function not getting the variable value in Netcool/Impact 6.1.1, you should assign the variable prior to the function call. In your case, instead of directly using `GotNodes[0].AlertKey` in the `ProcessFunction` call, assign it to a variable first. Here's how you can modify your code:\n\n1. Assign the value to a variable:\n   ```\n   var AlertKey = GotNodes[0].AlertKey;\n   ```\n\n2. Then, use this variable in your `ProcessFunction` call:\n   ```\n   ProcessFunction(AlertKey);\n   ```\n\nThis approach ensures that the value is properly passed to the User Defined Function, avoiding NULL style errors or failures to produce expected results. This method is consistent with the work-around provided in the related TechNote for handling similar issues with User Defined Functions in Netcool/Impact.",
    "id": "TECHQA_DEV_Q299_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q300",
    "question": "DB2 Non Reclaimable Storage .\nWe have tablespaces defined under DB2 9.5 that apparently are not able\nto reclaim storage back to the OS, but does that mean DB2 cannot reuse\nthis space as well?",
    "ground_truth": "1. Create **DMS** or automatic storage tablespaces in DB2 version **9.7** or later.\n",
    "answer": "Based on the provided context, if a tablespace in DB2 9.5 has `RECLAIMABLE_SPACE_ENABLED` set to 0, it means that the tablespace is not enabled for reclaimable storage, and DB2 cannot reclaim storage back to the OS. However, this does not necessarily mean that DB2 cannot reuse the space internally.\n\nIn other words, even if a tablespace is not enabled for reclaimable storage, DB2 can still reuse the space within the tablespace for other data. The `RECLAIMABLE_SPACE_ENABLED` flag only controls whether DB2 can return unused storage space back to the operating system, not whether DB2 can reuse the space internally.\n\nTo confirm, you can check the value of `RECLAIMABLE_SPACE_ENABLED` for your specific tablespace using the `MON_GET_TABLESPACE` table function, as shown in the example:\n\n`db2 \"SELECT varchar(tbsp_name, 30) as tbsp_name, tbsp_type, RECLAIMABLE_SPACE_ENABLED FROM TABLE(MON_GET_TABLESPACE('',-2))\"`\n\nIf the value is 0, it means that the tablespace is not enabled for reclaimable storage, but DB2 can still reuse the space internally. If you want to enable reclaimable storage for a tablespace, you will need to create the tablespace in DB2 Version 9.7 or later.",
    "id": "TECHQA_DEV_Q300_3",
    "label": 0.0
  },
  {
    "question_id": "TECHQA_DEV_Q303",
    "question": "Why are the users unable to login to Web GUI 8.1 after I modify timeout to 2147483647 in security.xml file ?\nI followed the Web GUI 8.1 reference guide here to switching off the session timeout\n\nhttp://www-01.ibm.com/support/knowledgecenter/SSSHTQ_8.1.0/com.ibm.netcool_OMNIbus.doc_8.1.0/webtop/wip/task/web_adm_settimeout.html\n\nAfter I edited /config/cells/JazzSMNode01Cell/security.xml file, modified timeout setting to 2147483647, users are not able to login anymore.",
    "ground_truth": "1. Navigate to the specified directory on DASH server.\n   On DASH server, navigate to **<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF**\n2. Take a backup of **consoleProperties.xml**.\n\n3. Open **consoleProperties.xml** in edit-mode.\n\n4. Search for **LTPAFIX** and change the value from 'true' to 'false'.",
    "answer": "The issue you're experiencing with users being unable to log in to Web GUI 8.1 after modifying the timeout to 2147483647 in the security.xml file is due to a known condition in DASH. This condition occurs because the large timeout value causes a conflict with a JavaScript call (settimeout) used by DASH, preventing logins.\n\nTo resolve this issue, you need to set the custom property LTPAFIX in the consoleProperties.xml file to \"false\". Here are the steps to follow:\n\n1. Navigate to `<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF` on your DASH server.\n2. Take a backup of the `consoleProperties.xml` file.\n3. Open `consoleProperties.xml` in edit mode.\n4. Search for \"LTPAFIX\" and change the value from \"true\" to \"false\".\n\nExample:\nBefore:\n```\n<consoleproperties:console-property id=\"LTPAFIX\" value=\"true\"/>\n```\nAfter:\n```\n<consoleproperties:console-property id=\"LTPAFIX\" value=\"false\"/>\n```\n5. Save the file.\n6. Restart the DASH server.\n\nThis should resolve the login issue caused by the large session timeout value.",
    "id": "TECHQA_DEV_Q303_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q305",
    "question": "Cognos Analytics - Images not displayed in PDF/Excel, working in HTML\nI've just completed an upgrade to Cognos Analytics 11.0.3. When running existing reports in HTML, the images are displayed but when I try to run them in PDF/Excel they are not.",
    "ground_truth": "1. Open up IIS **7.5**\n   \n2. Click on the root folder of your Cognos installation (E.g. C1021GA) in the navigation pane on the left side\n   \n3. When the root folder is selected, double-click **Authentication**\n   \n4. Ensure that **anonymous** access is enabled\n   \n5. Repeat steps 3 and 4 for the image folder and its parent folder.\n   \n6. If the user is concerned about security, they may want to restrict the child-folders (E.g. cgi-bin) and change the authentication settings accordingly\n   \n7. Run the report in export as Excel **2007** and PDF\n   ",
    "answer": "To resolve the issue of images not being displayed in PDF/Excel outputs in Cognos Analytics 11.0.3, while they are visible in HTML format, follow these steps:\n\n1. **Check Folder Permissions**: Ensure that the folder containing the images has the correct permissions configured. Enable anonymous access in IIS 7.5 for the root folder of your Cognos installation, the image folder, and its parent folder.\n\n2. **Verify Image Location**: Confirm that the images are located in the directory specified in the report settings. If the images are not in the specified location, move them to the correct directory.\n\n3. **Use Process Monitor for Diagnosis**: If the issue persists, use the Process Monitor tool to diagnose the problem. \n   - Download and run Process Monitor from the same machine where Cognos is installed.\n   - Open the report in Cognos Workspace.\n   - Start capturing events in Process Monitor.\n   - Export the report to Excel 2007 or PDF.\n   - Stop the capture and filter the events to find the image name to identify the reason for the failure under the 'Result' column.\n\nBy following these steps, you should be able to identify and resolve the issue preventing images from being displayed in PDF and Excel outputs in Cognos Analytics.",
    "id": "TECHQA_DEV_Q305_3",
    "label": 1.0
  },
  {
    "question_id": "TECHQA_DEV_Q306",
    "question": "Unable to view batches in DotEdit\nHi all,\n\nIs there any limitation to view batches in Dot Edit client application, because I am unable to see batches with QID more than 1119.\n\nAlso unable to see batches with status as \"Pending\".",
    "ground_truth": "1. Backup the **\\Datacap\\DotEdit\\apps.ini** file.\n   If the file does not exist, create a new apps.ini file or copy it from **\\Datacap\\tmweb.net**.\n2. Open it in notepad.exe or other editor.\n\n3. Find the app to be modified (for example [APT]).\n\n4. Add a new line containing **BatchLimit=xxx**.\n\n5. Save the file.",
    "answer": "To resolve the issue of being unable to view batches in DotEdit, particularly those with QID more than 1119 and status as \"Pending\", you need to adjust the batch limit in the DotEdit application. \n\n1. Backup the `\\Datacap\\DotEdit\\apps.ini` file. If the file does not exist, create a new one or copy it from `\\Datacap\\tmweb.net`.\n2. Open the file in Notepad or another editor.\n3. Find the application section to be modified (e.g., `[APT]`). If it does not exist, create a new section with the application name listed between square brackets.\n4. Add a new line containing `BatchLimit=xxx`, where `xxx` is the number of batches you want to be displayed. For example, if you want to see more than 100 batches, you could set `BatchLimit=200` or a higher number as needed.\n5. Save the file.\n\nPlease note that increasing the batch limit may cause a slowdown in the application's response time due to the gathering and formatting of the batch list. The optimal number will depend on your system conditions, infrastructure, and user expectations. \n\nAlso, ensure that you are using version 8.1 with Fix Pack 1 or newer, as this functionality might require this version or later.",
    "id": "TECHQA_DEV_Q306_3",
    "label": 1.0
  }
]