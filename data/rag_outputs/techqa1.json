[
  {
    "question_id": "TECHQA_TRAIN_Q000",
    "question": "User environment variables no longer getting picked up after upgrade to 4.1.1.1 or 4.1.1.2?\nHave you found that after upgrade to Streams 4.1.1.1 or 4.1.1.2, that environment variables set in your .bashrc are no longer being set? For example ODBCINI is not set for the database toolkit and you get\n\n     An SQL operation failed. The SQL state is 08003, the SQL code\n     is 0 and the SQL message is [unixODBC][Driver\n     Manager]Connnection does not exist.",
    "ground_truth": "1. Set environment variables that are needed by the application directly in the instance.\n   Use the command **streamtool setproperty** followed by the parameters **-d <domain> -i <instance>** and **--application-ev <VARIABLE NAME>=<VARIABLE VALUE>** to configure the environment variables.",
    "answer": "After upgrading to Streams 4.1.1.1 or 4.1.1.2, environment variables set in your .bashrc are not being picked up when Streams is run as a system service. To resolve this issue, you need to set the required environment variables directly in the Streams instance using the `streamtool` command.\n\nHere’s how to do it:\n\n1. Open your terminal.\n2. Use the following command to set the environment variable:\n\n   ```\n   streamtool setproperty -d <domain> -i <instance> --application-ev <VARIABLE NAME>=<VARIABLE VALUE>\n   ```\n\n   Replace `<domain>` with your domain name, `<instance>` with your instance name, `<VARIABLE NAME>` with the name of the environment variable (e.g., ODBCINI), and `<VARIABLE VALUE>` with the value you want to set.\n\nFor example, if you want to set the ODBCINI variable, the command would look like this:\n\n```\nstreamtool setproperty -d myDomain -i myInstance --application-ev ODBCINI=/path/to/odbc.ini\n```\n\nThis should resolve the issue with the environment variables not being recognized.",
    "id": "TECHQA_TRAIN_Q000_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q001",
    "question": "Netcool/Impact (all versions): How is the Exit() action function expected to work with User Defined Functions?\nNetcool/Impact (all versions)\n\nUsing the Exit() action function within a User Defined Function in a Policy will not exit the Policy process.",
    "ground_truth": "1. Set a variable that is then tested immediately after the **User Defined Function call**.",
    "answer": "The Exit() action function within a User Defined Function (UDF) in Netcool/Impact does not exit the entire Policy process; it only exits the UDF itself. To effectively exit the Policy process from within a UDF, you need to set a global variable that indicates the exit condition and then check that variable immediately after the UDF call.\n\nHere’s how you can implement this:\n\n1. Inside your User Defined Function, set a global variable to indicate that you want to exit the Policy:\n   ```ipl\n   SetGlobalVar(\"ExitNow\", 1);\n   Exit();\n   ```\n\n2. After calling the User Defined Function, check the global variable and exit the Policy if needed:\n   ```ipl\n   If(GetGlobalVar(\"ExitNow\") == 1) {\n       Log(ID+WP+\": Exiting policy...\");\n       Exit();\n   }\n   ```\n\nThis approach allows you to control the flow of your Policy based on conditions set within your UDF.",
    "id": "TECHQA_TRAIN_Q001_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q003",
    "question": "How to configure SSL mutual authentication in IBM HTTP Server?\nWe are running IHS v7 and our application team has a specific webservice that they require SSL mutual authentication to be enabled for at the http server. Does anyone know how to set this up on IHS? Or any documentation?\n\nThanks",
    "ground_truth": "1. Confirm that the **Global Security Kit (GSKit)** is installed and meets the minimum requirements\n   \n2. Create a key database file and certificates needed to authenticate the Web server during an SSL handshake\n   \n3. Enable **SSL directives** within the IBM HTTP Server configuration file (httpd.conf)\n   \n4. Information that IBM WebSphere® Support needs to debug SSL configuration and certificate issues related to the IBM HTTP Server\n   ",
    "answer": "To configure SSL mutual authentication in IBM HTTP Server (IHS) v7, follow these steps:\n\n1. **Install Global Security Kit (GSKit)**: Ensure that GSKit is installed and meets the minimum requirements.\n\n2. **Create Key Database**: Create a key database file (KDB) and generate the necessary certificates for both the server and client authentication.\n\n3. **Edit Configuration File**:\n   - Open the `httpd.conf` file for your IHS installation.\n   - Ensure the SSL module is loaded by confirming the following line is uncommented:\n     ```\n     LoadModule ibm_ssl_module modules/mod_ibm_ssl.so\n     ```\n\n4. **Set Up SSL VirtualHost**:\n   - Add a `<VirtualHost>` block for SSL configuration. Here’s an example:\n     ```apache\n     <VirtualHost *:443>\n         SSLEnable\n         SSLDisable\n         KeyFile \"c:/program files/ibm http server/key.kdb\"\n         SSLServerCert \"your_server_cert\"\n         SSLClientAuth on\n         SSLVerifyClient require\n         SSLVerifyDepth 2\n         # Additional SSL settings as needed\n     </VirtualHost>\n     ```\n\n5. **Client Certificate Configuration**: Ensure that the client certificates are properly configured and trusted by the server.\n\n6. **Restart IHS**: After making these changes, restart the IBM HTTP Server to apply the new configuration.\n\nFor detailed documentation, refer to the IBM Knowledge Center for your specific version of IHS, as it may contain additional configuration options and troubleshooting tips.",
    "id": "TECHQA_TRAIN_Q003_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q009",
    "question": "Unable to locate the More tab of Document class - Property definition tab - property template configuration to update Is Required setting.\nUnable to locate the More tab of Document class - Property definition tab - property template configuration to update Is Required setting. Environment is running on Content Engine 5.2.0.3.",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the Class Definition tab and click Save\n   ",
    "answer": "To update the \"Is Required\" setting for a property definition in the Document class using FileNet Content Engine (ACCE), follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click on the object store to open the Object Store tab.\n3. Expand the Data Design folder and then the Classes folder. Click on the document class to open the Document Class tab.\n4. From the Properties tab, open the Property Definitions dropdown and select the property definition you want to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the \"Is Required\" setting as needed.\n7. Go back to the Class Definition tab and click Save to apply your changes.\n\nIf you still cannot locate the \"More\" tab or the specific settings, ensure that you have the necessary permissions to access and modify property definitions in your environment.",
    "id": "TECHQA_TRAIN_Q009_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q011",
    "question": "Load SPSS 25 on a new computer\nI purchased SPSS 25 with a 12 month license on Jan 27. I loaded it and used it on my MacBook Pro. I now have a new MacBookPro. I was able to download the program but get a message that says I don't have a license. I do have the activation code. Can you please help me use this product on my new computer? Thanks!",
    "ground_truth": "1. Type (copy/paste) the following command:\n   Run the command **sudo chown -R root:admin 20** in the Terminal.\n2. Press Enter/Return.\n   \n3. Close Terminal.\n   \n4. Launch the **License Authorization Wizard**.\n   \n5. The warning message should no longer appear.\n   \n6. License your IBM SPSS Statistics product.\n   ",
    "answer": "To resolve the licensing issue with SPSS 25 on your new MacBook Pro, follow these steps:\n\n1. **Close SPSS and License Authorization Wizard**: Ensure that both the SPSS application and the License Authorization Wizard are closed.\n\n2. **Open Terminal**:\n   - Open Finder.\n   - Select the 'Go' menu.\n   - Choose 'Utilities'.\n   - Open the 'Terminal' program.\n\n3. **Change Directory**: In the Terminal, type the following command and press Enter:\n   ```\n   cd /Applications/IBM/SPSS/Statistics/\n   ```\n\n4. **Change Ownership**: Now, type the following command and press Enter:\n   ```\n   sudo chown -R root:admin 25\n   ```\n   You may be prompted to enter your administrator password.\n\n5. **Close Terminal**: After executing the command, close the Terminal.\n\n6. **Launch License Authorization Wizard**: Open the License Authorization Wizard again and enter your activation code.\n\n7. **Complete Licensing**: Follow the prompts to complete the licensing process.\n\nIf you still encounter issues, ensure you have administrator privileges on your Mac. If the problem persists, you may need to contact IBM SPSS Support for further assistance.",
    "id": "TECHQA_TRAIN_Q011_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q012",
    "question": "Are there any instructions for ulimit settings for WebSphere running on Linux?\nAre there any instructions for ulimit settings for WebSphere running on Linux?",
    "ground_truth": "1. Set the ulimit -u or nproc to a value of **131072** when running on Linux.\n   This adjustment is recommended by WebSphere Application Server Support to safely account for all the forked threads within processes that could be created.",
    "answer": "To configure the `ulimit` settings for WebSphere running on Linux, follow these recommendations:\n\n1. **Set the nproc limit**: It is recommended to set the `ulimit -u` (or `nproc`) to **131072**. This value allows for a sufficient number of threads in all processes, preventing out-of-memory errors related to thread creation.\n\n   You can set this limit by adding the following line to your shell configuration file (e.g., `.bashrc`, `.bash_profile`, or `/etc/security/limits.conf` for system-wide settings):\n\n   ```bash\n   ulimit -u 131072\n   ```\n\n2. **Restart WebSphere**: After changing the `ulimit` settings, you will need to restart the WebSphere Application Server for the new settings to take effect. If you are using WebSphere Application Server ND, ensure to restart both the node agent and the servers on the nodes.\n\n3. **Verify the settings**: To check the current `ulimit` settings for a running WebSphere process, refer to the IBM documentation on how to determine the `ulimit` settings of a running WebSphere Application Server process on Linux.\n\nBy following these steps, you should be able to configure the `ulimit` settings appropriately for your WebSphere environment on Linux.",
    "id": "TECHQA_TRAIN_Q012_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q013",
    "question": "Can I apply a TIP 2.2 fix pack directly to a TIP 2.1 installation?\nCan I apply a TIP 2.2 fix pack directly to a TIP 2.1 installation?",
    "ground_truth": "1. Ensure the target TIP installation is at TIPCore **2.2.0** or newer.\n   \n2. Upgrade TIP 2.1 installations to TIP 2.2 using the TIP **2.2.0.1** feature pack.\n   ",
    "answer": "No, you cannot apply a TIP 2.2 fix pack directly to a TIP 2.1 installation. You must first upgrade your TIP 2.1 installation to TIP 2.2 using the TIP 2.2.0.1 feature pack. You can obtain this feature pack from IBM Fix Central. \n\nTo proceed, follow these steps:\n\n1. Upgrade to TIP 2.2.0.1 by downloading the following items from IBM Fix Central:\n   - 2.2.0.1-TIV-TIP-<platform>-RP0001\n   - 2.2.0.1-TIV-TIP-FITSuit-RP0001vx\n   - 2201-fixpack-guide-PDF.pdf\n\n2. After upgrading, you can then apply the TIP 2.2 fix packs.\n\nTo check your current TIPCore version, use the DE listIU command. More details on this command can be found in the technical note [here](http://www-01.ibm.com/support/docview.wss?uid=swg21615989).",
    "id": "TECHQA_TRAIN_Q013_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q016",
    "question": "What can be done about \"Too many open files\" messages in the DASH systemOut?\nWhat can be done about \"Too many open files\" messages in the DASH systemOut log?",
    "ground_truth": "1. Use the command **ulimit -Xa** to display all current settings.",
    "answer": "To resolve the \"Too many open files\" messages in the DASH systemOut log, you can take the following steps:\n\n1. **Increase the Number of File Descriptors**:\n   - Use the command `ulimit -n [value]` to increase the limit on the number of open files. Replace `[value]` with a suitable number (e.g., 8000 or higher, but not exceeding 1048576 on certain Linux versions).\n   - Note that this change will only take effect after you restart your application server and nodeagent. Make sure to execute the `ulimit -n` command in the same command line session where you start the server.\n\n2. **Check for File Descriptor Leaks**:\n   - If you continue to encounter the error after increasing the limit, check for file descriptor leaks in your application code. You can use the `lsof` command to list open files and sockets, which can help identify any leaks.\n\n3. **Display Current ulimit Settings**:\n   - To see the current ulimit settings, run `ulimit -Xa`. This will show both soft and hard limits for the current session.\n\n4. **Consider System Limitations**:\n   - Be aware that some versions of Red Hat Enterprise Linux do not allow setting the limit to \"unlimited.\" If you attempt to do so, you will receive an error.\n\nFor further details, you can refer to the IBM support documentation linked in the context.",
    "id": "TECHQA_TRAIN_Q016_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q019",
    "question": "i cannot enter SPSS statistics trial program\nI've downloaded the 14-days trial of SPSS subscription for 32bit, windows. After opening the program I'm asked to login and after entering my username and password a blank page comes up. And there is no way to proceed from here. I already saw previous answers about SPSS trial Login error, and there is a link(https://ibm.box.com/s/huaafbjzabkyblh47n7g4l0o4gxp4zdy) to download the zip file of 'jxbrowser'. But i cannot enter the link, and the webpage says \"probably the address was changed or deleted.\"\n\ni'm using Windows 7(32bit), and just want to know how can i resolve it.",
    "ground_truth": "1. Uninstall the 32bit IBM SPSS Statistics Subscription software.\n   Remove the 32bit version of the software from your machine.\n2. Download and install the 64bit application from your **Products & Services** window on IBM.com.\n   Access your Products & Services window on the IBM.com website to find and install the 64bit version of IBM SPSS Statistics Subscription.\n3. If the issue persists, open a Service Request using the Client Support Portal.\n   Use the link **http://ibm.biz/IBMClientSuccessPortal** to submit a Service Request for further assistance.",
    "answer": "It seems that you are experiencing a login issue with the SPSS Statistics trial program, which may be related to the version you have installed. Since you are using Windows 7 (32-bit), ensure that you have indeed downloaded the correct 32-bit version of the software. \n\nIf you are certain that you have the correct version, but still encounter a blank page after logging in, try the following steps:\n\n1. **Check Internet Connection**: Ensure that your internet connection is stable, as a poor connection can lead to loading issues.\n\n2. **Clear Cache and Cookies**: Sometimes, clearing your browser's cache and cookies can resolve login issues. Try logging in again after doing this.\n\n3. **Reinstall the Software**: Uninstall the current SPSS Statistics trial program and then reinstall it. Make sure to download the latest version from the official IBM website.\n\n4. **Use a Different Browser**: If the login page is opening in a web browser, try using a different browser to see if that resolves the issue.\n\n5. **Contact Support**: If none of the above steps work, consider opening a Service Request using the Client Support Portal: [IBM Client Support Portal](http://ibm.biz/IBMClientSuccessPortal).\n\nIf you continue to have issues, please provide more details about any error messages you receive or any other symptoms you notice.",
    "id": "TECHQA_TRAIN_Q019_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q020",
    "question": "HATS Plugin Download\nHi\n\nI have RDZ 9.0 and want to install the HATS plugin.\n\nI've downloaded from this link:\n\nhttp://www.ibm.com/developerworks/downloads/ws/whats/\n\nHATS 9.0.0.0 but it won't install because RDZ itself is not enough and it sais I need one of the following:\n\nIBM Rational Application Developer for WebSphere Software\n\nIBM Rational Software Architect for WebSphere Software\n\nIBM Rational Developer for i for SOA Construction\n\nIBM Rational Business Developer\n\nIBM Integration Developer\n\nwhich I don't have.\n\nWhere can I download the HATS version that is compatible with RDZ 9.0 and doesn't need anything else?",
    "ground_truth": "1. See Installing HATS in the **Rational Host Access Transformation Services (HATS) V9.0 Information Center**.\nRefer to the installation instructions provided at the link: **http://pic.dhe.ibm.com/infocenter/hatshelp/v90/topic/com.ibm.hats.doc/doc/gsinstal.htm**",
    "answer": "To install the HATS plugin compatible with RDZ 9.0, you will need to ensure that you have the correct prerequisites. Unfortunately, the HATS 9.0.0.0 version you downloaded requires one of the following products, which you do not have:\n\n- IBM Rational Application Developer for WebSphere Software\n- IBM Rational Software Architect for WebSphere Software\n- IBM Rational Developer for i for SOA Construction\n- IBM Rational Business Developer\n- IBM Integration Developer\n\nCurrently, there is no version of HATS that is compatible with RDZ 9.0 without requiring one of the above products. You may need to consider obtaining one of the required products to proceed with the installation of HATS.\n\nFor further assistance, you can check the detailed system requirements and installation instructions in the HATS V9.0 Information Center [here](http://pic.dhe.ibm.com/infocenter/hatshelp/v90/index.jsp).",
    "id": "TECHQA_TRAIN_Q020_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q024",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM® SPSS® Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message: \n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction. \nNo additional authorizations are permitted on this code. \nWhat should I do?",
    "ground_truth": "1. Contact your **vendor**\n   For installation & licensing issues on the Student version and Graduate pack.",
    "answer": "To transfer your SPSS 24 license key to a new computer and resolve the authorization error, follow these steps:\n\n1. **Contact Your Vendor**: Since you are using the Graduate Pack version, the first step is to reach out to the vendor from whom you purchased the software. They can assist you with licensing issues and may be able to reset your license or provide a new activation code. Here are some vendor contacts you can use:\n   - Hearne: [Hearne Software](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub](http://onthehub.com/)\n   - StudentDiscounts.com: [StudentDiscounts.com](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Provide Details**: When you contact them, be sure to provide your current activation code and explain the error message you are receiving. This will help them assist you more effectively.\n\n3. **Follow Their Instructions**: The vendor may provide specific instructions or may need to reset your license on their end to allow you to activate SPSS on your new computer.\n\nBy following these steps, you should be able to resolve the licensing issue and successfully transfer your SPSS 24 license to your new computer.",
    "id": "TECHQA_TRAIN_Q024_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q031",
    "question": "Request fails with \"non idempotent request method - RFC 2616 sec 10.3. \"\nWhen a request is routed through DataPower and a redirect is done on a POST, the redirect will fail in DataPower and we can expect the following message to be logged in the error message: \"non idempotent request method - RFC 2616 sec 10.3.\"  How do I solve the problem?",
    "ground_truth": "1. Configure the IBM WebSphere **DataPower SOA** appliance web application firewall to handle 302 Redirects.",
    "answer": "To resolve the issue of receiving a \"non idempotent request method - RFC 2616 sec 10.3\" error when a POST request is redirected through DataPower, you need to configure the IBM WebSphere DataPower SOA appliance web application firewall to handle 302 redirects properly. \n\nHere are the steps to follow:\n\n1. **Obtain the ResetLocation.xsl stylesheet**: This stylesheet is necessary for configuring the web application firewall to manage redirects. You can find it in the support documentation or the links provided in your context.\n\n2. **Edit the ResetLocation.xsl**: Customize this stylesheet according to your environment and specific business requirements. This may involve modifying the logic to handle the redirect appropriately.\n\n3. **Configure the Web Application Firewall**: Implement the changes in your DataPower configuration to utilize the edited ResetLocation.xsl stylesheet. This will allow the firewall to process the 302 redirects without triggering the non-idempotent request error.\n\n4. **Test the Configuration**: After applying the changes, test the setup by sending a POST request that would normally trigger a redirect. Ensure that the request is processed correctly without errors.\n\nFor detailed instructions on how to implement these changes, refer to the attached documentation or the specific guides provided by IBM for your DataPower appliance.\n\nIf you need further assistance, please consult the IBM support resources or your system administrator.",
    "id": "TECHQA_TRAIN_Q031_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q037",
    "question": "How can multiple TDWC users logon into TDWC with same TWS user id?\nGiven that one TDWC user is already accessing TDWC and a second TDWC user using the same logon id wants to logon to TDWC sees the following error:\n\nAnother user is currently logged in with the same user ID. Select from the following options:\n\n    List item\n\nLog out the other user with the same user ID. You can recover changes made during the other user's session.\n\n    List item\n\nReturn to the Login page and enter a different user ID.\n\nHow can multiple users logon without one user needing to logout?",
    "ground_truth": "1. Log in as an administrative user.\n   \n2. Navigate to: **tip_home_dir/profiles/TIPProfile/config/cells/TIPCell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF/**\n   \n3. Edit **consoleProperties.xml**.\n   \n4. Locate the property with a id attribute of **ENABLE.CONCURRENT.LOGIN** and set its value to true.\n   \n5. Save the file and exit from the text editor.\n   \n6. Restart TIP server.\n   ",
    "answer": "To allow multiple TDWC users to log in with the same TWS user ID without requiring one user to log out, you need to configure the Tivoli Integrated Portal (TIP) to support concurrent logins. Here’s how to do it:\n\n1. Log in as an administrative user.\n2. Navigate to the following directory:  \n   `tip_home_dir/profiles/TIPProfile/config/cells/TIPCell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF/`\n3. Open the `consoleProperties.xml` file in a text editor.\n4. Find the property with the id attribute `ENABLE.CONCURRENT.LOGIN` and set its value to `true`.\n5. Save the changes and exit the text editor.\n6. Restart the TIP server for the changes to take effect.\n\nAfter completing these steps, multiple users should be able to log in using the same user ID simultaneously.",
    "id": "TECHQA_TRAIN_Q037_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q038",
    "question": "We want to backout the Cognos component of Business Monitor to a previous version. What do we have to take care of?\nWe want to backout the Cognos component of Business Monitor to a previous version. What do we have to take care of?",
    "ground_truth": "1. Stop the Cognos service and ensure that **Cognos Configuration** is not running.\n   \n2. Create a backup of the content store prior to upgrading.\n\n3. Restore the backup if a rollback to the original version is required.\n\n4. Refer to the notes on the fix pack.\n   The notes will include prerequisites on Backup/Restore of content store and other requirements.\n5. Check the backup directory for versions 8 - 10.2.1.\n   In the **<cognos_install>/uninstall/backup** directory, there will be a list of date stamped folders with the applied fix packs and/or interim fixes.\n6. Check the backup directory for versions **10.2.1 FP1** and above.\n   This information is stored in the **<cognos_install>/bkp** directory.\n7. Go into the folders and check the **cmplst.txt** file.\n   Look for the correct version to revert to.\n8. Copy the contents of the whole folder.\n   Paste it at the <cognos_install> level to overwrite the files applied by fix pack or interim fix update.\n9. Start the Cognos service.\n   ",
    "answer": "To back out the Cognos component of Business Monitor to a previous version, follow these steps:\n\n1. **Stop the Cognos Service**: Ensure that the Cognos service is stopped and that Cognos Configuration is not running.\n\n2. **Backup the Content Store**: If you haven't already, create a backup of the content store. This is crucial because reverting to a previous version will require restoring this backup. Note that any work done after the content store has been upgraded will be lost.\n\n3. **Locate Backup Files**: For versions 10.2.1 FP1 and above, check the `<cognos_install>/bkp` directory for backup files. For earlier versions, look in the `<cognos_install>/uninstall/backup` directory.\n\n4. **Check Version Compatibility**: Open the `cmplst.txt` file in the backup folders to identify the correct version you want to revert to.\n\n5. **Restore Backup**: Copy the contents of the folder corresponding to the desired version and paste it at the `<cognos_install>` level. This will overwrite the files applied by the fix pack or interim fix.\n\n6. **Start the Cognos Service**: Once the files have been restored, start the Cognos service again.\n\n7. **Verify Configuration**: After starting the service, verify that the Cognos environment is functioning as expected.\n\n**Important Note**: Be cautious when removing interim fixes, as later fixes may contain overlapping files. Always perform a full system and content store backup before attempting the rollback.",
    "id": "TECHQA_TRAIN_Q038_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q039",
    "question": "How to remove the default -Xcompressedrefs from my WebSphere Application Server\nMy understanding is that for performance reasons, the WebSphere Application server on 64bit JVMs is, by default, using compressed references (-Xcompressedrefs). Due to native OutOfMemory error, I would like to remove that default, so there is no such limitation imposed on my native memory size.",
    "ground_truth": "1. Use the JVM argument **-Xgc:preferredHeapBase=<address>**\n   This argument can be used to ensure the Java heap is allocated above the **4GB** address space.",
    "answer": "To remove the default `-Xcompressedrefs` from your WebSphere Application Server, you can set the generic JVM argument `-Xnocompressedrefs`. This will disable the use of compressed references, allowing your native memory to grow beyond the 4GB limit.\n\nHere are the steps to do this:\n\n1. **Access the WebSphere Admin Console**:\n   - Log in to the WebSphere Application Server administrative console.\n\n2. **Navigate to the JVM Settings**:\n   - Go to **Servers** > **Server Types** > **WebSphere application servers**.\n   - Click on the server for which you want to change the settings.\n\n3. **Modify the Generic JVM Arguments**:\n   - Click on **Java and Process Management** > **Process Definition**.\n   - Under **Java Virtual Machine**, find the **Generic JVM arguments** field.\n   - Add `-Xnocompressedrefs` to the existing arguments. Make sure to separate it from other arguments with a space.\n\n4. **Save and Restart**:\n   - Save your changes.\n   - Restart the server for the changes to take effect.\n\n**Important Considerations**:\n- Using `-Xnocompressedrefs` may significantly increase your Java heap memory requirements (up to 70% more). Therefore, you should adjust the Java heap size accordingly and monitor garbage collection.\n- Before implementing this change, ensure that you have ruled out any potential native memory leaks, as this setting can lead to unbounded growth of native memory.\n\nBy following these steps, you should be able to remove the default `-Xcompressedrefs` setting from your WebSphere Application Server.",
    "id": "TECHQA_TRAIN_Q039_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q042",
    "question": "Non-admin users cannot access webDAV filestore. What is the likely reason?\nA non-admin user trying to access the webDAV filestore is unable to do so and they see the below exception in the portal logs:\r\nCaused by: com.ibm.icm.da.DBAccessException: User id can not be null at com.ibm.icm.da.portable.connection.Logon.logon(Logon.java:159) at com.ibm.icm.da.portable.connection.ConnectionManager.logon(ConnectionManager.java:45)",
    "ground_truth": "1. Create/update the **store.puma_default.user.fbadefault.filter** custom property for the WP PumaStoreService Resource Environment Provider.",
    "answer": "The likely reason non-admin users cannot access the WebDAV filestore is that the authenticated user does not have the required attribute defined in the backend user registry, which matches the attribute specified in the `store.puma_default.user.fbadefault.filter` property of the WP PumaStoreService Resource Environment Provider. This is indicated by the error message \"User id can not be null.\"\n\nTo resolve this issue, follow these steps:\n\n1. **Check the `store.puma_default.user.fbadefault.filter` Property**:\n   - Access the Integrated Solutions Console.\n   - Locate the WP PumaStoreService Resource Environment Provider.\n   - Verify if the `store.puma_default.user.fbadefault.filter` property is defined. If it is not defined, the default value is \"uid\". If it exists, check the attribute it is set to.\n\n2. **Confirm User Attributes**:\n   - Perform an LDIF export of a sample user who is experiencing this issue (if using LDAP as the backend user registry).\n   - Ensure that the attribute defined in the `store.puma_default.user.fbadefault.filter` property exists for the user in the backend user registry. For example, if the property is set to \"cn\", confirm that the \"cn\" attribute is present for the user.\n\n3. **Update the Property if Necessary**:\n   - If the attribute does not exist for all Portal users, consider updating the `store.puma_default.user.fbadefault.filter` property to an attribute that is common across all users, such as \"cn\".\n\n4. **Restart the Server**:\n   - After making changes, restart the server to apply the new configuration.\n\nBy ensuring that the correct attribute is defined and exists for all users, non-admin users should be able to access the WebDAV filestore without encountering the \"User id can not be null\" error.",
    "id": "TECHQA_TRAIN_Q042_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q044",
    "question": "Authorization code missing for SPSS 25?\nI purchased the IBM SPSS from Amazon, and I do not know where to locate the authorization code of license code/key. Can anyone help me?",
    "ground_truth": "1. Contact your **vendor**\n   For installation and licensing issues on the Student version and Graduate pack, you should get in touch with the vendor.",
    "answer": "To locate the authorization code for your IBM SPSS 25 purchased from Amazon, you should first check the following:\n\n1. **Email Confirmation**: Look for an email from Amazon or the seller that may contain the authorization code. It is often included in the purchase confirmation or a separate email.\n\n2. **Product Packaging**: If you received a physical copy, the authorization code might be printed on the packaging or included in the documentation.\n\n3. **Contact Amazon Support**: If you cannot find the code, consider reaching out to Amazon's customer support for assistance.\n\n4. **Contact the Vendor**: Since you purchased the software, you can also contact the vendor directly for support. If the purchase was through a specific vendor listed in the context (like Hearne or JourneyEd), reach out to them for help with licensing issues.\n\nIf you still cannot locate the authorization code after these steps, I recommend contacting IBM SPSS support directly for further assistance.",
    "id": "TECHQA_TRAIN_Q044_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q048",
    "question": "How to change the maximun string length for properties in ACCE\nHI I am trying to change the maximum string length in ACCE like we will do in FEM but in the more Tab I am not seeing the option\n\nPlease guide me",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open Document Class tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the **Class Definition** tab and click Save\n   ",
    "answer": "To change the maximum string length for properties in ACCE, follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click on the object store to open the Object Store tab.\n3. Expand the Data Design folder and then the Classes folder. Click on the document class you want to modify to open the Document Class tab.\n4. In the Properties tab, open the Property Definitions dropdown and select the property definition you want to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the maximum string length as required.\n7. Go back to the Class Definition tab and click Save to apply your changes.\n\nIf you do not see the option to change the maximum string length, ensure that you have the necessary permissions to modify property definitions.",
    "id": "TECHQA_TRAIN_Q048_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q049",
    "question": "Help with Security Bulletin: A security vulnerability has been identified in WebSphere Application Server shipped with WSRR (CVE-2017-1731)\nI need to understand details regarding Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with IBM WebSphere Service Registry and Repository (CVE-2017-1741). We are running WAS traditional V8.5.  What is the recommended fix?",
    "ground_truth": "1. Upgrade to a minimal fix pack levels as required by interim fix and then apply Interim Fix **PI89498**.\n   ",
    "answer": "To address the security vulnerability identified in IBM WebSphere Application Server (CVE-2017-1731) for your version (V8.5), you should apply the recommended fix as follows:\n\n1. **Apply Interim Fix**: Look for and apply the interim fix associated with APAR PI89498. This fix is specifically designed to address the vulnerability.\n\n2. **Upgrade to Fix Pack**: Alternatively, you can upgrade to the latest Fix Pack for WebSphere Application Server V8.5 that includes the necessary security updates.\n\nMake sure to perform these actions as soon as practical to minimize any potential risk associated with the vulnerability. For more details on obtaining the interim fix or the latest Fix Pack, you can refer to IBM's support documentation or contact IBM support directly.",
    "id": "TECHQA_TRAIN_Q049_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q055",
    "question": "P8 CPE 5.2.1 error:  FNRCC0110E - ERROR FixedContentProviderCache.getProvider failed to init provider\nNew P8 CPE 5.2.1 install does not see the Centera Fixed Storage. The following error is returned:\n\nFNRCC0110E: CONTENT_FCP_OPERATION_FAILED: The [initialize] operation on the fixed content provider [com.filenet.engine.content.fcprovider.centera.CenteraFCP(0)] failed. FPLibrary (Not found in java.library.path)\n\nHow do I fix this?",
    "ground_truth": "1. Restart **WebSphere** from the IBM console.\n   After making any changes to the **setCenteraLibPath.sh** or **setCenteraLibPath.bat** file, you need to restart WebSphere from the IBM console or the changes will not be detected.",
    "answer": "To resolve the error \"FNRCC0110E - ERROR FixedContentProviderCache.getProvider failed to init provider\" related to the Centera Fixed Storage in your P8 CPE 5.2.1 installation, follow these steps:\n\n1. **Check the Library Path**: Ensure that the `setCenteraLibPath.sh` (for Unix/Linux) or `setCenteraLibPath.bat` (for Windows) file is correctly configured to include the path to the Centera SDK libraries.\n\n2. **Modify Startup Script**: If you have made changes to the `setCenteraLibPath.sh` or `setCenteraLibPath.bat`, ensure that these changes are included in the `setupcmdLine.sh` file. This is crucial for the WebSphere Application Server (WAS) to recognize the updated library path.\n\n3. **Restart WebSphere**: After making the necessary changes, restart the WebSphere Application Server from the command line, not just from the IBM console. This ensures that the changes to the library path are picked up correctly.\n\n4. **Test Connection**: Once WebSphere has restarted, try to test the connection again in the FileNet Enterprise Manager to see if the issue is resolved.\n\nBy following these steps, you should be able to fix the initialization error related to the Centera Fixed Storage. If the problem persists, further investigation into the configuration and environment may be necessary.",
    "id": "TECHQA_TRAIN_Q055_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q059",
    "question": "Uninstalling I5 OS agent failed\nI need to uninstall the I5OS agent before reinstalling a newer release of the same.\n\nCommand: DLTLICPGM LICPGM(5724C04)\n\nis anyway failing and I don't know how to proceed further. \n\nCan you please let me know the manual steps to uninstall the i5OS agent correctly ?",
    "ground_truth": "1. Try **DLTLICPGM 5724C04** for the Tivoli agent.\n\n2. If that does not work, run the following i5/OS commands.\n\n3. Run command: DLTLIB QAUTOMON.\n\n4. Run command: DLTLIB QAUTOTMP.\n\n5. Run command: **DLTUSRPRF QAUTOMON** and choose to remove all objects owned by this user.\n\n6. Start **qsh**.\n\n7. Delete /QIBM/USERDATA/IBM/ITM and all subdirectories in it.\n\n8. Delete /QIBM/PRODDATA/IBM/ITM and all subdirectories in it.\n\n9. Retry the **RSTLICPGM** commands specified in the user guide.",
    "answer": "To manually uninstall the I5OS agent after the DLTLICPGM command has failed, follow these steps:\n\n1. **Delete Libraries:**\n   - Run the following commands to delete the associated libraries:\n     ```\n     DLTLIB QAUTOMON\n     DLTLIB QAUTOTMP\n     ```\n\n2. **Delete User Profile:**\n   - Delete the user profile associated with the agent:\n     ```\n     DLTUSRPRF QAUTOMON\n     ```\n   - Choose the option to remove all objects owned by this user.\n\n3. **Delete Directories:**\n   - Start a QSH session and delete the following directories and all their subdirectories:\n     ```\n     delete /QIBM/USERDATA/IBM/ITM\n     delete /QIBM/PRODDATA/IBM/ITM\n     ```\n\n4. **Retry Installation:**\n   - After completing the above steps, you can retry the RSTLICPGM commands as specified in the user guide.\n\nMake sure to follow these steps carefully to ensure a complete uninstallation of the I5OS agent.",
    "id": "TECHQA_TRAIN_Q059_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q062",
    "question": "SAP Agent user authorizations\nHello, I cannot use the default SAP user IBMMON_AGENT provided by the SAP Agent transport. Internal rules requires to create a new user respecting specific naming convention. I know how to do it but I don't know the authorization I need to assign to the new user. Where can I find them ?\n\nThanks",
    "ground_truth": "1. If you don't want to use the default userid and profile, you need to create your own userid.\n   Create a new userid that will replace the default userid **IBMMON_AGENT**.\n2. Provide it with a set of minimum required authorization settings.\n   Assign the new userid a minimum required set of authorization settings as specified in the system.\n3. Refer to the values specified for the **/IBMMON/AUTH** profile available in the transport.\n   Check the /IBMMON/AUTH profile in the transport to understand the necessary authorizations needed for the new userid.\n4. By looking at this profile, you can obtain the needed authorization information.\n   Use the information from the /IBMMON/AUTH profile to ensure that the new userid has the correct authorization settings.",
    "answer": "To create a new SAP user that adheres to your internal naming conventions while ensuring it has the necessary authorizations for the MySAP agent, you should assign the same authorizations as those defined in the /IBMMON/AUTH profile. \n\nYou can find the specific authorization settings by referring to the /IBMMON/AUTH profile available in the transport that was imported into your SAP system. This profile contains the minimum required authorizations for the MySAP agent to function correctly.\n\nMake sure to review the authorizations listed in the profile and replicate them for your new user. This will ensure that your new user has the necessary permissions to perform data collection effectively.\n\nIf you need further details on the specific authorizations, you may want to consult the documentation or support resources related to the MySAP agent.",
    "id": "TECHQA_TRAIN_Q062_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q065",
    "question": "For Solaris how to write verbose gc output to a log file other than the native_stdout?\nA customer asked why no gc logs generated even if they use the -Xverbosegc option. So How can I write verbose gc output to a log file other than the native_stdout for SunOS?",
    "ground_truth": "1. Add the following parameters to the generic JVM arguments:\n   **-XX:+PrintGCDetails**, **-XX:+PrintGCDateStamps**, **-XX:+PrintHeapAtGC**, **-Xloggc:/tmp/gc.log**",
    "answer": "To write verbose garbage collection (GC) output to a log file in Solaris, you need to add specific JVM arguments to your configuration. Here’s how to do it:\n\n1. **Add the following parameters to your generic JVM arguments:**\n   ```\n   -XX:+PrintGCDetails \n   -XX:+PrintGCDateStamps \n   -XX:+PrintHeapAtGC \n   -Xloggc:/tmp/gc.log\n   ```\n\n2. **To enable log file rotation, include these additional parameters:**\n   ```\n   -XX:+UseGCLogFileRotation\n   -XX:NumberOfGCLogFiles=10\n   -XX:GCLogFileSize=10M\n   ```\n\n### Explanation of Parameters:\n- `-Xloggc:/tmp/gc.log`: Specifies the file where the GC logs will be written.\n- `-XX:+UseGCLogFileRotation`: Enables log file rotation.\n- `-XX:NumberOfGCLogFiles=10`: Sets the number of rotated log files to keep.\n- `-XX:GCLogFileSize=10M`: Defines the maximum size of each log file before rotation occurs.\n\n### Example:\nYour complete JVM arguments might look like this:\n```\n-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:/tmp/gc.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M\n```\n\nMake sure to adjust the file path and sizes according to your requirements. After making these changes, you should start seeing GC logs in the specified file.",
    "id": "TECHQA_TRAIN_Q065_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q067",
    "question": "ODM 8.7 TeamServer users active authoring rules and they get kicked out - transaction timeout or session timeout?\nSome of my users are being kicked out of TeamServer while actively authoring rules. What value would be controlling this behavior? Session timeout is at it's default 30 minutes. Does transaction timeout come in to play here or is there a different setting that might be causing this. Thanks.",
    "ground_truth": "1. Increase the **timeout** value in the **web.xml** file.\n   Locate the web.xml file in the RTS/DC EAR file, specifically found at **jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF**. Change the value of the property **ilog.rules.teamserver.transaction.timeout**.",
    "answer": "The issue you're experiencing with users being kicked out of TeamServer while actively authoring rules is likely related to the transaction timeout rather than the session timeout. By default, the transaction timeout is set to 10 minutes (600 seconds) in the web.xml file of the TeamServer application.\n\nTo resolve this issue, you can increase the transaction timeout value in the web.xml file. Here’s how to do it:\n\n1. Locate the web.xml file in your TeamServer EAR file:\n   - Path: `jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF\\web.xml`\n\n2. Open the web.xml file and find the following section:\n   ```xml\n   <context-param>\n       <description>Modify the timeout value that is associated with transactions (in seconds)</description>\n       <param-name>ilog.rules.teamserver.transaction.timeout</param-name>\n       <param-value>600</param-value>\n   </context-param>\n   ```\n\n3. Increase the `<param-value>` to a higher number (in seconds) based on your needs. For example, you could set it to 1200 for a 20-minute timeout:\n   ```xml\n   <param-value>1200</param-value>\n   ```\n\n4. Save the changes and redeploy the application.\n\nAdditionally, check your application server's transaction timeout settings (e.g., WebSphere) to ensure they are configured to accommodate the longer transaction times.\n\nBy increasing the transaction timeout, you should reduce the likelihood of users being kicked out while actively working on rules.",
    "id": "TECHQA_TRAIN_Q067_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q070",
    "question": "How do I search for a string which has reserved words or characters when searching in documents in Atlas?\nHow do I search for a string which has reserved words or characters when searching in documents in Atlas?",
    "ground_truth": "1. Use \"\\\" in front of the \"-\" when searching for a **string** that contains a \"-\".\n",
    "answer": "To search for a string that includes reserved words or characters in documents in Atlas, you need to escape those characters. For example, if your string contains a hyphen (\"-\"), you should precede it with a backslash (\"\\\") when performing your search. \n\nFor instance, to search for \"String1-String2\", you should enter it as \"String1\\-String2\".\n\nFor more details on handling special characters, please refer to the Oracle documentation on Special Characters in Oracle Text Queries.",
    "id": "TECHQA_TRAIN_Q070_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q071",
    "question": "Why does my upgrade to BigFix version 9.2.5 take a very long time?\nMy upgrade to BigFix version 9.2.5 takes a very long time. What do I need to do?",
    "ground_truth": "1. Allow the upgrade to complete.\n   Do not attempt to cancel or kill the upgrade process.\n2. Verify the upgrade is still active.\n   Check that the following process is still running: Windows: **BESAdmin.exe** or Linux: **BESAdmin**.",
    "answer": "The long duration of your upgrade to BigFix version 9.2.5 is likely due to the database upgrade process, which can take a significant amount of time. Here are the steps you can take to ensure that the upgrade is still in progress and to avoid any interruptions:\n\n1. **Check the Upgrade Status**:\n   - On **Windows**, look for the process `BESAdmin.exe` in the Task Manager.\n   - On **Linux**, check for the process `BESAdmin`.\n\n2. **Monitor CPU Usage**:\n   - The CPU usage of `BESAdmin` may be low during the database upgrade, so just confirming that the process is running is a good sign that the upgrade is still active.\n\n3. **Use Monitoring Tools**:\n   - For additional confirmation, you can monitor the database activity:\n     - On SQL Server, use SQL Server Profiler.\n     - On DB2, use the `CREATE EVENT MONITOR` statement to track SQL statement events.\n\n4. **Patience is Key**:\n   - It is crucial to allow the upgrade to complete without attempting to cancel or kill the process, even if it appears to be hung.\n\nIf you follow these steps and confirm that the upgrade process is still running, you should be able to wait it out. If you have further concerns or if the process seems to be stuck for an extended period, consider reaching out to IBM support for assistance.",
    "id": "TECHQA_TRAIN_Q071_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q080",
    "question": "Help with Action required for IIB H.E. V9 and WMB H.E. V8 for security vulnerabilities in Red Hat Linux (CVE-2011-5320, CVE-2017-15670, CVE-2017-15671, CVE-2017-15804)\nI need to understand details regarding Action required for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0 for security vulnerabilities in Red Hat Linux. Where can I find this information?",
    "ground_truth": "1. Contact Red Hat to obtain and install fixes for Red Hat Enterprise Linux (RHEL) Server **6.2**.",
    "answer": "To address the security vulnerabilities (CVE-2011-5320, CVE-2017-15670, CVE-2017-15671, CVE-2017-15804) in IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0, you should take the following action:\n\n1. **Contact Red Hat**: Reach out to Red Hat support to obtain the necessary fixes for Red Hat Enterprise Linux (RHEL) Server 6.2, as these versions are vulnerable.\n\n2. **Install the Fixes**: Once you have the fixes from Red Hat, ensure that you install them on your systems running the affected versions of RHEL.\n\nThis action is crucial to mitigate the identified security vulnerabilities. If you need further assistance, consider consulting the official IBM documentation or support channels.",
    "id": "TECHQA_TRAIN_Q080_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q081",
    "question": "'Access is denied' install errors with ICC\nInstalling ICC 4.0.1 and then FP2 gives the 'Access is denied' error on WASSERVICE.exe. How to resolve this?",
    "ground_truth": "1. Apply IBM Content Collector V4.0.1 Fix Pack **3** to upgrade from IBM Content Collector V4.0.1 to IBM Content Collector **V4.0.1.3**.\n",
    "answer": "To resolve the 'Access is denied' error when installing ICC 4.0.1 and FP2 related to WASSERVICE.exe, follow these steps:\n\n1. **Run as Administrator**: Ensure that you are running the installation as an administrator. Right-click on the installer and select \"Run as administrator.\"\n\n2. **Check Permissions**: Verify that you have the necessary permissions to access the installation directory and the WASSERVICE.exe file. You may need to adjust the permissions or take ownership of the file.\n\n3. **Disable Antivirus/Firewall**: Temporarily disable any antivirus or firewall software that may be blocking the installation process.\n\n4. **Check for Existing Services**: Ensure that there are no existing instances of WASSERVICE.exe running. You can check this in the Task Manager and end any instances if necessary.\n\n5. **Install Prerequisites**: Make sure that all prerequisites for IBM Content Collector V4.0.1 are installed. Refer to the installation instructions provided in the fix pack readme files.\n\n6. **Consult Documentation**: If the issue persists, consult the IBM support documentation for any specific troubleshooting steps related to the 'Access is denied' error.\n\nIf these steps do not resolve the issue, you may need to contact IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q081_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q082",
    "question": "XGS 5.3.0.6: Is there a way to replicate an inspection object under the same policy repository?\nIs there a way to replicate an inspection object under the same policy repository?",
    "ground_truth": "1. Right-click on an **IPS** object.\n   \n2. Left-click on **Clone**.\n   ",
    "answer": "Based on the provided context, there is no specific information regarding the replication of an inspection object under the same policy repository in XGS 5.3.0.6. However, it is mentioned that you can derive a new IPS object from an existing IPS object by right-clicking on an IPS object and selecting \"Clone.\" This may be a similar process for inspection objects, but it is not explicitly stated.\n\nIf you need to replicate an inspection object, I recommend checking the user interface for a similar cloning or duplication option, or consulting the official documentation for more detailed instructions. If this does not resolve your issue, I don't have further information on this topic.",
    "id": "TECHQA_TRAIN_Q082_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q085",
    "question": "WebSphere Business Integration (WBI) Adapter for Siebel timeouts: unable to process large orders?\nI receive the following error message when WebSphere Business Integration (WBI) Adapter for Siebel V2.6 tries to process an event in the event table for a large order:\n\nOMRPC Request xxx on connection xxx was abandoned after 600133 ms because it timed out. (SBL-JCA-317)\n\nWhat should I do?",
    "ground_truth": "1. Create a **siebel.properties** file and save it in the **classpath** of the adapter.\n\n2. Restart the adapter and broker to pick up the settings to establish the required connections.\n",
    "answer": "To resolve the timeout issue you're experiencing with the WebSphere Business Integration (WBI) Adapter for Siebel when processing large orders, you can modify the connection settings in the `siebel.properties` file. Here are the steps to do this:\n\n1. **Create or Edit the `siebel.properties` File**:\n   - If you don't already have a `siebel.properties` file, create one. If you do, open it for editing.\n   - Save this file in the classpath of the adapter (e.g., `<adapter project>\\connectorModule`).\n\n2. **Modify Timeout Settings**:\n   - Add or update the following properties in the `siebel.properties` file to increase the timeout values:\n     ```properties\n     siebel.conmgr.txtimeout = 3600000  # Set transaction timeout to 1 hour (in milliseconds)\n     siebel.conmgr.sesstimeout = 600000  # Set session timeout to 10 minutes (in milliseconds)\n     ```\n   - You can adjust these values based on your requirements, but ensure they are higher than the current timeout of 600133 ms.\n\n3. **Restart the Adapter and Broker**:\n   - After saving the changes to the `siebel.properties` file, restart the WBI adapter and the broker to apply the new settings.\n\n4. **Test the Configuration**:\n   - Attempt to process the large order again to see if the timeout issue is resolved.\n\nBy following these steps, you should be able to increase the timeout settings and successfully process large orders without encountering the timeout error.",
    "id": "TECHQA_TRAIN_Q085_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q087",
    "question": "Installation manager (IIM) fails to start on AIX, generates core file from GPF even though all GTK libs are installed.\nTrying to install DASH 3.1.3 on AIX but IIM won't start and instead creates a dump file with a GPF noted. We found a technical note with a list of the required libs for IIM on AIX and we have all of the latest versions of those libs. Why is the installer failing to start?",
    "ground_truth": "1. Install the **gtk+** RPM and dependencies on **AIX**.\n",
    "answer": "It seems that the Installation Manager (IIM) is failing to start due to issues with the SWT library, which is required for the GUI. Even though you have the GTK libraries installed, the error messages indicate that the SWT library cannot be found.\n\nHere are some steps you can take to resolve the issue:\n\n1. **Verify GTK Installation**: Ensure that the GTK libraries are correctly installed and that the versions meet the minimum requirements specified in the technical note. You can use the install script from the `gtk2_bundle_v2.tar` package to check this.\n\n2. **Check LIBPATH**: Make sure that the `LIBPATH` environment variable includes the path to the installed GTK libraries. You can set it using the following command:\n   ```bash\n   export LIBPATH=/opt/freeware/lib:$LIBPATH\n   ```\n\n3. **Check SWT Library Path**: The error messages indicate that the SWT library files are not found in the specified paths. Ensure that the SWT libraries are present in the expected directories. If they are missing, you may need to reinstall or properly configure the Installation Manager.\n\n4. **Run in Console Mode**: If the GUI continues to fail, consider using the Installation Manager in console mode or silent mode as a workaround. You can find more information on how to do this in the Installation Manager Information Center.\n\n5. **Check for Core Dump**: If the issue persists, analyze the core dump file generated (`core.YYYY0318.095945.7798784.0001.dmp`) for more detailed error information. This may provide insights into what is causing the GPF.\n\nIf you follow these steps and the issue is still unresolved, you may need to consult the product documentation or reach out to IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q087_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q091",
    "question": "Keys couldn't be imported. Unable to encrypt the FIPS key\nOn windows10 machine when I attempt to import the encryption key I am getting the error: \"Keys couldn't be imported. Unable to encrypt the FIPS key\". Because I cannot import the keys, I am unable to validate parameters.",
    "ground_truth": "1. Select **Local Security Policy** under Administrative tools\n   \n2. Navigate to Local Policies - Security Options\n   \n3. Select System Cryptography: Use **FIPS** compliant algorithms for encryption, hashing and signing and be sure it is Disabled\n   \n4. Run **dcskey e** again to export the key\n   ",
    "answer": "To resolve the issue of not being able to import the encryption key due to the \"Unable to encrypt the FIPS key\" error, you need to disable the FIPS compliant algorithms setting. Here are the steps to do this on your Windows 10 machine:\n\n1. Open the **Local Security Policy** by searching for it in the Start menu or accessing it through Administrative Tools.\n2. In the Local Security Policy window, navigate to **Local Policies** > **Security Options**.\n3. Find the policy named **System Cryptography: Use FIPS compliant algorithms for encryption, hashing and signing**.\n4. Set this policy to **Disabled**.\n5. After making this change, try to import the encryption key again.\n\nThis should allow you to successfully import the keys and validate the parameters.",
    "id": "TECHQA_TRAIN_Q091_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q092",
    "question": "ClassCastException IlrStorePolicy$SerializedENamedElement incompatible with EStructuralFeature\nWe keep getting the following error when navigating in Decision Center on Websphere Application Server.\n\njava.lang.ClassCastException: ilog.rules.teamserver.web.IlrStorePolicy$SerializedENamedElement incompatible with org.eclipse.emf.ecore.EStructuralFeature\n\nDoes anyone know how we can avoid this error?",
    "ground_truth": "1. Ensure there is no session object that is not **serializable**.\n   The object needs to implement java™.io.Serializable interface.\n   ",
    "answer": "The `ClassCastException` you are encountering in Decision Center on WebSphere Application Server is likely related to the serialization issue indicated by the `NotSerializableException` in the context provided. This suggests that there is a non-serializable object in your session data that is causing the error when the application attempts to serialize session information for performance monitoring.\n\nTo resolve this issue, follow these steps:\n\n1. **Identify Non-Serializable Objects**: Review the objects stored in your session to identify any that do not implement the `java.io.Serializable` interface. Specifically, look for instances of `com.com1.dept.nls.model.someModel` or similar custom classes.\n\n2. **Implement Serializable**: Ensure that all custom classes used in the session implement the `Serializable` interface. This can be done by adding `implements Serializable` to the class definition.\n\n   ```java\n   public class SomeModel implements Serializable {\n       // class implementation\n   }\n   ```\n\n3. **Check for Transient Fields**: If there are fields in your classes that should not be serialized, mark them as `transient`. This prevents them from being included in the serialization process.\n\n   ```java\n   private transient SomeNonSerializableType nonSerializableField;\n   ```\n\n4. **Disable SessionObjectSize Counter (Temporary Solution)**: If you need an immediate workaround and can afford to disable the session object size counter, you can do so. This will stop the error from occurring but is not a long-term solution.\n\n5. **Test Changes**: After making the necessary changes, redeploy your application and test to ensure that the error no longer occurs.\n\nBy ensuring that all session objects are serializable, you should be able to avoid the `ClassCastException` and `NotSerializableException` errors. If the problem persists after these changes, further investigation into the specific objects being stored in the session may be required.",
    "id": "TECHQA_TRAIN_Q092_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q098",
    "question": "Restore JazzSM DASH login page to default images\nWe've changed the JazzSM DASH login page images and want to restore them. What values do we use to revert those changes?",
    "ground_truth": "1. Stop the DASH server\n   \n2. Make a backup copy of the current xml files in the following directory\n   **<JazzSM_Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF**\n3. Go to **<JazzSM_Home>/profile/backups** and find a backup file from a previous day/time that contains the missing xml files\n   Example: isc_stores_backup_1427324004938.zip\n4. Unpack the zip file to a temporary location.\n   \n5. Restore these files in the **WEB-INF** directory from the backup.\n   \n6. Start **DASH**\n   \n7. Test if you can access the DASH Portal.\n   ",
    "answer": "To restore the JazzSM DASH login page images to their default settings, follow these steps:\n\n1. **Stop the DASH server** to ensure no changes are made while you are restoring files.\n   \n2. **Backup current files**: Make a backup copy of the current XML files in the following directory:\n   ```\n   <JazzSM_Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF\n   ```\n\n3. **Locate the backup**: Go to the backups directory:\n   ```\n   <JazzSM_Home>/profile/backups\n   ```\n   Find a backup file from a previous date that contains the original XML files, such as:\n   ```\n   isc_stores_backup_1427324004938.zip\n   ```\n\n4. **Unpack the backup**: Extract the contents of the zip file to a temporary location.\n\n5. **Restore the files**: Copy the relevant XML files from the unpacked backup into the `WEB-INF` directory.\n\n6. **Start the DASH server** again.\n\n7. **Test the login page**: Access the DASH Portal to confirm that the default images have been restored.\n\nBy following these steps, you should be able to revert the changes made to the login page images.",
    "id": "TECHQA_TRAIN_Q098_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q101",
    "question": "Installed an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\nInstalled an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\n\nI get the following messages in the logs:-\n\n/tmp/guard_stap.stderr.txt on the DB Server :- \"Server wasn't heard from for nn sec during this attempt nnn sec total), closing and re-opening\"\n\nand from the Guardium Appliance - via fileserver in the /log/opt-ibm-guardium-log/snif/snif.log \"Unauthorized client connecting from ,rejecting\"",
    "ground_truth": "1. Uncheck the **Approval** box\n   The S-TAPs should start connecting\n   ",
    "answer": "To resolve the issue of your STAP not showing up on the Appliance and the error messages in the logs, follow these steps:\n\n1. **Check the S-TAP Certification Settings**: Log into your Guardium Appliance and navigate to the S-TAP Certification screen.\n\n2. **Uncheck the Approval Needed Box**: Look for the option labeled \"S-TAP Approval Needed\" and ensure that it is unchecked. This setting can prevent the STAP from connecting properly.\n\n3. **Restart the STAP**: After making the change, restart the STAP on the DB Server to ensure it attempts to connect again.\n\n4. **Monitor the Logs**: Check the logs again on both the DB Server and the Guardium Appliance to confirm that the STAP is now connecting successfully.\n\nBy following these steps, the STAP should start connecting, and you should see it appear in the S-TAP Control on your Appliance.",
    "id": "TECHQA_TRAIN_Q101_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q104",
    "question": "Updating SCA applications & internal SCA module queues\nWhen updating an existing SCA module using the ISC, I noticed that internal SCA queues (sca/<module>/...) on the SCA.SYSTEM bus) are deleted and recreated.\n\nDoes this mean that any messages that may still reside on these internal queues would be deleted on a module update? If so, when updating SCA modules in a production environment, should these internal queues be monitored to be empty before updating a SCA module (to prevent loosing messages)?",
    "ground_truth": "1. Use the **SCA.recycleDestinations** custom Java™ virtual machine (JVM) property for the module.\n   Set the property to **false** to preserve SCA destinations.\n   ",
    "answer": "Yes, when updating an existing SCA module, the internal SCA queues associated with that module are deleted and recreated, which means any messages that may still reside on these internal queues will be lost during the update. \n\nTo prevent losing messages in a production environment, you should monitor these internal queues to ensure they are empty before proceeding with the update. Additionally, you can set the `SCA.recycleDestinations` custom JVM property to `false` to preserve the SCA destinations and their messages during the update process. \n\nMake sure to implement this property setting before performing the update to avoid any message loss.",
    "id": "TECHQA_TRAIN_Q104_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q109",
    "question": "Help with Action required for IIB H.E. V9 & WMB H.E. V8 for security vulnerabilities in Red Hat Linux\nI need to understand details regarding Action required for IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0 for security vulnerabilities in Red Hat Linux.\nThis is related to CVE-ID:\nCVE-2017-14746\nCVE-2017-15085\nCVE-2017-15086\nCVE-2017-15087\nCVE-2017-15275\n\nWhere can I find this information?",
    "ground_truth": "1. Contact Red Hat to obtain and install fixes for Red Hat Enterprise Linux (RHEL) Server **6.2**",
    "answer": "To address the security vulnerabilities (CVE-2017-14746, CVE-2017-15085, CVE-2017-15086, CVE-2017-15087, CVE-2017-15275) in IBM Integration Bus Hypervisor Edition V9.0 and WebSphere Message Broker Hypervisor Edition V8.0, you should take the following actions:\n\n1. **Contact Red Hat**: Reach out to Red Hat support to obtain the necessary fixes for Red Hat Enterprise Linux (RHEL) Server 6.2, which is the version shipped with your IBM products.\n\n2. **Install Fixes**: Once you have the fixes from Red Hat, ensure that you install them promptly to mitigate the vulnerabilities.\n\nFor further details, you may also refer to IBM's official documentation or support resources related to these products.",
    "id": "TECHQA_TRAIN_Q109_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q110",
    "question": "Why does my install of the latest Installation Manager on a Linux Ingram Server not function?\nI've installed the latest Installation Manager on an Ingram Server that I mount to different Linux machines where I have installed WebSphere Application Server. I received the following error when trying to use the Installation Manager:\n\n     00:02.25 ERROR [main] org.eclipse.equinox.log.internal.\n     ExtendedLogReaderServiceFactory safeLogged\n       Application error\n       java.lang.NoClassDefFoundError: org.eclipse.jface.dialogs.\n     ProgressMonitorDialog\n         at java.lang.ClassLoader.defineClassImpl(Native Method)\n         at java.lang.ClassLoader.defineClass(ClassLoader.java:324)\n         at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.\n     defineClass(DefaultClassLoader.java:188)\n         at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.\n     defineClassHoldingLock(ClasspathManager.java:632)\n\nI have unmounted and remounted the drive but does not appear to resolve the issue.",
    "ground_truth": "1. Only install the **Installation Manager** on a local disk.\n   ",
    "answer": "The error you are encountering is likely due to the fact that IBM Installation Manager should not be installed on an NFS mounted disk. The context indicates that there are known issues with the Installation Manager when installed on such a setup, including problems with JRE folders not being properly managed during installation and uninstallation.\n\nTo resolve this issue, you should uninstall the Installation Manager from the NFS mounted disk and then reinstall it on a local disk instead. This should help eliminate the `NoClassDefFoundError` and other related issues.\n\nHere are the steps you can follow:\n\n1. Uninstall the Installation Manager from the NFS mounted disk.\n2. Choose a local disk on your Linux machine for the installation.\n3. Download the latest version of the Installation Manager.\n4. Install the Installation Manager on the local disk following the standard installation procedure.\n\nAfter completing these steps, the Installation Manager should function correctly without the errors you were experiencing.",
    "id": "TECHQA_TRAIN_Q110_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q112",
    "question": "WAS 8.5.x - Writing a JMS message to a remote queue takes a long time. How to write the message faster?\nWe are writing a jms message from a websphere cell (cellA) to a queue hosted by another websphere cell (cellB). Sometimes we noticed that writing a message is very slow. Usually when a local queue will be used the time to write this messages is about 8 ms, but if the queue is located on a other cell is took significant longer (about 3000ms+ ).\n\nOur findings: After enabling following trace \"=info: com.ibm.ws.sib.trm.=finest\" the problem is related to:\n- com.ibm.ws.cluster.selection.NoAvailableTargetExceptionImpl\n- WaitForWLMDat 3 (com.ibm.ws.sib.trm.wlm.client.WaitForWLMData) [:] Sleeping for 2999 ms \"\n\nBecause of the sleep time the writing to the queue is slowed down. How to prevent the sleeping time of 3 seconds, when writing a message to a remote queue?",
    "ground_truth": "1. Check for hung threads in the **SystemOut.log**.\n\n2. Consider increasing the value of **sib.trm.linger** from three to give the HA manager more time to locate a messaging engine.\n\n3. Restart the server after changing the property.\n   Once the **sib.trm.linger** property has been modified, restart the server to apply the changes.",
    "answer": "To reduce the message writing time to a remote queue in WebSphere, you can adjust the `sib.trm.linger` property in the `sib.properties` file. This property controls the delay for the Work Load Manager (WLM) to locate a messaging engine before timing out. By default, this value is set to 3 seconds, which may be causing the delays you're experiencing.\n\nHere’s how to change it:\n\n1. Locate the `sib.properties` file:\n   - You can find it in either `<WAS_HOME>/properties` (for all profiles) or `<PROFILE_ROOT>/properties` (specific to your profile).\n\n2. Open the `sib.properties` file in a text editor.\n\n3. Add or modify the following line:\n   ```\n   sib.trm.linger=<new_value>\n   ```\n   Replace `<new_value>` with a higher value (e.g., 5 or 10 seconds) to give the WLM more time to locate the messaging engine.\n\n4. Save the changes.\n\n5. Restart the WebSphere server for the changes to take effect.\n\nAdditionally, ensure that there are no hung threads in the `SystemOut.log` that could be affecting performance. If your environment is heavily loaded, this adjustment should help improve the speed of writing JMS messages to the remote queue.",
    "id": "TECHQA_TRAIN_Q112_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q113",
    "question": "How do I configure logging for Atlas Extensions in Atlas 6.0.3.3?\nHow do I configure logging for Atlas Extensions in Atlas 6.0.3.3?",
    "ground_truth": "1. Navigate to **<Atlas_Install_folder>/Atlas/Properties folder**\n   \n2. Edit **log4.properties** file\n   \n3. Update the path Information for the following three properties\n   (1) **log4j.appender.MATTER_APPENDER.File=matter_adapter.log** (2) log4j.appender.PERSON_APPENDER.File=person_adapter.log (3) log4j.appender.ORG_UNIT_APPENDER.File=org_unit_adapter.log\n4. Save the file\n   \n5. Restart Atlas application server\n   ",
    "answer": "To configure logging for Atlas Extensions in Atlas 6.0.3.3, follow these steps:\n\n1. Navigate to the `<Atlas_Install_folder>/Atlas/Properties` directory.\n2. Open the `log4j.properties` file for editing.\n3. Update the path information for the following properties:\n   - `log4j.appender.MATTER_APPENDER.File=matter_adapter.log`\n   - `log4j.appender.PERSON_APPENDER.File=person_adapter.log`\n   - `log4j.appender.ORG_UNIT_APPENDER.File=org_unit_adapter.log`\n4. Save the changes to the file.\n5. Restart the Atlas application server to apply the new logging configuration.\n\nThis should enable the generation of the log files for Atlas Extensions.",
    "id": "TECHQA_TRAIN_Q113_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q118",
    "question": "Installation of Portal 7.0 CF fails with version mismatch\nInstallation of Portal 7.0 CF fails with message,\n\n\"Profile version is not the same as portal binary version before updating portal binary.\"",
    "ground_truth": "1. Use the command to update profiles not included in **AutoUpdateMultipleProfiles**.\n   Execute the command: **<wp_profile_root>/PortalServer/bin/UpdateProfile.bat|.sh install CF**\n2. Ensure all profiles are at the same level for future upgrades.\n   Confirm that all profiles are at the same level to allow for the application of future upgrades.",
    "answer": "To resolve the installation issue of Portal 7.0 CF with the version mismatch message, follow these steps:\n\n1. **Verify Profile Versions**: Ensure that all the profiles you are using are at the same version level before starting the upgrade. This is crucial as mismatched profile versions can cause installation failures.\n\n2. **Download Necessary Files**: Download the latest Combined Cumulative Fix and the WebSphere Portal Update Installer from the IBM support website. Make sure you have the correct version that matches your current Portal version.\n\n3. **Prepare Directories**: Create the necessary directories:\n   - Create `PortalServer_root/update` and extract the WebSphere Portal Update Installer there.\n   - Create `PortalServer_root/update/fixes` and extract the Combined Cumulative Fix file into this directory.\n\n4. **Update Profiles**: Run the appropriate command to update your profiles:\n   - For all platforms (except z/OS): \n     ```\n     <wp_profile_root>/PortalServer/bin/UpdateProfile.bat|.sh install CF\n     ```\n   - Use the command parameters to specify the installation directory and the cumulative fix.\n\n5. **Post-Update Steps**: If you are migrating from a previous version, ensure to run the migration commands as outlined in the context to gather necessary files.\n\nBy ensuring that all profiles are on the same version and downloading the correct update files, you should be able to resolve the version mismatch issue and successfully complete the installation. If issues persist, consider reviewing logs for additional error messages that might assist in troubleshooting further.",
    "id": "TECHQA_TRAIN_Q118_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q120",
    "question": "I am receiving AC power supply failures on my DataPower 9235 appliance. How can I resolve this?\nI am observing the following errors on my DataPower 9235 device:\n\n[failure] Power supply '1' has no AC input power, or is not present. [failure] Power supply '2' has no AC input power, or is not present.\n\nHow can this be resolved?",
    "ground_truth": "1. Reboot the **appliance**.\n   In most cases, rebooting the appliance will reset the sensors.",
    "answer": "To resolve the AC power supply failures on your DataPower 9235 appliance, follow these steps:\n\n1. **Check Power Supply Status**: Verify the LED indicators on both power supplies. If the LEDs are green, the power supplies are functioning normally.\n\n2. **Reboot the Appliance**: This can help reset the sensor readings that may be causing the false error messages. You can reboot the appliance using either the WebGUI or the CLI:\n\n   - **From the WebGUI**:\n     - Navigate to Control Panel → System Control.\n     - In the “Shutdown” section, select “Reboot System” and click “Shutdown”.\n\n   - **From the CLI**:\n     - Enter the command: `top`\n     - Then type: `shutdown reboot`\n     - Confirm with: `y`\n\n3. **Monitor for Recurrence**: After rebooting, monitor the appliance for any recurrence of the power supply failure messages. If the issue persists, gather the following information and contact IBM DataPower support:\n   - How many times you have seen the issue on the same appliance.\n   - Outputs from the following CLI commands:\n     - `show clock`\n     - `show version`\n     - `show ipmi`\n     - `show sensors-other`\n     - `config`\n     - `service show`\n     - `test hardware`\n\nThis problem is typically a false alarm and should not affect the operation of your appliance. If you continue to experience issues, reaching out to IBM support with the gathered information will be the next step.",
    "id": "TECHQA_TRAIN_Q120_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q121",
    "question": "ncp_poller failed with Out-of-memory in ITNM 3.9 FP4+IF1. What went wrong?.\nncp_poller is failed with out-fo-memory even if we have ITNM 3.9 FP4+IF1 latest FP\n\n2016-04-11T03:02:09: Fatal: F-RIV-002-014: [31869t] CRivError.cc(386) Out-of-memory - This process has run out of memory or exceeded the operating system memory limit for a 32 bit application - You must take action to reduce the amount of data this application is having to process new handler called\n\nHow to resolve this issue?.",
    "ground_truth": "1. Modify and uncomment the following line in **$NCHOME/etc/precision/NcPollerSchema.cfg**\n   **//update config.properties set BatchExtraThreads = 150;**",
    "answer": "The \"Out-of-memory\" error with ncp_poller in ITNM 3.9 FP4+IF1 indicates that the process is exceeding the memory limits set for a 32-bit application. Here are steps you can take to resolve this issue:\n\n1. **Increase the Number of Threads**: Since the default number of threads for ncp_poller is 100, you can increase this limit. To do this, modify the configuration file:\n   - Open the file located at `$NCHOME/etc/precision/NcPollerSchema.cfg`.\n   - Uncomment the line that sets `BatchExtraThreads` and change the value to a higher number (e.g., 150):\n     ```\n     update config.properties set BatchExtraThreads = 150;\n     ```\n\n2. **Reduce Data Processing**: If increasing the threads does not resolve the issue, consider reducing the amount of data that ncp_poller is processing. This could involve filtering out unnecessary data or optimizing the polling intervals.\n\n3. **Check System Memory**: Ensure that your system has enough physical memory available. If the system is running low on memory, consider upgrading the hardware or optimizing other applications running on the same server.\n\n4. **Switch to a 64-bit Application**: If possible, consider migrating to a 64-bit version of the application, as it can handle more memory than a 32-bit application.\n\n5. **Monitor Memory Usage**: Use monitoring tools to track memory usage by ncp_poller and identify any potential memory leaks or excessive consumption patterns.\n\nAfter making these changes, restart the ncp_poller service and monitor its performance to see if the issue persists.",
    "id": "TECHQA_TRAIN_Q121_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q123",
    "question": "Updating SCA applications & internal SCA module queues\nWhen updating an existing SCA module using the ISC, I noticed that internal SCA queues (sca/<module>/...) on the SCA.SYSTEM bus) are deleted and recreated.  One can potentially loose messages on these queues. Is there a fix to the problem?",
    "ground_truth": "1. Use the **SCA.recycleDestinations** custom Java™ virtual machine (JVM) property for the module.\n   Setting the property to **false** will preserve SCA destinations.",
    "answer": "To prevent the loss of messages in internal SCA queues when updating an SCA module, you can use the `SCA.recycleDestinations` custom JVM property. Set this property to `false` to ensure that the associated SCA destinations are preserved during the update process. This will help maintain the messages in the queues and avoid any potential data loss.",
    "id": "TECHQA_TRAIN_Q123_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q125",
    "question": "completeness report causes StackOverflowError in Decision Center\nWhen running the completeness report in Decision Center we sometimes get a StackOverflowError such as:\n\n     ...\n     Caused by: java.lang.StackOverflowError\n         at ilog.rules.validation.solver.IlcIntScalProd.extract(IlcIntScalProd.java:89)\n         at ilog.rules.validation.solver.IlcIntExpr.getPIntExp(IlcIntExpr.java:156)\n     ...",
    "ground_truth": "1. Adjust the stack sizes (**Xss** and **Xmso**) options.\n   \n2. Adjust the stack sizes if the first step does not work.\n   ",
    "answer": "The StackOverflowError you're encountering when running the completeness report in Decision Center is likely due to either a recursive function calling itself too many times or insufficient stack size allocated to the Java Virtual Machine (JVM).\n\nHere are steps to resolve the issue:\n\n1. **Increase the Stack Size**: \n   - You can modify the stack size by updating the JVM options. Look for the `-Xss` option in your JVM settings and increase the value. For example, you can try setting it to 1M with `-Xss1m`. Adjust based on your application's requirements.\n\n2. **Check for Infinite Recursion or Deep Nesting**:\n   - Review the code or the logic executed within the completeness report to identify any recursive functions that might not have a proper exit condition, causing infinite recursion.\n\n3. **Review Dependencies**:\n   - Ensure that any libraries or components your report relies on do not introduce recursive loops.\n\n4. **Analyze Logs**:\n   - Look in the server logs for any Out of Memory messages or additional StackOverflow messages that might provide more context about where the stack overflow is occurring.\n\n5. **Use Javacore**:\n   - If a javacore file was generated when the error occurred, analyze it for stack traces that might indicate which particular function or component is causing the recursion.\n\nBy following these steps, you should be able to mitigate the StackOverflowError in your Decision Center application. If the problem persists, consider reaching out to IBM support for assistance with more specific diagnostics.",
    "id": "TECHQA_TRAIN_Q125_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q129",
    "question": "How do I identify Indexing errors in Atlas database?\nHow do I identify Indexing errors in Atlas database?",
    "ground_truth": "1. Login to Atlas database as **PSSAPL** user\n   \n2. Run **select * from ctx_user_index_errors;**\n   \n3. Copy the value in the **ERR_TEXTKEY** Field\n   \n4. Run **select * from documentlibrary where rowid='<value from Step 3> ';**\n   \n5. This will list the document which has the indexing error\n   ",
    "answer": "To identify indexing errors in the Atlas database, follow these steps:\n\n1. Log in to the Atlas database as the PSSAPL user.\n2. Execute the query: `select * from ctx_user_index_errors;`\n3. Copy the value from the ERR_TEXTKEY field of the results.\n4. Run the query: `select * from documentlibrary where rowid='<value from Step 3>';`\n5. This will display the document associated with the indexing error.\n\nBy following these steps, you should be able to identify any indexing errors in your Atlas database.",
    "id": "TECHQA_TRAIN_Q129_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q131",
    "question": "Is it possible to move all the P8 logs out of the default location?\nWe are looking to move all the P8 logs out of the default FileNet folder in Websphere. The trace log can be moved easily; however, the error log and PE logs also need to be moved.",
    "ground_truth": "1. Add the system property **user.dir** in the JVM argument to the application server.\n   ",
    "answer": "Yes, it is possible to move all the P8 logs out of the default location in WebSphere. You can override the directory location for the logs, including error logs and PE logs, by adding the system property 'user.dir' in the JVM arguments of your WebSphere Application Server.\n\nHere’s how to do it:\n\n1. Access the WebSphere Administrative Console.\n2. Navigate to **Servers > Server Types > WebSphere application servers**.\n3. Select the server for which you want to change the log location.\n4. Click on **Java and Process Management > Process definition**.\n5. Under **Additional Properties**, click on **Java Virtual Machine**.\n6. In the **Generic JVM arguments** field, add the following:\n   ```\n   -Duser.dir=c:\\logs\n   ```\n   (replace `c:\\logs` with your desired directory path).\n\n7. Save the changes and restart the application server for the changes to take effect.\n\nThis will ensure that all specified logs, including the error logs and PE logs, are moved to the newly defined location.",
    "id": "TECHQA_TRAIN_Q131_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q132",
    "question": "How can I format a trace for CMOD v9.0 on Windows?\nHow can I format a CMOD trace on Windows?",
    "ground_truth": "1. Open command prompt\n   \n2. Navigate to the **CMOD\\9.0\\bin** directory\n   \n3. Issue ARSTFMT command\n   Use the ARSTFMT command as follows: **arstfmt -i C:\\Users\\IBM_ADMIN\\path\\to\\file -o C:\\Users\\IBM_ADMIN\\path\\to\\file\\name.txt**",
    "answer": "To format a trace for CMOD v9.0 on Windows, follow these steps:\n\n1. Open the Command Prompt.\n2. Navigate to the CMOD bin directory. For example:\n   ```\n   cd C:\\Program Files\\IBM\\Content Manager OnDemand\\9.0\\bin\n   ```\n3. Use the `ARSTFMT` command to format the trace file. The command syntax is as follows:\n   ```\n   arstfmt -i C:\\Users\\IBM_ADMIN\\path\\to\\file -o C:\\Users\\IBM_ADMIN\\path\\to\\file\\name.txt\n   ```\n   - Replace `C:\\Users\\IBM_ADMIN\\path\\to\\file` with the path to your unreadable trace file.\n   - Replace `C:\\Users\\IBM_ADMIN\\path\\to\\file\\name.txt` with the desired output path and filename for the formatted trace.\n\nAfter executing the command, you will have a readable text file of the trace.",
    "id": "TECHQA_TRAIN_Q132_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q134",
    "question": "Why Plug-in log file reports an error message after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver.\nDuring web server start-up, errors like the following will be logged into the Plug-in log file (http_plugin.log):\n\nERROR: lib_security: loadSecurityLibrary: Failed to load gsk library from /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64 ERROR: ws_transport: transportInitializeSecurity: Unable to load security library ERROR: ws_server: serverAddTransport: Failed to initialize security ERROR: ws_server: serverAddTransport: HTTPS Transport is skipped\n\nNote: This is an Apache 2.4 version on a Linux platform",
    "ground_truth": "1. Set the **LD_LIBRARY_PATH** environment variable.\n   Set the **LD_LIBRARY_PATH** environment variable to point to the library directory of the GSKit that comes with the IBM web server Plug-in.\n",
    "answer": "To resolve the error messages you're encountering in the Plug-in log file after installing and configuring the WebSphere Plugin 8.5 on your Apache 2.4 web server, you need to set the `LD_LIBRARY_PATH` environment variable to point to the correct library directory for the GSKit.\n\nHere are the steps to do this:\n\n1. **Determine the correct library path**:\n   Since you are using the 64-bit version of the WebSphere Plugin, you should set the `LD_LIBRARY_PATH` to:\n   ```\n   /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n   ```\n\n2. **Set the environment variable**:\n   You can set the `LD_LIBRARY_PATH` variable in the appropriate configuration file so that it is set every time the web server starts. \n\n   - For **RHEL Linux**, add the following line to `/etc/sysconfig/httpd`:\n     ```bash\n     export LD_LIBRARY_PATH=/opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n     ```\n\n   - For **SLES and SUSE Linux**, add the same line to `/usr/sbin/envvars`.\n\n3. **Restart the Apache web server**:\n   After making the changes, restart your Apache web server to apply the new environment variable settings.\n\nBy following these steps, the Plug-in should be able to locate the GSKit libraries, and the SSL transport initialization errors should be resolved.",
    "id": "TECHQA_TRAIN_Q134_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q140",
    "question": "A .NET API error is thrown when attempting to install ICC 4.0.1\nA .NET API error is thrown when attempting to install ICC 4.0.1. The error claims that either an incorrect version of the IBM FileNet P8 Content Processing Engine (CPE) .NET API 5.2.1.2 is installed or that it is missing some components.  How do I fix this?",
    "ground_truth": "1. Copy the software on a local disk.\n2. Start the re-installation of the .NET API.\n3. Select all sub-components of .NET framework **45** that were not listed before.",
    "answer": "To resolve the .NET API error when installing ICC 4.0.1, follow these steps:\n\n1. **Check Installation**: Go to \"Programs and Features\" on your computer to verify if the IBM FileNet P8 Content Processing Engine (CPE) .NET API 5.2.1.2 is installed. If it is not listed, it may be missing.\n\n2. **Reinstall CPE .NET API**:\n   - Copy the CPE 5.2.1.2 installation software to a local disk.\n   - Start the re-installation process for the CPE .NET API.\n   - During the installation, ensure you select all sub-components of the .NET Framework 4.5 that were not previously listed. If unsure, select all options.\n\n3. **Retry ICC Installation**: After successfully reinstalling the CPE .NET API, attempt to install ICC 4.0.1 again. This should resolve the error regarding missing components.\n\nIf you continue to experience issues, please check for any additional error messages or logs that may provide further insight.",
    "id": "TECHQA_TRAIN_Q140_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q141",
    "question": "How do I downgrade an IBM Gateway, DataPower, appliance to a lower major firmware release?\nI would like to know the proper, and supported, method to downgrade an appliance to prevent any issues or problems.",
    "ground_truth": "1. Use the **reinit** CLI command.\n   This command will allow you to reconfigure an IBM WebSphere DataPower SOA appliance. It will allow you to delete (not erase) all existing configuration and data from an IBM WebSphere DataPower SOA appliance.",
    "answer": "To downgrade your IBM DataPower appliance to a lower major firmware release, follow these steps:\n\n1. **Prepare for Downgrade:**\n   - Ensure you have a valid firmware image for the desired lower version available on the appliance. You can check existing firmware images through the WebGUI or by using the CLI command:\n     ```\n     xi52# configure\n     xi52# dir image:\n     ```\n\n2. **Backup Configuration:**\n   - It's critical to back up your current configuration and data, as downgrading may lead to data loss.\n\n3. **Reinitialize the Appliance:**\n   - You will need to reinitialize your appliance to apply the new firmware. Use the following CLI command:\n     ```\n     reinit\n     ```\n   - **Important:** This command will delete all configurations, and the admin password will revert to \"admin.\" After executing the command, you'll only be able to access the appliance using a serial connection.\n\n4. **Load Firmware Image:**\n   - Before running the `reinit` command, ensure that the firmware image for the downgrade is uploaded to the appliance. You can upload it via the WebGUI file management options or the Control Panel under System Control.\n\n5. **Reconfigure Settings:**\n   - After the appliance reboots, you will need to configure your Ethernet connection and any other settings again. Follow the relevant configuration guide from the IBM library page.\n\n6. **Verify the Downgrade:**\n   - Once you've completed the above steps, verify that the appliance is running the desired firmware version.\n\nIf you have RAID or HSM options installed, refer to the respective documentation to reinitialize them after the downgrade.\n\nFor detailed documentation and further instructions, visit the IBM library page: [IBM DataPower Documentation](http://www.ibm.com/software/integration/datapower/library/index.html).",
    "id": "TECHQA_TRAIN_Q141_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q145",
    "question": "How can I obtain a Java thread dump against an execution group in IIB v10?\nThis Q&A is abstracted from a PMR\n\nHow can I obtain a Java thread dump against an execution group in IIB v10?",
    "ground_truth": "1. Use this command to generate a Java dump on IIB v10.0.0.9+:\n   Execute the following command: **mqsichangeproperties <Int.Node> -e <Int.Server> -o ComIbmInternalSupportManager/Java/JVM -n dump -v <dump_type>**",
    "answer": "To obtain a Java thread dump against an execution group in IBM Integration Bus (IIB) v10.0.0.9 or later, follow these steps:\n\n1. Use the `mqsichangeproperties` command to generate the Java dump. The command format is as follows:\n   ```\n   mqsichangeproperties <Int.Node> -e <Int.Server> -o ComIbmInternalSupportManager/Java/JVM -n dump -v <dump_type>\n   ```\n\n2. Replace `<Int.Node>` with your integration node name and `<Int.Server>` with your integration server name.\n\n3. Choose the appropriate `<dump_type>` based on your needs:\n   - For a Java Heap dump, use `-v heap`.\n   - For a Java core dump, use `-v core` (only on IBM JRE platforms).\n   - For a system dump, use `-v system` (only on IBM JRE platforms).\n   - For all types (heap, core, and system), use `-v all` (only on IBM JRE platforms).\n\n4. Note that the dump files will be output to `$MQSI_WORKPATH/common/errors`.\n\n**Important:** This procedure is invasive and may impact the performance of the Integration Server process.\n\nIf you are using a version prior to v10.0.0.9, you will need to create a message flow to trigger the Java dump. Let me know if you need instructions for that as well.",
    "id": "TECHQA_TRAIN_Q145_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q150",
    "question": "Error: \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" occurs at portal startup\nWe are using Portal Server 8.5 and when starting the Portal server we see following error:\n\n0000005e MBeanStarter E com.ibm.wps.scripting.server.MBeanStarter loadExtensions failed to load extension: key: ServerExt.applications / value: com.ibm.wps.scripting.server.ApplicationServerExtensions\n\nHow can we resolve this error without installing a fix?",
    "ground_truth": "1. Open the **WAS** admin console\n   \n2. Navigate to Resources > Resource environment providers > WP ScriptingService > Custom properties\n   \n3. Locate an entry with the name **ServerExt.applications** and value **com.ibm.wps.scripting.server.ApplicationServerExtensions**\n   \n4. Delete this entry, save and restart the server\n   ",
    "answer": "To resolve the \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" error in Portal Server 8.5 without installing a fix, follow these steps:\n\n1. Open the WebSphere Application Server (WAS) admin console.\n2. Navigate to **Resources > Resource environment providers**.\n3. Select **WPScriptingService** and then go to **Custom properties**.\n4. Look for an entry named **ServerExt.applications** with the value **com.ibm.wps.scripting.server.ApplicationServerExtensions**.\n5. Delete this entry.\n6. Save your changes and restart the Portal server.\n\nThis should resolve the error during startup.",
    "id": "TECHQA_TRAIN_Q150_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q152",
    "question": "EIF probe not receiving itm events\nWhy is the event in the netcool isn't cleaned ?",
    "ground_truth": "1. Set the **connection_mode** in your **om_tec.config** on the ITM Server (TEMS) to use connection_less.\n   Modify the configuration file om_tec.config located on the ITM Server (TEMS) to change the setting for connection_mode from connection oriented to connection_less.",
    "answer": "To resolve the issue of the EIF probe not receiving ITM events and the clearing event not being reflected in OMNIbus, you need to change the connection mode in your `om_tec.config` file on the ITM Server (TEMS). \n\n1. Open the `om_tec.config` file.\n2. Locate the line that reads:\n   ```\n   ConnectionMode=co\n   ```\n3. Change it to:\n   ```\n   ConnectionMode=connection_less\n   ```\n4. After making this change, restart the EIF on your ITM by running the following command:\n   ```\n   tacmd refreshTECinfo -t eif\n   ```\n\nThis should allow the clearing events to be processed correctly. If the issue persists, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q152_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q154",
    "question": "IBM SPSS Statistics Subscription Installer not supported on Mac OS version OS X 10.9.5\nAttempted several times to install IBM SPSS statistics subscription installer. Followed online instructions to double click the blue and white statisticsSub_Installer and click open. The result a message installer not supported OS version. Attempted to turn off fire wall and install without success. Suggestions?",
    "ground_truth": "1. Install Apple Java SE **6 (1.6.0_65)** on OS X 10.9.\n2. Install IBM SPSS Statistics **22**.",
    "answer": "The IBM SPSS Statistics Subscription Installer is not supported on Mac OS X 10.9.5 (Mavericks). The versions of SPSS that are compatible with OS X 10.9 are IBM SPSS Statistics 22 and 23, but you may encounter issues with installation.\n\nTo resolve your issue, you can try the following steps:\n\n1. **Check Compatibility**: Ensure you are trying to install IBM SPSS Statistics 22 or 23, as these are the only versions supported on OS X 10.9.\n\n2. **Install Apple Java SE 6**: If you are attempting to install SPSS Statistics 22, you need to install Apple Java SE 6 (1.6.0_65) first. You can download it from [Apple's support page](http://support.apple.com/kb/dl1572).\n\n3. **Reboot and Retry**: After installing Java, reboot your Mac and then try running the SPSS installer again.\n\n4. **Check for Updates**: Ensure that your OS X is fully updated, as sometimes updates can resolve compatibility issues.\n\nIf you continue to experience issues, you may need to consider upgrading your operating system to a version that supports newer releases of SPSS, such as OS X 10.10 (Yosemite) or later.",
    "id": "TECHQA_TRAIN_Q154_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q159",
    "question": "Why can't IBM FileNet Content Platform Engine successfully connect to IBM FileNet Content Search Services?\nWhy can't IBM FileNet Content Platform Engine successfully connect to IBM FileNet Content Search Services? I see the following error in my p8_server_error.log.\n\nIQQG0205E The client [version: 5.2.0.2] is not compatible with the server [version: 2.1.0.0-1.1-4140.FP4].",
    "ground_truth": "1. Check the readme files for the installed IBM FileNet Content Platform Engine and **IBM FileNet Content Search Services** fix packs.",
    "answer": "The error you are encountering indicates that the version of the IBM FileNet Content Search Services client embedded in your IBM FileNet Content Platform Engine (version 5.2.0.2) is not compatible with the IBM FileNet Content Search Services server (version 2.1.0.0-1.1-4140.FP4). \n\nTo resolve this issue, you need to ensure that the versions of the client and server match. Here are the steps you can take:\n\n1. **Check Compatibility**: Review the readme files for both your IBM FileNet Content Platform Engine and IBM FileNet Content Search Services to find the compatible versions. The client version must match the server version requirements.\n\n2. **Upgrade/Downgrade**: Depending on the compatibility information you find:\n   - If the server version is outdated, consider upgrading the server to a version that is compatible with your client (5.2.0.2).\n   - Alternatively, if the server version is correct, you may need to downgrade your client to a compatible version.\n\n3. **Install Fix Packs**: If applicable, install any necessary fix packs that may resolve compatibility issues.\n\n4. **Restart Services**: After making changes, restart both the IBM FileNet Content Platform Engine and the IBM FileNet Content Search Services to ensure that the changes take effect.\n\nBy ensuring that both the client and server versions are compatible, you should be able to resolve the connection issue.",
    "id": "TECHQA_TRAIN_Q159_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q162",
    "question": "Crash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\nDetails of gpf crash events: A VerifyError was thrown due to \"Inaccessible class\" at offset 39(0x27) of the method executeInternal(Lorg/springframework/http/HttpHeaders;[B)Lorg/springfram ework/http/client/ClientHttpResponse of the above class org/springframework/http/client/HttpComponentsClientHttpRequest.\n\nLooking at method the bytecodes :\n\n31 invokespecial 15 org/apache/http/entity/ByteArrayEntity.([B)V 34 astore 4 36 aload3 37 aload 4 39 invokeinterface2 41 invokeinterface 16 org/apache/http/HttpEntityEnclosingRequest.setEntity(Lorg/apache/http/Ht tpEntity;)V\n\nThe above sequence of bytecodes indicates it created an instance of org/apache/http/entity/ByteArrayEntity, trying to cast it to type Lorg/apache/http/HttpEntity; which in turns led to the \"Inaccessible class\" VerifyError message.\n\nIt is clear that class org/apache/http/HttpEntity was not loaded at all:\n\n    allclasses | grep org/apache/http/HttpEntity",
    "ground_truth": "1. Update the application with HTTPCore and **HTTPClient** libraries bundled.\n   The application may need to be updated to include the HTTPCore and **HTTPClient** libraries to resolve the NoClassDefFoundError.",
    "answer": "To resolve the crash caused by the \"Inaccessible class\" VerifyError related to the Apache HTTPComponents vulnerabilities in WebSphere Application Server, you should follow these steps:\n\n1. **Apply the Fix**: Download and apply the fix PI50993 for your version of WebSphere Application Server. Ensure you follow the installation instructions provided in the readme.txt file included with the fix.\n\n2. **Update Dependencies**: After applying the fix, you may encounter a `NoClassDefFoundError` due to the API in HTTPCore and HTTPClient libraries no longer being visible to your application. To resolve this, update your application to include the necessary HTTPCore and HTTPClient libraries that are compatible with the version of WebSphere you are using.\n\n3. **Verify Class Loading**: Ensure that the classes `org/apache/http/HttpEntity` and other related classes are correctly loaded in your application. You can check this by running the command `allclasses | grep org/apache/http/HttpEntity` in your WebSphere environment.\n\n4. **Test Your Application**: After making these changes, thoroughly test your application to ensure that the crash no longer occurs and that all functionalities are working as expected.\n\nIf you continue to experience issues, consider reaching out to IBM Support for further assistance.",
    "id": "TECHQA_TRAIN_Q162_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q165",
    "question": "Is Java 8 supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or later?\nIs Java 8 supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or later?",
    "ground_truth": "1. Upgrade to WebSphere Application Server V9.\n   To deploy JDK **8** compiled web applications, please upgrade to WebSphere Application Server V9.",
    "answer": "No, Java 8 is not supported for EJBDeploy on WebSphere Application Server 8.5.5.9 or earlier. The EJBDeploy tool in WebSphere Application Server 8.5.5.x and below can only deploy Java EE applications compiled with a JDK level of 7 or below. To deploy applications compiled with JDK 8, you will need to upgrade to WebSphere Application Server V9.",
    "id": "TECHQA_TRAIN_Q165_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q166",
    "question": "Application code is overriding session timeout in WebSphere Application Server 7.0\nHow to check if application code is overriding session timeout? Is there a WebSphere trace that will show this information?",
    "ground_truth": "1. Reproduce the problem with **session tracing** enabled.\n\n2. Add debug code to the application.\n   Incorporate debug statements in your application to make it easier to identify the problem.",
    "answer": "To check if your application code is overriding the session timeout in WebSphere Application Server 7.0, you can enable detailed tracing to capture relevant information. Here’s how to do it:\n\n1. **Enable Diagnostic Trace**:\n   - In the WebSphere Application Server administrative console, navigate to **Troubleshooting** > **Logs and Trace**.\n   - Select your server and click on **Diagnostic Trace**.\n   - Ensure **Enable Log** is checked, set **Maximum File Size** to 100MB, and **Historical Files** to 10. Adjust these values if necessary.\n   - Click **OK**.\n\n2. **Set Trace Specification**:\n   - Click on **Change Log Level Details**.\n   - In the **Trace Specification** text box, enter the appropriate trace string based on your session data persistence method:\n     - For no persistence: `com.ibm.ws.session.*=all:com.ibm.ws.webcontainer.srt.*=all`\n     - For database persistence: (Refer to specific documentation for the correct string)\n     - For memory-to-memory persistence: `com.ibm.ws.webcontainer.httpsession.*=all:com.ibm.ws.webcontainer.srt.*=all:com.ibm.ws.drs.*=all`\n   - Click **Apply** and save your configuration.\n\n3. **Restart the Server**:\n   - Stop the Application Server.\n   - Clear all logs: `trace.log`, `SystemOut.log`, and `SystemErr.log`.\n   - Start the Application Server.\n\n4. **Reproduce the Issue**:\n   - After the server is running, reproduce the session timeout issue.\n\n5. **Collect Data**:\n   - Capture the trace file from the diagnostic trace.\n   - Collect all files from the following directories:\n     - `install_root/profiles/profile_name/logs/server_name`\n     - `install_root/profiles/profile_name/logs/ffdc`\n   - Also, collect the `server.xml` file from:\n     - `install_root/profiles/profile_name/config/cells/cell_name/nodes/node_name/servers/server_name`\n   - Finally, gather the `http_plugin.log` file.\n\nBy analyzing the trace logs and the collected data, you should be able to determine if the application code is overriding the session timeout settings. If you need further assistance, consider reaching out to IBM support or consulting the WebSphere Application Server documentation.",
    "id": "TECHQA_TRAIN_Q166_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q174",
    "question": "Can not create a portal wcm syndicator-subscriber pair. The \"Subscribe Now\" window pops up but is blank or corrupted. Why?\nCan not create a portal wcm syndicator-subscriber pair. The \"Subscribe Now\" window pops up but is blank or corrupted.",
    "ground_truth": "1. Make sure that the page on which the WCM authoring portlet is installed uses a theme with client-side rendering such as the **Page Builder** theme.\n\n2. Deploy the hidden Portal page on which the reserved authoring portlet is installed.\n\n3. Run the following task from the **wp_profile_root** / Config Engine directory.",
    "answer": "The issue you're experiencing with the \"Subscribe Now\" window being blank or corrupted may be related to the migration process of IBM WebSphere Portal V7.0, which can disable certain features, including the Web Content Manager (WCM) authoring portlet.\n\nTo resolve this issue, follow these steps:\n\n1. **Ensure the Correct Theme**: Make sure that the page where the WCM authoring portlet is installed uses a theme that supports client-side rendering, such as the Page Builder theme.\n\n2. **Deploy the Hidden Portal Page**: You need to deploy the hidden Portal page that contains the reserved authoring portlet. \n\n3. **Run the Config Engine Task**: Execute the following command from the `wp_profile_root/Config Engine` directory:\n\n   - For Windows:\n     ```\n     ConfigEngine.bat install-wcm-hidden-authoring-page -DWasPassword=password\n     ```\n\n   - For UNIX/Linux:\n     ```\n     ./ConfigEngine.sh install-wcm-hidden-authoring-page -DWasPassword=password\n     ```\n\n   - For z/OS:\n     ```\n     ./ConfigEngine.sh install-wcm-hidden-authoring-page -DWasPassword=password\n     ```\n\n   Replace `password` with your actual WebSphere password.\n\nNo restart of the Portal server is required after running this command.\n\nAfter completing these steps, check if the \"Subscribe Now\" window displays correctly. If the issue persists, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q174_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q178",
    "question": "ILMT agent doesn`t show the hostname on inventory hardware\nHello community: I have a problem with a host. I installed ILMT agent and i exec all the task (install scan,initiate scan,run capacity and upload results....) after that i not see the hostname at the ILMT webpage, i only recognized the host by the System ID. The Hypervisor is KVM. I do this tasks with many other host like that and i not found problems.I attached an image.\n\nCan you help me to manage this issue?\n\nThank you and Best regards.",
    "ground_truth": "1. Ensure that the import is not running and stop the BFI/SUA/LMT server.\n   \n2. To reset the sequence for all data sources and import all data, run the following query on the BFI/SUA/LMT database:\n   DB2:\n   **UPDATE dbo.DATASOURCE_SEQUENCES set LAST_SEQUENCE = blob(x'0000000000000000');**\n   \n   MSSQL:\n   **UPDATE dbo.datasource_sequences set last_sequence = 0x0000000000000000;**\n3. Start the BFI/SUA/LMT.\n   \n4. Run an import.\n   ",
    "answer": "It seems that the issue with the ILMT agent not showing the hostname on the inventory hardware could be related to the sequence number in the database, especially if there was a recent restoration of the BigFix server database. Here are the steps you can take to resolve this issue:\n\n1. **Check if the Import is Running**: Ensure that the import process is not currently running.\n\n2. **Stop the BFI/SUA/LMT Server**: You need to stop the BFI/SUA/LMT server to make changes to the database.\n\n3. **Reset the Sequence Number**: Run the following SQL query on your BFI/SUA/LMT database to reset the sequence number:\n   - For DB2:\n     ```sql\n     UPDATE dbo.DATASOURCE_SEQUENCES set LAST_SEQUENCE = blob(x'0000000000000000');\n     ```\n   - For MSSQL:\n     ```sql\n     UPDATE dbo.datasource_sequences set last_sequence = 0x0000000000000000;\n     ```\n\n4. **Start the BFI/SUA/LMT Server**: After resetting the sequence number, start the BFI/SUA/LMT server again.\n\n5. **Run an Import**: Finally, run an import to ensure that all data from the endpoints is imported, including the hostname.\n\nBy following these steps, you should be able to resolve the issue and see the hostname on the ILMT webpage. If the problem persists, you may need to re-run the scans on the affected endpoints.",
    "id": "TECHQA_TRAIN_Q178_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q184",
    "question": "I am trying to install Portal 8.5 on Windows and getting error, CRIMA1217E in the IIM logs\nWhile trying to install Portal 8.5 using IIM it fails and the following is in the IIM logs...\n\n     549 ERROR CRIMA1217E 01:01:00.16 A problem occurred during the\n     execution of the\n     C:\\IBM\\WebSphere\\PortalServer\\installer\\wp.config\\wizard\\repository\\repo\n     sitory_actions.xml file.\n           ERROR: Error executing the work flow.  Step 'Basic\n     Config' FAILED!.  Check the logs for additional error messages.\n     [C:\\IBM\\WebSphere\\PortalServer\\installer\\wp.config\\wizard\\repository\\rep\n     ository_actions.xml:622]\n         A package has an issue that cannot be resolved by\n     Installation Manager.\n         Identify the package that has the issue by looking at\n     the installation history. In Installation Manager, click File >\n     Installation History. In console mode, enter S: View Installation\n     History. Contact IBM customer support.\n     \n     550 ERROR  01:01:00.16 Creating WebSphere Portal Profile.  This\n     will take several minutes.",
    "ground_truth": "1. Stop all **WebSphere** processes on the machine\n\n2. Attempt to install the second Portal instance again",
    "answer": "To resolve the error CRIMA1217E you are encountering while trying to install Portal 8.5, follow these steps:\n\n1. **Stop All WebSphere Processes**: Ensure that all WebSphere and related processes are stopped on your machine. This is crucial as running processes can interfere with the installation.\n\n2. **Check Installation History**: After stopping the processes, you can check the installation history for any specific package issues. In Installation Manager, click on `File > Installation History`. If you are using console mode, enter `S` to view the installation history.\n\n3. **Retry Installation**: Once all processes are stopped and you've checked the installation history, attempt to install the second instance of Portal 8.5 again.\n\nIf you continue to experience issues, consider contacting IBM customer support for further assistance.",
    "id": "TECHQA_TRAIN_Q184_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q187",
    "question": "How to resolve coach service timeout or expired issue?\nCustomer has followed http://www-01.ibm.com/support/docview.wss?uid=swg21633251 and http://www-01.ibm.com/support/docview.wss?uid=swg21601357 to set up long time session but customer still got error message: \"The service you are trying to run has expired.\" only when the user keep a coach session idle that over 30 minutes.  How to resolve this issue?",
    "ground_truth": "1. Check Override in the **Override Session Management** section\n\n2. Select to set the time-out and the time-out value\n   This sets the application session to overwrite those values set at the parent, which in this case is the Server level.",
    "answer": "To resolve the \"The service you are trying to run has expired\" issue due to session timeout after 30 minutes of inactivity, you need to ensure that the HTTP session timeout is correctly configured at all relevant levels in your IBM WebSphere Application Server. Here are the steps to follow:\n\n1. **Check Server Level Settings**:\n   - Navigate to **Servers > Application Servers > Your Server > Web Container > Session Management**.\n   - Ensure that the session timeout is set to a value greater than 30 minutes. If you want to disable the timeout, select \"No time-out\".\n\n2. **Check Enterprise Application Level Settings**:\n   - Go to **Applications > Enterprise Applications > Your Application > Session Management**.\n   - Ensure that \"Override\" is checked and set the timeout value to greater than 30 minutes.\n\n3. **Check Web Application Level Settings**:\n   - Navigate to **Applications > Enterprise Applications > Your Application > Web Module > Your Web App.war > Session Management**.\n   - Again, ensure \"Override\" is checked and set a timeout value greater than 30 minutes.\n\n4. **Check Application Code**:\n   - If applicable, review the application code to see if the session timeout is being set using the `setMaxInactiveInterval()` method on the `HttpSession` object. Ensure this value is also greater than 30 minutes.\n\n5. **Save Configuration**:\n   - After making any changes, ensure you save the master configuration and restart the server if necessary for the changes to take effect.\n\nBy following these steps, you should be able to resolve the session timeout issue. If the problem persists, consider checking for any additional configurations or settings that may be overriding your session timeout values.",
    "id": "TECHQA_TRAIN_Q187_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q190",
    "question": "Does anyone know how to disable HTTPS to HTTP redirection for BPC Explorer?\nIt appears that by default, BPC comes configured with https instead of http.\n\nIs there a way to configure BPC to use http instead or are there steps for configuring BPC to use http? Need to avoid accessing BPC explorer via https.",
    "ground_truth": "1. Download the **unsecureExplorer.ant** script file.\n   The unsecureExplorer.ant script file is attached near the bottom of the page.\n2. Delete the old (invalid) backup **EAR** file before running the script.\n   If you previously switched Business Process Choreographer Explorer to use HTTP and are now installing an interim fix, fix pack, or refresh pack that updated Business Process Choreographer Explorer to the default HTTPS protocol, you must delete the following file: On Linux, UNIX-based and z/OS platforms, delete the install_root/ProcessChoreographer/internal/bpcexplorer_secure_backup.ear file. On Microsoft Windows platforms, delete the install_root\\ProcessChoreographer\\internal\\bpcexplorer_secure_backup.ear file.\n3. Run the script to patch the **bpcexplorer.ear** file.\n   In a network deployment environment, you must run the script on the deployment manager. On Linux, UNIX-based and z/OS platforms, enter the following command: install_root/ws_ant.sh -f unsecureExplorer.ant. On Windows platforms, enter the following command: install_root\\ws_ant.bat -f unsecureExplorer.ant. A backup copy of the original EAR file is created named bpcexplorer_secure_backup.ear.\n4. Deploy the patched **bpcexplorer.ear** file by updating the profile.\n   For more information about updating profiles for an interim fix, see the relevant documents for your version: For version 8.0.1.x: Profile update instructions for IBM Business Process Manager (BPM) interim fixes [http://www.ibm.com/support/docview.wss?uid=swg21608414]. For version 8.5 and later: Profile update instructions for IBM Business Process Manager (BPM) interim fixes [http://www.ibm.com/support/docview.wss?uid=swg21637449].",
    "answer": "To disable HTTPS and switch Business Process Choreographer (BPC) Explorer to use HTTP, follow these steps:\n\n1. **Download the unsecureExplorer.ant script**: This script is necessary to change the protocol from HTTPS to HTTP.\n\n2. **Backup the existing EAR file**: \n   - Navigate to the directory where the backup EAR file is located:\n     - For Linux, UNIX-based, and z/OS platforms: `install_root/ProcessChoreographer/internal`\n     - For Windows platforms: `install_root\\ProcessChoreographer\\internal`\n   - Make a backup of the current `bpcexplorer.ear` file if you haven't done so already.\n\n3. **Delete the old backup EAR file** (if applicable):\n   - If you are reverting from a previous HTTP configuration due to an update, delete the old backup EAR file:\n     - On Linux, UNIX-based, and z/OS platforms: `install_root/ProcessChoreographer/internal/bpcexplorer_secure_backup.ear`\n     - On Windows platforms: `install_root\\ProcessChoreographer\\internal\\bpcexplorer_secure_backup.ear`\n\n4. **Run the unsecureExplorer.ant script**: Execute this script to switch the protocol to HTTP.\n\n5. **Re-deploy the EAR file**: If necessary, copy or rename the backup EAR file `bpcexplorer_secure_backup.ear` to `bpcexplorer.ear` and overwrite any existing copy.\n\n6. **Update the profile**: Follow the instructions for updating profiles for any interim fixes or updates.\n\n**Important Note**: Using HTTP instead of HTTPS can expose your organization to security risks. It is recommended to use HTTPS whenever possible.\n\nIf you need further assistance or specific commands for running the script, please refer to the documentation or support resources provided by IBM.",
    "id": "TECHQA_TRAIN_Q190_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q195",
    "question": "How to resolve \"StringIndexOutOfBoundsException = null\"\nWhen importing a projects.csv file, the import fails with following error in the import logs:\n\nERROR - FAILED: Create failed for Projects row 1: StringIndexOutOfBoundsException = null Ensure that the COORDINATOR column is in the loginId:Role format to prevent errors.",
    "ground_truth": "1. Ensure that the **COORDINATOR** column is in the **loginId:Role** format",
    "answer": "To resolve the \"StringIndexOutOfBoundsException = null\" error when importing your projects.csv file, ensure that the COORDINATOR column is formatted correctly. The required format is `loginId:Role`. \n\nHere are the steps to fix the issue:\n\n1. Open your projects.csv file in a text editor or spreadsheet application.\n2. Locate the COORDINATOR column.\n3. Verify that each entry in this column follows the `loginId:Role` format. For example, it should look like `johnDoe:Manager`.\n4. If any entries do not conform to this format, correct them accordingly.\n5. Save the changes to the projects.csv file.\n6. Attempt the import process again.\n\nBy ensuring the COORDINATOR column is in the correct format, the import should proceed without errors.",
    "id": "TECHQA_TRAIN_Q195_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q199",
    "question": "How to start PC DMgr as a Windows service?\nhi all. I just installed BPM 8.5.0.1 Process Center on a Windows 2008 R2 cloud server. The default BPM85 typical installation installs ProcessCenter Quickstart web page for starting the Dmgr and NodeMgr servers using the installation admin user . However, logout stops the services started by and attached to the admin user. I need to have this ProcessCenter (and Deployment Env Process SErvers) BPM85 DMgr / Node/ WASND started as a managed Windows managed service. I didn't see a Service Definition page to select run as Windows service. Can I possibly run BPMConfig -start dmgrprofile as a Windows service or is a profile update to my dmgr (hope not) needed to do this?",
    "ground_truth": "1. Place the **WASServiceCmd.exe** utility in the following directory:\n   Move the **WASServiceCmd.exe** utility file to the **install_root\\bin** directory.\n2. Launch the command from the command line.\n   \n3. The WASServiceCmd utility prompts you to select specific options and settings from a list and then calls the WASService.exe command passing all selected parameters.",
    "answer": "To start the IBM BPM Dmgr/NodeMgr as a Windows service on your Windows Server 2008 R2, you can use the `WASServiceCmd.exe` utility. Here are the steps to follow:\n\n1. **Locate WASServiceCmd.exe**: Make sure that `WASServiceCmd.exe` is placed in the `install_root\\bin` directory of your BPM installation.\n\n2. **Open Command Prompt**: Launch Command Prompt with administrative privileges.\n\n3. **Run the WASServiceCmd Utility**: Execute the following command in your Command Prompt:\n   ```\n   WASServiceCmd.exe -add \"Deployment Mgr01\" -serverName \"dmgr\" -profilePath \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\" -logRoot \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\\logs\\dmgr\" -logFile \"C:\\Program Files\\IBM\\WebSphere\\AppServer\\profiles\\Dmgr01\\logs\\dmgr\\WS_startdmgr.log\" -encodeParams -stopArgs \"-username <your_username> -password <your_password>\" -startType manual -restart false\n   ```\n   Replace `<your_username>` and `<your_password>` with your actual BPM admin user credentials.\n\n4. **Verify the Creation of the Service**: After running the command, check if the service has been added by going to `Services` (you can search for `services.msc` in the Start menu).\n\n5. **Start the Service**: You can now start the Dmgr as a service either from the `Services` app or using a command line.\n\nBy following these steps, you can ensure that the Dmgr and NodeMgr servers run as managed Windows services, preventing them from stopping when the admin user logs out. If you have any issues with the service creation, check the `WASServiceCmd.log` file for detailed information regarding errors.",
    "id": "TECHQA_TRAIN_Q199_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q201",
    "question": "The config task wp-add-property is failing with \"Can not find EJB\" message while running on our Portal 8.5 cluster\nWe are trying to perform the following steps on our Portal cluster...\n\nhttp://www.ibm.com/support/knowledgecenter/SSHRKX_8.5.0/mp/install/add_attributes.html\n\nWe successfully ran the wp-la-install-ear task but now when attempting to run the wp-add-property task we see the following error in the ConfigTrace.log....\n\n [wplc-add-property] [2016-10-11 15:57:32.065] Can not find EJB:\n ejb/com/ibm/websphere/wim/ejb/WIMServiceHome\n [wplc-add-property] javax.naming.NameNotFoundException: Context:\n dmgrCell01/nodes/dmgrNode01/servers/dmgr, name:\n ejb/com/ibm/websphere/wim/ejb/WIMServiceHome: First component in name\n websphere/wim/ejb/WIMServiceHome not found. [Root exception is\n org.omg.CosNaming.NamingContextPackage.NotFound:",
    "ground_truth": "1. Uninstall the WIMSYSTEM enterprise application from the **WebSphere_Portal** server.\n\n2. Follow the steps in Document #1358381 to install the .ear file on the **DMGR**.\n   Refer to Document #1358381 available at **http://www.ibm.com/support/docview.wss?rs=899&uid=swg21358381** for detailed steps.",
    "answer": "The error \"Cannot find EJB: ejb/com/ibm/websphere/wim/ejb/WIMServiceHome\" indicates that the WIMSYSTEM.ear file is not installed on the Deployment Manager (DMGR), which is necessary for the wp-add-property task to succeed.\n\nTo resolve the issue, follow these steps:\n\n1. **Uninstall the WIMSYSTEM application**: Use the WebSphere Administrative Console to uninstall the WIMSYSTEM enterprise application from any non-DMGR node where it may be installed.\n\n2. **Install the application on the DMGR**: After uninstalling, follow the steps in Document #1358381 to install the WIMSYSTEM.ear file directly on the DMGR. Ensure that you verify the installation process to confirm it completes successfully.\n\n3. **Check server configuration**: After installation, review the `serverindex.xml` to ensure that the WIMSYSTEM.ear is listed under the DMGR.\n\n4. **Run wp-add-property**: Once the application is correctly installed on the DMGR, rerun the wp-add-property task.\n\nIf you have further issues, confirm that the bootstrap URL and server information are correct, and ensure there are no network issues affecting the connection to the DMGR.",
    "id": "TECHQA_TRAIN_Q201_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q202",
    "question": "How to find if Table was Created as NOT LOGGED INITIALLY?\nHow to find if Table was Created as NOT LOGGED INITIALLY?",
    "ground_truth": "1. Check if the table was created as 'Not Logged Initially' using **db2cat**.\n   Run the command **db2cat -db <dbname> -n <TableName> -s <Schema> -t | grep \"Table not logged\"** to check the table's logging status. If the output shows 'Table not Logged: 0', it indicates that the table was not created as NLI. If it shows '1', then the table was created as NLI.",
    "answer": "To determine if a table was created as NOT LOGGED INITIALLY in DB2, you can use one of the following methods:\n\n1. **Using `db2cat`:**\n   Open your command line and run the following command, replacing `<dbname>`, `<TableName>`, and `<Schema>` with your database name, table name, and schema respectively:\n\n   ```bash\n   db2cat -db <dbname> -n <TableName> -s <Schema> -t | grep \"Table not logged\"\n   ```\n\n   The output will indicate whether the table was created as NLI. If it shows `Table not logged : 0`, then the table was **not** created as NLI. If it shows `1`, then it indicates that the table was created as NLI.\n\n2. **Using `db2look`:**\n   You can also use the `db2look` command to extract the DDL information for the table. Use the following command:\n\n   ```bash\n   db2look -d <database_name> -t <table_name> -e -o <output_file_name.out>\n   ```\n\n   Check the output file to see if \"NOT LOGGED INITIALLY\" is mentioned in the DDL for the table.\n\n**Note:** If the table was altered to ACTIVATE NOT LOGGED INITIALLY, it will not appear in the results of these commands, as this setting only applies to the current unit of work. \n\nUsing these methods, you should be able to determine if the table was created with the NOT LOGGED INITIALLY option.",
    "id": "TECHQA_TRAIN_Q202_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q203",
    "question": "Limitations of sylog-TCP log target using DataPower Gateways\nI am trying to configure a log target using type syslog-TCP. It seems that the payload is getting truncated when I try to record custom logs to it using log-action. How can I workaround it.",
    "ground_truth": "1. Configure a server daemon to listen and capture the **DataPower** devices events.",
    "answer": "To address the issue of payload truncation when using the syslog-TCP log target on DataPower Gateways, consider the following workaround:\n\n1. **Switch to Syslog-ng**: Since the syslog protocol operates over UDP, which does not guarantee packet delivery, switching to Syslog-ng, which operates over TCP, can help ensure that log messages are delivered without truncation. This is particularly useful under high load conditions.\n\n2. **Configure Log Target**:\n   - Go to the default domain: `Objects > Log Targets`.\n   - Create a new log target with the following settings:\n     - **Name**: Provide a descriptive name for the log target.\n     - **Target Type**: Select `syslog`.\n     - **Local Identifier**: Enter a descriptive string for identification.\n     - **Remote Host Address**: Input the IP address of the remote syslog server.\n     - **Remote IP Port**: Use the appropriate port (commonly 514 for syslog).\n   - Ensure all other settings are left as defaults.\n\n3. **Monitor Log Events**: After configuring the log target, generate log events by performing transactions, such as saving configurations or running test loads. Monitor the `Status > Log Targets` menu in the WebGUI to check for any dropped log events.\n\n4. **Consider Alternative Logging Methods**: If issues persist, you might explore using file-type log targets or HTTP services for logging, as these methods can provide more reliable logging under certain conditions.\n\nBy implementing these steps, you should be able to mitigate the truncation issue and ensure more reliable logging from your DataPower Gateway.",
    "id": "TECHQA_TRAIN_Q203_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q207",
    "question": "How to configure the Data Power Agent to communicate on TLSv1.2 ?\nAPM agent for data power is not able to communicate with data power server when SSL is enabled. Since we are connecting to TLS version 1, where data power server supports only TLS 1.2.",
    "ground_truth": "1. Change the value of the configuration item **KBN_SOMA_PROTOCOL**.",
    "answer": "To configure the Data Power Agent to communicate using TLSv1.2, follow these steps based on your operating system:\n\n### For Windows:\n1. Open the configuration file `KBNENV_<instanceName>`.\n2. Locate the configuration item `KBN_SOMA_PROTOCOL`.\n3. Change its value to `TLSv1.2`.\n4. Save the changes.\n5. Restart the agent instance to apply the new configuration.\n\n### For Linux/Unix:\n1. Open the configuration file `bn_<instanceName>.config`.\n2. Find the configuration item `KBN_SOMA_PROTOCOL`.\n3. Set its value to `TLSv1.2`.\n4. Save the changes.\n5. Restart the agent instance to enable the new configuration.\n\nAfter completing these steps, the Data Power Agent should be able to communicate with the Data Power server using TLSv1.2.",
    "id": "TECHQA_TRAIN_Q207_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q210",
    "question": "How to wrap table column text in list tab for a specific table?\nI would like to wrap the text of table column into new a line.",
    "ground_truth": "1. Wrap table column text according to number of characters.\n   Use the property **wraplength** in the **tablecol tag**.",
    "answer": "To wrap the text of a specific table column in a list tab, you can use the `wraplength` property in the `tablecol` tag. For example, if you want to wrap the text after 100 characters, you can set it up like this:\n\n```html\n<tablecol dataattribute=\"description\" id=\"results_showlist_tablebody_3\" sortable=\"false\" width=\"200\" wraplength=\"100\"/>\n```\n\nThis configuration will ensure that the text in the specified column wraps to a new line once it reaches 100 characters. Adjust the `wraplength` value as needed for your specific requirements.",
    "id": "TECHQA_TRAIN_Q210_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q215",
    "question": "Is ITNM exposed to vulnerability CVE-2017-1194?.\nIs ITNM versions are affected by vulnerability CVE-2017-1194, because ITNM does shipped with WebSphere Application Server,  where I can find the details?.",
    "ground_truth": "1. Consult the security bulletin Cross-site request forgery in WebSphere Application Server (CVE-2017-1194)\n   Visit the URL **http://www-01.ibm.com/support/docview.wss?uid=swg22001226** for vulnerability details and information about fixes.",
    "answer": "Yes, ITNM (IBM Tivoli Network Manager) is exposed to vulnerability CVE-2017-1194, as it is shipped with WebSphere Application Server. The affected versions of ITNM include 3.9, 4.1, 4.1.1, and 4.2. \n\nFor detailed information about the vulnerability and available fixes, you can refer to the security bulletin at the following link: [Cross-site request forgery in WebSphere Application Server (CVE-2017-1194)](http://www-01.ibm.com/support/docview.wss?uid=swg22001226).",
    "id": "TECHQA_TRAIN_Q215_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q217",
    "question": "Download link for application support for OMEGAMON for Messaging on z/OS V7.5\nWhere is download link for application support for IBM OMEGAMON for Messaging on z/OS V7.5.0 on ITM SLES zlinux servers?",
    "ground_truth": "1. Download the IBM Tivoli OMEGAMON XE for Messaging V7.5.0 Data Files for z/OS DVD.\n   Access the following URL to download the DVD: **ftp://public.dhe.ibm.com/software/tivoli_support/misc/PandA/tools_agent/tools/appsupt/LCD7-3513-09.zip**.",
    "answer": "The download link for the application support for IBM OMEGAMON for Messaging on z/OS V7.5.0 is not provided in the retrieved context. The latest available version mentioned is for V7.3.0, which can be found at the following link: \n\n- [IBM Tivoli OMEGAMON XE for Messaging V7.3.0 Data Files for z/OS DVD](ftp://public.dhe.ibm.com/software/tivoli_support/misc/PandA/tools_agent/tools/appsupt/LCD7-3513-08.zip)\n\nFor further information or updates regarding V7.5.0, I recommend checking the IBM support website or contacting IBM support directly.",
    "id": "TECHQA_TRAIN_Q217_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q221",
    "question": "Case Analyzer is not working\nCaseAnalyzer is not working, no latest audit log although service is running\n\nError in log:\n\n\"CAPublisher c2dce3b9 [Error] Unexpected exception occurred while processing task CAPublisher for store CASTORE.; Exception: com.microsoft.sqlserver.jdbc.SQLServerException: The query processor ran out of internal resources and could not produce a query plan. This is a rare event and only expected for extremely complex queries or queries that reference a very large number of tables or partitions. Please simplify the query. If you believe you have received this message in error, contact Customer Support Services for more information.\"",
    "ground_truth": "1. Set the BATCH value for the **analyzer.db.updateMode** parameter.\n   Execute the following SQL query in the Case Analyzer store database: **UPDATE X_CAProperties SET PropValue='BATCH' WHERE PropName ='analyzer.db.updateMode'**",
    "answer": "To resolve the issue with Case Analyzer not working and the error related to the SQL Server query processor running out of internal resources, you can try changing the `analyzer.db.updateMode` parameter to `BATCH`. This may help improve performance and stability.\n\nHere are the steps to change the parameter:\n\n1. Access the Case Analyzer store database.\n2. Run the following SQL query to update the `analyzer.db.updateMode` parameter:\n\n   ```sql\n   UPDATE X_CAProperties SET PropValue='BATCH' \n   WHERE PropName ='analyzer.db.updateMode';\n   ```\n\n3. After executing the query, restart the Case Analyzer service to apply the changes.\n\nIf the issue persists after making this change, consider simplifying any complex queries or contacting Customer Support Services for further assistance.",
    "id": "TECHQA_TRAIN_Q221_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q224",
    "question": "Help with Security Bulletin: Vulnerability in Diffie-Hellman ciphers affects IBM WebSphere MQ Internet Passthru (CVE-2015-4000)\nI need to understand details regarding Security Bulletin: Vulnerability in Diffie-Hellman ciphers affects IBM WebSphere MQ Internet Passthru (CVE-2015-4000). What is the recommended fix?",
    "ground_truth": "1. Upgrade to IBM WebSphere MQ Internet Pass-Thru **2.1.0.2**",
    "answer": "To address the vulnerability in Diffie-Hellman ciphers affecting IBM WebSphere MQ Internet Passthru (CVE-2015-4000), you should upgrade to IBM WebSphere MQ Internet Passthru version 2.1.0.2 or later. This version resolves the security issue associated with the Logjam attack.\n\nIf you are currently using version 2.1.0.1, 2.0, or any older releases, please follow these steps:\n\n1. Download the latest version (2.1.0.2) from the IBM support site: [IBM WebSphere MQ Internet Pass-Thru](http://www.ibm.com/support/docview.wss?uid=swg24006386).\n2. Follow the installation instructions provided in the documentation to complete the upgrade.\n\nThere are no workarounds or mitigations available for this vulnerability, so upgrading is essential for maintaining security.",
    "id": "TECHQA_TRAIN_Q224_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q225",
    "question": "Why the Portal 7.0.0.2 - CF29 upgrade is failing ?\nWhy the Portal 7.0.0.2 - CF29 upgrade is failing ?",
    "ground_truth": "1. Increase the **was.notification.timeout** to **1200** (seconds) in WP DeploymentService.\n\n2. Re-run the **upgrade-profile** task.",
    "answer": "The upgrade of Portal 7.0.0.2 - CF29 is likely failing due to a timeout issue during the upgrade-profile task. To resolve this, you should increase the `was.notification.timeout` to 1200 seconds in the WP DeploymentService. You can do this through the WebSphere Admin Console or the Deployment Manager (Dmgr). \n\nIf the `was.notification.timeout` property is not already listed under custom properties, you will need to add it manually. \n\nAfter making this change, re-run the upgrade-profile task to proceed with the migration. \n\nMake sure to check the `consolidatedXMLAccessResult.xml` file for any additional errors if the issue persists.",
    "id": "TECHQA_TRAIN_Q225_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q226",
    "question": "Can I disable RC4 cyphers in TIP?\nHow can one disable the RC4 cypers in Tivoli Integrated Portal?",
    "ground_truth": "1. Log into the Websphere Application server and navigate to: SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n\n2. Select the **RC4** ciphers from the **Selected ciphers** list, and then click the **<<Remove** button.\n\n3. Click the 'Apply' button, and then the 'Save (to the master configuration)' link.\n\n4. Restart **TIP**.\n   ",
    "answer": "To disable RC4 ciphers in Tivoli Integrated Portal (TIP), follow these steps:\n\n1. Log into the WebSphere Application Server.\n2. Navigate to: **SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)**.\n3. In the \"Selected ciphers\" list, select the *RC4* ciphers and click the \"<<Remove\" button.\n4. Click the \"Apply\" button, then click the \"Save (to the master configuration)\" link.\n5. Restart TIP to apply the changes.\n\nThis will effectively disable RC4 ciphers in your TIP configuration.",
    "id": "TECHQA_TRAIN_Q226_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q227",
    "question": "Why SET CHLAUTH ACTION(REMOVE) is not successful\nI have the following CHLAUTH records defined for channel BMMADMIN.SVRCONN:\n\n     DIS CHLAUTH(BMM*) ALL\n          1 : DIS CHLAUTH(BMM*) ALL\n     AMQ8878: Display channel authentication record details.\n        CHLAUTH(BMMADMIN.SVRCONN)               TYPE(USERMAP)\n        DESCR(BTMA channel)                     CUSTOM( )\n        ADDRESS(10.199.103.0)                   CLNTUSER(CHADVT3UTBMMPA$)\n        MCAUSER(mqm)                            USERSRC(MAP)\n        ALTDATE(2016-01-26)                     ALTTIME(20.38.12)\n     AMQ8878: Display channel authentication record details.\n        CHLAUTH(BMMADMIN.SVRCONN)               TYPE(USERMAP)\n        DESCR( )                                CUSTOM( )\n        ADDRESS( )                              CLNTUSER(chadvt3utbm)\n        MCAUSER(mqm)                            USERSRC(MAP)\n        ALTDATE(2016-01-27)                     ALTTIME(18.03.44)\n\nI am attempting to remove the first of the two records above with this command, but receive the response \"record not found\":\n\n     SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)\n          3 : SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)\n     AMQ8884: Channel authentication record not found.\n\nHow do I fix this problem??",
    "ground_truth": "1. Include the **single** quotes when specifying the value during an ACTION(REMOVE)",
    "answer": "The issue you're encountering with the command `SET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)` returning \"record not found\" is likely due to the case sensitivity of the `CLNTUSER` parameter. \n\nIn IBM MQ, the `CLNTUSER` value is folded to upper-case when stored. Therefore, you should use the upper-case version of the `CLNTUSER` when attempting to remove the record. \n\nTo fix the problem, try the following command:\n\n```plaintext\nSET CHLAUTH(BMMADMIN.SVRCONN) TYPE(USERMAP) CLNTUSER('CHADVT3UTBMMPA$') ACTION(REMOVE)\n```\n\nIf that still does not work, ensure that you are using the correct case for the `CLNTUSER`. You can check the exact case by running:\n\n```plaintext\nDISPLAY CHLAUTH(BMMADMIN.SVRCONN)\n```\n\nThen, use the exact case as displayed in the output for the `CLNTUSER` in your `SET CHLAUTH` command. If the displayed `CLNTUSER` is in a different case, adjust your command accordingly. \n\nIf you continue to face issues, please double-check that the record you are trying to remove actually exists and that there are no typos in the command.",
    "id": "TECHQA_TRAIN_Q227_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q228",
    "question": "DB2 Non Reclaimable Storage .\nWe have tablespaces defined under DB2 9.5 that apparently are not able\nto reclaim storage back to the OS, but does that mean DB2 cannot reuse\nthis space as well?",
    "ground_truth": "1. Create the **DMS** or automatic storage tablespaces in DB2 Version **9.7** or later.\n",
    "answer": "In DB2, if a tablespace has the `RECLAIMABLE_SPACE_ENABLED` value set to 1, it means that the tablespace is enabled for reclaimable storage. However, if the tablespace was created in DB2 version 9.5, it will not be able to utilize the reclaimable storage feature, as this feature is only available for tablespaces created in DB2 version 9.7 or later.\n\nIn your case, since you have tablespaces defined under DB2 9.5, they cannot reclaim storage back to the OS, and they also cannot reuse that space. To take advantage of reclaimable storage, you would need to create new DMS or automatic storage tablespaces in DB2 version 9.7 or later.\n\nTo summarize:\n1. Tablespaces created in DB2 9.5 cannot reclaim or reuse storage.\n2. Upgrade to DB2 version 9.7 or later and create new DMS or automatic storage tablespaces to utilize the reclaimable storage feature.",
    "id": "TECHQA_TRAIN_Q228_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q231",
    "question": "Netcool/Impact (all versions): OMNIbusEventReader Filter Analyzer error \"rule includes an unsupported expression\"\nNetcool/Impact (all versions): OMNIbusEventReader Filter Analyzer error \"rule includes an unsupported expression\"\n\nThis occurs when comparing two ObjectServer fields against each other in a Filter.",
    "ground_truth": "1. Locate the **EventReader** properties file.\nNavigate to the following file path: **$NCHOME/impact/etc/[ImpactServerName]_[EventReaderName].props**, where [ImpactServerName] is the name of the ImpactServer (NCI by default) and [EventReaderName] is the lower-case name of the EventReader (for example: omnibuseventreader).\n2. Add the consolidatefilters property.\nInsert the following line into the properties file: **impact.[EventReaderName].consolidatefilters=false**, where [EventReaderName] is the lower-case name of the EventReader (for example: omnibuseventreader).\n3. Restart the ImpactServer.\nOnce the property has been added to the file, restart the ImpactServer to enable the changes.",
    "answer": "To resolve the error \"rule includes an unsupported expression\" in the Filter Analyzer for Netcool/Impact, follow these steps:\n\n1. Locate the EventReader properties file on your server:\n   ```\n   $NCHOME/impact/etc/[ImpactServerName]_[EventReaderName].props\n   ```\n   Replace `[ImpactServerName]` with your ImpactServer name (default is NCI) and `[EventReaderName]` with the lower-case name of your EventReader (e.g., `omnibuseventreader`).\n\n2. Open the properties file in a text editor.\n\n3. Add the following line to the file:\n   ```\n   impact.[EventReaderName].consolidatefilters=false\n   ```\n   Ensure that you replace `[EventReaderName]` with the correct lower-case name.\n\n4. Save the changes.\n\n5. Restart the ImpactServer to apply the changes. If you're in a clustered environment, follow these steps:\n   - Stop all Secondary ImpactServers first.\n   - Stop and restart the Primary ImpactServer.\n   - Restart the Secondary ImpactServers.\n\nPlease note that this change will not affect the EventReader's ability to parse filters, but it will resolve the Filter Analyzer's limitation with unsupported expressions. If further issues persist, consult the TechNote \"EventReader Filters not applied to SQL select statement.\"",
    "id": "TECHQA_TRAIN_Q231_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q234",
    "question": "How do I create a windows service for WebSphere Application Server version 7.0.X?\nIs there a tool that can help me create the windows service in an automated form?",
    "ground_truth": "1. Place the **WASServiceCmd.exe** utility in the **install_root\\bin** directory.\n2. Launch the command from the command line.\n   ",
    "answer": "To create a Windows service for WebSphere Application Server version 7.0.X, you can use the WASServiceCmd utility, which simplifies the process and reduces potential errors. Here’s how to do it:\n\n1. **Download the WASServiceCmd utility**: The utility might come in a file that needs to be renamed. If you encounter a file with a .wss extension, download it and rename it to have a \".zip\" extension (e.g., docview.zip or WASServiceCmd.zip) to access the utility.\n\n2. **Place the Utility**: Once the utility is extracted, move the `WASServiceCmd.exe` file to the `install_root\\bin` directory of your WebSphere Application Server installation.\n\n3. **Open Command Prompt**: Launch Command Prompt on your Windows machine.\n\n4. **Run WASServiceCmd**: Execute `WASServiceCmd.exe`. The utility will prompt you to select specific options and settings from a list.\n\n5. **Follow Prompts**: Follow the prompts to enter the necessary parameters. This utility will then call `WASService.exe` with the options you selected. This greatly streamlines the creation of the Windows service.\n\n6. **Check Log**: After the service is created, check the `WASServiceCmd.log` in the current directory for details of the command executed.\n\nThis process will allow you to create the Windows service automatically with minimal configuration required manually. If you run into issues, refer to any troubleshooting guides available on IBM’s support pages specific to Windows services for WebSphere.",
    "id": "TECHQA_TRAIN_Q234_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q235",
    "question": "Cannot start Maximo/SCCD with error BMXAA4087E - The MAXMESSAGE value for group login and key username could not be retrieved.\nCannot start Maximo/SCCD with error BMXAA4087E - The MAXMESSAGE value for group login and key username could not be retrieved.",
    "ground_truth": "1. Make sure **MXServer** is stopped.\n\n2. Connect to database back end and update mxe.db.format.nullvalue by running following query.\nRun the query: **update maximo.maxpropvalue set propvalue='COALESCE' where propname='mxe.db.format.nullvalue';**\n3. Start **MXServer** again.",
    "answer": "To resolve the error BMXAA4087E when starting Maximo/SCCD, follow these steps:\n\n1. **Stop the MXServer** if it is currently running.\n\n2. **Connect to your IBM DB2 database** using a database management tool.\n\n3. **Run the following query** to check the current value of `mxe.db.format.nullvalue`:\n   ```sql\n   select propvalue from maximo.maxpropvalue where propname='mxe.db.format.nullvalue';\n   ```\n\n4. **If the result is not 'COALESCE'**, update the value by executing the following query:\n   ```sql\n   update maximo.maxpropvalue set propvalue='COALESCE' where propname='mxe.db.format.nullvalue';\n   ```\n\n5. **Start the MXServer** again.\n\nThis should resolve the issue and allow Maximo/SCCD to start without the BMXAA4087E error.",
    "id": "TECHQA_TRAIN_Q235_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q236",
    "question": "Cannot Authorize SPSS 19 Installation on New Computer,Need to Authorize SPSS 19 on a New Computer\nI'm currently using SPSS 19 and need to install it on a new computer, however, it will not authorize. I've spoken to SPSS support by phone but they recommended checking here. I'm running on a Mac, OS X Sierra, for SPSS 19. Would someone please be able to assist?,I'm currently running SPSS 19 and need to install it on a new computer. When I try to authorize it, it fails. I've spoken to SPSS over the phone to no avail. I'm running OS X Sierra. Could anyone please help?",
    "ground_truth": "1. Install the latest FixPack **2** for IBM SPSS Statistics **24** on Mac.",
    "answer": "SPSS 19 is no longer supported by IBM, and it may not be compatible with macOS Sierra (10.12) or any newer versions. Since you are trying to install SPSS 19 on a new computer running macOS Sierra, the authorization failure could be due to compatibility issues.\n\nHere are some steps you can take:\n\n1. **Check Compatibility**: Ensure that SPSS 19 is compatible with macOS Sierra. Since SPSS 19 is an older version, it may not work properly on this OS.\n\n2. **Reinstall SPSS 19**: If you haven't already, try uninstalling and then reinstalling SPSS 19. Make sure to follow the installation instructions carefully.\n\n3. **Run as Administrator**: If possible, try running the installation and authorization process as an administrator. Right-click on the SPSS application and select \"Run as Administrator.\"\n\n4. **Contact IBM Sales**: Since SPSS 19 is no longer supported, consider contacting IBM Sales to inquire about upgrading to a newer version of SPSS that is compatible with your operating system.\n\n5. **Check for Updates**: If you have access to a newer version of SPSS (like SPSS 24 or 25), consider upgrading, as these versions are supported on macOS Sierra.\n\nIf these steps do not resolve the issue, I recommend seeking further assistance from IBM or considering an upgrade to a supported version of SPSS.",
    "id": "TECHQA_TRAIN_Q236_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q237",
    "question": "What is the best practice for working with BPM support\nWhen working with the BPM product set there are a lot of configuration files, logs and applications which can be exported for analysis by the support team. What are the best practices for working with the BPM support team?",
    "ground_truth": "1. Collect the troubleshooting data if you need help from **IBM Business Process Manager Support**.\n   ",
    "answer": "To effectively work with the IBM Business Process Manager (BPM) support team, follow these best practices:\n\n1. **Gather Required Information**: Before contacting support, collect relevant configuration files, logs, and any other data that can help diagnose the issue. This includes:\n   - SystemOut.log file located at `install_root/profiles/profile_name/logs/server_name`.\n   - Any error messages or codes that appeared around the time the issue occurred.\n\n2. **Use MustGather Documentation**: Refer to the MustGather documentation specific to your BPM version to ensure you collect all necessary data. This will expedite the troubleshooting process.\n\n3. **Utilize IBM Support Resources**:\n   - Use the [IBM Support Assistant](http://www.ibm.com/software/support/isa/) to search for known problems and solutions.\n   - Check the [IBM dW Answers](https://developer.ibm.com/answers/topics/bpm/) and developerWorks community for similar issues and resolutions.\n\n4. **Search for Fixes**: If you identify a potential fix, search [Fix Central](http://www.ibm.com/support/fixcentral/) for interim fixes that may apply to your situation.\n\n5. **Document Your Findings**: Keep a record of the symptoms, steps taken, and any relevant logs or configuration changes. This information will be valuable when communicating with the support team.\n\nBy following these steps, you can provide the BPM support team with the information they need to assist you effectively.",
    "id": "TECHQA_TRAIN_Q237_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q250",
    "question": "Why are the changes not reflected in the user interface when you update a Notice Questionnaire Template or Publish a Hold Notice using IBM Atlas?\nWhy are the changes not reflected in the user interface when you.update a Notice Questionnaire Template or Publish a Hold Notice using IBM Atlas?",
    "ground_truth": "1. Contact **Oracle** support\n   \n2. Apply the **Patch:17501296**\n   ",
    "answer": "The changes are not reflected in the user interface when updating a Notice Questionnaire Template or publishing a Hold Notice in IBM Atlas due to an Oracle bug (17501296) in version 11.2.0.4.0. To resolve this issue, you should contact Oracle support and request the application of Patch 17501296. This should address the problem and ensure that your updates are properly reflected in the user interface.",
    "id": "TECHQA_TRAIN_Q250_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q254",
    "question": "Why is my delete virtual portal timing out after 120 seconds?\nWhen deleting a virtual portal via the Portal Admin User Interface (UI), it fails to complete. Examination of the SystemOut.log shows the following message:\n\nWTRN0006W: Transaction 0000014BB8A229770000000161570720292692D3DEAA2109E6D66CBE4D063A1626DCF4E80000014BB8A229770000000161570720292692D3DEAA2109E6D66CBE4D063A1626DCF4E800000001 has timed out after 120 seconds.\n\n00000006 TimeoutManage I WTRN0124I: When the timeout occurred the thread with which the transaction is, or was most recently, associated was Thread[WebContainer : 2,5,main]. The stack trace of this thread when the timeout occurred was: java.net.SocketInputStream.socketRead0(Native Method) java.net.SocketInputStream.read(SocketInputStream.java:140)\n....",
    "ground_truth": "1. Increase the total transaction lifetime timeout and maximum transaction timeout values.\nSet the timeout values to **600** seconds or greater using the instructions in the Related information section below.\n2. Update to Cumulative Fix (CF) **9** or later.\nDo this if the problem persists after addressing the change in suggestion #1 and the error in SystemOut.log shows that the timeout still occurs after 120 seconds. This update will provide the fix for APAR PI04872.\n3. Add or update the custom property to the **WCM_WCMConfigService** Resource Environment Provider.\nSet the Name to **wcm.transaction.timeout** and the Value to **600** (for example).",
    "answer": "The timeout you are experiencing when deleting a virtual portal is likely due to the transaction exceeding the default timeout of 120 seconds, which is insufficient in environments with Managed Pages in WebSphere Portal 8.0. Here are actionable steps to resolve this issue:\n\n1. **Increase Transaction Timeout Values**:\n   - Access your WebSphere Portal administrative settings.\n   - Increase both the total transaction lifetime timeout and the maximum transaction timeout to a value greater than 120 seconds (e.g., 600 seconds).\n   - Make these changes in the server configuration where the timeouts are set.\n\n2. **Update WCM Transaction Timeout Property**:\n   - If the problem persists after the above change, ensure you have applied Cumulative Fix (CF) 9 or later.\n   - Navigate to the WCM_WCMConfigService Resource Environment Provider.\n   - Add or update the following custom property:\n     - **Name**: `wcm.transaction.timeout`\n     - **Value**: `600` (or a suitable value based on your environment).\n\n3. **Monitoring**:\n   - After making these adjustments, monitor the SystemOut.log to ensure that the timeout no longer occurs. Adjust the timeout values further if necessary, depending on the behavior observed.\n\nThese steps should help resolve the timeout issue when deleting a virtual portal. If you continue to face issues, additional investigation may be required.",
    "id": "TECHQA_TRAIN_Q254_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q256",
    "question": "Error running krzgrant.sql script provided with 6.3.1.2-TIV-ITM_KRZ-IF0003.tar\nWhen running the krzgrant.sql script provided in the package - 6.3.1.2-TIV-ITM_KRZ-IF0003.tar get the following errors:\n\nERROR at line 1:\nORA-00942: table or view does not exist ORA-06512: at line 50 \n\nHow to correct this?",
    "ground_truth": "1. Run the **krzgrant.sql** script in **6.3.1-TIV-ITM_KRZ-FP0001**",
    "answer": "To resolve the ORA-00942 error when running the `krzgrant.sql` script, you need to ensure that the Oracle Database Extended agent user has the necessary permissions to access all required tables and views. Here are the steps you can take:\n\n1. **Grant Permissions**: Make sure that the user running the `krzgrant.sql` script has been granted SELECT permissions on the necessary views, such as `SYS.DBA_QUEUES`, `SYS.DBA_JOBS`, and `SYS.DBA_USERS`. You can do this by executing the following SQL commands as a user with sufficient privileges (like SYS or SYSTEM):\n\n   ```sql\n   GRANT SELECT ON SYS.DBA_QUEUES TO your_agent_user;\n   GRANT SELECT ON SYS.DBA_JOBS TO your_agent_user;\n   GRANT SELECT ON SYS.DBA_USERS TO your_agent_user;\n   ```\n\n   Replace `your_agent_user` with the actual username of the Oracle Database Extended agent.\n\n2. **Use a Customized SQL XML File**: If you continue to encounter the error, consider creating a customized SQL XML file. You can copy the SQLInfo definition from the default `krzsql.xml` file and replace the `QueryName` and `GrantName` with 'dual'. This can help avoid the error by allowing the agent to run without needing access to the specific tables/views.\n\n3. **Run the Correct Version of the Script**: If the issue persists, try running the `krzgrant.sql` script from the earlier version, specifically `6.3.1-TIV-ITM_KRZ-FP0001`, as it has been noted as a workaround for this error.\n\nBy following these steps, you should be able to resolve the ORA-00942 error and successfully run the `krzgrant.sql` script.",
    "id": "TECHQA_TRAIN_Q256_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q258",
    "question": "Hide a page in dotedit step\nI am working on datacap 8.1 version. I have 2 pages in a batch. Page 1 with status as 1, Page 2 with status as 20. Both are of same page type. In verification step (dotedit) I want to hide the page which is with status 20. I have given status 20 in ignored page status in web administrator for verify. But still when I navigate through pages in dotedit batch view the respective panel is loading. I am able to submit the batch even if I have one page in a batch with 20 as status.\n\nIs there any way to hide the page (we have multiple same type of pages in a batch) from dotedit based on the page status?",
    "ground_truth": "1. Create a special page type attached at the batch level called something like DeleteMe.\n   \n2. Use an action like BlankPagesIDBySize to identify the blank page.\n   Use the function BlankPagesIDBySize with parameters (1000, DeleteMe) to find the blank pages.\n3. Create a rule with the action **DeleteChildType(DeleteMe)** and attach it at the batch level.\n   This rule will remove all pages with the page type DeleteMe from the batch.",
    "answer": "To hide a page in the dotedit step of IBM Datacap 8.1 based on its status, you can utilize a similar approach as the one described for removing blank pages. Here’s a step-by-step solution to achieve this:\n\n1. **Create a Custom Page Type**: In your Datacap configuration, create a new page type, for instance, `HiddenPageType`.\n\n2. **Identify the Page to Hide**: Use a validation rule or a method to identify the page with status 20. This can be done by creating a custom action that checks the page status.\n\n3. **Perform the Action**: Implement an action that will assign the `HiddenPageType` to any pages that have the status 20. For example, you could create a rule that looks like this:\n   - Example: `SetPageTypeIfStatus(PageType, PageStatus)`, where you check if `PageStatus` is 20 and then set it to `HiddenPageType`.\n\n4. **Delete or Ignore the Page**: You can then create another rule to delete these pages marked as `HiddenPageType`. \n   - Example: `DeleteChildType(HiddenPageType)`. Attach this rule at the batch level.\n\n5. **Update Batch View Configurations**: Ensure that your web administrator settings for the verification step ignore the `HiddenPageType` pages as you have already configured for status 20.\n\nBy following these steps, you should be able to effectively hide the page with status 20 in the dotedit step. If you have any custom rules or actions, make sure they are properly integrated into your workflow.",
    "id": "TECHQA_TRAIN_Q258_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q260",
    "question": "Framework Manager data source error\nUsers receive the following error on selecting a data source from the list defined in IBM Cognos within Framework Manager 10.2.2 Fix Pack 5\n\nalt text\n\nThat error (BMT-IMP-0002 Failed to Execute Metadata request. CM-REQ-4342 An error occurred with the client. CAF-WRN-2082 An error has occurred.) prevents all users to add an existing data source via Framework Manager.\n\nHow can we fix this?",
    "ground_truth": "1. Grant user the required **Import relational metadata** capability.",
    "answer": "To resolve the Framework Manager data source error (BMT-IMP-0002), you need to ensure that the user has the required \"Import relational metadata\" capability. Follow these steps:\n\n1. In Cognos Connection, navigate to the menu and select 'Launch > IBM Cognos Administration'.\n2. Click on the 'Security' tab.\n3. On the left side, select 'Capabilities'.\n4. Find the capability labeled \"Import relational metadata\" and click \"Actions\" > Set Properties.\n5. Go to the 'Permissions' tab.\n6. Add the user, group, or role that needs access to this capability, granting them Read, Execute, and Traverse permissions.\n\nAfter making these changes, have the user try to select the data source again. This should resolve the error.",
    "id": "TECHQA_TRAIN_Q260_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q262",
    "question": "Scroll bar in search results resets to the top position in Internet Explorer\nIn IBM Content Navigator, scroll bar in search results resets to the top position in Internet Explorer V9, V10, and V11. This does not happen with Mozilla Firefox or Google Chrome.",
    "ground_truth": "1. Upgrade to **Microsoft Edge** browser",
    "answer": "To resolve the issue of the scroll bar in search results resetting to the top position in Internet Explorer V9, V10, and V11 while using IBM Content Navigator, you should upgrade to the Microsoft Edge browser. This issue is specific to Internet Explorer and has been fixed in Microsoft Edge. \n\nFor more information on Microsoft Edge support, you can visit [this link](http://www.ibm.com/support/docview.wss?uid=swg21976776).",
    "id": "TECHQA_TRAIN_Q262_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q263",
    "question": "Where can I get ITM 6.3.0 Fixpack 6 ?  Is it available now ?\nWhere can I get ITM 6.3.0 Fixpack 6 ? Is it available now ?",
    "ground_truth": "1. Access the fix download page.\nVisit the URL: **http://www.ibm.com/support/fixcentral/swg/quickorder?parent=ibm%7ETivoli&product=ibm/Tivoli/IBM+Tivoli+Monitoring&release=All&platform=All&function=fixId&fixids=6.3.0-TIV-ITM-FP0006&source=fc** to download the fix 6.3.0-TIV-ITM-FP0006.",
    "answer": "You can download IBM Tivoli Monitoring 6.3.0 Fix Pack 6 (6.3.0-TIV-ITM-FP0006) from IBM Fix Central. It was released on December 11, 2015, and is available for both upgrade and fresh installation. \n\nTo access the download, visit the following link: [IBM Fix Central](http://www.ibm.com/support/fixcentral/swg/quickorder?parent=ibm%7ETivoli&product=ibm/Tivoli/IBM+Tivoli+Monitoring&release=All&platform=All&function=fixId&fixids=6.3.0-TIV-ITM-FP0006&source=fc). \n\nMake sure to select the appropriate file based on your operating system and requirements.",
    "id": "TECHQA_TRAIN_Q263_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q270",
    "question": "How to resolve \"An unexpected error occurred. Contact your system administrator. ICWPA1001E\"\nWhen trying to add people to a matter request when there are more than 1000 people in the clipboard, the following error is reported:\n\nAn unexpected error occurred. Contact your system administrator. ICWPA1001E\"",
    "ground_truth": "1. When you add people from the clipboard, add fewer than **1000** people at one time.\n",
    "answer": "To resolve the \"An unexpected error occurred. Contact your system administrator. ICWPA1001E\" issue, you need to reduce the number of people in the clipboard. The system has a known limitation that prevents adding more than 1000 people at once. \n\nTo work around this limitation, try the following steps:\n\n1. Select fewer than 1000 people from your clipboard.\n2. Add these selected people to the matter request.\n3. If you need to add more people, repeat the process with a new selection of up to 1000 individuals at a time.\n\nThis should help you avoid the error and successfully add people to your matter request.",
    "id": "TECHQA_TRAIN_Q270_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q274",
    "question": "Error when using profilePath parameter with BPMConfig to create a profile\nWhen creating a profile using the BPMConfig command and the -profilePath parameter to define a custom directory to store the profile data, the creation fails with the following error message if the directory already exists (even if it is empty):\ncom.ibm.bpm.config.BPMConfig.main(): The profile path <profile_path> must not exist.....",
    "ground_truth": "1. Make sure a **profilePath** value does not exist.",
    "answer": "The error you are encountering when using the `-profilePath` parameter with BPMConfig indicates that the specified profile path already exists, which is not allowed. To resolve this issue, follow these steps:\n\n1. **Check the Profile Path**: Ensure that the directory you are specifying with the `-profilePath` parameter does not already exist. If it does, you will need to choose a different path or delete the existing directory if it is not needed.\n\n2. **Create Parent Directory**: Make sure that the parent directory of your desired profile path exists. For example, if you want to create a profile at `/usr/BPM850profiles/myProfile`, ensure that `/usr/BPM850profiles` exists, but do not create the `myProfile` directory itself.\n\n3. **Permissions**: Verify that you have the necessary write permissions for the parent directory to allow the creation of a new directory for the profile.\n\n4. **Use Correct Syntax**: If you are on Windows, remember to use double backslashes (`\\\\`) or forward slashes (`/`) in your path.\n\nBy following these steps, you should be able to successfully create the profile without encountering the error. If you continue to experience issues, consider checking the logs for more detailed error messages.",
    "id": "TECHQA_TRAIN_Q274_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q276",
    "question": "Netcool/Impact (all versions): JMSListener does not reconnect when JMS server is restarted\nJMSListener does not reconnect when JMS server is restarted.\nCreated JMS datamodel to connect to JMS queue. Restart the JBOSS service on JBOSS server on which JMS queue exists Impact attempt to connect to JMS queue fails and it says connection could not be made. However, restart Impact process and click on test connection it gives connection OK message.\n\nHave configured reconnect properties:\n\n     impact.MyJMSListener.jms.autoreconnect=true\n     impact.MyJMSListener.jms.autoreconnect.pollinterval=20000",
    "ground_truth": "1. Locate the properties file for the JMSListener.\n   The properties file can be found at the following path: **$NCHOME/impact/etc/[ImpactServerName]_[JMSListenerName].props**, where [ImpactServerName] is the name of the ImpactServer (for example: NCI) and [JMSListenerName] is the name of the JMSListener Service (for example: MyJMSListener).\n2. Set the autoreconnect property.\n   Add the following line to the properties file: **impact.[JMSListenerName].autoreconnect=true**, replacing [JMSListenerName] with the name of the JMSListener Service (for example: MyJMSListener).\n3. Set the autoreconnect poll interval.\n   Add the following line to the properties file: **impact.[JMSListenerName].autoreconnect.pollinterval=[TimeValue]**, where [JMSListenerName] is the name of the JMSListener Service and [TimeValue] is the desired polling interval value in milliseconds (for example: 30000 which is equivalent to 30 seconds). Note that the properties should not include the additional .jms bit.",
    "answer": "To resolve the issue with the JMSListener not reconnecting when the JMS server is restarted, you need to ensure that the properties for the JMSListener are correctly configured in the properties file. \n\n1. Locate the properties file for your JMSListener, which should be at:\n   ```\n   $NCHOME/impact/etc/[ImpactServerName]_[JMSListenerName].props\n   ```\n   Replace `[ImpactServerName]` with the name of your ImpactServer (e.g., NCI) and `[JMSListenerName]` with the name of your JMSListener Service (e.g., MyJMSListener).\n\n2. Update the properties in this file to remove the `.jms` part. They should be set as follows:\n   ```\n   impact.MyJMSListener.autoreconnect=true\n   impact.MyJMSListener.autoreconnect.pollinterval=20000\n   ```\n\n3. After making these changes, restart the Impact process to apply the new configuration.\n\nBy ensuring that the properties are set correctly without the additional `.jms` segment, the JMSListener should be able to reconnect automatically when the JMS server is restarted.",
    "id": "TECHQA_TRAIN_Q276_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q277",
    "question": "No data in some workspaces for MySQL agent\nWhy Monitoring agent for MySQL when configured to monitor MySQL server versions 5.7.6 and above does not collect data for some of the attribute groups?",
    "ground_truth": "1. Use the **show_compatibility_56** system variable.\n   This system variable affects whether MySQL 5.6 compatibility is enabled concerning how system and status variable information is provided by the INFORMATION_SCHEMA. It should be used when running the agent on MySQL server versions **5.7.6** and above.",
    "answer": "To resolve the issue of no data being collected by the MySQL monitoring agent for versions 5.7.6 and above, you need to enable the `show_compatibility_56` system variable. This variable affects how system and status variable information is provided by the `INFORMATION_SCHEMA`.\n\nHere are the steps to enable it:\n\n1. **Check the Current Value**: First, check the current value of the `show_compatibility_56` variable by running the following command in the MySQL command prompt:\n   ```sql\n   SHOW GLOBAL VARIABLES LIKE \"show_compatibility_56\";\n   ```\n\n2. **Set the Variable**: If the value is `OFF`, you can enable it by executing:\n   ```sql\n   SET GLOBAL show_compatibility_56=ON;\n   ```\n\n3. **Persistent Change**: To make this change persistent across server restarts, add the following line to your MySQL configuration file (`my.cnf`):\n   ```\n   show_compatibility_56=ON\n   ```\n   - For Windows, the `my.cnf` file is typically located at `<MySQL_Installation_Dir>/my.cnf`.\n   - For UNIX/Linux, it is usually found at `/etc/my.cnf`.\n\n4. **Restart MySQL Server**: After modifying the `my.cnf` file, restart the MySQL server for the changes to take effect.\n\nBy following these steps, the monitoring agent should start collecting data for the specified attribute groups. If you continue to experience issues, please check the JDBC trace logs for any additional errors.",
    "id": "TECHQA_TRAIN_Q277_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q278",
    "question": "How to control SDMS database size?\nITCAM for SOA 7.1.1 was installed about 3 years ago. I already know that SDMS database size may increase with no limit. Has anyone found a way to keep under control this behavior?",
    "ground_truth": "1. Schedule a daily job to run the **kd4TrimDB2db** utility.\n   To keep only the latest 24 hours of data every day, you should set up a task that executes the **kd4TrimDB2db** utility on a daily basis.",
    "answer": "To control the size of the SDMS database in ITCAM for SOA 7.1.1, you can implement a regular pruning strategy since there is no automatic mechanism for this version. Here are the steps you can take:\n\n1. **Use the kd4TrimDB2db Utility**: Schedule a daily job to run the `kd4TrimDB2db` utility. This utility will help you prune the database by keeping only the latest 24 hours of data.\n\n2. **Set Up a Scheduled Job**: Depending on your operating system, you can use cron jobs (Linux) or Task Scheduler (Windows) to automate the execution of the `kd4TrimDB2db` utility daily.\n\n3. **Refer to the Wiki Page**: For detailed instructions on how to use the utility and set up the job, you can visit the following link: [Pruning SDMS Relationship Metrics Tables](https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Tivoli+Composite+Application+Manager/page/Pruning+SDMS+Relationship+Metrics+Tables).\n\nBy following these steps, you should be able to manage the growth of your SDMS database effectively.",
    "id": "TECHQA_TRAIN_Q278_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q280",
    "question": "How to set database specific custom properties in WebSphere Application Server?\nI am using Websphere Application Server (WAS) v8.5.x with Oracle 11.1 JDBC drivers and I want to set some oracle specific custom properties, when connecting to the database in Websphere Application Server. How to set such specific properties in Websphere Application Server?",
    "ground_truth": "1. Set a Custom Property in the datasource.\n   In the datasource, configure a Custom Property with the Name set to **connectionProperties** and the Value set to **propertyA=valueA;propertyB=valueB**.",
    "answer": "To set Oracle-specific custom properties in WebSphere Application Server (WAS) v8.5.x when using Oracle 11.1 JDBC drivers, you can follow these steps:\n\n1. **Access the DataSource Configuration**:\n   - Log in to the WebSphere Administrative Console.\n   - Navigate to **Resources** > **JDBC** > **Data sources**.\n   - Select the DataSource you want to configure.\n\n2. **Set Custom Properties**:\n   - In the DataSource settings, look for the section labeled **Custom properties**.\n   - Add a new custom property with the following details:\n     - **Name**: `connectionProperties`\n     - **Value**: Specify your Oracle properties in the format `propertyA=valueA;propertyB=valueB`. For example, to set the property `oracle.jdbc.V8Compatible=true`, you would enter:\n       ```\n       oracle.jdbc.V8Compatible=true\n       ```\n\n3. **Save and Test**:\n   - Save your changes.\n   - Test the DataSource to ensure that the custom properties are applied correctly.\n\nBy following these steps, you can successfully set database-specific custom properties for your Oracle JDBC connection in WebSphere Application Server.",
    "id": "TECHQA_TRAIN_Q280_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q283",
    "question": "What is the latest Alcatel 5620 SAM probe?\nWe have the nco_p_alcatel_5620_sam_v13 probe, is there a newer version of the probe.\nDoes this probe support Release 14 of the 5620 SAM?",
    "ground_truth": "1. Download the package from the IBM Passport Advantage website.\n   Visit the IBM Passport Advantage website at **www-01.ibm.com/support/knowledgecenter/SSSHTQ/omnibus/probes/nokia_nfmp/wip/concept/nknfmp_intro.html** to download the package you require.",
    "answer": "I don't know.",
    "id": "TECHQA_TRAIN_Q283_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q285",
    "question": "How do I upgrade my virtual DataPower Appliance from 5.0 firmware to 6.0+ firmware?\nWhen attempting to upgrade my Virtual DataPower Appliance from 5.0.0.0 firmware version to 6.0+ firmware versions, I receive a failure message.",
    "ground_truth": "1. Install the **5.0.0.8** or later fix pack.",
    "answer": "To successfully upgrade your Virtual DataPower Appliance from firmware version 5.0.0.0 to 6.0+ firmware, follow these steps:\n\n1. **Confirm Your Current Version**: Ensure that your current firmware version is at least 5.0.0.8. If it is below this version, you need to upgrade to 5.0.0.8 or later first.\n\n2. **Install the 5.0.0.8 or Later Fix Pack**: If not already done, download and install the 5.0.0.8 fix pack from Fix Central. This is essential as it contains critical fixes necessary for the upgrade.\n\n3. **Upgrade to 6.0+ Firmware**: Once you have 5.0.0.8 installed, you can proceed to upgrade to the 6.0+ firmware. Ensure that the upgrade file you are using is compatible and contains no issues.\n\n4. **Error Handling**: If you still receive a failure message during the upgrade, verify the integrity of your upgrade file and check for any additional prerequisites or compatibility notes on the specific firmware version you are trying to install. \n\nIf you follow these steps and ensure your versions are correct, you should be able to upgrade successfully.",
    "id": "TECHQA_TRAIN_Q285_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q286",
    "question": "Port number error starting 9.0 Launcher\nI'm attempting to start up v9.0 for the first time with one .msl file on a Windows server and get the following error.  I also have v8.4 on this server and it starts fine.  I do not have v8.4 running when I attempt to start v9.0.\n\nCannot recognize if the system RecordChangeSystem.msl; has started. Reason: Server is unable to get the status of the system on port number 6,002.\n\nI have the port range set to 7000/8000.  I've never seen this error before.\n\nAny help?  Thanks.",
    "ground_truth": "1. Obtain patch for APAR **PI64816**.\n   ",
    "answer": "It seems that you are encountering a port number issue while starting v9.0 of your software. The error indicates that the server is unable to get the status of the system on port 6002, while your configuration specifies a port range of 7000 to 8000.\n\nHere are steps you can take to resolve the issue:\n\n1. **Check Port Configuration:**\n   - Ensure that your server is properly configured to allow communications on port 6002 or update your v9.0 configuration to use a port within the range of 7000-8000.\n\n2. **Firewall Settings:**\n   - Verify that any firewalls on the server or network do not block port 6002. If blocked, either open that port or use a port within your specified range.\n\n3. **Check Other Instances:**\n   - Confirm that no other instances of v9.0 (or any other software) are using port 6002. Sometimes port conflicts can arise if other applications are binding to the same port.\n\n4. **Check for Updates:**\n   - As a final step, check for any updates or patches that may address known issues with v9.0. Sometimes, specific issues are documented in release notes or knowledge bases.\n\nIf you've taken these steps and still face the issue, please provide additional details about your server environment and any other relevant configurations, and I'll do my best to assist further.",
    "id": "TECHQA_TRAIN_Q286_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q294",
    "question": "IZE0106E Connect failed with \"Unsupported CICS release\" after upgrading CICS TS V5.x\nDo I have to upgrade my CICS Explorer to the same release as CICS Transaction Server for z/OS (CICS TS)? I recently upgraded to a new release of CICS TS and now when I attempt to connect to CICS Explorer using a CMCI connection, I get message \nIZE0106E Connect failed with \"Unsupported CICS release\" after upgrading \nin CICS Explorer.",
    "ground_truth": "1. Upgrade to the latest release of **CICS** Explorer.\n",
    "answer": "Yes, you need to upgrade your CICS Explorer to a version that is compatible with your upgraded CICS TS. The error message \"IZE0106E Connect failed with 'Unsupported CICS release'\" indicates that your current version of CICS Explorer does not support the CICS TS release you upgraded to. \n\nIBM recommends using the latest release of CICS Explorer for optimal functionality. While CICS Explorer V5.4 is compatible with CICS TS V4.1 through V5.4, it will not be compatible with a newer version of CICS TS that you are now using. \n\nTo resolve this issue, download and install the latest version of CICS Explorer from IBM to ensure compatibility with your upgraded CICS TS.",
    "id": "TECHQA_TRAIN_Q294_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q295",
    "question": "Why are ITNM or Omnnibus WebGUI java applets fail to load with \"Missing Permissions manifest attribute in main jar\"\nWhy are ITNM or Omnnibus WebGUI java applets fail to load with \"Missing Permissions manifest attribute in main jar\"",
    "ground_truth": "1. Use the HATool.{bat|sh} command located in the **<TIP HOME>/profiles/TIPProfile/bin/ha** directory.\n\n2. Run the command with the following syntax: **HATool.{bat|sh} modules <db2 username> <db2 password>**",
    "answer": "The error \"Missing Permissions manifest attribute in main jar\" typically indicates that the Java applet you are trying to load does not have the necessary permissions specified in its manifest file. This can happen if the applet is not signed correctly or if the required permissions are not defined.\n\nTo resolve this issue, you can try the following steps:\n\n1. **Check the JAR File**: Ensure that the JAR file for the applet is signed. You can do this by checking the manifest file (MANIFEST.MF) inside the JAR. It should contain a line like `Permissions: all-permissions`.\n\n2. **Re-sign the JAR**: If the JAR is not signed, you will need to sign it using a valid certificate. You can use the `jarsigner` tool that comes with the JDK to sign the JAR file.\n\n3. **Update Java Security Settings**: Sometimes, Java security settings can prevent applets from loading. Go to the Java Control Panel and adjust the security settings to allow the applet to run. You may need to add the site to the Exception Site List.\n\n4. **Clear Java Cache**: Clear the Java cache to ensure that the latest version of the applet is being loaded. You can do this from the Java Control Panel under the \"General\" tab by clicking on \"Delete Files\".\n\n5. **Check Browser Compatibility**: Ensure that you are using a compatible browser, as some modern browsers have deprecated support for Java applets.\n\nIf these steps do not resolve the issue, you may need to consult the documentation for ITNM or Omnibus WebGUI or contact your system administrator for further assistance.",
    "id": "TECHQA_TRAIN_Q295_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q296",
    "question": "Is it possible to controle which ciphers are available in Tivoli Integrated Portal?\nIs it possible to controle which ciphers are available in Tivoli Integrated Portal?",
    "ground_truth": "1. Log into the Websphere Application server and navigate to:\n   SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP)\n2. Select the **RC4** ciphers from the **Selected ciphers** list, and then click the **<<Remove** button.\n   \n3. Click the 'Apply' button, and then the 'Save (to the master configuration)' link.\n   \n4. Restart **TIP**.\n   ",
    "answer": "Yes, it is possible to control which ciphers are available in Tivoli Integrated Portal (TIP). To disable RC4 ciphers, follow these steps:\n\n1. Log into the Websphere Application Server and navigate to:\n   - SSL certificate and key management > SSL configurations > NodeDefaultSSLSettings > Quality of protection (QoP).\n\n2. Select the *RC4* ciphers from the \"Selected ciphers\" list, and then click the \"<<Remove\" button.\n\n3. Click the \"Apply\" button, and then the \"Save (to the master configuration)\" link.\n\n4. Restart the Tivoli Integrated Portal.\n\nThis process will effectively remove the RC4 ciphers from your configuration.",
    "id": "TECHQA_TRAIN_Q296_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q297",
    "question": "What action is required for IBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server for the GNU C library (glibc) vulnerability (CVE-2015-0235)?\nIBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server requires customer action for the GNU C library (glibc) vulnerability that has been referred to as \"GHOST\". What action is required?",
    "ground_truth": "1. Contact **Red Hat** to obtain fixes.\n\n2. Install fixes for Red Hat Enterprise Linux (RHEL).",
    "answer": "To address the GNU C library (glibc) vulnerability (CVE-2015-0235) in IBM WebSphere MQ Hypervisor Edition for Red Hat Enterprise Linux Server, you need to take the following action:\n\n1. **Contact Red Hat**: Reach out to Red Hat support to obtain the necessary fixes for the vulnerability.\n2. **Install the Fixes**: Once you have the fixes, ensure that you install them on your Red Hat Enterprise Linux (RHEL) system.\n\nFor more detailed information, you can refer to the Red Hat Customer Portal regarding the GHOST vulnerability [here](https://access.redhat.com/articles/1332213).",
    "id": "TECHQA_TRAIN_Q297_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q300",
    "question": "How to access the 2nd portal profile?\nHello,\n\nI created a second WebSphere portal profile (wp_profile2) under C:\\IBM\\WebSphere as part of setting up multi-profile environment on windows using WebSphere Portal 8.0.0.1 CF04/WAS 8.0.0.10. I started the WebSphere_Portal under this profile successfully and am trying to access this new portal profile from a web browser using http://<host>:port/wps/myportal. I tried all the ports listed in SystemOut log but none of them seem to work and the one that appears to work is writing below error in logs and is showing a blank page:\n\n \n\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O javax.servlet.jsp.JspException: com.ibm.portal.resolver.exceptions.LocalizedIOException: RT7507E: Unable to initialize Repository: Default.\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O  at com.ibm.wps.engine.templates.themes.Default.render(Default.java:237)\n[11/10/15 9:45:13:374 PST] 00000044 SystemOut     O  at com.ibm.wps.engine.templates.ThemeTemplate.render(ThemeT\n\n \n\nDoes anyone have any idea of how to fix the above issues and get the portal access working?\n\nAppreciate your help regarding this.\n\n \n\nThank you.",
    "ground_truth": "1. Remove the copy so that the only file in .\\wp_profile\\PortalServer\\jcr\\lib\\com\\ibm\\icm is **icm.properties**",
    "answer": "To resolve the issue of accessing your second WebSphere portal profile (wp_profile2) and the error message \"RT7507E: Unable to initialize Repository: Default,\" follow these steps:\n\n1. **Check for Duplicate Configuration Files**: Navigate to the directory `C:\\IBM\\WebSphere\\wp_profile2\\PortalServer\\jcr\\lib\\com\\ibm\\icm`. Ensure that there is only one `icm.properties` file present. If you find any other files with similar names (like `icm-copy.properties`), remove or rename them.\n\n2. **Restart the Server**: After ensuring that only the `icm.properties` file is present, restart the WebSphere_Portal server under the wp_profile2 profile.\n\n3. **Check Logs for Further Errors**: After restarting, monitor the SystemOut.log for any additional errors that may indicate further issues.\n\n4. **Access the Portal**: Try accessing the portal again using the URL `http://<host>:<port>/wps/myportal`, replacing `<host>` and `<port>` with the appropriate values for your setup.\n\nBy following these steps, you should be able to resolve the initialization issue and access your second portal profile. If the problem persists, further investigation into the logs may be necessary.",
    "id": "TECHQA_TRAIN_Q300_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q301",
    "question": "How do you switch on the indexing of sparse file in StoredIQ?\nBy default these are skipped - does anyone know where to switch them on on the dataserver?",
    "ground_truth": "1. SSH into the Data Server(s) and enter the following command at the prompt;\n   Use SSH to connect to the Data Server(s). Once connected, input the command: **psql -U dfuser dfdata -c \"insert into adminknobs (name,value,description,valuetype,use) VALUES ('read_sparse_files','1','Read sprase data objects','int','1')\"**.\n2. Verify that the output of the command is **INSERT 0 1**.\n\n3. If so, enter the following command and wait for the UI to come back up: **service siqinit restart**.",
    "answer": "To switch on the indexing of sparse files in StoredIQ, follow these steps:\n\n1. **Ensure No Jobs Are Running**: Make sure that no jobs are currently running on the Data Server.\n\n2. **SSH into the Data Server**: Use SSH to connect to your Data Server.\n\n3. **Enter the Command to Enable Sparse File Processing**: Execute the following command:\n\n   ```bash\n   psql -U dfuser dfdata -c \"insert into adminknobs (name,value,description,valuetype,use) VALUES ('read_sparse_files','1','Read sparse data objects','int','1')\"\n   ```\n\n   You should see the response: \n   ```\n   INSERT 0 1\n   ```\n\n4. **Restart the Service**: Enter the following command to restart the service:\n\n   ```bash\n   service siqinit restart\n   ```\n\n   Wait for the UI to come back up.\n\n5. **Verification**: You should again see the confirmation of the insert. If everything is correct, sparse data objects will now be processed during your data harvesting.\n\n6. **Caution**: If you are using a policy that leaves a sparse file viewable while backing up the original file, keep in mind that this may lead to increased disk space usage as SIQ accesses every sparse file.\n\nNow you can run your harvests as normal.",
    "id": "TECHQA_TRAIN_Q301_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q304",
    "question": "In FileNet Workplace XT .csv files open as a text file instead of using MS Excel\nThe .csv file was created through WorkplaceXT and it only can be opened as the text file instead of the Excel file, and the mime type is text/csv, not application/vnd.ms-excel. However, when creating the same .csv document through ACCE, the mime Type is \"application/vnd.ms-excel\" shown under the Properties tab and Content Element tab.",
    "ground_truth": "1. Add a section to **Web.xml** mapping the extension to the mime type.\n   Include the following <mime-mapping> section in the Web.xml file: **<mime-mapping><extension>csv</extension><mime-type>application/vnd.ms-excel</mime-type></mime-mapping>**.",
    "answer": "To resolve the issue of .csv files opening as text files instead of in MS Excel within FileNet Workplace XT, you need to update the Web.xml configuration to correctly map the .csv file extension to the appropriate mime type. Here are the steps to do this:\n\n1. Locate the `Web.xml` file in your FileNet Workplace XT installation directory.\n2. Open the `Web.xml` file in a text editor with administrative privileges.\n3. Add the following section to the file to map the .csv extension to the Excel mime type:\n\n   ```xml\n   <mime-mapping>\n       <extension>csv</extension>\n       <mime-type>application/vnd.ms-excel</mime-type>\n   </mime-mapping>\n   ```\n\n4. Save the changes to the `Web.xml` file.\n5. Restart the FileNet Workplace XT application to apply the changes.\n\nAfter completing these steps, .csv files created through Workplace XT should open in MS Excel instead of as text files.",
    "id": "TECHQA_TRAIN_Q304_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q305",
    "question": "Need help accessing my SPSS access code?\nI downloaded SPSS GradPack (Standard) 25 6 Months for my Mac. The IBM SPSS Statistics 24 licensing page pops up for me to enter the code. I enter the code provided and then hit next, and it tells me the code is too short to be valid? What code do I use then? I need this resolved fast, my first assignment is due soon. I was only given a 16-digit access code, not a 20-digit?\n\n\n\nThis dW Answers question is about an IBM document with the Title:\nSPSS Student Version and Graduate Pack Resources",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "It seems that the access code you received is not the correct format for the version of SPSS you are trying to install. The 16-digit code you have may not be the full licensing code required for activation. \n\nTo resolve this issue quickly, I recommend the following steps:\n\n1. **Contact Your Vendor**: Since you are using the SPSS GradPack, reach out to the vendor from whom you purchased the software. They should be able to provide you with the correct licensing code or clarify the issue. Here are some vendor links you can use:\n   - Hearne: [Hearne Software](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub](http://onthehub.com/)\n   - StudentDiscounts.com: [StudentDiscounts](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Check Documentation**: Review any documentation or emails you received when you purchased the software. There may be additional instructions or a different code provided.\n\n3. **Reinstall if Necessary**: If you continue to have issues, consider uninstalling and reinstalling the software to see if that prompts for the correct code again.\n\nMake sure to act quickly, as your assignment is due soon. Good luck!",
    "id": "TECHQA_TRAIN_Q305_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q306",
    "question": "Hey, how can I transfer my spss 24 licence from my old macbook to the new one?\nI made the backup from my laptop to my new one, but SPSS doesnt allow me to start, because of the licence! Also I tried the SPSS Licence wizard on the new macbook, but it is not possible to fill in my licence\n\nI didn't find a option to deactivate the licence on the previous macbook.. how can I solve this problem?",
    "ground_truth": "1. Type (copy/paste) the following command:\n   Run the command **sudo chown -R root:admin 20** in the Terminal.\n2. Press Enter/Return.\n   \n3. Close Terminal.\n   \n4. Launch the **License Authorization Wizard**.\n   ",
    "answer": "To transfer your SPSS 24 license from your old MacBook to your new one, follow these steps:\n\n1. **Deactivate License on Old MacBook**:\n   - Open SPSS on your old MacBook.\n   - Go to the License Authorization Wizard (LAW).\n   - Look for an option to deactivate or transfer the license. If you cannot find this option, you may need to contact IBM SPSS Support for assistance.\n\n2. **Prepare New MacBook**:\n   - Ensure you have administrator privileges on your new MacBook. If you encounter a warning about not having the correct privileges, follow these steps:\n     - Close SPSS and the License Authorization Wizard if they are open.\n     - Open Finder, go to the 'Go' menu, select 'Utilities', and open 'Terminal'.\n     - Type the following command and press Enter:\n       ```\n       sudo chown -R root:admin /Applications/IBM/SPSS/Statistics/24\n       ```\n     - Enter your administrator password when prompted.\n     - Close Terminal.\n\n3. **Activate License on New MacBook**:\n   - Launch the License Authorization Wizard on your new MacBook.\n   - Enter your license information when prompted.\n\nIf you still encounter issues with the license transfer or cannot deactivate the license on the old MacBook, please contact IBM SPSS Support for further assistance.",
    "id": "TECHQA_TRAIN_Q306_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q307",
    "question": "Product upgrade installed a second instance of the DE, causing upgrade failure.\nThe Deployment Engine should only have one instance installed on a server with IBM products installed. In this case, a second DE was installed, which caused the failure of the Product upgrade. Error: Wrong Deployment Engine.\n\nProduct install failed. You will get a message similar to this: You are updating an instance of (Product name) that was installed using the Tivoli Deployment Engine (DE) located at \"/home/nc_admin/.acsi_FQDN\". However you are now using the DE located at \"/home/nc_admin/.acsi_HOSTNAME\".\n\nWhen the DE is installed as non-root ( in this case nc_admin ), it will install the DE in the user home directory, in this case /home/nc_admin, and use the FQDN in the name: /home/nc_admin/.acsi_FQDN",
    "ground_truth": "1. Make sure the current upgrade is using the same version of **JVM** as the original install.\n  ",
    "answer": "To resolve the issue of the failed product upgrade due to the installation of a second instance of the Deployment Engine (DE), follow these steps:\n\n1. **Check the Error Message:** Verify which instance of the DE is valid by referring to the error message. It will indicate the correct DE location (e.g. \"/home/nc_admin/.acsi_FQDN\").\n\n2. **Backup the Valid DE Installation:**\n   - Run the following command to create a backup of the valid DE installation:\n     ```bash\n     cp -r /home/nc_admin/.acsi_FQDN /home/nc_admin/.acsi_FQDN_backup\n     ```\n\n3. **Remove the Invalid DE Directory:**\n   - Move the newly created invalid DE directory to a backup location:\n     ```bash\n     mv /home/nc_admin/.acsi_HOSTNAME /home/nc_admin/.acsi_HOSTNAME_backup\n     ```\n\n4. **Create a Soft Link to the Valid DE:**\n   - Navigate to the DE home directory:\n     ```bash\n     cd /home/nc_admin\n     ```\n   - Create a symbolic link to the valid DE:\n     ```bash\n     ln -s /home/nc_admin/.acsi_FQDN .acsi_HOSTNAME\n     ```\n\n5. **Confirm the Link Was Created Successfully:**\n   - Verify the link with the following command:\n     ```bash\n     ls -lart\n     ```\n   - Look for output similar to this:\n     ```\n     lrwxrwxrwx 1 nc_admin ncoadmin <date> .acsi_HOSTNAME -> /home/nc_admin/.acsi_FQDN\n     ```\n\n6. **Retry the Product Upgrade:**\n   - Before retrying the product upgrade, make sure there are no other required cleanups as indicated by the product documentation.\n\nBy following these steps, you should be able to resolve the upgrade failure related to the Deployment Engine issue.",
    "id": "TECHQA_TRAIN_Q307_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q310",
    "question": "What may be the cause of unclosed MQ object connections on DataPower?\nHow can I resolve open MQ object connections that did not close out on DataPower?",
    "ground_truth": "1. Change the **cache timeout** on the IBM WebSphere DataPower MQ manager (mq-qm) object.\n   Consider using the cache timeout at **60** seconds. Best practice is to use a value less than the **KeepAlive Timeout** of the MQ Queue Manager (qmgr).",
    "answer": "The cause of unclosed MQ object connections on DataPower is likely due to the MQ manager object's idle connection not being closed when using the default cache timeout, which is an empty string. \n\nTo resolve the issue of open MQ object connections, you should change the cache timeout on the IBM WebSphere DataPower MQ manager (mq-qm) object. A recommended starting value is 60 seconds. Ensure that this value is less than the KeepAlive Timeout of the MQ Queue Manager (qmgr) to prevent further issues.\n\nHere are the steps to change the cache timeout:\n\n1. Access the DataPower management interface.\n2. Locate the MQ manager object (mq-qm).\n3. Modify the cache timeout setting to a value of 60 seconds or less.\n4. Save the changes and monitor the connections to ensure they close as expected.\n\nThis should help in managing the MQ object connections effectively.",
    "id": "TECHQA_TRAIN_Q310_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q314",
    "question": "how to Configure the server to only accept strong encryption protocols such as TLS1.1?\nhow to Configure the server to only accept strong encryption protocols such as TLS1.1?",
    "ground_truth": "1. Add the following directive to the **httpd.conf** file to disable SSLv3 and SSLv2:\n# Disable SSLv3 for CVE-2014-3566\n# SSLv2 is disabled in V8R0 and later by default, and in typical V7\n# and earlier configurations disabled implicitly when SSLv3 ciphers\n# are configured with SSLCipherSpec.\nSSLProtocolDisable SSLv3 SSLv2\n\n2. Stop and restart **IHS** for the changes to take effect.",
    "answer": "To configure your server to only accept strong encryption protocols such as TLS 1.1, follow these steps:\n\n1. **Edit the `httpd.conf` file**: Locate your server's `httpd.conf` file, which is typically found in the installation directory of your IBM HTTP Server.\n\n2. **Disable SSLv3 and SSLv2**: Add the following directive to disable SSLv3 and SSLv2, ensuring that only TLS 1.1 and higher protocols are enabled:\n\n   ```apache\n   # Disable SSLv3 and SSLv2\n   SSLProtocolDisable SSLv3 SSLv2\n   ```\n\n3. **Move SSLEnable to VirtualHost**: If you have configured SSL with `SSLEnable` in the global (non-virtualhost) scope, you will need to move it into a virtualhost scope to apply the `SSLProtocolDisable` directive.\n\n4. **Restart the Server**: After making these changes, stop and restart your IBM HTTP Server for the changes to take effect.\n\n5. **Verify Configuration**: After restarting, you can verify that only TLS 1.1 and higher protocols are accepted by using tools like SSL Labs' SSL Test or similar.\n\nBy following these steps, your server will be configured to only accept strong encryption protocols such as TLS 1.1.",
    "id": "TECHQA_TRAIN_Q314_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q318",
    "question": "fixlets do not appear in console bigfix\nWork with ILTM 9.2.7 / 9.5.4.38. In the bigfix console the fixlets do not appear, under the tree: Sites-> IBM License Reporting (ILTM) v9 -> Fixlets and Task.\n\nAttached image. Do you have any ideas?\n\nGreetings and thank you BigFix",
    "ground_truth": "1. Check with the firewall/proxy/IPS/network admin.\n   Ask the firewall, proxy, IPS, or network administrator to check the logs for any dropped packets or downloads.\n2. Adjust rules to allow **BES** Support site content.\n   Request the administrator to adjust the rules to allow the BES Support site content to pass through.\n3. Try turning off **Internet Explorer Enhanced Security Configuration**.\n",
    "answer": "To resolve the issue of fixlets not appearing in the BigFix console under the IBM License Reporting (ILTM) site, follow these steps:\n\n1. **Check Network Security Devices**: Verify if there is an Intrusion Prevention System (IPS), firewall, or proxy appliance between your BigFix server and the sync.bigfix.com servers. These devices may be blocking the download of site content. Consult with your network administrator to check the logs for any dropped packets or downloads and adjust the rules to allow traffic to sync.bigfix.com.\n\n2. **Review Error Logs**: Look for error messages in the `BESRelay.log` and `GatherDB.log` on the BigFix server. If you see messages indicating an \"Unexpected HTTP response: 404,\" it confirms that the server is unable to gather site content.\n\n3. **Disable Internet Explorer Enhanced Security Configuration**: If your BigFix server is running Windows, check if the Internet Explorer Enhanced Security Configuration is enabled for Administrators. If it is, try disabling it to see if that resolves the issue. You can find instructions on how to do this [here](https://blogs.technet.microsoft.com/chenley/2011/03/10/how-to-turn-off-internet-explorer-enhanced-security-configuration/).\n\nAfter performing these steps, restart the BigFix services and check if the fixlets appear in the console. If the issue persists, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q318_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q319",
    "question": "Why does my login fail when I use the ltpa-usrnm attribute?\nYou use a Domino server as your LDAP, and the login attribute you want to use is ltpa-usrnm. This is acceptable, as the login attribute can be set accordingly in the wimconfig.xml. When the search string is built for the login, it is in the form, cn=username, o=orgname.\n\nThis cause the following exception to the returned:\n\n[3/30/16 9:56:03:453 CDT] 000000f7 exception E com.ibm.ws.wim.adapter.ldap.LdapConnection getAttributes CWWIM4520E The 'javax.naming.InvalidNameException: \"CN=username/O=orgname\": [LDAP: error code 34 - Invalid DN Syntax]; remaining name '\"CN=username/O=orgname'\";",
    "ground_truth": "1. Set a custom property using the command.\n   **$AdminTask configureAdminWIMUserRegistry {-customProperties {\"com.ibm.ws.wim.registry.allowDNPrincipalNameAsLiteral =true\"}}**",
    "answer": "The login failure when using the `ltpa-usrnm` attribute may be due to the presence of an equal sign \"=\" in the username, which causes the Virtual Member Manager (VMM) to interpret it as a distinguished name (DN). This results in an `InvalidUniqueNameException`.\n\nTo resolve this issue, you can set a custom property that allows the login name to be treated as a literal rather than a DN. Here’s how to do it:\n\n1. Open your command line interface.\n2. Run the following command:\n\n   ```bash\n   $AdminTask configureAdminWIMUserRegistry {-customProperties {\"com.ibm.ws.wim.registry.allowDNPrincipalNameAsLiteral=true\"} }\n   ```\n\n3. After executing the command, restart your server for the changes to take effect.\n\nThis should allow you to log in successfully using the `ltpa-usrnm` attribute, even if the username contains an equal sign. If the problem persists, please check for any additional configuration issues or consult the IBM support documentation for further assistance.",
    "id": "TECHQA_TRAIN_Q319_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q330",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator v2.0.3, to fit content by height or width?",
    "ground_truth": "1. Add the parameter-value pair in the Additional Settings section of the **Daeja ViewONE** panel.\n\n2. Click **New** in the Additional Settings section.\n\n3. Save the changes.\n\n4. Re-launch the viewer.",
    "answer": "To change the default 'fit content by' behavior of the Daeja viewer in IBM Content Navigator v2.0.3, follow these steps:\n\n1. **Access the Admin Desktop**: Log in to the IBM Content Navigator admin desktop.\n\n2. **Navigate to Daeja ViewONE Panel**: Locate the Daeja ViewONE panel.\n\n3. **Add Parameter-Value Pair**:\n   - For the **Daeja Professional viewer**, go to the **Professional tab**.\n   - For the **Daeja Virtual viewer**, go to the **Virtual tab**.\n   - Click on **New** in the Additional Settings section.\n\n4. **Set the Scale Parameter**:\n   - To fit content by width, enter the parameter-value pair: `scale: \"ftow\"`.\n   - To fit content by height, enter the parameter-value pair: `scale: \"ftoh\"`.\n\n5. **Save Changes**: After adding the parameter, save the changes.\n\n6. **Restart the Viewer**: The changes will take effect the next time the viewer is launched.\n\nBy following these steps, you can successfully change the default 'fit content by' behavior of the Daeja viewer.",
    "id": "TECHQA_TRAIN_Q330_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q331",
    "question": "mirandabarby\nI have purchased a grad pack of SPSS. How do I enter the authorisation code to activate/license",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To enter the authorization code for your SPSS Grad Pack, follow these steps:\n\n1. Open the SPSS software on your computer.\n2. When prompted, look for an option to enter your authorization code or license key. This is usually during the installation process or when you first launch the software.\n3. Enter the authorization code exactly as provided to you.\n\nIf you encounter any issues during this process, or if you do not see the option to enter the code, please contact the vendor from whom you purchased the Grad Pack for further assistance. You can reach out to vendors like Hearne, On the Hub, or JourneyEd for support.",
    "id": "TECHQA_TRAIN_Q331_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q334",
    "question": "Datetime export to FileNet\nHi there\n\n \n\nI created an application in Datacap that export to FileNet a Datetime field. In FEM I have a property type of Datetime. I'm using the following to send value to FileNet:\n\nFNP8_SetProperty (\"DataEmissao,@DATE(dd/MM/yyyy)+@STRING( )+@TIME(HH:MM),Datetime\")\n\n \n\nThe export works fine, but if I check the Datetime property in FEM I can see that the TIME was stored wrong, exactly 3 hours less.\n\ne.g:\n\nCurrent Datetime is: 19/08/2013 18:10\n\nValue stored in FEM: 19/08/2013 15:10\n\n \n\nCan someone help me? What I'm doing wrong?\n\n \n\nThank's",
    "ground_truth": "1. Modify the date/time value into proper GMT/UTC format of **YYYY-MM-DDTHH:MM[:SS]**\n\n2. Add a time offset to account for the GMT time difference, e.g. YYYY-MM-DDTHH:MM:SS-HH:MM",
    "answer": "To resolve the issue of the incorrect time being stored in FileNet, you need to ensure that the datetime value is properly formatted to UTC before exporting it. Here’s how you can do that:\n\n1. **Convert the Local Time to UTC**: Use the `IsFieldDateWithReformat(s)` action to convert your local datetime to UTC format. This will ensure that the time is correctly adjusted.\n\n2. **Format the Datetime**: After converting to UTC, format the datetime in the required format `YYYY-MM-DDTHH:MM:SS` and append the appropriate GMT offset. For example, if you are in a timezone that is UTC-3, you would append `-03:00`.\n\n3. **Update Your Export Code**: Modify your export code to include these steps. Here’s an example of how you can structure it:\n\n   ```plaintext\n   IsFieldDateWithReformat(s) // Converts to UTC\n   rrSet(@F+-03:00,@F) // Appends the GMT offset\n   FNP8_SetProperty(\"DataEmissao,@F\", \"Datetime\")\n   ```\n\nThis will ensure that the datetime value is correctly stored in FileNet with the appropriate time adjustment. Make sure to replace `-03:00` with your actual timezone offset if it differs. \n\nBy following these steps, the datetime should be stored correctly without the 3-hour discrepancy.",
    "id": "TECHQA_TRAIN_Q334_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q336",
    "question": "Why does silent install abort indicating files are locked?\nSilent installs can fail reporting that there are locked files under the ITM installation directory on Windows platform. Why does this happen?\n\nExample:\n\nC:\\IBM\\ITM\\InstallITM\\\nAbort IBM Tivoli Monitoring 20160203 1832.log\n\n02-03-2016 18:37:10: File C:\\IBM\\ITM\\TMAITM6\\deploy.jar is locked.\n02-03-2016 18:37:10: File C:\\IBM\\ITM\\TMAITM6\\deploy.jar could not be renamed, errors may occur.\n02-03-2016 18:37:17: Directory C:\\IBM\\ITM has locked files.\n02-03-2016 18:37:17: Correct and launch setup again.\n02-03-2016 18:37:17: Directory C:\\IBM\\ITM has locked files, unable to continue.\n02-03-2016 18:37:17: SEVERE: ERROR - Install aborted.",
    "ground_truth": "1. Shut down all components before performing any product upgrade.\n   Ensure that all components, including **monitoring servers**, portal server, and portal clients, are shut down before proceeding with the product upgrade.",
    "answer": "Silent installations of the IBM Tivoli Monitoring (ITM) can abort due to locked files in the installation directory because the installer is preventing the overwriting of files that are currently in use. To resolve this issue, follow these steps:\n\n1. **Check Installation Log**: Locate the installation log file in the `<ITMHOME>\\InstallITM` directory, named like `AbortIBMTivoliMonitoring<DATE TIME>.log`. Search for instances of the `CheckLockedFiles` string within this log to identify which files are locked.\n\n2. **Identify and Stop Processes**: Use Task Manager or a similar tool to identify the processes that are locking the files listed in the log. Stop these processes to unlock the files.\n\n3. **Modify Response File**: \n   - Open the silent installation response file (often named `silent.txt` or `NT_Silent_Install.txt` on Windows).\n   - Add the following line to the `[INSTALLATION SECTION]`:\n     ```\n     Locked Files=continue\n     ```\n   - This allows the silent installation to proceed even if files are locked. Note that if you assign any other value, the installation may fail.\n\n4. **Reboot the System**: After making the modification, reboot the computer before attempting to run the installation again. This step ensures that any potential issues with the directory structure are cleared and prevents possible corruption.\n\nBy completing these steps, you should be able to successfully perform a silent installation without encountering locked file errors.",
    "id": "TECHQA_TRAIN_Q336_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q337",
    "question": "Why does the other instance of my multi-instance qmgr seem to hang after a failover?\nQueue manager will not start after failover.",
    "ground_truth": "1. Rename the file **amqalchk.fil**, which is found under **mq\\qmgrs\\qmgrname\\** on the shared drive (to something like amqalchk.fil_OLD).\n2. Restart the **queue manager**.\n   ",
    "answer": "The issue you're experiencing with your multi-instance queue manager hanging after a failover is likely due to a logger failure caused by missing or damaged logs. To resolve this, follow these steps:\n\n1. Navigate to the shared drive where your queue manager files are located.\n2. Locate the file named `amqalchk.fil` in the directory `mq\\qmgrs\\qmgrname\\`.\n3. Rename the file to something like `amqalchk.fil_OLD`.\n4. Attempt to restart the queue manager.\n\nThis should help resolve the issue and allow the queue manager to start successfully on the secondary node. If the problem persists, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q337_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q338",
    "question": "VScan not working after migrating Datacap Application from 8.1 to 9.0.1\nI have recently migrated one datacap application developed in Datacap 8.1 to Datacap 9.0.1. I followed the complete instruction provided in the link \n\nhttp://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.develop.doc/dcadv001.htm\n\n \n\nAfter migration, when I tried to execute the application using Datacap Desktop. I got errors that \"This batch has no data to process. Aborting\" and \"Unable to run queue\". I am attaching the screenshots of error. I am also attaching the DStudio rule's screenshot.\n\nI have verified and configured all the required settings.\n\nPlease guide if someone has faced the similar issue and resolved it.",
    "ground_truth": "1. Ensure the DCO name matches as it appears in **Datacap Studio**.\n   Check the DCO name for both correct spelling and **case-sensitivity**.",
    "answer": "It seems that the issue you're facing with VScan after migrating your Datacap application from 8.1 to 9.0.1 may be related to case sensitivity in the DCO names. Here’s a step-by-step guide to resolve the problem:\n\n1. **Log in to the TMWeb client.**\n2. **Navigate to the Administrator tab.**\n3. **Select the VScan task from the Workflow.**\n4. **Click on Setup under Program.**\n5. **Check the value of the Panel.** Ensure that it matches exactly (including case) with what is defined in Datacap Studio. For example, if the DCO name in Datacap Studio is \"TravelDocs\", make sure the Panel value is also \"TravelDocs\" and not \"TRAVELDOCS\".\n6. **Make any necessary changes to the Panel value.**\n7. **Click Save to apply the changes.**\n\nAfter making these adjustments, try executing the application again in Datacap Desktop. This should resolve the errors you are encountering. If the problem persists, please provide additional details or screenshots for further assistance.",
    "id": "TECHQA_TRAIN_Q338_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q339",
    "question": "Why I get pop-up message of \"undefined\" when accessing TCR 3.1.2.1 in IE 11?\nWhen I access Tivoli Common Reporting -> Launch -> Administration, will get repeated message window with content of \"underfined\". This happened only with IE11 and TCR 3.1.2.1",
    "ground_truth": "1. Access the Tivoli Common Reporting dispatcher link.\n   Navigate to the following URL: **https://JazzSM_hostname:port/tarf/servlet/dispatch**",
    "answer": "To resolve the issue of receiving a pop-up message of \"undefined\" when accessing Tivoli Common Reporting (TCR) 3.1.2.1 in Internet Explorer 11, you should use the Tivoli Common Reporting dispatcher link directly. \n\nFollow these steps:\n\n1. Open Internet Explorer 11.\n2. Enter the following URL in the address bar, replacing `JazzSM_hostname` and `port` with your specific server's hostname and port number:\n   ```\n   https://JazzSM_hostname:port/tarf/servlet/dispatch\n   ```\n   For example, if your hostname is `JazzSM` and the port is `16311`, the URL would be:\n   ```\n   https://JazzSM:16311/tarf/servlet/dispatch\n   ```\n\n3. Press Enter to access the dispatcher link.\n\nThis should help you bypass the compatibility issues and access the TCR functionalities without encountering the \"undefined\" pop-up message.",
    "id": "TECHQA_TRAIN_Q339_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q340",
    "question": "Why is an error seen while running run-svrssl-config?\nFollowing error is seen while running run-svrssl-config ConfigEngine task:\n\n     action-run-pdjrte-config-zos-wp.ac.impl: \n     [validateHost] Validating hostname(s) in the following argument: tam001:7136:1,tam002:7136:2\n          [echo] Command to run is: java com.tivoli.pd.jcfg.SvrSslCfg -action config -admin_id sec_master -admin_pwd ****** -appsvr_id myAppSvr -port 7223 -mode remote -policysvr\n     tam001:7135:1,tam002:7135:2 -authzsvr tam001:7136:1,tam002:7136:2 -cfg_file /opt/WebSphere/AppServer/tivoli/tam/PdPerm.properties -key_file /opt/WebSphere/AppServer/tivoli/tam/pdperm.ks\n          [java] Executing java with empty input string\n          [java] Exception in thread \"main\"\n          [java] [\n          [java] HPDMG0759W The user name already exists in the registry.\n          [java] ]\n          [java] at com.tivoli.pd.jutil.ob.a(ob.java:40)\n          [java] at com.tivoli.pd.jutil.ob.a(ob.java:66)",
    "ground_truth": "1. Use a unique value for **wp.ac.impl.PDServerName**",
    "answer": "The error you are encountering, \"HPDMG0759W The user name already exists in the registry,\" indicates that the app server ID you are using is already registered in the Tivoli Access Manager's repository. To resolve this issue, you can take one of the following actions:\n\n1. **Use a Unique App Server ID**: Modify the `wp.ac.impl.PDServerName` parameter in the `wkplc_comp.properties` file to a unique value that has not been used before. This will prevent the conflict with the existing user name.\n\n2. **Remove the Existing App Server ID**: If you prefer to keep the current app server ID, you can manually remove it from the Tivoli Access Manager's repository by running the following command in a command prompt on the portal server:\n\n   ```bash\n   java com.tivoli.pd.jcfg.SvrSslCfg -action unconfig -admin_id sec_master -admin_pwd ****** -appsvr_id myAppSvr -port 7223 -mode remote -policysvr tam001:7135:1 -authzsvr tam002:7136:2 -cfg_file /opt/WebSphere/AppServer/tivoli/tam/PdPerm.properties -key_file /opt/WebSphere/AppServer/tivoli/tam/pdperm.ks\n   ```\n\nMake sure to replace `myAppSvr` with the actual app server ID you are using, and ensure that the paths and parameters are correct for your environment.\n\nAfter performing one of these steps, try running the `run-svrssl-config` task again.",
    "id": "TECHQA_TRAIN_Q340_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q341",
    "question": "How to check IBM Java ORB build version in WebSphere Application Server?\nJust a simple question: How to check IBM Java ORB build version in WebSphere Application Server?",
    "ground_truth": "1. Run command: **<washome>/java/bin/java -Xbootclasspath/p:<washome>/java/jre/lib/ext/ibmorb.jar com.ibm.rmi.util.Version**",
    "answer": "To check the IBM Java ORB build version in WebSphere Application Server, you can use the following command:\n\n```bash\n<washome>/java/bin/java -Xbootclasspath/p:<washome>/java/jre/lib/ext/ibmorb.jar com.ibm.rmi.util.Version\n```\n\nMake sure to replace `<washome>` with the actual path to your WebSphere installation. This command will display the version information for the IBM Java ORB.",
    "id": "TECHQA_TRAIN_Q341_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q348",
    "question": "Why does DSM error log have errors for SQLCODE=-206 errors reported for ISAS core warehouse database?\nDSM error log have errors for SQLCODE=-206 errors reported for ISAS core warehouse database. How do Isolve the problem?",
    "ground_truth": "1. Run the **db2updvnn** command according to the db2level of your monitored database",
    "answer": "The SQLCODE=-206 error in the DSM error log indicates that there is an issue with the database system catalog not being updated after applying a new DB2 fixpack. This can lead to the database using outdated routines, which results in the error.\n\nTo resolve this issue, follow these steps:\n\n1. **Check the Current Version**: Run the following command on your monitored database to check the version number:\n   ```\n   db2 \"select versionnumber from sysibm.sysversions order by 1 desc\"\n   ```\n   Ensure that the version number matches the DB2 level supported by DSM.\n\n2. **Update the Database**: If the version number is lower than expected, you need to update the database system catalog. Use the appropriate `db2updvnn` command based on your DB2 version:\n   - For DB2 V9.7: `db2updv97`\n   - For DB2 V10.1: `db2updv10`\n   - For DB2 V10.5: `db2updv105`\n   - For DB2 V11.1: `db2updv111`\n\n   You can find more details on how to run these commands in the IBM documentation linked in the context.\n\n3. **Verify the Update**: After running the update command, check the version again using the first command to ensure it reflects the correct level.\n\n4. **Restart DSM**: Once the database is updated, restart the IBM Data Server Manager to see if the errors persist.\n\nBy following these steps, you should be able to resolve the SQLCODE=-206 errors in your DSM error log.",
    "id": "TECHQA_TRAIN_Q348_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q350",
    "question": "Missing option to fill in attributes when trying to deploy a pattern\nI tried to deploy a pattern and I have some parameters to modify at deployment time. But I can't see my parts/attributes in the Component Attribute List.",
    "ground_truth": "1. Lock any one of the attributes, such as the **name** attribute.\n   This action causes the other component attributes to be displayed for configuration.",
    "answer": "To resolve the issue of missing options to fill in attributes when deploying a pattern, you need to lock at least one attribute of the component that has a data dependency. For example, you can lock the name attribute. Once you do this, the other component attributes should become visible and available for configuration during the pattern deployment.",
    "id": "TECHQA_TRAIN_Q350_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q353",
    "question": "CQWEB  can\\'t retrieve repository dropdown list options in RedHat Linux, how to deal with it ?\nI setup a cq demo env in redhat linux with oracle database, CQ 7.1.2, LRKS 8.1.3,  Linux CQ client can login CQ as the following picture 1, but CQWEB login page can't retrieve the repository dropdown list options as the following picture 2.  I used cqreg to register CQ database:\n\ncqreg add_dbset -v ORACLE -s 192.168.0.84 -d ESBDB -u cqadmin -p cqadmin -dbset CQ_DEMO_ORACLE -co LOB_TYPE=CLOB -force\n\n How do I deal with it?",
    "ground_truth": "1. Run **cqreg initialize**.\n2. Run the command as the root user if the same error persists.\n3. Ensure the **CQ_DATABASES** environment variable is set to the desired registry path.\n4. Set the variable accordingly if it is not set correctly.\n5. Run the previously mentioned commands again.",
    "answer": "To resolve the issue with CQWEB not retrieving the repository dropdown list options, you'll need to ensure that the ClearQuest database registry is correctly initialized. Follow these steps:\n\n1. **Run the Initialization Command**: Execute the following command to initialize the registry:\n\n   ```bash\n   cqreg initialize\n   ```\n\n   Ensure that you run this command as the root user to avoid permission issues.\n\n2. **Check the Registry Path**: Verify that the directory for the registry exists. The default path is typically:\n\n   ```\n   /opt/rational/clearquest/CQDB_rgys/cqdb_registry/\n   ```\n\n   If this directory does not exist, the initialization may not have completed successfully.\n\n3. **Set the Environment Variable**: Make sure that the `CQ_DATABASES` environment variable is set to the desired registry path:\n\n   ```bash\n   export CQ_DATABASES=/opt/rational/clearquest/CQDB_rgys/cqdb_registry/\n   ```\n\n4. **Re-Run the Database Set Command**: After initializing and ensuring the environment variable is set, you can try running your database set command again:\n\n   ```bash\n   cqreg add_dbset -v ORACLE -s 192.168.0.84 -d ESBDB -u cqadmin -p cqadmin -dbset CQ_DEMO_ORACLE -co LOB_TYPE=CLOB -force\n   ```\n\n5. **Check Logs for Errors**: If the problem persists, check the relevant logs for any errors that may provide additional insight into what is failing.\n\nIf you follow these steps and still face issues, consider looking for specific error messages in the logs or configurations that may need adjustment.",
    "id": "TECHQA_TRAIN_Q353_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q358",
    "question": "Cannot create syndication pair between Virtual Portals with a different user repository than Base Portal\nSteps:\r\nI have two different user repositories one to manage my base portal and Virtual Portals. (p.e: For Base Portal I use ITDS, and for VPs I use AD) with differents admin users each.\r\nThen I created two VPs using the AD repository, and my VPs admin user on the credential vault.\r\nTried to create a syndication relationship , that is failing with the error:\r\n\"Could not communicate with the target URL. Please check that the Syndicator URL details are entered correctly, and that the credential slot user exists on the target server.\"",
    "ground_truth": "1. Make the **Admin** user visible on both base and virtual Portals",
    "answer": "To resolve the issue of not being able to create a syndication pair between your Base Portal and Virtual Portals with different user repositories, follow these steps:\n\n1. **Ensure Admin User Visibility**: The administrator user that you are using for syndication must be visible and have access to both the Base Portal and the Virtual Portals. This means that the admin user should exist in both user repositories (ITDS for Base Portal and AD for Virtual Portals).\n\n2. **Check User Credentials**: Verify that the credentials for the admin user are correctly configured in the credential vault for both the Base Portal and the Virtual Portals.\n\n3. **Access Rights**: Make sure that the admin user has the necessary permissions to perform syndication tasks on both portals. This includes checking the roles and access rights assigned to the user in both realms.\n\n4. **Syndicator URL**: Double-check the Syndicator URL details to ensure they are entered correctly. This includes verifying the format and ensuring that the URL is reachable from the server where the Base Portal is hosted.\n\n5. **Test Connectivity**: If possible, test the connectivity to the target URL from the Base Portal server to ensure there are no network issues preventing communication.\n\nBy ensuring that the admin user is properly configured and has access to both portals, you should be able to successfully create the syndication relationship. If the problem persists, consider reviewing the logs for any additional error messages that may provide further insight.",
    "id": "TECHQA_TRAIN_Q358_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q360",
    "question": "Is it possible to monitor Memory/LPAR metrics using ITM HMC agent?\nI understand the ITM AIX Premium agent captures these metrics but like to know if it is possible to monitor Memory/LPAR metrics using ITM HMC agent?",
    "ground_truth": "1. Use the Query Editor and select Server **LPARs_V9** under **KPH SERVER LPARS**.",
    "answer": "Yes, it is possible to monitor Memory/LPAR metrics using the ITM HMC agent. The HMC Base Agent includes new attributes for LPAR memory metrics, specifically:\n\n- **Current_Memory**: The current amount of memory configured for the LPAR.\n- **Running_Memory**: The amount of memory varied on-line by the LPAR.\n\nTo display these metrics in the Tivoli Enterprise Portal, you can use the Query Editor and select **Server LPARs_V9** under **KPH SERVER LPARS**. This will allow you to monitor the memory metrics effectively.",
    "id": "TECHQA_TRAIN_Q360_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q366",
    "question": "How do to restore corrupted Object server DB using data from Backup Object server in Linux?\nError: E-REG-002-025: Region 'table_store', from directory '/opt/IBM/tivoli/netcool/omnibus/db/NCOMS/', has been recovered in a corrupt state: Extent statistics mismatch Error: E-OBX-102-020: Failed to start the storage system. (-490:Extent statistics mismatch)",
    "ground_truth": "1. Create a temporary directory using the command **mkdir /tmp/backup**\n2. Use nco_sql to obtain a backup\n   Execute **./nco_sql -server NCOMS**, enter the password when prompted, and then run the commands 'alter system backup '/tmp/backup';' followed by 'go'. After that, type 'quit' to exit the nco_sql.\n3. Verify that /tmp/backup contains *.tab files.\n   \n4. Compressed /tmp/backup\n   \n5. Copy of **ObjectServers** properties file (i.e. NCOMS.props)\n   \n6. If you can provide the root password, do so.\n   ",
    "answer": "To restore a corrupted ObjectServer database using data from a backup on Linux, follow these steps:\n\n1. **Stop the ObjectServer**: Ensure that the ObjectServer is not running to prevent any conflicts during the restoration process.\n\n2. **Create a temporary directory**: \n   ```bash\n   mkdir /tmp/restore\n   ```\n\n3. **Copy the backup files**: Move the backup files (e.g., *.tab files) from your backup location to the temporary restore directory. If your backup is in `/tmp/backup`, you can use:\n   ```bash\n   cp /tmp/backup/*.tab /tmp/restore/\n   ```\n\n4. **Restore the database**: Use the `nco_sql` command to restore the database from the backup files. Run the following command:\n   ```bash\n   ./nco_sql -server NCOMS\n   Password: \n   1> alter system restore '/tmp/restore';\n   2> go\n   (0 rows affected)\n   1> quit\n   ```\n\n5. **Verify the restoration**: Check the logs to ensure that the restoration was successful and that there are no errors.\n\n6. **Start the ObjectServer**: Once the restoration is complete and verified, start the ObjectServer again.\n\n7. **Check for errors**: After starting, monitor the logs for any errors to ensure that the ObjectServer is functioning correctly.\n\nIf you encounter any issues during these steps, please refer to the specific error messages for further troubleshooting.",
    "id": "TECHQA_TRAIN_Q366_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q367",
    "question": "1040ez 9.0 Application\nHi\n\nI have downloaded sample Datacap 9 applications (1040ez, Express, Survey) using below link and copied in my local system C:\\Datacap and added reference in Datacap.xml file.\n\nIBM Datacap 9.0 and IBM Datacap 9.0.1 DDK sample applications\n\nBut i'm unable to login Datacap Studio & Tmweb.net . (I tried to with re generating encryption keys but no luck).\n\nCan anyone let me know the reason, anything I missed in configuration ?\n\nMy Datacap version in Local Machine\n\nIBM Datacap 9.0.0.3\n\nBuild: v 9.0.0.72\n\nThanks",
    "ground_truth": "1. If this is a new server where **Datacap** has never been run and encryption has not been set up at all, follow the instructions at Exporting encryption keys\n\n2. If this is an existing server or a new server where the previous steps have been completed, distribute the **dc_ktf.xml** file to the client folder for all clients that will be used following the instructions at Importing encryption keys to **Datacap** computers",
    "answer": "It seems that you are encountering a login issue with IBM Datacap Studio and Tmweb.net due to potential problems with encryption key setup. Here are the steps you can take to resolve this issue:\n\n1. **Check Encryption Key Setup**: Since you mentioned that you tried regenerating encryption keys, ensure that the encryption keys are properly set up. If this is a new installation, follow the instructions for exporting encryption keys from the IBM documentation. You can find the relevant instructions here: [Exporting encryption keys](http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain011_copyto_cs1.htm).\n\n2. **Distribute the dc_ktf.xml File**: If you have already set up encryption keys previously, make sure that the `dc_ktf.xml` file is distributed to the client folder for all clients that will be used. Follow the instructions for importing encryption keys: [Importing encryption keys to Datacap computers](http://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.install.doc/dcain010_copyto_wtminstall1.htm).\n\n3. **Verify Database Connection**: Ensure that the Taskmaster Server can connect to the admin database. Check the database connection settings in your configuration files.\n\n4. **Check Logs for Errors**: Review the Taskmaster Server (tms) logs for any additional error messages that might provide more context on the issue.\n\nBy following these steps, you should be able to resolve the login issue. If the problem persists, consider reaching out to IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q367_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q368",
    "question": "Does ITCAM for MQ monitoring agent (kmq) use SYSTEM.MQXR.COMMAND.QUEUE causing Unknown Object Name [2085] event?\nUsing the ITCAM MQ Monitoring agent, we have a situation that generates alerts when a 2085 event (object unknown) occurs. We have recently seen alerts for the queue SYSTEM.MQXR.COMMAND.QUEUE\nWe found following technote:\nUnknown Object Name [2085], SYSTEM.MQXR.COMMAND.QUEUE\nhttp://www-01.ibm.com/support/docview.wss?uid=swg21681687\n\nThis technote does not mention Tivoli monitoring product, and only mentions monitoring products such as Nastel and InfraRed360.\nDoes Tivoli monitoring agent for WebSphere MQ use the SYSTEM.MQXR.COMMAND.QUEUE? We are try to find out which application is causing the 2085 event.",
    "ground_truth": "1. Use the runmqsc display connection command to find the process id (PID) and application name.\n   \n2. Invoke the command under runmqsc.\n   Using the above example of the queue Q1, the complete command is: **display conn(*) where(objname eq Q1) all**.",
    "answer": "The ITCAM for MQ monitoring agent (kmq) does not specifically mention the use of the SYSTEM.MQXR.COMMAND.QUEUE in the context of generating the Unknown Object Name [2085] event. The alerts you are seeing for the 2085 event related to this queue may be due to an application attempting to access a queue that does not exist or is not available.\n\nTo identify which application is causing the 2085 event, you can use the `runmqsc` command to check for any connections to the queue manager. Specifically, you can run the following command to display all connections and their associated application names:\n\n```bash\ndisplay conn(*) where(objname eq SYSTEM.MQXR.COMMAND.QUEUE) all\n```\n\nThis command will provide you with details about any applications that are currently connected to the SYSTEM.MQXR.COMMAND.QUEUE, including the process ID (PID) and application name (APPLTAG). \n\nIf you find an application that is trying to access the queue, you can further investigate that application to determine why it is generating the 2085 event. If no connections are found, it may indicate that the application is attempting to access the queue incorrectly or that the queue does not exist.\n\nIf you need further assistance, please provide additional details about your setup or any specific error messages you are encountering.",
    "id": "TECHQA_TRAIN_Q368_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q372",
    "question": "How to fix error CRIMA1217E when upgrade JAZZ from 1.1.0 to 1.1.3 failed?\nHow to fix problem when upgrade JAZZ from 1.1.0 to 1.1.3 failed?",
    "ground_truth": "1. Use the attached script to initiate the upgrade.\n   This script is necessary to give the **non-root** user (who originally installed this Jazz for Service Management instance) the correct permissions for the upgrade process. Usage: **./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\"**",
    "answer": "To fix the error CRIMA1217E when upgrading Jazz from version 1.1.0 to 1.1.3, follow these steps:\n\n1. **Check Permissions**: Ensure that the non-root user who installed Jazz for Service Management has the correct permissions to run the upgrade script.\n\n2. **Use the Upgrade Script**: Initiate the upgrade using the provided script `JazzSMgrpModeUpgrade.sh`. This script will set the necessary permissions for the upgrade process.\n\n3. **Run the Script**: Execute the script with the required arguments. The command format is as follows:\n\n   ```bash\n   ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location\" \"[Response_file_with_absolute_Path]\"\n   ```\n\n   For example, if you are using default installation paths, the command would look like this:\n\n   ```bash\n   ./JazzSMgrpModeUpgrade.sh \"/home/root/IBM/InstallManager/\" \"/opt/IBM/JazzSM/\" \"/opt/Download/dash_upgrade_rsp.xml\"\n   ```\n\n4. **For GUI Mode**: If you prefer to use the GUI for the installation, run the script with just the first two mandatory arguments:\n\n   ```bash\n   ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location\"\n   ```\n\n5. **Follow Prompts**: If using GUI mode, follow the prompts to complete the upgrade process.\n\nBy following these steps, you should be able to resolve the upgrade issue and successfully upgrade Jazz to version 1.1.3.",
    "id": "TECHQA_TRAIN_Q372_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q373",
    "question": "RecognizePageFieldsICR_C aborts with Page Type change\nI have an DeveloperWorks application that runs: Survey.  In the application PageID Task there is a function that sets the Page Type to ReliefForm (based on a barcode)\n\nDoes anyone know why when I change the SetPageType to set another name, the RecognizePageFieldsICR_C in the Profiler Task aborts?  If I put the name back the action runs fine.",
    "ground_truth": "1. Set the c_cr variable to USA prior to the call to recognition.\nUse the command **SaveAsCurrentObjVariable(\"c_cr\", \"USA\")** to set the variable.",
    "answer": "The issue you're experiencing with the `RecognizePageFieldsICR_C` aborting when you change the Page Type likely stems from the ICR engine not recognizing the new Page Type you set. When you change the Page Type, the corresponding configuration for ICR recognition may not be properly defined or set up for that new type.\n\nTo resolve this issue, follow these steps:\n\n1. **Check ICR Configuration**: Ensure that the new Page Type you are trying to set has the necessary ICR configurations defined in your Datacap application. This includes ensuring that the fields expected for recognition are properly defined for that Page Type.\n\n2. **Set the c_cr Variable**: Before calling the `RecognizePageFieldsICR_C`, make sure to set the `c_cr` variable appropriately. For example, if you are working with US documents, you can set it as follows:\n   ```plaintext\n   SaveAsCurrentObjVariable(\"c_cr\", \"USA\")\n   ```\n\n3. **Test with Default Page Type**: If the new Page Type continues to cause issues, revert to the original Page Type that works and verify that all configurations are correct. Then, incrementally change settings to identify what specifically causes the abort.\n\n4. **Review Logs**: Check the log files for any additional error messages or warnings that may provide more context on why the recognition fails with the new Page Type.\n\nIf you follow these steps and the issue persists, you may need to consult the Datacap documentation or reach out to IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q373_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q380",
    "question": "How do I view Custodian Notes in Atlas Preservation Plan?\nHow do I view Custodian Notes in Atlas Preservation Plan?",
    "ground_truth": "1. Click the **Show Custodian Notes** button.",
    "answer": "To view Custodian Notes in the Atlas Preservation Plan, follow these steps:\n\n1. Open the Preservation Plan and click on the \"Notes\" tab.\n2. If you see a blank page, look for the \"Show Custodian Notes\" button and click it. This will display the custodian notes.\n3. If you want to return to viewing the Plan Notes, simply click the \"Show Plan Notes\" button.\n\nThis will allow you to toggle between the Custodian Notes and the Plan Notes as needed.",
    "id": "TECHQA_TRAIN_Q380_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q382",
    "question": "Where to download SPSS Statistics 24.0 Fix Pack 2\nI found the pack from following link: https://www-01.ibm.com/support/docview.wss?uid=swg24043574\n\nBut where should I download it?",
    "ground_truth": "1. Log in as a local administrator.\n2. Download the Fix Pack to a temporary location on your hard drive.\n3. Ensure that no versions of Statistics are running.\n4. Run the Statistics **24.0.0.2** Fix Pack executable.\n   Remember to use **Run as Administrator** by first right-clicking on the executable file.\n5. Statistics 24.0.0.2 is ready to run.\n   Navigate to the Help -> About menu to confirm that version 24.0.0.2 is the installed version.",
    "answer": "To download SPSS Statistics 24.0 Fix Pack 2, you can use the following link for the appropriate version based on your platform:\n\n- For **Windows 64-bit**: [Download Windows 64-bit Fix Pack 2](https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATC-WIN64-FP002&includeRequisites=1&includeSupersedes=0&downloadM)\n\n- For **Windows 32-bit**: [Download Windows 32-bit Fix Pack 2](https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATC-WIN32-FP002&includeRequisites=1&includeSupersedes=0&downloadM)\n\n- For **Mac**: [Download Mac Fix Pack 2](https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATC-Mac-FP002&includeRequisites=1&includeSupersedes=0&downloadM)\n\n- For **Linux 64-bit**: [Download Linux 64-bit Fix Pack 2](https://www-945.ibm.com/support/fixcentral/swg/downloadFixes?parent=SPSS&product=ibm/Information+Management/SPSS+Statistics&release=24.0.0.1&platform=All&function=fixId&fixids=24.0-IM-S24STATC-Linux8664-FP002&includeRequisites=1&includeSupersedes=0&downl)\n\nMake sure to log in as a local administrator and follow the installation instructions provided in the context.",
    "id": "TECHQA_TRAIN_Q382_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q384",
    "question": "Where do I find list of all document formats indexable and supported by ICC Content Search Services Support (CSSS)?\nWhere do I find list of all document formats indexable and supported by ICC Content Search Services Support (CSSS)?",
    "ground_truth": "1. Visit the following link to determine which document types are supported by CSS/Outside In: **http://www-01.ibm.com/support/knowledgecenter/SSNW2F_5.2.1/com.ibm.p8.ce.admin.tasks.doc/cbr/csscbr_indexable_documenttype.htm?lang=en**",
    "answer": "To find the list of all document formats indexable and supported by ICC Content Search Services Support (CSSS), you can refer to the following link: \n\n[IBM Content Collector Indexable Document Types](http://www-01.ibm.com/support/knowledgecenter/SSNW2F_5.2.1/com.ibm.p8.ce.admin.tasks.doc/cbr/csscbr_indexable_documenttype.htm?lang=en)\n\nThis page provides detailed information on the document types supported by CSS/Outside In technology.",
    "id": "TECHQA_TRAIN_Q384_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q388",
    "question": "How to set database specific custom properties in WebSphere Application Server?\nI am using Websphere Application Server (WAS) v8.5.x with Oracle 11.1 JDBC drivers and I want to set some oracle specific properties, when connecting to the database in Websphere Application Server. (specifically: defaultRowPrefetch). How to set such specific properties in Websphere Application Server?",
    "ground_truth": "1. Load the property into a **Properties** object.\n2. Call **getConnection** with the **Properties** object.",
    "answer": "To set the `defaultRowPrefetch` property for your Oracle JDBC connections in WebSphere Application Server (WAS) v8.5.x, you cannot set it as a custom property in the datasource. Instead, you need to configure it programmatically. Here’s how to do it:\n\n1. **Create a Properties Object**: In your Java code, create a `Properties` object to hold the connection properties.\n\n   ```java\n   Properties props = new Properties();\n   props.setProperty(\"oracle.jdbc.defaultRowPrefetch\", \"your_value_here\"); // Set your desired value\n   ```\n\n2. **Get Connection with Properties**: Use the `getConnection` method of your `DataSource` to obtain a connection, passing the `Properties` object.\n\n   ```java\n   Connection conn = dataSource.getConnection(props);\n   ```\n\nBy following these steps, you can set the `defaultRowPrefetch` property effectively for your Oracle database connections in WebSphere Application Server.",
    "id": "TECHQA_TRAIN_Q388_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q389",
    "question": "What are the supported Macintosh Operating System versions for IBM SPSS Statistics 19, 20, 21, 22 and 23?\nI would like to know what are the supported Macintosh Operating system versions for IBM SPSS Statistics versions 18, 19, 20, 21, 22 and 23?",
    "ground_truth": "1. Visit the following URL to access the IBM Software Product Compatibility Reports: **http://publib.boulder.ibm.com/infocenter/prodguid/v1r0/clarity/index.jsp**.",
    "answer": "The supported Macintosh Operating System versions for IBM SPSS Statistics are as follows:\n\n- **SPSS Statistics 18, 19, and 20**: These versions are no longer supported by IBM, and specific OS compatibility information is not provided in the context.\n\n- **SPSS Statistics 21**: \n  - Supported on:\n    - Mac OS X Lion (10.7)\n    - Mac OS X Snow Leopard (10.6)\n    - Mac OS X Mountain Lion (10.8)\n\n- **SPSS Statistics 22**: \n  - Supported on:\n    - Mac OS X Yosemite (10.10) (with FixPack 2)\n    - Mac OS X El Capitan (10.11)\n    - Mac OS X Mountain Lion (10.8)\n    - Mac OS X Lion (10.7)\n    - Mac OS X Snow Leopard (10.6)\n\n- **SPSS Statistics 23**: \n  - Supported on:\n    - Mac OS X Yosemite (10.10)\n    - Mac OS X El Capitan (10.11)\n    - Mac OS X Mavericks (10.9) (with Java SE 6 installed)\n\nFor the most accurate and detailed compatibility information, it is recommended to check the IBM Software Product Compatibility Reports.",
    "id": "TECHQA_TRAIN_Q389_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q390",
    "question": "Netcool/Impact (all versions): DataType incorrect on Secondary\nThe DataType is not being correctly replicated across the ImpactServer Cluster. The .type file of the Secondary ImpactServer configuration is truncated with the error message:\n\nError 500: Mark invalid",
    "ground_truth": "1. Add the property to **$NCHOME/impact/etc/<SERVERNAME>_server.props** file\n   The property must be added to the specified server properties file where the size limit can be set to values such as 8192, 16384, 32768, etc.\n2. Restart the ImpactServer to enable the new property\n3. Ensure the ImpactServer started as **Primary** has the correct, uncorrupted **.type** file\n4. Ensure there are no trailing white-space characters on the property\n   Make sure that there are no trailing white-space characters in the property being added, as these can invalidate properties in lower versions of Impact.",
    "answer": "To resolve the issue of the DataType not being correctly replicated across the ImpactServer Cluster, follow these steps:\n\n1. **Identify the Server Properties File**: Locate the server properties file for each ImpactServer in your cluster. The file is typically found at `$NCHOME/impact/etc/<SERVERNAME>_server.props`.\n\n2. **Add the Property**: Open the properties file for each ImpactServer and add the following property to increase the file size limit for USERPARAMETERS:\n   ```\n   userparameters.size.limit=32768\n   ```\n   (You can adjust the size limit as needed, e.g., 8192, 16384, or 32768.)\n\n3. **Check for Trailing Whitespace**: Ensure there are no trailing whitespace characters on the property line, as these can invalidate properties in lower versions of Impact.\n\n4. **Restart the ImpactServers**: After adding the property, restart all ImpactServers in the cluster. Make sure that the ImpactServer that starts as Primary has the correct, uncorrupted .type file to ensure proper replication.\n\n5. **Verify Replication**: After the servers have restarted, check if the DataType is now correctly replicated across the cluster.\n\nBy following these steps, you should be able to resolve the replication issue. If the problem persists, further investigation may be required.",
    "id": "TECHQA_TRAIN_Q390_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q391",
    "question": "Can an update query be run against the C&DS repository to update job results?\nWe have jobs set up in SPSS Deployment Manager. We would like to do a mass change of the location set up on the location set on the location tab.",
    "ground_truth": "1. Work with your **IT administrator** to clean up your file system.\n2. Point your file system to a new location or manually update all of your jobs.",
    "answer": "No, an update query cannot be run against the C&DS repository to perform a mass change of job results in SPSS Deployment Manager. The job data is stored as metadata, and there is no batch process available for this purpose. It is recommended to work with your IT administrator to either clean up your file system, point it to a new location, or manually update each job's location settings.",
    "id": "TECHQA_TRAIN_Q391_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q393",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?",
    "ground_truth": "1. In Content Navigator v2.0.2, set the value of the parameter 'scale' as follows.\n   In the **..navigator.war/applets/filenetViewer_properties.jsp** file, set the parameter 'scale' to **scale: \"ftow\"** to fit content by width or **scale: \"ftoh\"** to fit content by height.",
    "answer": "To change the default 'fit content by' behavior of the Daeja viewer in IBM Content Navigator, follow these steps based on your version:\n\n**For Content Navigator v2.0.2:**\n1. Open the file located at `..navigator.war/applets/filenetViewer_properties.jsp`.\n2. Set the value of the parameter 'scale':\n   - To fit content by width, use: `scale: \"ftow\"`\n   - To fit content by height, use: `scale: \"ftoh\"`\n3. Alternatively, you can make the same changes in the `filenetViewer_properties.jsp` file under `ECMClient\\configure\\explodedformat\\navigator\\applets`.\n4. After making the changes, rebuild and redeploy the EAR file.\n5. Restart the application server.\n\n**For Content Navigator v2.0.3:**\n1. Go to the Daeja ViewONE panel in the admin desktop.\n2. In the Additional Settings section, add the parameter-value pair:\n   - For the Professional viewer, use the Professional tab.\n   - For the Virtual viewer, use the Virtual tab.\n3. Click \"New\" to add the parameter-value pair.\n4. Save the changes, and they will take effect when the viewer is relaunched.\n\nMake sure to save all changes and restart the necessary services for them to be applied.",
    "id": "TECHQA_TRAIN_Q393_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q398",
    "question": "Cannot create syndication pair between Virtual Portals with a different user repository than Base Portal\nSteps:\n\nI have two different user repositories one to manage my base portal and Virtual Portals. (p.e: For Base Portal I use ITDS, and for VPs I use AD) with differents admin users each.\n\nThen I created two VPs using the AD repository, and my VPs admin user on the credential vault.\n\nTried to create a syndication relationship , that is failing with the error:\n\n\"Could not communicate with the target URL. Please check that the Syndicator URL details are entered correctly, and that the credential slot user exists on the target server.\"",
    "ground_truth": "1. Make the **Admin** user visible on both base and virtual Portals.",
    "answer": "To resolve the issue of not being able to create a syndication pair between your Base Portal and Virtual Portals with different user repositories, follow these steps:\n\n1. **Ensure Admin User Visibility**: The administrator user that you are using for syndication must exist in both the Base Portal and the Virtual Portals. This means you need to ensure that the admin user from the ITDS repository (Base Portal) is also recognized in the AD repository (Virtual Portals).\n\n2. **Check User Access**: Verify that the admin user has the necessary permissions to access both the Base Portal and the Virtual Portal. The user should be listed as a Domain Admin for both portals.\n\n3. **Update Credential Vault**: Make sure that the credentials for the admin user are correctly stored in the credential vault and that they are accessible for both portals.\n\n4. **Test Syndication URL**: Double-check the Syndicator URL details to ensure they are entered correctly. Make sure that the URL points to the correct Virtual Portal.\n\n5. **Review Realm Configuration**: Confirm that the realms are correctly configured and that the base entries for both the Base Portal and Virtual Portals are set up properly.\n\nBy ensuring that the admin user is visible and has access to both portals, you should be able to successfully create the syndication relationship. If the problem persists, consider reviewing the logs for any additional error messages that may provide further insight.",
    "id": "TECHQA_TRAIN_Q398_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q401",
    "question": "How do I tell when there are mismatched MQ jars in my application server?\nMismatched jar files can cause strange and unpredictable errors when using the MQ JMS classes from a .war file.",
    "ground_truth": "1. Remove any **MQ** jar files bundled with the **Java EE** application.\n",
    "answer": "To determine if there are mismatched MQ jars in your application server, follow these steps:\n\n1. **Run the `mqjavalist.sh` Script**: Execute the `mqjavalist.sh` script to list the MQ jar files and their versions. This script will help you identify any discrepancies in the versions of the MQ jars being used.\n\n2. **Review the Output**: Look for the implementation versions of the MQ jars in the output. Specifically, check for the `com.ibm.mqjms.jar` file. It should match the expected version (e.g., 7.1.0.0 - k000-L111005). If you see different versions, such as an earlier version (e.g., 7.0.1.5), this indicates a mismatch.\n\n3. **Check Classpath Entries**: Ensure that your application server's classpath does not include extra copies of the MQ jar files. If there are unnecessary entries, remove them to avoid conflicts.\n\n4. **Remove Bundled MQ Jars**: If your Java EE application (.ear or .war) includes its own copies of MQ jar files, remove them. Instead, rely on the MQ Resource Adapter's jars to ensure consistency.\n\n5. **Update the Jars if Necessary**: If you find that the `com.ibm.mqjms.jar` version is outdated, extract the correct version from the `wmq.jmsra.rar` file using the `jar` program, and replace the older version. Use `chown` and `chmod` to set the correct permissions on the new jar file.\n\nBy following these steps, you can identify and resolve any mismatched MQ jars in your application server, which should help prevent unpredictable errors.",
    "id": "TECHQA_TRAIN_Q401_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q413",
    "question": "VScan not working after migrating Datacap Application from 8.1 to 9.0.1\nHello,\n\nI have recently migrated one datacap application developed in Datacap 8.1 to Datacap 9.0.1. I followed the complete instruction provided in the link \n\nhttp://www.ibm.com/support/knowledgecenter/SSZRWV_9.0.1/com.ibm.dc.develop.doc/dcadv001.htm\n\n \n\nAfter migration, when I tried to execute the application using Datacap Desktop. I got errors that \"This batch has no data to process. Aborting\" and \"Unable to run queue\". I am attaching the screenshots of error. I am also attaching the DStudio rule's screenshot.\n\nI have verified and configured all the required settings.\n\nPlease guide if someone has faced the similar issue and resolved it.\n\nThanks.",
    "ground_truth": "1. Ensure the DCO name matches as it appears in **Datacap Studio**.\n   The DCO name must be spelled correctly and match in case-sensitivity to avoid issues.",
    "answer": "To resolve the issue with VScan not working after migrating your Datacap application from 8.1 to 9.0.1, follow these steps:\n\n1. **Check DCO Name Case Sensitivity**: Ensure that the DCO name in your Datacap Desktop matches exactly (including case) with what is defined in Datacap Studio. For example, if the DCO name is \"TravelDocs\" in Datacap Studio, it should not be \"TRAVELDOCS\" in Datacap Desktop.\n\n2. **Log into TMWeb Client**:\n   - Go to the **Administrator** tab.\n   - Select the **VScan** task from the Workflow.\n\n3. **Update Panel Value**:\n   - Click on **Setup** under the Program section.\n   - Change the value of the **Panel** to match the case-sensitive name from Datacap Studio (e.g., change \"TRAVELDOCS\" to \"TravelDocs\").\n   - Click **Save**.\n\n4. **Test the Application**: After making these changes, try executing the application again using Datacap Desktop.\n\nIf you continue to experience issues, please provide additional details or screenshots of the configuration for further assistance.",
    "id": "TECHQA_TRAIN_Q413_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q421",
    "question": "Authorization code issue\nlike many of the other questions posted on here ... I'm having trouble authenticating my SPSS authorization code. Then there is an issue getting a license code back from the IBM proxy server to complete my download. Please help.",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To resolve your authorization code issue with SPSS, follow these steps:\n\n1. **Contact Your Vendor**: Since you are experiencing installation and licensing issues, it's best to reach out to the vendor from whom you purchased the SPSS software. Here are some options:\n   - Hearne: [Hearne Software](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub](http://onthehub.com/)\n   - StudentDiscounts.com: [StudentDiscounts](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Check Your Internet Connection**: Ensure that your internet connection is stable, as a poor connection can hinder the communication with the IBM proxy server.\n\n3. **Re-enter the Authorization Code**: Double-check that you are entering the authorization code correctly, as any mistakes can lead to authentication issues.\n\n4. **Firewall/Antivirus Settings**: Sometimes, firewall or antivirus settings can block the connection to the IBM server. Temporarily disable them to see if that resolves the issue.\n\nIf these steps do not resolve your problem, please provide more details or contact your vendor for further assistance.",
    "id": "TECHQA_TRAIN_Q421_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q423",
    "question": "Report stuck in current queue\nWe have one report that has been showing in the admin current\nactivities status tab for 20+ days and we have had 2 full re-starts\nsince then. Also it appears we have interactive jobs staying around as well for past days and days.\n\nHow can we clean this up ?",
    "ground_truth": "1. Stop the **Cognos Service**\n   \n2. Take a physical backup of the Content Store or Notification database\n   \n3. Select the appropriate folder for your content store or notification database type under **<install>/configuration/schemas/delivery/<dbtype>/**\n   \n4. Run **NC_DROP_<dbtype>.sql** against the content store or notification database\n   \n5. Restart **Cognos Services**\n   \n6. Restore the content or notification store from the last backup version if dropping the NC* tables does not resolve the issue\n   ",
    "answer": "To resolve the issue of the report being stuck in the current queue for over 20 days, you can follow these steps:\n\n1. **Stop the Cognos Service**: Ensure that the Cognos service is completely stopped before making any changes.\n\n2. **Backup the Content Store**: Take a physical backup of your Content Store or Notification database to prevent any data loss.\n\n3. **Run the Cleanup Script**:\n   - Navigate to the appropriate folder for your content store or notification database type under `<install>/configuration/schemas/delivery/<dbtype>/`.\n   - Execute the script `NC_DROP_<dbtype>.sql` against the content store or notification database. This script is designed to drop the NC* tables that may be causing the reports to get stuck.\n\n4. **Restart Cognos Services**: After running the script, restart the Cognos services to apply the changes.\n\nIf the issue persists after these steps, consider restoring the content or notification store from the last backup version.\n\nMake sure to monitor the system after performing these actions to ensure that reports are processing correctly.",
    "id": "TECHQA_TRAIN_Q423_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q424",
    "question": "Unable to unistall Data Studio 3.1.1 on Windows\nWe use Data Studio 3.1.1.0 with DB2 WSE V9.7 FP11 on Windows 2008. While trying to new version of Data Studio 4.1.2, we are able to install it successfully. But unable to uninstall the existing 3.1.1.0, getting the jvm error \"Could not find the main class\". How we can delete it?",
    "ground_truth": "1. Uninstall all products including Install Manager (IM)\n\n2. Reinstall Install Manager (IM) and Data Studio **4.1.2**\n   ",
    "answer": "To uninstall Data Studio 3.1.1 on your Windows system, follow these steps:\n\n1. **Use Installation Manager (IM)**:\n   - Open IBM Installation Manager.\n   - Attempt to uninstall Data Studio 3.1.1 from there. If it fails, proceed to the next steps.\n\n2. **Manually Clean Up Remaining Packages**:\n   - Navigate to the following directories and delete any remaining files related to Data Studio:\n     - `C:\\Program Files\\IBM\\{IBMIMShared | SDPShared}`\n\n3. **Delete IBM Installation Manager**:\n   - Delete the IM installation directory:\n     - `C:\\Program Files\\IBM\\Installation Manager\\`\n   - Delete the IM Agent Data directory:\n     - For Windows 7: `C:\\ProgramData\\IBM\\Installation Manager`\n   - Remove the Windows registry entry:\n     - Open `regedit` and navigate to `HKEY_LOCAL_MACHINE\\SOFTWARE\\IBM\\Installation Manager`. Delete this entry.\n\n4. **Reinstall Installation Manager**:\n   - Download and reinstall IBM Installation Manager.\n\n5. **Reinstall Data Studio 4.1.2**:\n   - After successfully reinstalling IM, proceed to install Data Studio 4.1.2.\n\nThis process should help you remove the problematic version of Data Studio and allow you to use the new version without issues. If you encounter further problems, consider reaching out to IBM support for additional assistance.",
    "id": "TECHQA_TRAIN_Q424_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q425",
    "question": "Upgrading the feature level to 8 for a VOB and ACLs\nWe have upgraded to Clearcase version 8.0.1.3  ( on Windows 2008 Server) \nHow to upgrade the feature level of a single VOB from 5 to 8 ?",
    "ground_truth": "1. Run the command **cleartool chflevel -replica <new feature level> replica:<replica name>@\\<vob tag>**\n2. Run the command **cleartool chflevel -family <new feature level> vob:\\<vob tag>**",
    "answer": "To upgrade the feature level of a single VOB from 5 to 8 in ClearCase, follow these steps:\n\n1. **Open a Command Prompt**: Ensure you have administrative privileges.\n\n2. **Set into a View**: Navigate to the appropriate ClearCase view where the VOB is mounted.\n\n3. **Mount and Change Directory**: Change to the directory of the VOB tag.\n\n4. **Describe the VOB**: Check the current feature level by running:\n   ```\n   cleartool describe -long vob:.\n   ```\n\n5. **Determine the Replica Name**: Use the following command to find the replica name:\n   ```\n   cleartool lsreplica\n   ```\n   Note the default replica name, which is usually \"original\".\n\n6. **Change the Feature Level**:\n   - First, raise the replica feature level:\n     ```\n     cleartool chflevel -replica 8 replica:original@/<vob tag>\n     ```\n   - Then, raise the VOB family feature level:\n     ```\n     cleartool chflevel -family 8 vob:/<vob tag>\n     ```\n   You may receive a warning about compatibility with earlier versions of ClearCase. Confirm the change by typing `y`.\n\n7. **Verify the New Feature Level**: Run the describe command again to confirm the upgrade:\n   ```\n   cleartool describe -long vob:.\n   ```\n\nThis process will successfully upgrade the feature level of your specified VOB to 8 without affecting other VOBs on the server.",
    "id": "TECHQA_TRAIN_Q425_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q429",
    "question": "Does Portal 7.0.0.2 CF20 support upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60?\nDoes Portal 7.0.0.2 CF20 support upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60?",
    "ground_truth": "1. Obtain the fix from DB2 on **z/OS support** or **IBMLINK**.",
    "answer": "The context does not provide specific information regarding the compatibility of the DB2 JDBC Driver versions 4.11.77 and 4.18.60 with Portal 7.0.0.2 CF20. Therefore, I don't know if upgrading the DB2 JDBC Driver from 4.11.77 to 4.18.60 is supported. It is recommended to consult the WebSphere Portal Support Statement or contact IBM support for definitive guidance on this matter.",
    "id": "TECHQA_TRAIN_Q429_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q430",
    "question": "DASH 3.1.2.1 to 3.1.3.0 taking long time\nDASH 3.1.2.1 to 3.1.3.0 taking long time. How to fix this?",
    "ground_truth": "1. Use the attached script to initiate the upgrade.\n   The attached script is required to start the upgrade process. The script provides the **non-root** user, who originally installed the Jazz for **Service Management** instance, with the necessary permissions for the upgrade.",
    "answer": "To address the issue of the DASH 3.1.2.1 to 3.1.3.0 upgrade taking a long time, you may need to ensure that the upgrade process is initiated correctly, especially if you are encountering permission issues. Here’s a step-by-step solution:\n\n1. **Check Permissions**: Ensure that the user account you are using has the necessary permissions to execute the upgrade. If the installation was done as a non-root user, you may need to adjust permissions.\n\n2. **Use the Upgrade Script**: Run the provided upgrade script to ensure the correct permissions are set. Use the following command format:\n\n   ```bash\n   ./JazzSMgrpModeUpgrade.sh \"IM_Install_Location\" \"JazzSM_Install_Location\" \"[Response_file_with_absolute_Path]\"\n   ```\n\n   - Replace `\"IM_Install_Location\"` with the path to your Installation Manager.\n   - Replace `\"JazzSM_Install_Location\"` with the path to your Jazz for Service Management installation.\n   - The response file argument is optional for GUI mode but required for silent mode.\n\n3. **Monitor the Upgrade Process**: After initiating the upgrade with the script, monitor the process to see if it completes in a reasonable time. If it continues to take too long, check for any logs or error messages that may indicate what is causing the delay.\n\n4. **Consider Silent Installation**: If the GUI mode is slow, you might want to try the silent installation by providing all three arguments to the script.\n\nIf you continue to experience issues, please provide more details about any error messages or logs you encounter during the upgrade process.",
    "id": "TECHQA_TRAIN_Q430_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q431",
    "question": "Install path under \"Program Files\"\nMy path for the OS agent is e:\\Program Files\\IBM. Is there any issues or underlying problems if I install under \"Program Files\"? Just want to make sure no issues with a \"space\" in the install path.",
    "ground_truth": "1. Specify location with no **spaces** for the installation path.",
    "answer": "Installing the OS agent under \"Program Files\" with a path that includes spaces (e.g., \"e:\\Program Files\\IBM\") may lead to issues during installation. Based on the context provided, the installation process for ITM on Windows OS fails when the path contains spaces, as indicated by the error message received during installation attempts.\n\nTo avoid potential problems, it is recommended to:\n\n1. **Remove the space in the directory path**: Use a path without spaces, such as \"e:\\IBM\" or \"e:\\ProgramFiles\\IBM\".\n\n2. **If you must use a path with spaces**, ensure that the NTFS 8.3 name creation is enabled. You can check this by looking at the registry setting at:\n   ```\n   HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\\NtfsDisable8dot3NameCreation\n   ```\n   If it is set to (2), you can check the 8.3 name creation status for your volumes using the command:\n   ```\n   fsutil 8dot3name query e:\n   ```\n\nIn summary, it is best to avoid spaces in the installation path to ensure a smooth installation process.",
    "id": "TECHQA_TRAIN_Q431_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q440",
    "question": "SCM check analyses showing as not reported in the SCA user interface\nSCM check analyses showing as <not reported> the SCA user interface.\n\nCheck analyses in the SCA interface are showing as in the SCA user interface where at one point they were activated and returning data. Now they are not activated and not returning data.\n\nHow do I solve this issue?",
    "ground_truth": "1. Have an active operator reactivate the check analyses.\n   \n2. Run a new import in **SCA**.\n",
    "answer": "To resolve the issue of SCM check analyses showing as <not activated> in the SCA user interface, follow these steps:\n\n1. **Reactivate the Check Analyses**: Have an active operator log into the SCA user interface and reactivate the check analyses that are currently showing as <not activated>.\n\n2. **Run a New Import**: After reactivating the analyses, perform a new import in the SCA to ensure that the changes take effect and the data is returned.\n\n3. **Best Practice**: Consider creating a dedicated operator account specifically for activating SCM check analyses. This account should be kept active and should not be deleted to prevent similar issues in the future.\n\nBy following these steps, you should be able to resolve the issue and have the check analyses return data as expected.",
    "id": "TECHQA_TRAIN_Q440_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q441",
    "question": "How to serve static images from our HTTP Server instead of WebSphere 8.5 application?\nHow to serve static images from our HTTP Server instead of WebSphere 8.5 application?",
    "ground_truth": "1. Use **fileServingEnabled=\"true\"** in the **ibm-web-ext.xmi** file.\n   This will cause the plug-in to use a wildcard entry for the context-root of your web application.\n   ",
    "answer": "To serve static images from your IBM HTTP Server (IHS) instead of your WebSphere 8.5 application, follow these steps:\n\n1. **Create a Static Directory**: Under the IHS DocumentRoot directory, create a subdirectory called \"static\" and place your static files (e.g., images) there. For example:\n   ```\n   /usr/IBM/HTTPServer/htdocs/static/\n   ```\n\n2. **Configure Rewrite Rules**: In your IHS configuration file (usually `httpd.conf`), add the following rewrite rules to direct requests for static files to the IHS server:\n   ```apache\n   <ifModule mod_rewrite.c>\n   RewriteEngine on\n   RewriteRule ^/myapp/static/(.*) /static/$1 [PT]\n   </ifModule>\n   ```\n\n3. **Set Up Your Application**: In your WebSphere application, ensure that the `fileServingEnabled` property in the `ibm-web-ext.xmi` file is set to `true`. This allows the application to serve other static files not intended for IHS.\n\n4. **Reference Static Files**: In your web application, reference the static files using relative paths. For example:\n   ```html\n   <img src=\"static/picture.jpg\" alt=\"Picture\">\n   ```\n\n5. **Accessing Files**: Users will access the static images via URLs like:\n   ```\n   http://hostname/myapp/static/picture.jpg\n   ```\n   This request will be handled by IHS, serving the file from the `/static/` directory you created.\n\nBy following these steps, you can successfully serve static images from your HTTP Server instead of the WebSphere application.",
    "id": "TECHQA_TRAIN_Q441_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q443",
    "question": "How to get debug information when the IBM Content Navigator Installer is failing on the Unix Platform?\nHow to get debug information when the IBM Content Navigator Installer is failing on the Unix Platform?",
    "ground_truth": "1. Enter one of the following commands based on the shell you are using: **export LAX_DEBUG=true**, **setenv LAX_DEBUG true**, **LAX_DEBUG=true**, or **set LAX_DEBUG**.\n\n2. Run your installer.\n",
    "answer": "To get debug information when the IBM Content Navigator Installer is failing on the Unix platform, follow these steps:\n\n1. Open your Unix command line.\n2. Depending on your shell, enter one of the following commands to enable debug output:\n   - For bash: `export LAX_DEBUG=true`\n   - For csh or tcsh: `setenv LAX_DEBUG true`\n   - For sh: `LAX_DEBUG=true`\n   - For ksh: `set LAX_DEBUG`\n3. After setting the debug environment variable, run the installer.\n\nIf you want to redirect the debug output to a file, do the following:\n\n1. Set the debug variable to output to a file by using: `export LAX_DEBUG=file` (or the appropriate command for your shell).\n2. Run the installer.\n3. Once the installation is complete, a file named `jx.log` will be created in the same directory as your installer. This file will contain the complete debug output.\n\nThis information should help you diagnose the issue with the installer.",
    "id": "TECHQA_TRAIN_Q443_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q449",
    "question": "How do I identify people in scope across Matters in Atlas?\nHow do I identify people in scope across Matters in Atlas?",
    "ground_truth": "1. Create a query by joining REP_PEOPLE_INSCOPE_VW view with other views.\n   Join the REP_PEOPLE_INSCOPE_VW view with the **REP_MATTER_VW**, **REP_REQUEST_VW**, **REP_NOTICES_VW**, and **REP_PERSON_VW** views to create a query.",
    "answer": "To identify people in scope across Matters in Atlas, you can use the REP_PEOPLE_INSCOPE_VW view. Create a query by joining this view with the following views: REP_MATTER_VW, REP_REQUEST_VW, REP_NOTICES_VW, and REP_PERSON_VW. \n\nFor more detailed information on the Matter-related views, refer to the reporting views documentation at this link: [IBM Reporting Views Documentation](https://www.ibm.com/support/knowledgecenter/SS5JP8_6.0.3/com.ibm.aps.use.doc/apsrv0044.html).",
    "id": "TECHQA_TRAIN_Q449_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q452",
    "question": "Cannot start the IBM Content Collector Configuration Store Service\nHow to resolve when the IBM Content Collector Configuration Store Service cannot be started?",
    "ground_truth": "1. Shutdown the IBM Content Collector Configuration Store Service if it is running.\n\n2. Make a backup copy of all files under the directory: **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore**\n3. Show hidden folders by changing the configuration in Folder and Search options > View tab > Hidden files and folders > Show hidden files, folders, and drives.\n\n4. Free up disk space on the drive.\n\n5. Delete the following files:\n- **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\logs\\* **\n- **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solmsg.out**\n- **C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solerror.out**\n\n6. If restoring the configuration store to a previously backed up copy is required, run **afuConfigStoreTool -backup**. See production documentation for more information on running this tool. Otherwise, proceed to the next step.\n\n7. Restart IBM Content Collector services.",
    "answer": "To resolve the issue of the IBM Content Collector Configuration Store Service not starting, follow these steps:\n\n1. **Shutdown the Service**: Ensure that the IBM Content Collector Configuration Store Service is not running. If it is, stop the service.\n\n2. **Backup Configuration Files**: Create a backup of all files in the following directory:\n   ```\n   C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\n   ```\n   Note: If you cannot see the `C:\\ProgramData` folder, you may need to enable the display of hidden files. Go to Folder and Search options > View tab > select \"Show hidden files, folders, and drives.\"\n\n3. **Free Up Disk Space**: Check the disk space on the drive where the service is installed and free up some space if it is low.\n\n4. **Delete Corrupted Log Files**: Navigate to the following directory and delete the files inside the `logs` folder:\n   ```\n   C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\logs\\*\n   ```\n   Also, delete the following files:\n   ```\n   C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solmsg.out\n   C:\\ProgramData\\IBM\\ContentCollector\\ConfigurationStore\\solerror.out\n   ```\n   **Important**: Only delete the files within the `logs` folder, not the folder itself.\n\n5. **Restore Backup (if needed)**: If you need to restore the configuration store from a backup, use the command:\n   ```\n   afuConfigStoreTool -backup\n   ```\n   Refer to the production documentation for more details on using this tool.\n\n6. **Restart the Service**: Finally, restart the IBM Content Collector services.\n\nFollowing these steps should help you resolve the issue with the Configuration Store Service.",
    "id": "TECHQA_TRAIN_Q452_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q454",
    "question": "Column Analysis on Informix database using odbc connector fails with error SQLSTATE = HY000: Native Error Code = -256\nColumn Analysis on Informix database using odbc connector fails with error SQLSTATE = HY000: Native Error Code = -256",
    "ground_truth": "1. Set the Transaction handling>Isolation Level from **none** to **Auto-Commit**.\n   ",
    "answer": "To resolve the error SQLSTATE = HY000: Native Error Code = -256 when performing Column Analysis on your Informix database using the ODBC connector, you should change the Transaction handling settings. Specifically, set the Isolation Level from \"none\" to \"Auto-Commit.\" This adjustment should help eliminate the transaction-related error you are encountering.",
    "id": "TECHQA_TRAIN_Q454_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q455",
    "question": "How can I query the Derby database in Portal via SQL statements?\nI have a Portal system I just installed. I have not yet run database-transfer to copy the data from the Derby database to a DB2, Oracle, or SQL Server database. I don't wish to transfer to an external database and I have a need to run a SQL query against a table or two in the Derby database to troubleshoot an issue. \r\nHow can I perform this action?",
    "ground_truth": "1. Use **dblook** and **ij** utilities to obtain the data and structure of the WebSphere Portal database.",
    "answer": "To query the Derby database in your Portal system using SQL statements, follow these steps:\n\n1. **Stop the Portal Server**: Before accessing the Derby database, ensure that the Portal server is stopped to avoid any data corruption.\n\n2. **Open Command Prompt/Terminal**: Launch a command prompt (Windows) or terminal (Linux/Unix).\n\n3. **Navigate to the ij Utility**: Change the directory to where the `ij` utility is located. This is typically found in `<was_root>/AppServer/derby/bin/embedded`.\n\n4. **Start the ij Utility**: Enter the command to start `ij`. You should see the prompt `ij>`.\n\n5. **Connect to the Derby Database**: Use the following command to connect to your Derby database:\n   ```\n   ij> connect 'jdbc:derby:C:\\IBM\\WebSphere\\wp_profile\\derby\\wpsdb';\n   ```\n\n6. **Run Your SQL Queries**: You can now execute SQL statements. For example, to select data from a table, you can use:\n   ```\n   ij> select * from user_desc where oid=1000;\n   ```\n\n7. **Additional Commands**: You can also run SQL scripts or export data using commands like:\n   ```\n   ij> run 'myquery.sql';\n   ```\n\nMake sure to replace the paths and table names with those relevant to your setup. If you encounter any issues, ensure that the database path is correct and that the Portal server is indeed stopped.",
    "id": "TECHQA_TRAIN_Q455_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q458",
    "question": "Error TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during import-nodes sub-task\nError TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during import-nodes sub-task",
    "ground_truth": "1. Navigate to **Applications > WebSphere enterprise applications > JavaContentRepository**.\n   \n2. Target a specific application status.\n   \n3. Check the box for the **WebSphere_Portal** server.\n   \n4. Click **Enable Auto Start**.\n   \n5. Save changes.\n   \n6. Restart **Portal**.\n\n7. After making this change, attempt the CF upgrade again.\n   ",
    "answer": "To resolve the error TASK001X while upgrading Portal 8.0.0.1 to 8.0.0.1 CF14 during the import-nodes sub-task, follow these steps:\n\n1. **Access the WebSphere Admin Console**:\n   - Open your WebSphere Application Server (WAS) Admin Console.\n\n2. **Navigate to Applications**:\n   - Go to `Applications > WebSphere enterprise applications`.\n\n3. **Locate JavaContentRepository**:\n   - Find the application named `JavaContentRepository`.\n\n4. **Enable Auto Start**:\n   - Click on `Target specific application status`.\n   - Check the box for the `WebSphere_Portal` server.\n   - Click on `Enable Auto Start`.\n   - Save the changes.\n\n5. **Restart Portal**:\n   - Restart your Portal server to apply the changes.\n\n6. **Retry the Upgrade**:\n   - After the Portal has restarted, attempt the CF upgrade again.\n\nThis should resolve the issue related to the remote task execution failure. If the problem persists, check the server logs for more detailed error messages.",
    "id": "TECHQA_TRAIN_Q458_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q460",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM® SPSS® Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message: \n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction. \nNo additional authorizations are permitted on this code. \nWhat should I do?\n\n\n\nThis dW Answers question is about an IBM document with the Title: \nSPSS Student Version and Graduate Pack Resources",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To transfer your SPSS 24 license key to a new computer and resolve the authorization error, follow these steps:\n\n1. **Contact Your Vendor**: Since you are using the Student Version or Graduate Pack, the first step is to reach out to the vendor from whom you purchased the software. They can assist you with licensing issues. Here are some options:\n   - Hearne: [Hearne Software](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub](http://onthehub.com/)\n   - StudentDiscounts.com: [Student Discounts](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Check License Activation Limits**: The error message indicates that you may have reached the limit for generating new licenses with your activation code. Your vendor can confirm if this is the case and may provide a solution or a new activation code.\n\n3. **Uninstall from Old Computer**: If you still have access to the old computer, ensure that you have uninstalled SPSS from there. This may free up the license for use on the new computer.\n\n4. **Follow Vendor Instructions**: Once you contact the vendor, follow their specific instructions for transferring your license.\n\nIf you continue to experience issues, the vendor will be your best resource for resolving the problem.",
    "id": "TECHQA_TRAIN_Q460_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q461",
    "question": "How can I configure TIP to clear the ARGUS cache without having to do a system restart?\nArgus stores it's role authorizations in memory cache, and is not cleaned out unless the TIP is restarted. The \"cacheTime\" variable in the configFile.xml configuration file controls this, which is set to -1 by default. If the number of TIP roles is high, it can cause Java OOM errors.",
    "ground_truth": "1. Configure ‘cacheTime’ to non -1 value.\n   Set the value of 'cacheTime' to **1200000**, which is equivalent to 20 minutes.\n2. Restart the TIP server, which is normally referred to as **server1**.",
    "answer": "To configure TIP to clear the ARGUS cache without needing a system restart, you need to change the `cacheTime` variable in the `config.xml` file. By default, this variable is set to -1, which means the cache will not be cleared until the TIP server is restarted.\n\nHere are the steps to configure it:\n\n1. Navigate to the `config.xml` file located at `<TIP_HOME>/profiles/TIPProfile/config/cells/TIPCell/commonauthz/`.\n2. Open the `config.xml` file in a text editor.\n3. Locate the `cacheTime` variable. If it is set to -1, change it to a non-negative value. A recommended initial value is 1200000 (which equals 20 minutes).\n4. Save the changes to the `config.xml` file.\n5. Restart the TIP server (typically `server1`) for the changes to take effect.\n\nAfter making this change, the ARGUS cache will be cleared automatically based on the specified `cacheTime`, helping to prevent Java OutOfMemory errors without requiring a full server restart.",
    "id": "TECHQA_TRAIN_Q461_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q466",
    "question": "What happens if I lost my seed and salt value?\nIn ISDS, what happens if I lost my seed and salt value?\n\n\n\nThis dW Answers question is about an IBM document with the Title:\nOpen Mic Webcast: Configuring SDS 8.0.1 Virtual Appliance with a remote DB2 database - Tuesday, 17 Jan 2017 [presentation slides are attached; includes link to replay]",
    "ground_truth": "1. Create a new instance with a new encryption seed value.\n   \n2. Use the **db2ldif** utility to export data.\n   \n3. Use the **ldif2db** utility to import data.",
    "answer": "If you have lost your seed and salt value in ISDS, there is no way to recover the original seed value used during instance creation. The only solution is to create a new instance with a new encryption seed value. Here are the steps to follow:\n\n1. **Set up a new instance** (let's call it \"newinst\"):\n   ```bash\n   $> idsicrt -I newinst -e thisismyencryptionseed -l (/home/newinst) -n\n   $> idscfgdb -I newinst -w ldap -a newinst -t newinst -l (/home/newinst) -n\n   $> idscfgsuf -s \"o=ibm,c=us\" -I newinst -n\n   $> idsdnpw -u cn=root -p root -I newinst -n\n   ```\n\n2. **Note the new encryption seed** (let's call it `new_encryptionseed`).\n\n3. **Retrieve the new salt value** by running:\n   ```bash\n   $> ldapsearch -D <administrator DN> -w <administrator password> -b \"cn=crypto,cn=localhost\" -s base objectclass=* ibm-slapdCryptoSalt\n   ```\n   (Let's call this value `new_saltvalue`).\n\n4. **Use the `db2ldif` utility** on the old instance (let's call it \"oldinst\") to export the data:\n   ```bash\n   $> db2ldif -o outputfile -I oldinst -k new_encryptionseed -t new_saltvalue\n   ```\n\n5. **Reload the data** into the new instance using the `ldif2db` utility.\n\nBy following these steps, you can preserve your data and passwords on the new instance.",
    "id": "TECHQA_TRAIN_Q466_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q467",
    "question": "How can we change the password for LDAP bind user?\nWe need to change our LDAP bind user due to security requirement. Is there any documentation for the procedure?",
    "ground_truth": "1. Follow a coordinated update procedure when needing to change the user account and/or password.\n   This coordinated update procedure should be applied specifically to FileNet Content Engine versions **4.x** and above.",
    "answer": "To change the password for your LDAP bind user, follow these steps:\n\n1. **Change the Password on the LDAP Server**:\n   - Use the LDAP interface to change the password for the existing bind user account.\n\n2. **Update Directory Configuration in FEM**:\n   - Launch FileNet Enterprise Manager (FEM).\n   - Navigate to **Domain properties > Directory Configuration**.\n   - Select the appropriate Directory Configuration and click on the **Modify** button.\n   - In the **General Tab**:\n     - Update the **Directory Service User** with the new user's full distinguished name (DN).\n     - Check the **Change password** checkbox and enter the new password.\n     - Click **OK**. You will see a message indicating that the application server needs to be restarted.\n\n3. **Update Application Server Configuration**:\n   - Do not restart the application server yet. Instead, go to the application server's administrative console (e.g., WebSphere, WebLogic, or JBoss).\n   - For **WebSphere**: Go to **Global Security > Configure under User Account Repository**. Modify the **Bind Distinguished Name (DN)** and **Bind Password**, then save the changes.\n   - For **WebLogic**: Go to **Security Realms > myrealm > Providers > ldap provider**. Click on the **Provider Specific** tab and change the **Principal** and **Credential**.\n   - For **JBoss**: Navigate to `<JBoss Home>\\server\\<CE Server>\\conf` and edit `login-config.xml`. Update the `bindDN` and `bindCredential` in the \"FileNet\" application-policy.\n\n4. **Restart the Application Server**:\n   - After completing the above steps, you can now restart the application server to apply the changes.\n\n5. **Additional Steps (if applicable)**:\n   - If the bind user is also the CE admin user, ensure to add the new user to all existing objects in the P8 domain as needed.\n\nMake sure to follow these steps carefully to ensure a smooth transition to the new password. If you need further assistance, please refer to the specific documentation linked in the context or consult your system administrator.",
    "id": "TECHQA_TRAIN_Q467_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q470",
    "question": "Does Logout button get disabled in ICM for SSO with Tivoli Access Manager ?\nDoes Logout button get disabled in ICM for SSO with Tivoli Access Manager ?",
    "ground_truth": "1. Remove the **Log Out** option by customizing the banner user session context menu.",
    "answer": "In a SPNEGO/Kerberos Single Sign-On (SSO) environment, the Log Out option in IBM Content Navigator may appear enabled, even though it should be disabled. If you want to remove the Log Out option from the user session context menu, you can customize it by following these steps:\n\n1. In the administration tool, select **Menus**.\n2. Enter \"User\" in the **Name contains** filter field.\n3. Select the **Default banner user session context menu** and click **Copy**.\n4. Enter a name for the new menu, such as \"Banner user session context menu - no Log Out option\".\n5. Remove the **Log Out** option from the Selected list.\n6. Save the new menu.\n7. Open the **Desktops configuration**, then open your desktop configuration.\n8. Select the **Menus** tab and scroll to the **Feature Context Menus** section.\n9. Select the new menu you created for the Banner user session context menu type.\n10. Save your desktop.\n\nThe changes will take effect when the modified desktop is reloaded. This will effectively remove the Log Out option from the menu in your SSO environment.",
    "id": "TECHQA_TRAIN_Q470_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q472",
    "question": "The Ping Probe will not start with SetUID configured\nThe Netcool OMNIbus Ping Probe will not start with SetUID configured. What should I check?",
    "ground_truth": "1. Change the owner to **root** and permissions to **setuid**.\n   \n2. Put either a copy of the required libraries, or a symbolic link to the required libraries in one of the trusted paths.\n   The trusted paths include **/lib** or **/usr/lib**.",
    "answer": "To resolve the issue with the Netcool OMNIbus Ping Probe not starting with SetUID configured, follow these steps:\n\n1. **Change Ownership and Permissions**:\n   - Navigate to the directory where the Ping Probe is installed:\n     ```bash\n     cd $OMNIHOME/probes/aix5/\n     ```\n   - Change the owner to root and set the SetUID permission:\n     ```bash\n     chown root:root nco_p_ping\n     chmod +s nco_p_ping\n     ```\n\n2. **Create Symbolic Links for Required Libraries**:\n   - Since AIX ignores the LIBPATH setting when running as SetUID root, you need to create symbolic links to the required libraries in a trusted path like `/usr/lib`. First, navigate to the `/usr/lib` directory:\n     ```bash\n     cd /usr/lib\n     ```\n   - Create symbolic links for the required libraries. You can find the required libraries by running:\n     ```bash\n     dump -H $NCHOME/omnibus/platform/aix5/nco_p_ping\n     ```\n   - Then, create the symbolic links as needed. For example:\n     ```bash\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libgsk*\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libPa_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libnetcool_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libslclient_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libOpl_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libsybct_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libsybcs_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libsybtcl_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libsybcomn_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libtre.a\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libsybintl_r.so\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libicuuc40.a\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libicui18n40.a\n     ln -s /opt/IBM/netcool/platform/aix5/lib/libicudata40.a\n     ```\n\n3. **Recheck After Fix Pack**:\n   - If you apply a Fix Pack for OMNIbus core, remember to recreate the symbolic links as necessary.\n\nBy following these steps, you should be able to start the Ping Probe successfully with SetUID configured.",
    "id": "TECHQA_TRAIN_Q472_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q473",
    "question": "Why Summarization and pruning are failing with SQL Error Code = -4220 on AIX_LPAR table?\nSummarization and pruning are failing with SQL Error Code = -4220 on AIX_LPAR table.  What's the fix?",
    "ground_truth": "1. Update the invalid data with a valid **UTF-8** character string.",
    "answer": "The SQL Error Code -4220 indicates that there is invalid UTF-8 data in a character column of the AIX_LPAR table, which is causing the summarization and pruning to fail. To resolve this issue, follow these steps:\n\n1. **Identify Invalid Data**: Use the following SQL query to find the byte values in the character column that is causing the issue:\n   ```sql\n   SELECT HEX(column_name) FROM AIX_LPAR;\n   ```\n   Replace `column_name` with the actual name of the character column you suspect is problematic.\n\n2. **Update Invalid Data**: Once you identify the invalid byte sequences, update the affected rows with valid UTF-8 character strings. For example:\n   ```sql\n   UPDATE AIX_LPAR SET column_name = 'valid_string' WHERE condition;\n   ```\n   Ensure that `valid_string` is a proper UTF-8 string and `condition` targets the rows with invalid data.\n\n3. **Alternative Configuration (if applicable)**: If you are using a compatible version of the JCC driver (DB2 LUW 9.5 Fix Pack 8 and later, or DB2 10.1 onwards), you can set the following configuration property to handle invalid UTF-8 data without throwing an exception:\n   ```java\n   db2.jcc.charsetDecoderEncoder=3\n   ```\n   This will replace invalid byte sequences with the Unicode REPLACEMENT CHARACTER (U+FFFD).\n\nBy following these steps, you should be able to resolve the SQL Error Code -4220 and successfully perform summarization and pruning on the AIX_LPAR table.",
    "id": "TECHQA_TRAIN_Q473_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q475",
    "question": "How can I fix blank pull down  \"Console Settings\" menu after successful install of JazzSM 1.2.1.1 and WebSphere 8.5.5.9?\nWebSphere version 8.5.5.9 didn't include jar files that were available in previous releases of WebSphere that are required by DASH for various tasks.",
    "ground_truth": "1. Download DASH **3.1.2.1** Cumulative Patch 5 from the provided site.\n   You can download the missing jar files from the following URL: **http://www-933.ibm.com/support/fixcentral/swg/selectFixes?parent=ibm~Tivoli&product=ibm/Tivoli/Jazz+for+Service+Management&release=1.1&platform=All&function=all**.",
    "answer": "To fix the blank \"Console Settings\" menu after successfully installing JazzSM 1.2.1.1 and WebSphere 8.5.5.9, you need to install the missing .jar files that are required for DASH functionality. These files are included in DASH 3.1.2.1 Cumulative Patch 5.\n\nHere are the steps to resolve the issue:\n\n1. **Download Cumulative Patch 5**: Go to the following link to download DASH 3.1.2.1 Cumulative Patch 5:\n   [IBM Fix Central](http://www-933.ibm.com/support/fixcentral/swg/selectFixes?parent=ibm~Tivoli&product=ibm/Tivoli/Jazz+for+Service+Management&release=1.1&platform=All&function=all)\n\n2. **Install the Patch**: Follow the installation instructions provided with the patch to ensure it is applied correctly.\n\n3. **Verify Installation**: After installation, you can verify if the patch has been successfully installed by running the following command:\n   ```\n   <JazzSM_HOME>/ui/bin/consolecli Version\n   ```\n   If the patch is installed, the output will indicate the patch number.\n\n4. **Restart Services**: After applying the patch, restart your WebSphere and JazzSM services to ensure all changes take effect.\n\nFollowing these steps should resolve the issue with the blank \"Console Settings\" menu. If the problem persists, please consult the IBM support documentation or reach out to their support team for further assistance.",
    "id": "TECHQA_TRAIN_Q475_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q478",
    "question": "How to define shared libraries for ODM ruleApps on WAS traditional?\nWhat is the proper way to define a shared lib for RuleApps without giving up the isolated mode of the XU resource adapter? Is it \"works as designed\" that isolating of the XU prevents the resource adapter from seeing shared lib classes from other classloaders?",
    "ground_truth": "1. Go to the JDBC Provider and enable **isolate the resource provider**.\n   Enabling **isolate this resource provider** ensures that only the jar specified in the classpath will be used for all the datasources under that particular **JDBC** provider.",
    "answer": "To define shared libraries for ODM RuleApps on WebSphere Application Server (WAS) traditional while maintaining the isolated mode of the XU resource adapter, you should follow these steps:\n\n1. **Enable Isolation**: Go to the JDBC Provider settings and ensure that \"Isolate this resource provider\" is enabled. This setting ensures that only the specified jar in the classpath is used for all datasources under that JDBC provider.\n\n2. **Define Shared Libraries**: Create a shared library in WAS that includes the necessary jar files for your ODM RuleApps. This can be done through the administrative console by navigating to `Environment > Shared libraries` and defining a new shared library.\n\n3. **Reference the Shared Library**: Associate the shared library with your RuleApps by going to the application settings and adding the shared library to the classloader policy. Make sure to set the classloader policy to \"Parent Last\" to ensure that the application uses the classes from the shared library before looking in the parent classloader.\n\n4. **Resource Adapter Configuration**: If you are using the XU resource adapter, be aware that isolating the resource provider may prevent the resource adapter from accessing shared library classes from other classloaders. This behavior is expected and is designed to avoid class conflicts.\n\n5. **Testing**: After configuration, deploy your RuleApps and test to ensure that the shared libraries are being accessed correctly without classloader conflicts.\n\nBy following these steps, you can define shared libraries for ODM RuleApps while keeping the isolated mode of the XU resource adapter intact. If you encounter issues, refer to the provided Knowledge Center articles for further guidance on JDBC provider settings and considerations for isolated resource providers.",
    "id": "TECHQA_TRAIN_Q478_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q483",
    "question": "How do I tell when there are mismatched MQ jars in my application server?\nMismatched jar files can cause strange and unpredictable errors when using the MQ JMS classes.",
    "ground_truth": "1. Use the **mqjavalist.sh** script.\n   This script simplifies the process of finding and eliminating duplicate copies of the **MQ** jar files on Linux and UNIX systems.",
    "answer": "To determine if there are mismatched MQ jars in your application server, follow these steps:\n\n1. **Run the mqjavalist.sh Script**: First, make sure you have the `mqjavalist.sh` script available. You may need to set execute permissions with:\n   ```bash\n   chmod +x mqjavalist.sh\n   ```\n\n2. **Execute the Script**: Run the script in your terminal:\n   ```bash\n   ./mqjavalist.sh\n   ```\n\n3. **Review the Output**: Look through the script's output carefully. Check the implementation versions of the jar files:\n   - Specifically, you want to check the version of `com.ibm.mqjms.jar`.\n   - If there are discrepancies (for example, if you see different versions listed), it indicates that you have mismatched jar files.\n\n4. **Identify Duplicates**: If the script lists multiple versions, determine which versions are loaded by your Java SE or Java EE applications. Only mismatched jars affecting these applications need to be addressed.\n\n5. **Eliminate Unnecessary Jars**: If your application bundles its own MQ jars (inside .ear or .war files), consider removing these and relying only on the versions provided by the MQ Resource Adapter.\n\n6. **Replace with Correct Version**: If you find a mismatch (e.g., `com.ibm.mqjms.jar` shows an implementation version that is earlier than expected), locate the correct version in `wmq.jmsra.rar`, extract it, and replace the old jar. Ensure to set the appropriate file permissions using `chown` and `chmod`.\n\nBy following these steps, you can effectively identify and resolve any mismatched MQ jars in your application server, minimizing the chance of unpredictable errors.",
    "id": "TECHQA_TRAIN_Q483_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q489",
    "question": "Recurrent RES StaleConnectionException\nHow to prevent rule execution failing because of recurrent StaleConnectionException on ODM 8.8 Rule Execution Server?",
    "ground_truth": "1. Set the Minimum connections to **0**.\n\n2. Set the values for **Unused timeout** and **Reap timeout** so that the sum does not exceed any network level idle connection timeout.\n",
    "answer": "To prevent the recurrent `StaleConnectionException` when using the ODM 8.8 Rule Execution Server, follow these steps to configure the WebSphere Application Server data source connection pool:\n\n1. **Set the Minimum Connections**: Configure the minimum connections setting to `0`. This avoids keeping idle connections in the pool, which might become stale.\n\n2. **Adjust Timeout Settings**:\n   - Set the **Unused Timeout**: This defines how long connections can remain unused before they're considered stale.\n   - Set the **Reap Timeout**: This determines how long the pool will wait before cleaning up stale connections.\n\n3. **Ensure Correct Sum of Timeout Values**: Make sure the sum of the Unused Timeout and Reap Timeout values does not exceed the network-level idle connection timeout set by any firewall or network settings. This will help reduce the chances of connections being discarded due to inactivity.\n\nBy making these configurations, you should be able to minimize or eliminate the occurrence of `StaleConnectionException` during rule execution. For detailed instructions on configuring the connection pool, refer to the WebSphere Application Server documentation.",
    "id": "TECHQA_TRAIN_Q489_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q490",
    "question": "TWS / DWC and WebSphere 8.5.5.4+\nWebSphere for TWS & DWC were upgraded to 8.5.5.4 on most servers in a particular environment. However, any TWS servers that still had 8.5.5.2, could no longer be seen by the new DWC / WAS 8.5.5.4 servers. Those lower WAS version engines could not be added to the DWC.\n\nErrors seen are:\n\n     AWSUI0833E The operation could not be completed. There has been a communication failure. \n     The internal message is: AWSJCO005E WebSphere Application Server has given the following error: Error getting WsnNameService properties.",
    "ground_truth": "1. Configure your **TWS** engines to use **TLS** instead of SSL",
    "answer": "To resolve the issue of TWS servers running on WebSphere Application Server (WAS) version 8.5.5.2 not being visible to the upgraded DWC/WAS 8.5.5.4 servers, you need to configure the TWS engines to use TLS instead of SSL. This is necessary because DWC 9.3 (which uses WAS 8.5.5.4) has SSLv3 disabled due to security vulnerabilities, while TWS versions 9.2 and earlier use SSLv3 by default.\n\nHere are the steps to configure your TWS engines to use TLS:\n\n1. **Backup and Edit Security Configuration:**\n   - Open the file: `TWA_HOME/WAS/TWSProfile/config/cells/TWSNodeCell/security.xml`\n   - Find the line with `sslProtocol` and change `\"SSL_TLS\"` to `\"TLS\"`.\n   - Find the line with `ssl.protocol` and change `value=\"SSL\"` to `value=\"TLS\"`.\n\n2. **Update SSL Client Properties:**\n   - Open the file: `TWA_HOME/WAS/TWSProfile/properties/ssl.client.props`\n   - Find the line `com.ibm.ssl.protocol=SSL` and change it to `com.ibm.ssl.protocol=TLS`.\n   - Open the file: `TWA_HOME/WAS/TWSProfile/temp/ssl.client.props`\n   - Find the line `com.ibm.ssl.protocol=SSL` and change it to `com.ibm.ssl.protocol=TLS`.\n\n3. **Restart WebSphere Application Server:**\n   - Stop and restart WAS to apply the changes.\n\n4. **Reconfigure DWC 9.2 or 9.1 Installations:**\n   - If you have any DWC 9.2 or 9.1 installations that need to connect to these TWS engines, you must also configure them to use TLS by making the same changes in their respective `security.xml` and `ssl.client.props` files:\n     - `TWA_HOME/JazzSM/profile/config/cells/JazzSMNode01Cell/security.xml`\n     - `TWA_HOME/JazzSM/profile/properties/ssl.client.props`\n     - `TWA_HOME/JazzSM/profile/temp/ssl.client.props`\n\n5. **Consider Impact on Dynamic Agent:**\n   - Be aware that configuring TLS may also impact the Dynamic Agent, so review any necessary configurations as per technote 1689332.\n\nBy following these steps, your TWS servers should be able to communicate with the DWC/WAS 8.5.5.4 servers without encountering the communication failure errors.",
    "id": "TECHQA_TRAIN_Q490_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q494",
    "question": "Why do we observe the transaction rollback errors J2CA0024E and DSRA0080E with Oracle 12c and how can we fix it?\nWe are using BPM Advanced v8.5.6 in connection with the Oracle JDBC Driver 12.1.0.1.0. We observe many database transaction rollback exceptions:\n\n     J2CA0024E: Method rollback, within transaction branch ID <null> of resource pool jdbc/BPEDB, caught com.ibm.ws.exception.WsException: DSRA0080E: An exception was received by the Data Store Adapter. See original exception message: Could not rollback with auto-commit set on. with SQL State : 99999 SQL Code : 17274\n\nDue to the technote \"Advanced database support for IBM BPM Standard, IBM BPM Advanced, and IBM Business Monitor on distributed platforms\" this is a supported configuration.\n\nWhy do we observe these errors and how can we fix it?",
    "ground_truth": "1. Add the following JVM property to the Monitor server JVM: **oracle.jdbc.autoCommitSpecCompliant=false**",
    "answer": "The transaction rollback errors J2CA0024E and DSRA0080E you are encountering with Oracle 12c in your BPM Advanced v8.5.6 setup are likely related to the JDBC driver configuration. Specifically, the error message indicates an issue with the auto-commit setting.\n\nTo resolve this issue, you should add the following JVM property to your IBM Business Monitor server:\n\n```\noracle.jdbc.autoCommitSpecCompliant=false\n```\n\nThis property adjustment is necessary when using the Oracle 12c JDBC driver to ensure compatibility and proper transaction handling.\n\nHere are the steps to add the JVM property:\n\n1. Open the administrative console for your IBM Business Monitor server.\n2. Navigate to the server settings where you can configure JVM properties.\n3. Add the property `oracle.jdbc.autoCommitSpecCompliant` and set its value to `false`.\n4. Save the changes and restart the server for the new settings to take effect.\n\nAfter making this change, monitor your application to see if the transaction rollback errors persist. If they do, further investigation into the transaction management and database connection settings may be required.",
    "id": "TECHQA_TRAIN_Q494_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q497",
    "question": "Login to DASH  returned  \"Page cannot be displayed\" error\nLogin to DASH  returned  \"Page cannot be displayed\" error",
    "ground_truth": "1. Change the directory to **<JazzSM Home>/ui/bin**\n   \n2. Run the following command: **./consoleLogCollector.sh or .bat**\n   \n3. Send us the console_logs.zip file located in **<JazzSM Home>/ui** directory\n   \n4. Attach the console_logs.zip file to the associated Problem Management Record (PMR)\n   \n5. Include the time the issue was reproduced in the PMR update\n   \n6. Provide the DASH version info using the command: **<JazzSM Home>/ui/bin/consolecli.sh Version**\n   \n7. Upload the resulting output file to the PMR\n   ",
    "answer": "To resolve the \"Page cannot be displayed\" error when logging into DASH, follow these steps to enable trace logging and collect relevant logs for further analysis:\n\n1. **Enable Trace Logging:**\n   - Log into DASH.\n   - Navigate to **Console Settings** > **Websphere Administrative Console**.\n   - Go to **Troubleshooting** > **Logs & Trace**.\n   - Click on **Server1** and select **Diagnostic Trace Service**.\n   - Increase the **Maximum Number of Historical Files** from 1 to 10 and click **Apply**.\n   - Select **Change Log Detail Levels**.\n   - In the **Runtime** tab, clear the trace string in the **Groups** box and replace it with:\n     ```\n     *=info: com.ibm.isc.*=all: com.ibm.isclite.*=all: com.ibm.iscportal.*=all: com.ibm.isclite.service.datastore.consoleproperties.*=INFO\n     ```\n   - Click **Apply**. If you want the tracing to persist after server restarts, do this from the **Configuration** tab and click **Save**.\n\n2. **Reproduce the Issue:**\n   - After enabling tracing, reproduce the \"Page cannot be displayed\" error. Note the exact time the issue occurs for correlation with the logs.\n\n3. **Run the Log Collector:**\n   - Change the directory to `<JazzSM Home>/ui/bin`.\n   - Run the command:\n     ```\n     ./consoleLogCollector.sh (or .bat for Windows)\n     ```\n   - This will generate a `console_logs.zip` file located in `<JazzSM Home>/ui`.\n\n4. **Submit the Logs:**\n   - Attach the `console_logs.zip` file to the associated Problem Management Record (PMR).\n   - Include the time the issue was reproduced and the DASH version info from `<JazzSM Home>/ui/bin/consolecli.sh Version`.\n\nBy following these steps, you will gather the necessary information to diagnose the issue effectively. If you need further assistance, please provide the logs to the support team.",
    "id": "TECHQA_TRAIN_Q497_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q503",
    "question": "Can I remove the write permissions for \"other\" in ../ibm/common/acsi?\nCan I remove \"write\" permission for \"other\" for all the sub-directories and files under the following directory,\n\n    /usr/ibm/common/acsi  \n    /var/ibm/common/acsi  \n\nWill it cause any problem?",
    "ground_truth": "1. Remove world **writable** permissions from **DE** directories.",
    "answer": "Yes, you can remove the write permissions for \"other\" in the directories `/usr/ibm/common/acsi` and `/var/ibm/common/acsi`, as well as for all sub-directories and files under these directories. Based on the context provided, it has been confirmed that removing world-writable permissions from these directories will not impact functionality. \n\nTo do this, you can use the following command:\n\n```bash\nchmod -R o-w /usr/ibm/common/acsi\nchmod -R o-w /var/ibm/common/acsi\n```\n\nThis command will recursively remove write permissions for \"other\" users from the specified directories and their contents. \n\nHowever, please ensure to monitor the system after making these changes to confirm that everything continues to function as expected.",
    "id": "TECHQA_TRAIN_Q503_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q504",
    "question": "OMNIBUS   nco_p_mttrapd : Malformed traps\nHow can you determine why the MTTrapd [SNMP] probe drops traps?",
    "ground_truth": "1. Ensure that the traps are being dropped from specific devices under normal load.\n2. Use **snoop**, **tcpdump** or **Wireshark** to capture the traps that are being dropped on the probe servers port.",
    "answer": "To determine why the MTTrapd [SNMP] probe is dropping traps, follow these steps:\n\n1. **Check for Overloading**: Ensure that traps are not being dropped due to high load. Monitor the system load during the times traps are dropped.\n\n2. **Capture Dropped Traps**: Use tools like `snoop`, `tcpdump`, or `Wireshark` to capture the SNMP traps on the probe server's port (typically port 162). \n\n3. **Analyze the Captured Data**: Load the captured PCAP file into Wireshark and visually inspect the traps. Ensure that each trap has the required `enterprise-oid` and `uptime` fields, as traps lacking these will be dropped by the NET-SNMP libraries.\n\n4. **Check Configuration**: Verify that the MTTrapd probe and Netcool/OMNIbus are updated to the latest fix pack. Ensure that the probe is correctly configured, including settings for SNMPv3 traps if applicable.\n\n5. **Protocol Settings**: If traps are being sent over different protocols, set the Protocol to 'ALL' in the configuration to capture both TCP and UDP traps.\n\n6. **Review SNMPv3 Configuration**: For SNMPv3 traps, ensure that there is a unique `creatruser` entry for each device in the `mttrapd.conf` file, including the device's unique `engine-id`.\n\n7. **Contact Support**: If the traps appear to be RFC compliant and the configuration is correct, gather the PCAP file, the probe's debug log, and the property file, and contact IBM Tivoli Netcool support for further analysis.\n\nBy following these steps, you should be able to identify the cause of the dropped traps.",
    "id": "TECHQA_TRAIN_Q504_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q505",
    "question": "How do I transfer my SPSS 24 license key to a new computer?\nI need to transfer my SPSS 24 license key to a new computer. I was able to download IBM® SPSS® Statistics Standard GradPack 24 for Windows (12-Mo Rental) onto the new computer, but every time I put in the activation code, I am met with this error message:\n\nAuthorization failed.: You are not allowed to generate any more new licenses.\nEnd Of Transaction.\nNo additional authorizations are permitted on this code.\nWhat should I do?",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To transfer your SPSS 24 license key to a new computer and resolve the authorization error, follow these steps:\n\n1. **Contact Your Vendor**: Since you are using the GradPack version, the first step is to reach out to the vendor from whom you purchased the software. They can assist you with licensing issues and may be able to reset your license or provide a new activation code. Here are some vendor options:\n   - Hearne: [Hearne Software Support](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub Support](http://onthehub.com/)\n   - StudentDiscounts.com: [StudentDiscounts Support](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd Support](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Check License Transfer Policy**: Ensure that you are following the correct procedure for transferring licenses as per the vendor's policy. Some licenses may have restrictions on how many times they can be activated.\n\n3. **Uninstall from Old Computer**: If you still have access to the old computer, uninstall SPSS from there to free up the license.\n\n4. **Reattempt Activation**: After contacting your vendor and following their guidance, try to activate SPSS again on your new computer.\n\nIf you continue to experience issues, the vendor will be your best resource for further assistance.",
    "id": "TECHQA_TRAIN_Q505_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q507",
    "question": "Why are the users unable to login to Web GUI 8.1 after I modify timeout to 2147483647 in security.xml file ?\nI followed the Web GUI 8.1 reference guide here to switching off the session timeout\n\nhttp://www-01.ibm.com/support/knowledgecenter/SSSHTQ_8.1.0/com.ibm.netcool_OMNIbus.doc_8.1.0/webtop/wip/task/web_adm_settimeout.html\n\nAfter I edited /config/cells/JazzSMNode01Cell/security.xml file, modified timeout setting to 2147483647, users are not able to login anymore.",
    "ground_truth": "1. Navigate to the **<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF** on DASH server.\n\n2. Take a backup of **consoleProperties.xml**.\n\n3. Open **consoleProperties.xml** in edit-mode.\n\n4. Change the value of **LTPAFIX** from true to false.\n\n5. Save the file.\n\n6. Restart the DASH server.",
    "answer": "The issue you're facing with users being unable to log into Web GUI 8.1 is due to setting the session timeout to a very large value (2147483647) in the `security.xml` file, which causes a conflict with JavaScript timeout calls used by DASH. To resolve this, follow these steps:\n\n1. Navigate to the following directory on your DASH server:  \n   `<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF`\n\n2. Take a backup of the `consoleProperties.xml` file.\n\n3. Open `consoleProperties.xml` in edit mode.\n\n4. Search for the line containing `LTPAFIX` and change the value from `\"true\"` to `\"false\"`.\n\n   Example:  \n   Before:  \n   `<consoleproperties:console-property id=\"LTPAFIX\" value=\"true\"/>`  \n   After:  \n   `<consoleproperties:console-property id=\"LTPAFIX\" value=\"false\"/>`\n\n5. Save the changes to the `consoleProperties.xml` file.\n\n6. Restart the DASH server.\n\nThis should resolve the login issues for the users.",
    "id": "TECHQA_TRAIN_Q507_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q512",
    "question": "Installing RAA plugin in RDz\nHi,\n\nI'm trying to install the RAA plugin in RDz.\n\nBut the installation manager mentions that it is not compatibble with an other package, in casu the IBM CICS Explorer SDK. But I would like to install both, is this not possible?",
    "ground_truth": "1. Find the jar files by opening the **RAAiInstallRepository.zip** file and looking in thepluginsfolder for these two files: **com.ibm.dmh.raai_*.jar**, **com.ibm.raa.integrate.doc_*.jar**\n\n2. Find the dropinssubdirectory.\n   \n3. Right click on the properties to find the shortcut used to start RDz.\n   \n4. Look at the Target property to see where **eclipse.exe** resides.\n   For example: C:\\Program Files\\IBM\\SDP.\n5. Create a dropinssubdirectory if one does not exist.\n   \n6. Copy the two jar files above to thedropinssubdirectory.\n   \n7. Restart RDz (Run as administrator).\n   \n8. Verify you have an **Asset Analyzer** entry in the left pane after RDz restarts by clicking on Window > Preferences from the menu.",
    "answer": "To install the RAA plugin in RDz while encountering compatibility issues with the IBM CICS Explorer SDK, you can manually install the RAA plugin by following these steps:\n\n1. **Locate the RAAi Installation Files**:\n   - Open the `RAAiInstallRepository.zip` file.\n   - Navigate to the `plugins` folder and find the following two jar files:\n     - `com.ibm.dmh.raai_*.jar`\n     - `com.ibm.raa.integrate.doc_*.jar`\n\n2. **Find the Dropins Subdirectory**:\n   - Right-click on the shortcut used to start RDz and select Properties.\n   - Check the `Target` property to find the location of `eclipse.exe`. For example, it might be located at `C:\\Program Files\\IBM\\SDP`.\n\n3. **Create the Dropins Subdirectory**:\n   - Navigate to the directory where `eclipse.exe` is located.\n   - Create a folder named `dropins` if it does not already exist.\n\n4. **Copy the Jar Files**:\n   - Copy the two jar files you found in step 1 into the `dropins` subdirectory you created in step 3.\n\n5. **Restart RDz**:\n   - Make sure to run RDz as an administrator when restarting.\n\n6. **Verify Installation**:\n   - After RDz restarts, check for the Asset Analyzer entry in the left pane by clicking on `Window > Preferences` from the menu.\n\nIf you wish to remove the RAA plugin later, simply delete the two jar files from the `dropins` subdirectory.\n\nThis method allows you to install the RAA plugin without conflicting with the IBM CICS Explorer SDK.",
    "id": "TECHQA_TRAIN_Q512_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q514",
    "question": "Why is WAS sending duplicate requests though our Portal application user clicks submit button only once?\nIs there any setting in WAS,Portal or IHS that can help prevent duplicate requests?",
    "ground_truth": "1. Use **ServerIOTimeoutRetry** to decrease the number of retries.",
    "answer": "To prevent duplicate requests in your Portal application when the submit button is clicked only once, you can consider the following actions:\n\n1. **Check for Client-Side Issues**: Ensure that the submit button is not being triggered multiple times due to client-side scripts or browser behavior. Implementing a client-side mechanism to disable the button after the first click can help.\n\n2. **Web Server Configuration**: Adjust the configuration of your web server (IBM HTTP Server) to limit the number of child processes and increase the number of threads per process. This can help manage incoming requests more effectively and reduce the chances of duplicate submissions.\n\n3. **Session Affinity Settings**: Ensure that your session management is correctly configured. If you are using Memory-to-Memory (M2M) session replication, set the `GetDWLMTable` property in the plug-in configuration to `\"true\"` to maintain session affinity.\n\n4. **Retry Settings**: Review the `ServerIOTimeoutRetry` setting introduced in plug-in apar PM70559. This setting controls the number of retries for requests that time out. Adjusting this may help reduce duplicate requests caused by timeouts.\n\n5. **Monitor and Log Requests**: Implement logging to monitor incoming requests and identify patterns that lead to duplicates. This can help in diagnosing the root cause.\n\nBy following these steps, you should be able to mitigate the issue of duplicate requests in your application. If the problem persists, further investigation into the application logic and server configurations may be necessary.",
    "id": "TECHQA_TRAIN_Q514_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q515",
    "question": "SPSS will not start on Mac\nI downloaded SPSS about 3 weeks ago. On the day when I downloaded it, it was working fine. Last week, I tried starting SPSS but it did not start. I tried reinstalling it, it still would not open. I've updated JAVA (thought this would be a problem), it slowly opened the program but then now that I have reinstalled it and entered in my code, I've used up my code and I have no authorization. But just now, I started SPSS and the same problem is happening. The IBM SPSS name screen appears but nothing happens.\n\n    SPSS would not start.\n\n    Even if it does start, I have licensing problems.",
    "ground_truth": "1. Delete the file: **com.ibm.spss.plist** on your Macintosh.",
    "answer": "To resolve the issue of SPSS not starting on your Mac, follow these steps:\n\n1. **Delete the Preferences File**:\n   - Open Finder and navigate to your Library folder:\n     - Click on the 'Home' (house) icon in the left-hand pane.\n     - Select the 'Go' menu at the top of the screen.\n     - Press the 'Option' key to reveal the 'Library' option and select it.\n   - Open the 'Preferences' folder.\n   - Locate the file named `com.ibm.spss.plist`.\n   - Rename it to `old_com.ibm.spss.plist` or delete it.\n\n   Alternatively, you can use the Terminal:\n   - Open the Terminal application.\n   - Type the following command and press Enter:\n     ```\n     rm -fR ~/Library/Preferences/com.ibm.spss.plist\n     ```\n\n2. **Restart Your Mac**:\n   - After deleting the preferences file, restart your computer.\n\n3. **Launch SPSS**:\n   - Open SPSS again. The first launch may take longer due to Java initialization, but subsequent launches should be quicker.\n\n4. **Check Licensing**:\n   - If you encounter licensing issues, ensure that you have a valid license code. If you've used up your code, you may need to contact IBM support for assistance with reauthorization.\n\nBy following these steps, you should be able to resolve the startup issue with SPSS on your Mac. If the problem persists, consider reaching out to IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q515_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q516",
    "question": "RecognizePageFieldsICR_C aborts with Page Type change\nI have an DeveloperWorks application that runs: Survey. In the application PageID Task there is a function that sets the Page Type to ReliefForm (based on a barcode)\n\nDoes anyone know why when I change the SetPageType to set another name, the RecognizePageFieldsICR_C in the Profiler Task aborts? If I put the name back the action runs fine.",
    "ground_truth": "1. Set the **c_cr** variable to **USA** prior to the call to recognition.",
    "answer": "The issue you're experiencing with the `RecognizePageFieldsICR_C` aborting when you change the Page Type likely stems from the ICR engine not recognizing the new Page Type you've set. When you change the Page Type, the corresponding recognition settings may not be configured for that new type, leading to the error.\n\nTo resolve this, ensure that the ICR engine is properly configured for the new Page Type. You can do this by setting the `c_cr` variable before calling the `RecognizePageFieldsICR_C` function. Here’s how you can do it:\n\n1. In Datacap Studio, before the call to `RecognizePageFieldsICR_C`, add the following line to set the `c_cr` variable to the appropriate value for your new Page Type. For example, if your new Page Type is still within the USA context, you would set it as follows:\n\n   ```plaintext\n   SaveAsCurrentObjVariable(\"c_cr\", \"USA\")\n   ```\n\n2. After setting the `c_cr` variable, proceed with the call to `RecognizePageFieldsICR_C`.\n\nBy ensuring that the `c_cr` variable is set correctly for the new Page Type, the ICR engine should be able to recognize the fields without aborting. If the problem persists, double-check that the new Page Type is properly defined and that all necessary recognition settings are in place.",
    "id": "TECHQA_TRAIN_Q516_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q517",
    "question": "Installed an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\nInstalled an STAP on a DB Server but it does not show up on my Appliance in S-TAP Control etc\n\nI get the following messages in the logs:-\n\n/tmp/guard_stap.stderr.txt on the DB Server :- \"Server wasn't heard from for nn sec during this attempt nnn sec total), closing and re-opening\"\n\nand from the Guardium Appliance - via fileserver in the /log/opt-ibm-guardium-log/snif/snif.log \"Unauthorized client connecting from ,rejecting\".\n\nHow do I correct the problem?",
    "ground_truth": "1. Uncheck the **Approval** box",
    "answer": "To resolve the issue of your STAP not showing up on the Appliance and the error messages in the logs, follow these steps:\n\n1. **Check the S-TAP Certification Settings**: Log into your Guardium Appliance and navigate to the S-TAP Certification screen.\n\n2. **Uncheck the Approval Needed Box**: Look for the option labeled \"S-TAP Approval Needed\" and ensure that it is unchecked. This setting can prevent STAPs from connecting properly.\n\n3. **Restart the STAP**: After making the change, restart the STAP on your DB Server to ensure it attempts to connect again.\n\n4. **Monitor the Logs**: Check the logs again after restarting to see if the connection issues persist. Look for any new error messages or confirmations of a successful connection.\n\nBy unchecking the approval box, the STAPs should start connecting to the Appliance without issues. If problems continue, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q517_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q520",
    "question": "OCR Results for Bold fonts\nHi all,\n\nI am having issue with extracting front that are bold, big front. May I know if Datacap have limitation on capturing metadata with big, bold front such as title of the document. I am using RecognizePageOCR_A for extraction of meta data and every other words were being extracted fine except those that are big. The attachment are the sample of front that could not be captured.",
    "ground_truth": "1. Verify that the newest recognition engine is being used.\n   Currently this can be achieved by using the **RecognizePageOCR_S** action from the **ocr_sr** library.",
    "answer": "It seems that the issue you're experiencing with extracting bold, large fonts in IBM Datacap is related to the \"Word too tall\" error. This occurs when the height of the word exceeds the configured limit for the OCR engine.\n\nTo resolve this issue, you can try the following steps:\n\n1. **Verify the Recognition Engine**: Ensure that you are using the latest recognition engine. You should be using the `RecognizePageOCR_S` action from the `ocr_sr` library.\n\n2. **Increase the Height Limit**: You can increase the maximum character height limit by using the `SetMaxCharacterHeightTMM(x)` function, where `x` is the height in pixels. The default limit is typically 64 pixels for 300 DPI. Adjust this value based on your needs.\n\n3. **Reduce Font Size**: If possible, consider reducing the size of the bold text in your document or lowering the DPI of the image to decrease the pixel height of the words.\n\nBy following these steps, you should be able to improve the OCR results for bold fonts in your documents.",
    "id": "TECHQA_TRAIN_Q520_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q521",
    "question": "Cannot open module in exclusive edit - (no such file or directory)\nHello.\n\nI have a module, that I can open normally, but when I try to open it in Exclusive Edit it tells me that \"no such file or directory\"\n\nWhat does this mean?",
    "ground_truth": "1. Upgrade to IBM Rational DOORS Version **9.4.0.1**",
    "answer": "The error message \"no such file or directory\" when trying to open a module in Exclusive Edit mode in IBM DOORS indicates that a user session file is likely corrupted on the database server. Here are the steps you can take to resolve this issue:\n\n1. **Check for Corrupted Session Files**: The error suggests that the session file `session.ixc` is missing or corrupted. You will need to retrieve this file from a backup if available.\n\n2. **Contact Support**: Since modifying files in the DOORS database can lead to data corruption, it is recommended to contact IBM Rational Support for assistance. Provide them with the `session.ixc` file from the module directory mentioned in the error message.\n\n3. **Repair the Session File**: Support will help you repair the session index file. This may require all users to log out and the DOORS database server to be shut down until the repaired file is returned and inserted.\n\n4. **Workaround**: If you have a backup of the missing session file, you can insert it into the module's `current.ver` directory. This can be done without restarting the database server, but it should only be performed by Rational Support to avoid data corruption.\n\n5. **Upgrade DOORS**: If you are using a version prior to 9.4.0.1, consider upgrading to this version or later, as the defect causing this issue has been resolved in that release.\n\nBy following these steps, you should be able to resolve the issue and open the module in Exclusive Edit mode.",
    "id": "TECHQA_TRAIN_Q521_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q524",
    "question": "I have an issues with V701 SCSQAUTH/SCSQANLE and MQ V8, my batch jobs receiving an ABEND (ABN=102-00000000).\nI have an issues with V701 SCSQAUTH/SCSQANLE and MQ V8, my batch jobs receiving an ABEND (ABN=102-00000000).",
    "ground_truth": "1. Correct the **STEPLIB** for the batch job to point to the **V7.1.0** libraries.\n   ",
    "answer": "To resolve the ABEND (ABN=102-00000000) issue with your batch jobs in MQ V8, you need to address the mismatch in code levels between the libraries being used and the queue manager version. Here are the steps to fix the problem:\n\n1. **Check the Current Libraries**: Verify that your batch job is currently using the V701 libraries (e.g., SCSQAUTH dataset).\n\n2. **Update the STEPLIB**: Modify the STEPLIB in your batch job to point to the V710 libraries instead. This is necessary because the V710 SCSQAUTH will allow your application to connect to both V710 and V701 queue managers.\n\n3. **Test the Batch Job**: After updating the STEPLIB, rerun your batch job to see if the issue is resolved.\n\nBy ensuring that your batch job uses the correct version of the libraries, you should be able to eliminate the ABEND 102 error. If you continue to experience issues, further investigation may be needed.",
    "id": "TECHQA_TRAIN_Q524_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q525",
    "question": "Can I change the ITCAM J2EE Agent Monitoring Level via the TEPS in version 7.1.1?\nIn the 7.1 version of the J2EE agent I could use the Agent Configuration to change the Monitoring Level for the agent- https://www.ibm.com/support/knowledgecenter/en/SS3JRN_7.2.0/com.ibm.itcamfapps_ad.doc_72/J2EE_agent_tema_install_guide/step10.html\n\nSo how can I change the Monitoring Level in the 7.1.1 agent?",
    "ground_truth": "1. Make a copy of the <hostname>_yj.xml file.\n   In the **$ITM_HOME/config** (Unix) directory or **%ITM_HOME%\\TMAITM6** (Windows), locate the <hostname>_yj.xml file and create a duplicate of this file.\n2. Stop the agent.\n\n3. Make changes to the parameters in the <hostname>_yj.xml file.\n\n4. Save the file.\n\n5. Restart the agent.",
    "answer": "To change the Monitoring Level in the J2EE agent version 7.1.1, you'll need to modify the relevant XML configuration files as the configuration panels no longer allow this option. Here are the steps:\n\n1. **Locate the Configuration File**:\n   - For Unix systems, navigate to `$ITM_HOME/config`.\n   - For Windows systems, navigate to `%ITM_HOME%\\TMAITM6`.\n   - Find the `<hostname>_yj.xml` file.\n\n2. **Create a Backup**: \n   - Make a copy of the `<hostname>_yj.xml` file to ensure you can revert to the original settings if needed.\n\n3. **Stop the Agent**: \n   - Before making changes, stop the J2EE agent.\n\n4. **Edit the XML File**:\n   - Open the `<hostname>_yj.xml` file with a text editor.\n   - Locate the parameters for Monitoring Level and Sampling Rate.\n   - Modify these values according to your requirements.\n\n5. **Save Changes**: \n   - Save the modified XML file.\n\n6. **Restart the Agent**: \n   - Start the agent again.\n\nThe new Monitoring Level and Sampling Rate will be applied once the agent is restarted. If you're deploying a new Weblogic application, make sure to stop the agent, modify the `<hostname>_yj_<wls_instance>.xml` file, and restart the agent.\n\nIf you have further questions or run into issues, please feel free to ask!",
    "id": "TECHQA_TRAIN_Q525_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q528",
    "question": "We have configured a new LDAP server in Atlas but why does authentication work for only some users ?\nWe have configured a new LDAP server in Atlas but why does authentication work for only some users ?",
    "ground_truth": "1. Ensure the user who failed to login exists in **Atlas** and is active.\n   \n2. If the user does not exist or is not active, create the corresponding user manually.\n",
    "answer": "To resolve the issue with LDAP authentication in Atlas where it works for only some users, verify the following:\n\n1. **User Existence**: Ensure that the users experiencing authentication failures exist in Atlas and are marked as active. \n\n2. **Manual Creation or Import**: If any users do not exist, either create them manually in Atlas or use the HR Loader to import users from the new LDAP server.\n\nBy following these steps, you should be able to resolve the authentication issues for the affected users.",
    "id": "TECHQA_TRAIN_Q528_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q537",
    "question": "Netcool/Impact 6.1.0: How to change the HSQLDB password?\nNetcool/Impact 6.1.0: How to change the HSQLDB password?",
    "ground_truth": "1. Run command: **SET PASSWORD <password>;**",
    "answer": "To change the HSQLDB password in Netcool/Impact 6.1.0, follow these steps:\n\n1. **Connect to the HSQLDB**: Use the command line to connect to your HSQLDB instance. The default server name is `NCI` and the port number is `5435`. The default password is blank.\n\n2. **Change the Password**: Once connected, issue the command:\n   ```\n   SET PASSWORD \"<new_password>\";\n   ```\n   Replace `<new_password>` with your desired password (make sure to use double quotes).\n\n3. **Update the DataSource**:\n   - **Method A (Encryption)**:\n     - Use `nci_crypt` to encrypt the new password.\n     - Edit the HSQLDB DataSource configuration file to replace the default encrypted password value with your new encrypted password.\n     - Restart the ImpactServer to apply the changes.\n\n   - **Method B (GUI)**:\n     - Alternatively, you can use the Impact configuration GUI to update the DataSource with the new password directly. This method does not require encryption or a server restart.\n\nBy following these steps, you will successfully change the HSQLDB password in Netcool/Impact 6.1.0.",
    "id": "TECHQA_TRAIN_Q537_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q538",
    "question": "Is ITCAM Data Collector for WebSphere 7.2.0.0.14 available?\nIs ITCAM Data Collector for WebSphere 7.2.0.0.14 available?",
    "ground_truth": "1. Go to the following URL: **http://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAM_DC-IF0014&includeSupersedes=0&source=fc**",
    "answer": "The ITCAM Data Collector for WebSphere version 7.2.0.0.14 is not mentioned in the provided context. The latest version listed is 7.2.0.0.11. If you need this specific version, I recommend contacting IBM Customer Support for further assistance.",
    "id": "TECHQA_TRAIN_Q538_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q543",
    "question": "RHEL7.2: CF servers crashed when db2cluster -cm -list -alert command issued\nEnvironment: DB2 11.1 GA / RHEL7.2\n\nWhenever I execute \"db2cluster -cm -list -alert\", 0x80090030 logged in db2diag.log on member nodes. Finally CF servers become STOPPED status with high probability.\n\n  2016-09-12-15.51.35.731323+540 I362836576E602       LEVEL: Severe  \n  PID     : 22991                TID : 70366596624816 PROC : db2sysc 0  \n  INSTANCE: db2inst1             NODE : 000           DB   : SAMPLE\n  HOSTNAME: pscale00.ibm.com  \n  EDUID   : 112                  EDUNAME: db2LLMn2 (SAMPLE) 0  \n  FUNCTION: DB2 UDB, RAS/PD component, pdLogCaPrintf, probe:876  \n  DATA #1 : <preformatted>  \n  NotifyConn_t.wait (PsGetNotification:) failed: 0x80090030  \n  DATA #1 : <preformatted>  \n  If a CF return code is displayed above and you wish to get  \n  more information then please run the following command:  \n    \n  db2diag -cfrc <CF_errcode>",
    "ground_truth": "1. Add the setting **RemoveIPC=no** to file **/etc/systemd/logind.conf**",
    "answer": "The issue you're experiencing with the `db2cluster -cm -list -alert` command causing CF servers to crash is related to a known bug in RHEL 7.2, where the logind service removes IPC resources owned by the user when they log off. This results in the error code 0x80090030 being logged in the `db2diag.log`.\n\nTo resolve this issue, you can apply the following local fix:\n\n1. Open the logind configuration file in a text editor:\n   ```bash\n   sudo vi /etc/systemd/logind.conf\n   ```\n\n2. Add or modify the following line in the file:\n   ```plaintext\n   RemoveIPC=no\n   ```\n\n3. Save the changes and exit the editor.\n\n4. Restart the logind service to apply the changes:\n   ```bash\n   sudo systemctl restart systemd-logind\n   ```\n\nAfter making this change, try running the `db2cluster -cm -list -alert` command again to see if the issue is resolved. If the problem persists, further investigation may be required.",
    "id": "TECHQA_TRAIN_Q543_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q544",
    "question": "Unable to login to TEP with TEPS LDAP authentication\nTEPS LDAP has been configured correctly. User id can be searched successfully in eWAS.\n\nThe login appears to be attempting to authenticate with the HUB TEMS rather than going through Websphere to contact the LDAP server.",
    "ground_truth": "1. Remove the TEPS variable **KFW_AUTHORIZATION_USE_EWAS** from the **KFWENV**.\n\n2. Restart the TEPS.\n\n3. Verify that all users can log in.",
    "answer": "To resolve the issue of being unable to log in to TEP with TEPS LDAP authentication, follow these steps:\n\n1. **Remove the TEPS Variable**: Locate the TEPS environment variable `KFW_AUTHORIZATION_USE_EWAS` in your KFWENV configuration.\n\n2. **Restart TEPS**: After removing the variable, restart the TEPS service to apply the changes.\n\n3. **Verify Login**: Once the TEPS has restarted, attempt to log in again with the affected user accounts to check if the issue is resolved.\n\nThis should allow the authentication process to correctly go through WebSphere and contact the LDAP server, enabling successful logins for all users.",
    "id": "TECHQA_TRAIN_Q544_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q545",
    "question": "Netcool/Impact 6.1.0: SelfMonitoring events are being incorrectly cleared by OMNIbus GenericClear Automation\nNetcool/Impact 6.1.0: SelfMonitoring events are being incorrectly cleared by OMNIbus GenericClear Automation\n\nWhen there are multiple SelfMonitoring events reporting stopped Impact Services and one of those Impact Services is restarted the resolution event is used by the OMNIbus GenericClear (and DeleteClears) Automations to delete ALL the events.",
    "ground_truth": "1. Upgrade to **Fix Pack 1** or higher.\n",
    "answer": "To resolve the issue of SelfMonitoring events being incorrectly cleared by the OMNIbus GenericClear Automation in Netcool/Impact 6.1.0, you have a couple of options:\n\n1. **Upgrade to Fix Pack 1 or higher**: The simplest and most effective solution is to upgrade your Netcool/Impact to Fix Pack 1 (6.1.0-TIV-NCI-FP0001) or a later version. This fix addresses the issue where the alert key value for SelfMonitoring events does not include service details, which leads to incorrect clearing of events.\n\n2. **Create a PolicyActivator**: If upgrading is not immediately feasible, you can create a PolicyActivator that polls at a higher rate than the GenericClear Automation. This Policy should extract the service name from the Summary field of the events and append it to the Agent field. This modification will help the GenericClear Automation uniquely identify and correlate Problem and Resolution events, preventing the incorrect clearing of all SelfMonitoring events.\n\nFor more detailed information, you can refer to APAR IV13297, which documents this issue and its resolution. \n\nMake sure to implement one of these solutions to prevent the unwanted clearing of your SelfMonitoring events.",
    "id": "TECHQA_TRAIN_Q545_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q547",
    "question": "Do I need to manually apply SDA function for ITCAM for SOA 7.2 FP1 ifix 5?\nThe SDA function for ITCAM for SOA 7.2 FP1 ifix 5 works for TEMS but IS NOT coded to work for TEPS. User is required to manually apply the support files on TEPS for this version (ifix 5).\n\ndoes this need a manual apply for TEPS only for SOA 7.2, FP1 and ifix 5 ?\"",
    "ground_truth": "1. User has to manually apply SOA **7.2 FP1 ifix 5** support files on TEPS.",
    "answer": "Yes, you need to manually apply the support files for TEPS for ITCAM for SOA 7.2 FP1 ifix 5. The SDA function is only coded to work for TEMS, so it does not automatically update TEPS. You must apply the support files manually for this version.",
    "id": "TECHQA_TRAIN_Q547_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q549",
    "question": "What does the end-file-message mean while doing a launchpad.sh in the MS\"\nI am getting an end-file-message means while doing a launchpad.sh in the MS. How do I solve the problem?",
    "ground_truth": "1. Use the commands shown below to verify you have them installed.\n   \n2. If not installed, contact your **Linux system administrator** and install these required libraries.\n   ",
    "answer": "The \"end-file-message\" you are encountering while running `launchpad.sh` indicates that there are missing Linux system libraries, specifically the compat-libstdc++ or libstdc++ libraries, which are often required for the installer to function properly.\n\nTo resolve this issue, follow these steps:\n\n1. **Check for Missing Libraries**: Use the following commands to verify if the required libraries are installed:\n   ```bash\n   rpm -qa | grep compat-libstdc++\n   rpm -qa | grep libstdc++\n   ```\n\n2. **Install Missing Libraries**: If you find that the libraries are missing, you can install them using your package manager. For example, on RHEL, you can use:\n   ```bash\n   sudo yum install compat-libstdc++-33\n   sudo yum install libstdc++-32\n   ```\n\n3. **Run the Installer in Console Mode**: If the graphical mode still fails, try running the installer in console mode by using the following command:\n   ```bash\n   ./launchpad.sh -console\n   ```\n   or for silent installation:\n   ```bash\n   ./silent_MS_linux.bin -silent\n   ```\n\nIf you continue to experience issues after ensuring the libraries are installed, please consult your Linux system administrator for further assistance.",
    "id": "TECHQA_TRAIN_Q549_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q552",
    "question": "How to export key from SSL certificate in IBM HTTP Server 7; getting restricted policy error\nWe're trying to export our IHS 7 SSL key to PKCS12 format so we can use it on our Load Balancer, but it fails with some policy error:\n\n     $/usr/IBM/HTTPServer/bin/gsk7cmd -cert -export -db /usr/IBM/HTTPServer/ssl/key.kdb -pw #### -label \"domain1\" -type cms -target /tmp/domain1.p12 -target_type PKCS12 -target_pw ####\n     \n     The command cannot complete because your JRE is using restricted policy files.\n\nSame error happens in Ikeyman tool. Any ideas?",
    "ground_truth": "1. Download and install a later Java 32-bit x86 AMD/Intel Java SDK.\n   Access the WebSphere Support web site at **http://www-01.ibm.com/support/docview.wss?rs=180&uid=swg24023707** and download the Java SDK. Then, install the SDK into the IBM HTTP Server java and plug-ins java folder.",
    "answer": "To resolve the \"restricted policy\" error when exporting your SSL key to PKCS12 format in IBM HTTP Server 7, follow these steps:\n\n1. **Locate the Restricted JCE Policy Files**:\n   Navigate to the directory: `<ihsinst>/java/jre/lib/security/`.\n\n2. **Rename and Move the Restricted Files**:\n   - Move the following files to a directory outside the JDK class path:\n     - `local_policy.jar`\n     - `US_export_policy.jar`\n\n3. **Download Unrestricted JCE Policy Files**:\n   - Download the unrestricted JCE policy files that correspond to your Java version from the IBM support site. Ensure you select the correct version based on your Java SR version (you can check this by running `java -version`).\n\n4. **Replace the Restricted Files**:\n   - Place the downloaded unrestricted JCE policy files into the `<ihsinst>/java/jre/lib/security/` directory, ensuring they are named `local_policy.jar` and `US_export_policy.jar`.\n\n5. **Restart the Ikeyman Utility**:\n   - After replacing the files, restart the Ikeyman utility to ensure it picks up the new unrestricted JCE policy files.\n\nBy following these steps, you should be able to export your SSL key without encountering the restricted policy error.",
    "id": "TECHQA_TRAIN_Q552_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q555",
    "question": "SPSS free trial not working on MAC - gets stuck in when it should be launching and goes nowhere\nI downloaded the SPSS software on my mac running Yosemite 10.10.5. The trial was activated by IBM, they sent me several emails stating this.\n\nSo I tried to launch the app and get stuck here alt text There is no progress after an hour; and I tried to launch several times, it never gets out of this screen.",
    "ground_truth": "1. Install Statistics 22 **Fixpack 2**.",
    "answer": "To resolve the issue with SPSS not launching on your Mac running Yosemite (10.10.5), follow these steps:\n\n1. **Install Statistics 22 FixPack 2**: Since you are using SPSS Statistics 22, you need to install FixPack 2 to ensure compatibility with Yosemite. You can find it on the IBM support website.\n\n2. **Reinstall Apple Java 6**: It may be necessary to reinstall the legacy Apple Java 6 for SPSS to function properly on Yosemite. You can download it from the Apple support website [here](http://support.apple.com/kb/dl1572).\n\n3. **Check for Updates**: Ensure that your SPSS software is fully updated. Sometimes, updates can resolve launch issues.\n\n4. **Restart Your Mac**: After making the above changes, restart your Mac to ensure all updates and installations take effect.\n\n5. **Try Launching SPSS Again**: After the restart, attempt to launch SPSS again.\n\nIf the problem persists after following these steps, you may need to contact IBM support for further assistance.",
    "id": "TECHQA_TRAIN_Q555_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q557",
    "question": "How do I resolve a performance issue with my applicaiton running on a DB2 client as a result of low level segement calls issued by DB2?\nCurrently experiencing a performance issue with an application running on a DB2 client, the stack traces reveals that multiple segment() calls are being issued by DB2 and they are failing. What can be done to resolve this issue?",
    "ground_truth": "1. Issue the command at the DB2 client.\n   Type and execute the command **db2trc alloc** in the DB2 client terminal. The command will allocate the necessary IPC resources to prevent failures of **semget()** calls.\n",
    "answer": "To resolve the performance issue with your application running on a DB2 client that's related to low-level `semget()` calls, follow these steps:\n\n1. **Run the Command:** At the DB2 client, execute the following command:\n   ```\n   db2trc alloc\n   ```\n   This command allocates the necessary Inter Process Communication (IPC) resources that DB2 needs, which will prevent the `semget()` calls from failing.\n\n2. **Add to Startup Script:** Since you will need to run the `db2trc alloc` command each time the client is restarted, it's advisable to add this command to your startup script to ensure it runs automatically whenever the client is launched.\n\n3. **Verify with Truss:** To confirm that the application is issuing `semget()` calls, you can use `truss`. Consult your operating system's documentation on how to perform and interpret a `truss` command.\n\nBy executing these steps, you should see an improvement in your application's performance and a reduction in the failing `semget()` calls.",
    "id": "TECHQA_TRAIN_Q557_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q561",
    "question": "I am getting an error when attempting to apply CF09 on Portal 8001 on a secondary cluster node\nThe ConfigTrace.log shows the following....\n\n     [wsadmin] com.ibm.websphere.management.exception.AdminException:\n     ADMA5026E: No valid target is specified in ObjectName\n     WebSphere:cell=<cellname>,node=<nodename>,server=webserver1 for\n     module ilwwcm-authoring.war+WEB-INF/web.xml.\n       [wsadmin] ADMA5026E: No valid target is specified in ObjectName\n     WebSphere:cell=<cellname>,node=<nodename>,server=webserver1 for\n     module ilwwcm-authoring.war+WEB-INF/web.xml.",
    "ground_truth": "1. Ensure the remote Dmgr is started prior to the upgrade.\n   \n2. Verify the Dmgr profile name.\n   Navigate to the Dmgr's **AppServer/bin** folder and execute the command: **./manageprofiles.sh|bat -listProfiles**.\n3. Pass in the correct Dmgr profile name according to the installation option.",
    "answer": "To resolve the error you are encountering when applying CF09 on Portal 8001 on a secondary cluster node, follow these steps:\n\n1. **Ensure the Deployment Manager (Dmgr) is Running**: The error indicates that the wsadmin script is unable to connect to the Dmgr. If you are using a remote Dmgr, make sure it is started before attempting the upgrade. If you are using a local Dmgr, ensure it is running as well.\n\n2. **Check the Dmgr Profile Name**: If the Dmgr was stopped during the upgrade, verify the correct Dmgr profile name. Navigate to the Dmgr's `AppServer/bin` folder and execute the following command:\n   ```bash\n   ./manageprofiles.sh|bat -listProfiles\n   ```\n   Ensure that the profile name you are using matches one of the listed profiles.\n\n3. **Set the Correct Connection Type**: The `wsadminConnType` should be set to SOAP for a cluster. If it is set to NONE, you will need to adjust this setting.\n\n4. **Retry the Upgrade**: After ensuring the Dmgr is running and the correct profile name is being used, attempt to apply the CF09 upgrade again.\n\nBy following these steps, you should be able to resolve the ADMA5026E error and successfully apply the fix pack. If the issue persists, please provide additional details for further assistance.",
    "id": "TECHQA_TRAIN_Q561_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q569",
    "question": "Authorization failed.: The Authorization Code entered is not for this product/version.\nIf you have multiple Authorization Codes, please check you have entered the correct one.",
    "ground_truth": "1. Check that your authorization code matches the version and software product you are trying to license.\n\n2. Visit the Predictive Analytics Community Get Help page.\n   Access the webpage at **https://developer.ibm.com/predictiveanalytics/get-help/** for assistance with your authorization codes, including direct links to the **License Key Center** and information about Support options.",
    "answer": "To resolve the \"Authorization failed\" error message, follow these steps:\n\n1. **Verify Authorization Code**: Ensure that the authorization code you are entering matches the specific product and version of IBM SPSS Statistics or Modeler that you have installed. \n\n2. **Check for Multiple Codes**: If you have multiple authorization codes, double-check that you are using the correct one for the installed version of the software.\n\n3. **Visit Support Resources**: For further assistance, you can visit the Predictive Analytics Community Get Help page at [IBM Predictive Analytics Help](https://developer.ibm.com/predictiveanalytics/get-help/) for direct links to the License Key Center and additional support options.\n\n4. **Contact Support**: If you continue to experience issues, consider reaching out to IBM support or visiting the Statistics forum for more help: [IBM Statistics Forum](https://developer.ibm.com/answers/topics/statistics.html?smartspace=predictive-analytics).\n\nBy ensuring the authorization code matches your product version and utilizing the provided resources, you should be able to resolve the issue.",
    "id": "TECHQA_TRAIN_Q569_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q577",
    "question": "My SystemOut.log is overfilled by messages SECJ0371W (LTPA token expired). I am sick and tired of them. Can I disable them?\nMy SystemOut.log is overfilled by messages SECJ0371W (LTPA token expired). I am sick and tired of them. Can I disable them?",
    "ground_truth": "1. Set the security custom property **com.ibm.websphere.security.ltpa.disableSECJ0371W** to **true** in order to disable future logging of the **SECJ0371W** message.",
    "answer": "To disable the SECJ0371W (LTPA token expired) messages from being logged in your SystemOut.log, you can set a security custom property in your IBM WebSphere Application Server. \n\nHere are the steps to do this:\n\n1. Access the WebSphere Application Server administrative console.\n2. Go to **Security** > **Global security**.\n3. Under the **User account** settings, look for **Custom properties**.\n4. Add a new property with the following details:\n   - **Name:** `com.ibm.websphere.security.ltpa.disableSECJ0371W`\n   - **Value:** `true`\n5. Save your changes and restart the server for the changes to take effect.\n\nThis setting will disable future logging of the SECJ0371W messages. \n\nMake sure that you are using at least WebSphere Application Server fix pack 8.0.0.13 or 8.5.5.10 for this property to be recognized.",
    "id": "TECHQA_TRAIN_Q577_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q580",
    "question": "WebSphere MQ Hypervisor Edition requires customer action for the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423)\nWebSphere MQ Hypervisor Edition requires customer action for the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423)\nWhere can I find additional information on what action is required?",
    "ground_truth": "1. Contact **Red Hat** to obtain fixes.\n\n2. Install fixes for Red Hat Enterprise Linux (RHEL).",
    "answer": "To address the GNU C library (glibc) vulnerabilities (CVE-2015-1472 & CVE-2013-7423) in WebSphere MQ Hypervisor Edition, you should contact Red Hat to obtain the necessary fixes for Red Hat Enterprise Linux (RHEL). \n\nFor additional information, you can refer to the following resources:\n- Red Hat vulnerabilities by CVE name: [Red Hat CVE Database](https://access.redhat.com/security/cve/)\n- IBM support document for further details: [IBM Support Document](http://www.ibm.com/support/docview.wss?uid=swg21903158)\n\nMake sure to apply the recommended fixes as soon as possible to mitigate the vulnerabilities.",
    "id": "TECHQA_TRAIN_Q580_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q581",
    "question": "OOM exception thrown when trying to configure an ITCAM for WAS 7.2 Data Collector\nI am trying to configure an ITCAM for WAS 7.2.0.0.x DC using config.sh, but getting OOM exceptions, as following:\n\n./config.sh\n\nLog file name: /opt/IBM/ITM/dchome/7.2.0.0.10/data/config-trace.log.\n\nList of TCP/IP interfaces discovered:\n\n       1. ...\n     Enter a number [default is: 1]:\n     1\n     JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2017/08/22 12:27:03 - please wait.\n....\n     java.lang.OutOfMemoryError: java.lang.OutOfMemoryError: Java heap space\n\nLooking at the javacore.txt files, I can see that this is the command throwing an OOM\n\n1CICMDLINE /opt/IBM/ITM/JRE/aix526/bin/java -classpath /opt/IBM/ITM/dchome/7.2.0.0.10/bin/jython/jython.jar:/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib/installbundle.jar -Xms256m -Xmx256m -Dpython.path=/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib:/opt/IBM/ITM/dchome/7.2.0.0.10/bin/lib org.python.util.jython /opt/IBM/ITM/dchome/7.2.0.0.10/bin/config.py\n\nHow could I solve this?",
    "ground_truth": "1. Make a backup of the config.sh file.\n\n2. Edit the config.sh file.\n\n3. Search for the following line **JAVA_OPTS** in the config.sh file.\n\n4. Change the **JAVA_OPTS=\"-Xms256m -Xmx256m\"** to a higher value.\n\n5. Save the file.\n\n6. Restart the config.",
    "answer": "To resolve the OutOfMemoryError (OOM) exception you are encountering while configuring the ITCAM for WAS 7.2 Data Collector, you need to increase the Java heap size settings in the `config.sh` script. Here are the steps to do this:\n\n1. **Backup the config.sh file**: Before making any changes, create a backup of the `config.sh` file to ensure you can restore it if needed.\n\n   ```bash\n   cp /opt/IBM/ITM/dchome/7.2.0.0.10/bin/config.sh /opt/IBM/ITM/dchome/7.2.0.0.10/bin/config.sh.bak\n   ```\n\n2. **Edit the config.sh file**: Open the `config.sh` file in a text editor.\n\n   ```bash\n   vi /opt/IBM/ITM/dchome/7.2.0.0.10/bin/config.sh\n   ```\n\n3. **Locate the JAVA_OPTS line**: Search for the line that starts with `JAVA_OPTS`. It should look like this:\n\n   ```bash\n   JAVA_OPTS=\"-Xms256m -Xmx256m\"\n   ```\n\n4. **Increase the heap size**: Change the values to a higher setting, for example:\n\n   ```bash\n   JAVA_OPTS=\"-Xms512m -Xmx512m\"\n   ```\n\n5. **Save the changes**: Save the file and exit the text editor.\n\n6. **Restart the configuration**: Run the `config.sh` script again to see if the issue is resolved.\n\n   ```bash\n   ./config.sh\n   ```\n\nBy increasing the heap size, you should be able to avoid the OutOfMemoryError and successfully configure the ITCAM Data Collector. If you continue to experience issues, consider increasing the heap size further.",
    "id": "TECHQA_TRAIN_Q581_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q582",
    "question": "Problems downloading SPSS Statistics Premium Grad Pack v.24- Mac\nPurchased SPSS Statistics Premium Grad Pack v.24. for Mac from THINKedu.com. Have tried a dozen times to download it but fails. Tried using wifi, direct ethernet connection, Firefox, Safari, and Chrome incognito, with no other programs running in background. Have purchased previous versions from another vendor multiple times without an issue. THINKedu would not offer additional support, directing me to contact IBM instead. IBM Software Support @ (919) 864-3512 said \"there is no phone support for students for SPSS\" and directed me to ask a question here instead. Saw a suggestion for an installer on another post; seems to lead to a trial version- is that the best idea?",
    "ground_truth": "1. Go to the **Free Trial** Version.",
    "answer": "To resolve your issue with downloading SPSS Statistics Premium Grad Pack v.24 for Mac, follow these steps:\n\n1. **Check Your Purchase Confirmation**: Ensure you have the correct download link or access credentials provided by THINKedu.com after your purchase.\n\n2. **Use the IBM Passport Advantage Website**: Go to the IBM Passport Advantage Web Site [here](http://www.ibm.com/software/howtobuy/passportadvantage/paocustomer/sdma/SDMA?PO=DOWNLOAD_FIND_BY_PART_NUMBER). Look for the specific version you purchased (SPSS Statistics Desktop 24.0 for Mac OS Multilingual eAssembly CRZ10ML).\n\n3. **Download the Correct File**: Make sure you are downloading the correct file for your operating system. For Mac, you should look for the eAssembly file labeled as \"CRZ10ML\".\n\n4. **Disable Security Software Temporarily**: If you have antivirus or firewall software running, try temporarily disabling it, as it may interfere with the download.\n\n5. **Try a Different Network**: If possible, try downloading from a different network (e.g., a friend's house or a public Wi-Fi) to rule out any network-related issues.\n\n6. **Clear Browser Cache**: Clear your browser's cache and cookies, then attempt the download again.\n\n7. **Use a Different Browser**: Although you've tried multiple browsers, ensure you are using the latest version of each browser. Sometimes, using a different browser can help.\n\n8. **Check for System Updates**: Ensure your Mac is up to date with the latest software updates, as this can sometimes resolve compatibility issues.\n\nIf these steps do not resolve the issue, you may want to consider reaching out to IBM support through their online support channels or forums, as they may have additional resources or solutions specific to your situation.",
    "id": "TECHQA_TRAIN_Q582_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q584",
    "question": "Help with Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with WSRR (CVE-2017-1741)\nI need to understand details regarding Security Bulletin: Vulnerability identified in IBM WebSphere Application Server shipped with IBM WebSphere Service Registry and Repository (CVE-2017-1741). We are running WAS traditional V9.0.0.0.  What is the recommended fix?",
    "ground_truth": "1. Upgrade to a minimal fix pack levels as required by interim fix and then apply Interim Fix **PI89498**.\n   Visit the link **http://www-01.ibm.com/support/docview.wss?uid=swg24044512** to find the necessary information.",
    "answer": "To address the vulnerability identified in IBM WebSphere Application Server (CVE-2017-1741) for your version (WAS traditional V9.0.0.0), you should take the following steps:\n\n1. **Upgrade to a Fix Pack**: Upgrade your WebSphere Application Server to at least Fix Pack 9.0.0.7 or later. This is crucial to ensure that you have the latest security updates.\n\n2. **Apply Interim Fix**: If you prefer not to upgrade to the latest Fix Pack immediately, you can apply Interim Fix PI89498. Make sure to check the specific requirements for your current version and apply any necessary interim fixes or updates.\n\n3. **Monitor Security Bulletins**: Subscribe to IBM's notifications for future security bulletins to stay informed about any new vulnerabilities and fixes.\n\nFor detailed instructions on applying the fix or for further assistance, refer to the IBM support documentation or contact IBM support directly.",
    "id": "TECHQA_TRAIN_Q584_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q585",
    "question": "Minimum Size of QR Code for Datacap to identify correctly\nWhat is the recommended minimum size of the barcode for the Datacap to identify it properly.",
    "ground_truth": "1. Ensure the width of the thinnest bar (X-dimension) is at least one pixel, and two pixels are recommended for best results.\n   At **200** DPI, each bar must be at least .01 inch wide, which typically translates to about 4 to 5 characters per inch.\n2. Set the X-dimension or width of the narrowest black bar and white space between bars to at least 20 mils.\n   This is equivalent to 1/50 inch or 1/2 mm. When scanned perfectly, this would result in 4 pixels at 200 DPI and 6 pixels at 300 DPI.\n3. For Code 39 symbols, use a **20** mil X-dimension for a density of approximately **3.6** characters per inch.\n   The optimal height should be at least 1/4 inch or 15% of the width, whichever is greater, though this is not an absolute requirement. The minimum quiet zone (white space before and after the bar code) specified by the standard is 1/5 inch.",
    "answer": "The recommended minimum size for a QR code to be correctly identified by IBM Datacap is that the width of the thinnest bar (X-dimension) should be at least 20 mils (1/50 inch, or 1/2 mm). This translates to a minimum of 4 pixels at 200 DPI and 6 pixels at 300 DPI. Additionally, ensure that the height of the QR code is at least 1/4 inch or 15% of the width, whichever is greater, and maintain a minimum quiet zone (white space) of 1/5 inch before and after the barcode.",
    "id": "TECHQA_TRAIN_Q585_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q587",
    "question": "Why can't I connect to HTTPS server using Installation Manager 1.7.2?\nWhen using IBM Installation Manager 1.7.2 to connect to a HTTPS server, I get the following message:\n\nThe following repositories are not connected: https://www.ibm.com/software/repositorymanager/service/com.ibm. websphere.ND.v85/8.5.5.2.\n\nWhen I try to hit the URL, I get a 404 error.",
    "ground_truth": "1. Update IBM Installation Manager to version **1.7.4**, **1.8** or newer.",
    "answer": "The issue you're encountering is due to the version of IBM Installation Manager you're using (1.7.2), which does not support connecting to HTTPS servers that have SSL security protocol disabled. To resolve this, you should update your IBM Installation Manager to at least version 1.7.4 or, preferably, to version 1.8 or newer. This will provide the necessary support for the TLS protocol, allowing you to connect to the HTTPS server. You can download the updated version from the IBM support site.",
    "id": "TECHQA_TRAIN_Q587_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q589",
    "question": "How to have IBM HTTP Server re-direct an application URL from HTTPS to HTTP?\nWe have an application which uses SSL, but we need to make this http only. We disabled all the SSL, but many clients URLs are still pointing to https. So we need a HTTP Server redirect to change these URLs from https to http. Is this possible?",
    "ground_truth": "1. Make sure the LoadModule line for mod_rewrite is uncommented in the httpd.conf\n   Check the httpd.conf file and ensure that the following line is not commented out: **LoadModule rewrite_module modules/mod_rewrite.so**\n2. Add the specified lines to the global scope or any port 80 VirtualHost stanzas in the httpd.conf\n   Include the following lines in the global scope or in any defined port 80 VirtualHost sections of the httpd.conf:\n   - **RewriteEngine on**\n   - **RewriteCond %{SERVER_PORT} =80**\n   - **RewriteRule ^(.*) https://%{SERVER_NAME}%{REQUEST_URI} [R,L]**\n3. Restart the IBM HTTP Server after making the preceding changes\n   ",
    "answer": "To redirect application URLs from HTTPS to HTTP using the IBM HTTP Server, you can utilize the `mod_rewrite` module. Here’s how to set it up:\n\n1. **Ensure `mod_rewrite` is enabled**: Open your `httpd.conf` file and make sure the following line is uncommented:\n   ```\n   LoadModule rewrite_module modules/mod_rewrite.so\n   ```\n\n2. **Add rewrite rules**: In the same `httpd.conf` file, add the following lines to the global scope or within the port 80 VirtualHost section:\n   ```apache\n   RewriteEngine on\n   RewriteCond %{HTTPS} on\n   RewriteRule ^(.*)$ http://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]\n   ```\n\n   This configuration checks if the request is using HTTPS and redirects it to the same URL using HTTP.\n\n3. **Restart the server**: After making these changes, restart the IBM HTTP Server to apply the new configuration.\n\n4. **Test the redirect**: Ensure that when you access the application URL with HTTPS, it correctly redirects to HTTP.\n\nBy following these steps, you should be able to redirect all HTTPS requests to HTTP effectively.",
    "id": "TECHQA_TRAIN_Q589_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q595",
    "question": "How can I configure a DataPower MQ client to use mutual authentication with SSL?\nI am looking to setup a DataPower MQ Client to use SSL in mutual authentication mode with a Remote WebSphere MQ Manager.",
    "ground_truth": "1. Configure WebSphere MQ **Queue Manager** (Remote MQ Server) to use SSL authentication.\n\n2. Configure WebSphere MQ Client to use SSL authentication.\n   \n3. Verify that WebSphere MQ Client can PUT/GET message(s).\n   Use application programs such as **amqsputc** and **amqsgetc** with the MQ Queue Manager to test the SSL mutual authentication mode.",
    "answer": "To configure a DataPower MQ client to use mutual authentication with SSL for a Remote WebSphere MQ Manager, follow these steps:\n\n1. **Prerequisites**: Ensure that the WebSphere MQ Queue Manager is configured to use SSL authentication with `SSLCAUTH` set to \"required\". Refer to the IBM documentation for detailed steps on this configuration: [WebSphere MQ SSL Configuration](http://publib.boulder.ibm.com/infocenter/wmqv7/v7r0/topic/com.ibm.mq.explorer.doc/e_ssl.htm).\n\n2. **Upload Key Files**: Upload the `key.kdb` and `key.sth` files to the `cert:` directory of your DataPower appliance.\n\n3. **Configure MQ Client Object**:\n   - Access the DataPower management interface.\n   - Locate the MQ client object (mq-qm object) that you want to configure.\n   - Set the key database to use the uploaded `key.kdb` file located in the `cert:` directory.\n   - Ensure that the cipher specification is set appropriately (e.g., `TRIPLE_DES_SHA_US`).\n\n4. **SSL Proxy Profile**: If you are using DataPower firmware 3.8.2 or later, you can also create an SSL Proxy Profile that includes a Crypto profile with Identification Credential. For more details, refer to the DataPower InfoCenter:\n   - [SSL Proxy Profile for Fixpack V7.1.0.x](https://www.ibm.com/support/knowledgecenter/SS9H2Y_7.1.0/com.ibm.dp.doc/mq_securingwithansslproxyprofileobject.html)\n   - [SSL Proxy Profile for Fixpack V7.2.0.x](https://www.ibm.com/support/knowledgecenter/SS9H2Y_7.2.0/com.ibm.dp.doc/mq_securingwithansslproxyprofileobject.html)\n\n5. **Testing**: Verify that the WebSphere MQ Client can successfully PUT/GET messages using application programs like `amqsputc` and `amqsgetc` with the MQ Queue Manager in SSL mutual authentication mode.\n\nBy following these steps, you should be able to configure your DataPower MQ client for mutual authentication with SSL.",
    "id": "TECHQA_TRAIN_Q595_1"
  },
  {
    "question_id": "TECHQA_TRAIN_Q597",
    "question": "How do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator, to fit content by height or width?\nHow do I change the default 'fit content by' behaviour of Daeja viewer in IBM Content Navigator v2.0.2, to fit content by height or width?",
    "ground_truth": "1. Set the value of the parameter 'scale' in the **..navigator.war/applets/filenetViewer_properties.jsp** file.\n   To fit content by width, specify - **scale: \"ftow\"**, To fit content by height, specify - **scale: \"ftoh\"**.\n2. Save the changes.\n   The changes should be picked up when the viewer is re-launched.",
    "answer": "To change the default 'fit content by' behavior of the Daeja viewer in IBM Content Navigator v2.0.2, follow these steps:\n\n1. Open the file located at `..navigator.war/applets/filenetViewer_properties.jsp`.\n2. Set the value of the parameter 'scale':\n   - To fit content by width, use: `scale: \"ftow\"`\n   - To fit content by height, use: `scale: \"ftoh\"`\n\n3. Alternatively, you can make the same changes in the `filenetViewer_properties.jsp` file located under `ECMClient\\configure\\explodedformat\\navigator\\applets`.\n4. After making the changes, rebuild and redeploy the EAR file.\n5. Restart the application server.\n\nOnce these steps are completed, the changes will take effect the next time the viewer is launched.",
    "id": "TECHQA_TRAIN_Q597_1"
  },
  {
    "question_id": "TECHQA_DEV_Q002",
    "question": "Unable to open profile from P8 Content Engine Configuration manager (CMUI) on Redhat Linux 7.2, getting GPF and javacore dump.\nLaunch configmgr then try to open an existing profile. Once I click ok on the dialog box to\n\"Verify your application server setting before proceeding...\" Configuration manager would crash and GPF. I can see the javacore.txt and dmp file created.\nThe javacore.txt contains the following:\n\n0SECTION TITLE subcomponent dump routine NULL =============================== 1TICHARSET UTF-8 1TISIGINFO Dump Event \"gpf\" (00002000) received 1TIDATETIME Date: 2016/05/05 at 04:53:30 1TIFILENAME Javacore filename: /opt/IBM/FileNet/ContentEngine/tools/configure/javacore.20160505.045330.25035.0002.txt 1TIREQFLAGS Request Flags: 0x81 (exclusive+preempt) 1TIPREPSTATE Prep State: 0x100 (trace_disabled) 1TIPREPINFO Exclusive VM access not taken: data may not be consistent across javacore sections NULL ------------------------------------------------------------------------ 0SECTION GPINFO subcomponent dump routine NULL ================================ 2XHOSLEVEL OS Level : Linux 3.10.0-327.13.1.el7.x86_64 2XHCPUS Processors - 3XHCPUARCH Architecture : x86 3XHNUMCPUS How Many : 1 3XHNUMASUP NUMA is either not supported or has been disabled by user NULL\n1XHEXCPCODE J9Generic_Signal_Number: 00000004 1XHEXCPCODE Signal_Number: 0000000B 1XHEXCPCODE Error_Value: 00000000 1XHEXCPCODE Signal_Code: 00000080 1XHEXCPCODE Handler1: F72A2E6A 1XHEXCPCODE Handler2: F724D00A 1XHEXCPCODE InaccessibleAddress: 00000000 NULL\n1XHEXCPMODULE Module: /lib/libcairo.so.2 1XHEXCPMODULE Module_base_address: D55FC000\n\nThis is a Redhat Linux 7.2 environment with Content Platform Engine CPE 5.2.1.4.",
    "ground_truth": "1. Install the missing libraries **adwaita-gtk2-theme** (32 and 64 bit) and **adwaita-gtk3-theme** 64 bit.\n\n2. Please contact **RedHat** to obtain the missing libraries.",
    "answer": "To resolve the issue of the Configuration Manager User Interface (CMUI) crashing with a GPF when trying to open a profile on Redhat Linux 7.2, you need to install the missing libraries. Specifically, you should install the following:\n\n1. **adwaita-gtk2-theme** (both 32-bit and 64-bit versions)\n2. **adwaita-gtk3-theme** (64-bit version)\n\nYou can obtain these libraries by contacting RedHat support or by using the package manager to install them if they are available in your repositories. \n\nOnce you have installed the required libraries, try launching the Configuration Manager again and see if the issue is resolved.",
    "id": "TECHQA_DEV_Q002_1"
  },
  {
    "question_id": "TECHQA_DEV_Q008",
    "question": "How can I export a private key from DataPower Gateway Appliance?\nHow can I export a private key from DataPower Gateway appliance?",
    "ground_truth": "1. Using the **crypto-export** command.\n   HSM-enabled DataPower appliances provide the capability to export private keys by utilizing the **crypto-export** command.",
    "answer": "To export a private key from an HSM-enabled IBM WebSphere DataPower Gateway Appliance, follow these steps:\n\n1. **Ensure HSM Initialization**: Both the exporting and importing HSMs must be initialized and in the same key sharing domain. They should be set to the same security level (either Security Level 2 or Security Level 3).\n\n2. **Check Key Exportability**: Confirm that the private key you want to export was marked as exportable at the time of its creation. This is controlled by the `exportable` option in the `keygen` command.\n\n3. **Synchronize Key-Wrapping Keys**: Use the `hsm-clone-kwk` command to synchronize the key-wrapping keys between the two HSMs. This command must be executed four times:\n   - Once on the source HSM appliance.\n   - Once on the destination HSM appliance.\n   - Again on the source HSM appliance.\n   - Finally, once more on the destination HSM appliance.\n   Each execution requires the output file from the previous step as input.\n\n4. **Export the Key**: After synchronization, use the `crypto-export` command to export the private key from the source appliance.\n\n5. **Import the Key**: On the destination appliance, use the `crypto-import` command to import the private key.\n\nMake sure to refer to the IBM documentation for any specific command syntax and additional details. If you encounter issues, ensure that all conditions mentioned above are met.",
    "id": "TECHQA_DEV_Q008_1"
  },
  {
    "question_id": "TECHQA_DEV_Q010",
    "question": "We transferred the database to an external database on our Portal 8.5 environment and now seeing errors, EJPDB0085W and EJPFD0016E in the logs\nAfter transferring the Portal database we seeing the following....\n\n     [3/1/16 6:22:19:481 CST] 00000071 DataStoreServ W com.ibm.wps.services.\n     datastore.DataStoreServiceImpl checkCorrectSetup EJPDB0085W: The\n     character encoding of the database is not UTF-8.\n     [3/1/16 6:22:19:528 CST] 00000071 Servlet       E com.ibm.wps.engine.\n     Servlet init EJPFD0016E: Initialization of service failed.\n                                      com.ibm.wps.util.DataBackendException:\n     EJPDB0160E: The sanity checks of the database layer failed.\n                     at com.ibm.wps.services.datastore.DataStoreServiceImpl.\n     checkCorrectSetup(DataStoreServiceImpl.java:712)\n                     at com.ibm.wps.services.datastore.DataStoreServiceImpl.\n     init(DataStoreServiceImpl.java:288)\n\n...\n\n     [3/1/16 6:22:19:824 CST] 00000071 DatabaseInsig W com.ibm.wps.datastore.\n     dbinsight.DatabaseInsight checkCharacterEncodingForOracle EJPDB0166W:\n     The character encoding of database domain [[Domain: jcr]] is not\n     correct. The value [WE8MSWIN1252] is set for key [NLS_CHARACTERSET] in\n     parameter section [NLS_DATABASE_PARAMETERS] where expected values only\n     can contain one of [[UTF8, AL16UTF16, AL32UTF8, UTFE]].\n\\",
    "ground_truth": "1. Drop the entire Portal database.\n\n2. Recreate the Portal database using specifications provided in the **InfoCenter**.",
    "answer": "The errors EJPDB0085W and EJPFD0016E indicate that the character encoding of your database is not set to UTF-8, which is required for the IBM WebSphere Portal environment. To resolve this issue, you will need to recreate your Portal database with the correct character encoding.\n\nHere are the steps you should follow:\n\n1. **Drop the Existing Database**: Since the current database is not configured correctly, you will need to drop it.\n\n2. **Recreate the Database**: Follow the specifications provided in the IBM InfoCenter for creating a database with the correct character encoding. Ensure that you use one of the supported Unicode character sets such as UTF8, AL32UTF8, or AL16UTF16.\n\n   You can find the relevant documentation here: [IBM InfoCenter - Create Database](http://publib.boulder.ibm.com/infocenter/wpdoc/v6r1m0/topic/com.ibm.wp.ent.doc/config/aix_oracle_create_db.html).\n\n3. **Verify Character Encoding**: After recreating the database, run the following SQL statements to confirm that the character sets are set correctly:\n   ```sql\n   SELECT VALUE FROM NLS_DATABASE_PARAMETERS WHERE PARAMETER IN ('NLS_CHARACTERSET', 'NLS_NCHAR_CHARACTERSET');\n   SELECT PROPERTY_VALUE FROM DATABASE_PROPERTIES WHERE PROPERTY_NAME IN ('NLS_CHARACTERSET', 'NLS_NCHAR_CHARACTERSET');\n   ```\n   Both queries should return values indicating a Unicode character set (e.g., AL16UTF16).\n\n4. **Restart the Portal**: Once the database is recreated and verified, restart your WebSphere Portal to see if the errors are resolved.\n\nBy following these steps, you should be able to resolve the character encoding issues and eliminate the errors in your logs.",
    "id": "TECHQA_DEV_Q010_1"
  },
  {
    "question_id": "TECHQA_DEV_Q011",
    "question": "How to proceed when jextract utility is throwing an OutOfMemory error ?\nI was getting a crash and was told to provide a \"jextracted core dump\". I ran the jextract command as instructed:\n\n/java/jre/bin/jextract [CORE_PATH]\n\nbut I am getting now an OutOfMemory error when jextract itself is running so I cannot proceed with the original crash investigation.",
    "ground_truth": "1. Increase the heap size using the **-J-Xmx** option.\n   ",
    "answer": "To resolve the OutOfMemory error when running the jextract utility, you should increase the maximum heap size allocated to jextract. You can do this by using the `-J-Xmx` option followed by the desired memory size. \n\nHere’s how to proceed:\n\n1. **Determine the appropriate heap size**: Decide how much memory you want to allocate. For example, if you want to allocate 2048 MB, you would use `-J-Xmx2048m`.\n\n2. **Run the jextract command with increased heap size**: Modify your command to include the `-J-Xmx` option. For example:\n   ```\n   /java/jre/bin/jextract -J-Xmx2048m [CORE_PATH]\n   ```\n\n3. **Replace `[CORE_PATH]`**: Ensure you replace `[CORE_PATH]` with the actual path to your core dump file.\n\n4. **Execute the command**: Run the modified command in your terminal.\n\nBy increasing the heap size, you should be able to avoid the OutOfMemory error and proceed with processing the core dump. If you continue to experience issues, consider further increasing the heap size or checking if the core dump is compatible with jextract as per the context provided.",
    "id": "TECHQA_DEV_Q011_1"
  },
  {
    "question_id": "TECHQA_DEV_Q016",
    "question": "How to configure DC to look on a different App server for the SSP?\nI have a single Application server with the RES console installed, and then a separate application server with the XU, the ssp ear, etc. on that one. Each app server is configured separately with respective ports. for example, mgmt server (with the RES console only) has port 8000, and the runtime server (with all of the runtime components) has port 9000.\n\nThe problem I am running into is the following:\n\nWhen I am trying to run a DVS test suite from Decision Center against RES, (my server endpoint in Decision Center is configured as http://hostname:port/res)\n\nI am getting a \"the host and port are responsive but the \"/testing/sspService\" cannot be found. This is expected if it is looking on the same server as the RES console since the application (ssp) is not deployed there.\n\nHowever, I cannot seem to configure the RES console to not assume that the ssp is running on the same port.",
    "ground_truth": "1. Pack all your XOMs into the **ssp.war**.\n\n2. Deploy the SSP on each server.\n   Ensure that the ssp.war is deployed on each server along with a **XU** connection factory and the appropriate datasource definition.\n\n3. Create your own SSP resolver and add it to the **teamserver.war** file and set the teamserver.defaultSSPResolver.class property to this class.\n\n4. Implement the method **IlrSSPResolver.getSSPURL(String serverName,URL url)**.",
    "answer": "To configure your Decision Center (DC) to look for the SSP on a different application server, you will need to implement a custom SSP resolver. Here are the steps to achieve this:\n\n1. **Create a Custom SSP Resolver**:\n   - Implement your own class that extends `IlrSSPResolver`.\n   - Override the method `getSSPURL(String serverName, URL url)` to return the appropriate SSP URL based on the server name.\n\n   Example implementation:\n   ```java\n   public class CustomSSPResolver extends IlrSSPResolver {\n       @Override\n       public URL getSSPURL(String serverName, URL url) {\n           if (serverName.equals(\"testingServer1\")) {\n               return new URL(\"http://server1:9080/testing\");\n           } else if (serverName.equals(\"testingServer2\")) {\n               return new URL(\"http://server2:9080/testing\");\n           } else {\n               return new URL(\"http://defaultHost:9080/testing\");\n           }\n       }\n   }\n   ```\n\n2. **Add the Custom Resolver to the Team Server**:\n   - Package your custom resolver class into the `teamserver.war`.\n   - Set the property `teamserver.defaultSSPResolver.class` to the fully qualified name of your custom resolver class in the configuration.\n\n3. **Deploy the SSP on Each Server**:\n   - Ensure that the `ssp.war` is deployed on each application server where you want to run the tests, along with the necessary XU connection factory and datasource definitions.\n\n4. **Test Your Configuration**:\n   - After deploying the changes, run your DVS test suite from the Decision Center again. It should now correctly route the requests to the specified SSP based on the server you are testing against.\n\nBy following these steps, you should be able to configure your Decision Center to look for the SSP on a different application server successfully.",
    "id": "TECHQA_DEV_Q016_1"
  },
  {
    "question_id": "TECHQA_DEV_Q021",
    "question": "How to refresh a DataPower WebService Proxy which WSDL got changed?\nI have made changes to a WSDL stored in DP local filesystem.\n\nHow can I make the WSP reflect this change since DataPower Gateway 7.1.0 WebService Proxy WebGUI doesn't offer the \"Refresh\" button anymore?\n\nIs there a best practice to refresh the WSP if I modified my WSDL?",
    "ground_truth": "1. Disable and re-enable the service.\n   To refresh a **WSDL** in the **local:///** directory, you need to disable the service and then re-enable it.",
    "answer": "To refresh a DataPower WebService Proxy (WSP) after making changes to a WSDL stored in the local filesystem, you need to disable and then re-enable the service. The WSDL Cache policy does not automatically refresh WSDL files located in the local directory, as it only works with WSDL files hosted on external URLs. \n\nHere are the steps to refresh your WSP:\n\n1. Log in to the DataPower WebGUI.\n2. Navigate to the WebService Proxy you want to refresh.\n3. Disable the WebService Proxy.\n4. Wait a few moments, then re-enable the WebService Proxy.\n\nThis process will ensure that the WSP reflects the changes made to the WSDL file.",
    "id": "TECHQA_DEV_Q021_1"
  },
  {
    "question_id": "TECHQA_DEV_Q025",
    "question": "How to import a certificate in ITCAM for Data Power ?\nHow can I import a certificate in ITCAM for Data Power?",
    "ground_truth": "1. Import the certification file into the agent.\n   Use the command: **/usr/ITM/JRE/aix526/jre/bin/keytool -import -trustcacerts -alias\nligitalsso -keystore /usr/ITM/JRE/aix526/jre/bin/lib/security/cacerts\n-storepass <fileName> -file /NEWSSL-sscert.cer**\n",
    "answer": "To import a certificate in ITCAM for Data Power, follow these steps:\n\n1. Ensure you have the certificate file ready in either `.cer` or `.pem` format. Make sure the file is in ASCII format, not binary.\n\n2. Open a terminal and execute the following command, replacing `<fileName>` with the name of your certificate file:\n\n   ```\n   /usr/ITM/JRE/aix526/jre/bin/keytool -import -trustcacerts -alias ligitalsso -keystore /usr/ITM/JRE/aix526/jre/bin/lib/security/cacerts -storepass changeit -file /path/to/your/certificate/NEWSSL-sscert.cer\n   ```\n\n   - Adjust the path to your Java location if necessary.\n   - Replace `/path/to/your/certificate/NEWSSL-sscert.cer` with the actual path to your certificate file.\n\n3. When prompted, confirm the import by typing \"yes\".\n\nThis should successfully import the certificate into the ITCAM Agent for Data Power. If you encounter any errors, check the trace log for details.",
    "id": "TECHQA_DEV_Q025_1"
  },
  {
    "question_id": "TECHQA_DEV_Q027",
    "question": "How to create batches for bulk upload\nI am new in datacap 9.0 .I just started developing with datacap studio and currently I have learned  to recognize, capture and export the data into filenet.\n\nNow I want to Create batches of image or pdf files so that I can process images and pdf .\n\n \n\nAs per requirement client is sharing document at one shared location.I need to pickup all the documnets from shared location. For creating batches which tool I should use? how it works?\n\n \n\nCan anyone help how I proceed with this.\n\n \n\nRegards,\n\nChhaya Sahu",
    "ground_truth": "1. Run Rulerunner Manager.\n   \n2. On the Rulerunner tab, stop the service.\n   \n3. On the Rulerunner Login tab, click **Connect**.\n   \n4. On the **Workflow** tab, expand the hierarchy on the right and highlight **VScan**.\n   \n5. In the Settings section in the lower right, set skipsamebatch to **1**.\n   \n6. Highlight the line labeled <dbs> above VScan in the thread hierarchy.\n   \n7. Set skipsamebatch to **1** there also.\n   \n8. Click Save, then go back to the Rulerunner tab and start the service.\n   ",
    "answer": "To create batches for bulk upload in Datacap 9.0, you can use the VScan task within the Rulerunner service. Here’s how to proceed:\n\n1. **Set Up Rulerunner**:\n   - Open the Rulerunner Manager.\n   - Stop the Rulerunner service from the Rulerunner tab.\n\n2. **Configure VScan**:\n   - Click on the Rulerunner Login tab and connect.\n   - Navigate to the Workflow tab and expand the hierarchy to find VScan.\n   - In the Settings section, set `skipsamebatch` to 1. This ensures that the same batch is not processed multiple times.\n   - Highlight the line labeled `<dbs>` above VScan in the thread hierarchy and set `skipsamebatch` to 1 there as well.\n\n3. **Save and Restart**:\n   - Click Save to apply the changes.\n   - Go back to the Rulerunner tab and start the service.\n\n4. **Turn Off Mixed Queuing** (if necessary):\n   - If you encounter issues with batches being left in a running state, you may need to turn off Mixed Queuing:\n     - Stop the Rulerunner service again.\n     - In the Rulerunner Settings subtab, uncheck Mixed Queuing.\n     - Save the changes and restart the service.\n\n5. **Pick Up Documents**:\n   - Ensure that your workflow is set up to pick up documents from the shared location where the client is sharing them.\n\nBy following these steps, you should be able to create batches of image or PDF files for processing in Datacap. If you have further questions or run into issues, feel free to ask for more specific guidance.",
    "id": "TECHQA_DEV_Q027_1"
  },
  {
    "question_id": "TECHQA_DEV_Q029",
    "question": "Recurrent RES StaleConnectionException\nHow to prevent rule execution failing because of recurrent StaleConnectionException on ODM 8.8 Rule Execution Server?",
    "ground_truth": "1. Set the Minimum connections to **0**\n\n2. Set the values for **Unused timeout** and **Reap timeout** so that the sum does not exceed any network level idle connection timeout",
    "answer": "To prevent recurrent `StaleConnectionException` issues on the ODM 8.8 Rule Execution Server, you can take the following steps to configure the WebSphere Application Server data source connection pool:\n\n1. **Set Minimum Connections to 0**: This prevents the connection pool from maintaining idle connections that may become stale. By setting the minimum connections to 0, you avoid keeping connections that are no longer valid.\n\n2. **Configure Unused Timeout and Reap Timeout**: Adjust the values for both the Unused timeout and Reap timeout settings. Ensure that the sum of these two values does not exceed any network-level idle connection timeout set by firewalls or other network devices. This helps in ensuring that connections are refreshed before they become stale.\n\nFor detailed instructions on configuring the connection pool, refer to the WebSphere documentation on [data source connection pool settings](http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/index.jsp?topic=/com.ibm.websphere.nd.multiplatform.doc/info/ae/ae/udat_conpoolset.html).\n\nBy implementing these changes, you should be able to reduce or eliminate the occurrences of `StaleConnectionException` in your environment.",
    "id": "TECHQA_DEV_Q029_1"
  },
  {
    "question_id": "TECHQA_DEV_Q030",
    "question": "For HP-UX how to write verbose gc output to a log file other than the native_stdout?\nA customer asked why no gc logs generated even if they use the -Xverbosegc option. So How can I write verbose gc output to a log file other than the native_stdout for HP-UX?",
    "ground_truth": "1. Add the following parameters to the generic JVM arguments:\n   **-XX:+PrintGCDetails**\n   **-XX:+PrintGCDateStamps**\n   **-XX:+PrintHeapAtGC**\n   **-Xverbosegc:file=/tmp/gc_pid$$.vgc**",
    "answer": "To write verbose garbage collection (GC) output to a log file on HP-UX, you need to add specific parameters to your JVM arguments. Here’s how to do it:\n\n1. **Add the following parameters to your generic JVM arguments:**\n   ```\n   -XX:+PrintGCDetails \n   -XX:+PrintGCDateStamps \n   -XX:+PrintHeapAtGC \n   -Xverbosegc:file=/tmp/gc_pid$$.vgc\n   ```\n\n   - The `$$` will be replaced with the process ID of the Java process, ensuring that each log file is unique.\n\n2. **To enable log file rotation, add these parameters:**\n   ```\n   -XX:+UseGCLogFileRotation \n   -XX:NumberOfGCLogFiles=10 \n   -XX:GCLogFileSize=10M\n   ```\n\n   - This configuration will create up to 10 log files, each with a maximum size of 10 MB.\n\n3. **Make sure to replace `/tmp/gc_pid$$.vgc` with your desired log file path if needed.**\n\nBy following these steps, you should be able to generate verbose GC logs in a specified log file instead of the default standard output.",
    "id": "TECHQA_DEV_Q030_1"
  },
  {
    "question_id": "TECHQA_DEV_Q033",
    "question": "Limitations of sylog-TCP log target using DataPower Gateways\nI am trying to configure a log target using type syslog-TCP. It seems that the payload is getting truncated when I try to record custom logs to it using log-action. Why is this? How can I workaround it.",
    "ground_truth": "1. Configure a server daemon to listen and capture the **DataPower** devices events.\n   ",
    "answer": "The truncation of payloads when using the syslog-TCP log target in DataPower Gateways may be due to the device's finite logging capacity and prioritization of client traffic over log events. When the device is under high load, log events can be dropped, leading to incomplete logs.\n\nTo work around this issue, consider the following options:\n\n1. **Use Syslog-ng**: Instead of the default syslog protocol, configure a server daemon like Syslog-ng that operates over TCP. This ensures that log messages are reliably delivered to the destination, reducing the risk of truncation.\n\n2. **Adjust Event Subscriptions**: In the DataPower WebGUI, navigate to Objects > Log Targets and ensure that you have selected all relevant events under the Event Subscriptions tab. This may help capture more comprehensive logs.\n\n3. **Implement Off-Device Logging**: Configure off-device logging to capture logs in a more reliable manner. This can be done by setting up a log target that writes to a local file on the device's file system, which can then be uploaded to a remote server.\n\n4. **Monitor Load Conditions**: Be aware of the device's load conditions. If you are debugging under high load, consider reducing the load or increasing the logging capacity to prevent log events from being dropped.\n\nBy implementing these strategies, you should be able to mitigate the issue of truncated logs when using the syslog-TCP log target.",
    "id": "TECHQA_DEV_Q033_1"
  },
  {
    "question_id": "TECHQA_DEV_Q038",
    "question": "ODM 8.7 TeamServer users active authoring rules and they get kicked out - transaction timeout or session timeout?\nSome of my users are being kicked out of TeamServer while actively authoring rules. What value would be controlling this behavior? Session timeout is at it's default 30 minutes. Does transaction timeout come in to play here or is there a different setting that might be causing this. Thanks.",
    "ground_truth": "1. Increase the timeout value in the web.xml file of the RTS/DC EAR file.\n   Locate the web.xml file in the path **jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF**.\n2. Change the value of the property **ilog.rules.teamserver.transaction.timeout**.",
    "answer": "The issue you're experiencing with users being kicked out of TeamServer while actively authoring rules is likely related to the transaction timeout rather than the session timeout. By default, the transaction timeout is set to 10 minutes (601 seconds), which can cause transactions to roll back if they take longer than this to complete.\n\nTo resolve this, you can increase the transaction timeout value in the `web.xml` file of the TeamServer application. Here’s how to do it:\n\n1. Locate the `web.xml` file in the TeamServer EAR file:\n   - Path: `jrules-teamserver-<appserver>.ear\\teamserver.war\\WEB-INF\\web.xml`\n\n2. Find the following section in the `web.xml` file:\n   ```xml\n   <context-param>\n       <description>Modify the timeout value that is associated with transactions (in seconds)</description>\n       <param-name>ilog.rules.teamserver.transaction.timeout</param-name>\n       <param-value>600</param-value>\n   </context-param>\n   ```\n\n3. Increase the `<param-value>` to a higher number (in seconds) that suits your needs. For example, you might set it to `1200` for a 20-minute timeout:\n   ```xml\n   <param-value>1200</param-value>\n   ```\n\n4. Save the changes and redeploy the application.\n\nAdditionally, check your application server's transaction timeout settings (e.g., WebSphere) to ensure they are configured to accommodate the longer transaction times.\n\nBy adjusting these settings, you should be able to prevent users from being kicked out during active authoring sessions.",
    "id": "TECHQA_DEV_Q038_1"
  },
  {
    "question_id": "TECHQA_DEV_Q039",
    "question": "How do I upgrade my virtual DataPower Appliance from 5.0 firmware to 6.0+ firmware?\nWhen attempting to upgrade my Virtual DataPower Appliance from 5.0.0.8 firmware version to 6.0+ firmware versions, I receive a failure message.",
    "ground_truth": "1. Install the **5.0.0.8** or later fix pack to upgrade to **6.0.0.0** or later.\n   The fix pack contains a required fix to allow the larger sized firmware image to fit.",
    "answer": "To successfully upgrade your Virtual DataPower Appliance from firmware version 5.0.0.8 to 6.0+ firmware versions, follow these steps:\n\n1. **Ensure Compatibility**: Confirm that your current firmware version is 5.0.0.8 or later. If you are on an earlier version, you must first upgrade to 5.0.0.8.\n\n2. **Install Required Fix Pack**: Make sure you have the 5.0.0.8 fix pack installed. This fix pack contains critical updates necessary for the upgrade process. You cannot upgrade to 6.0.0.0 or later without it.\n\n3. **Download the 6.0+ Firmware**: Obtain the 6.0.0.0 or later firmware image from the appropriate source.\n\n4. **Perform the Upgrade**: Follow the standard upgrade procedure for your Virtual DataPower Appliance to install the 6.0+ firmware.\n\n5. **Check for Errors**: If you encounter any failure messages during the upgrade, ensure that you are not trying to install any fix pack from Fix Central that is earlier than the 5.0.0.8 fix pack, as this can lead to compatibility issues.\n\nBy following these steps, you should be able to upgrade your Virtual DataPower Appliance successfully. If you continue to experience issues, please provide the specific error message for further assistance.",
    "id": "TECHQA_DEV_Q039_1"
  },
  {
    "question_id": "TECHQA_DEV_Q040",
    "question": "Why Plug-in log file reports an error message after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver.\nDuring web server start-up, errors like the following will be logged into the Plug-in log file (http_plugin.log):\n\nERROR: lib_security: loadSecurityLibrary: Failed to load gsk library from /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64 ERROR: ws_transport: transportInitializeSecurity: Unable to load security library ERROR: ws_server: serverAddTransport: Failed to initialize security ERROR: ws_server: serverAddTransport: HTTPS Transport is skipped\n\nNote: This is after install & configure the WebSphere Plugin 8.5 version on a Apache 2.4 webserver  on a Linux platform",
    "ground_truth": "1. Set the **LD_LIBRARY_PATH** environment variable to point to the library directory of the **GSKit** that comes with the IBM web server Plug-in.",
    "answer": "To resolve the error messages you're encountering in the Plug-in log file after installing and configuring the WebSphere Plugin 8.5 on your Apache 2.4 web server, you need to set the `LD_LIBRARY_PATH` environment variable to point to the correct library directory for the GSKit.\n\nHere are the steps to do this:\n\n1. **Identify the correct library path**:\n   Since you are using the 64-bit version of the WebSphere Plugin, you should set the `LD_LIBRARY_PATH` to:\n   ```\n   /opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n   ```\n\n2. **Set the environment variable**:\n   You can set the `LD_LIBRARY_PATH` in the appropriate configuration file so that it is set every time the web server starts. \n\n   - For **RHEL Linux**, add the following line to `/etc/sysconfig/httpd`:\n     ```bash\n     export LD_LIBRARY_PATH=/opt/IBM/WebSphere/Plugins/gsk8/gsk8_64/lib64/\n     ```\n\n   - For **SLES and SUSE Linux**, add the same line to `/usr/sbin/envvars`.\n\n3. **Restart the Apache web server**:\n   After making the changes, restart your Apache web server to apply the new environment variable settings.\n\n4. **Check the Plug-in log file**:\n   After restarting, monitor the `http_plugin.log` file to ensure that the error messages no longer appear and that the HTTPS transport is initialized correctly.\n\nBy following these steps, the Plug-in should be able to locate the necessary GSKit libraries, and the errors should be resolved.",
    "id": "TECHQA_DEV_Q040_1"
  },
  {
    "question_id": "TECHQA_DEV_Q043",
    "question": "Where I can get ITNM 4.2.0.1 GA version download details with Part number?.\nHow to download and install IBM Tivoli Network Manager IP Edition Version 4.2 Fix Pack 1 (GA) using the Passport Advantage Web site?.",
    "ground_truth": "1. Download all of the parts that you need, both required and optional.\n\n2. Unpack each of the parts into a single temporary directory on your system.\n   \n3. Follow the instructions in the **Installing** section of the **IBM Knowledge Center** to install the product.",
    "answer": "To download IBM Tivoli Network Manager IP Edition Version 4.2.0.1 (GA) and find the part number, follow these steps:\n\n1. **Log in to Passport Advantage**: Go to the [Passport Advantage Online Web site](https://www.ibm.com/software/howtobuy/passportadvantage/pao_customers.htm) and log in with your credentials.\n\n2. **Navigate to Software Downloads**: Click on \"Software download & media access,\" then select \"Download finder.\"\n\n3. **Search for the Product**: In the search box, type \"Tivoli Network Manager\" and expand the Tivoli Software eAssembly.\n\n4. **Select Downloadable Parts**: Look for the part number CNE9VEN, which corresponds to \"IBM Tivoli Network Manager IP Edition 4.2.0.1 for Linux.\" This part includes the base product, core components, GUI components, and topology database scripts.\n\n5. **Download the Software**: Choose the images you wish to download from the list provided.\n\nFor installation instructions, refer to the [IBM Tivoli Network Manager IP Edition V4.2 Quick Start Guide](https://www-01.ibm.com/support/docview.wss?uid=swg27048605).\n\nIf you need further assistance, you can access IBM Tivoli Product support [here](https://www.ibm.com/software/sysmgmt/products/support/IBMTivoliNetworkManagerIPEdition.html).",
    "id": "TECHQA_DEV_Q043_1"
  },
  {
    "question_id": "TECHQA_DEV_Q047",
    "question": "I need to move my perpetual license of SPSS v24 to my new machine.\nI have my authorization code first given to me, but since we did not renew our support contract we can't seem to download the software. I was originally told that I could download the trial version and it would have the authorization wizard where I could input the code and move forward. But the only downloadable version is subscription version with no authorization wizard. How do I move forward?",
    "ground_truth": "1. Renew your software **Subscription and Maintenance**.\n   You can order the Media CD copy of the software that your company purchased. The software version on the Media CD will be the version available up to the time your subscription has expired.",
    "answer": "To move your perpetual license of SPSS v24 to your new machine, you will need to obtain the software since your Subscription and Maintenance has expired. Here are your options:\n\n1. **Renew Subscription and Maintenance**: The easiest way to regain access to download the software is to renew your Subscription and Maintenance. This will allow you to download the software directly from Passport Advantage Online.\n\n2. **Order Media CD**: If you prefer not to renew your subscription, you can contact IBM's sales department to inquire about ordering a Media CD copy of SPSS v24. This CD will contain the version of the software available up to the time your subscription expired. You can find your local IBM Sales contact at [IBM Planetwide](https://www.ibm.com/planetwide/).\n\n3. **Trial Version**: If you still want to try the trial version, be aware that it may not include the authorization wizard you need to input your code. Therefore, this option may not be viable for your situation.\n\nChoose one of these options to proceed with moving your SPSS license to your new machine.",
    "id": "TECHQA_DEV_Q047_1"
  },
  {
    "question_id": "TECHQA_DEV_Q048",
    "question": "Need to understand what exact counters are needed for the ITM IIS agent?\nNeed to understand what exact counters are needed for the ITM IIS agent to collect website details and web site status. unable to find what \ncounters are required in the IIS doc.",
    "ground_truth": "1. Install IIS 6.0 **management compatibility pack** on your Windows Server.\n   ",
    "answer": "To collect website details and website status using the ITM IIS agent, you need to ensure that the following IIS Role Services are installed:\n\n1. **IIS 6 Management Compatibility**\n2. **IIS 6 Metabase Compatibility**\n3. **IIS 6 WMI Compatibility**\n4. **IIS 6 Scripting Tools**\n5. **IIS 6 Management Console**\n\nAdditionally, you must install the **IIS v6.0 Management Compatibility pack** on your Windows Server, even if you are using a higher version of IIS (like IIS 7.0 or above). \n\nTo install these components, follow these steps:\n\n1. Open the **Server Manager** on your Master or Replica host.\n2. Select the **Roles** option and click the **Add Roles** button.\n3. In the Add Roles Wizard, select the **Web Server (IIS)** checkbox and click **Next**.\n4. When prompted, click **Add Required Features**.\n5. Continue through the wizard, ensuring that the required IIS 6 Management Compatibility features are selected.\n\nAfter installing these components, restart the ITM IIS agent to ensure it starts collecting data properly. \n\nIf you still encounter issues, please check the Windows Application event log for any related errors.",
    "id": "TECHQA_DEV_Q048_1"
  },
  {
    "question_id": "TECHQA_DEV_Q051",
    "question": "We got a NullPointerException when bootstrapping the object store or accessing Site Preferences/Access Role on WorkplaceXT\nAfter logging into FileNet Workplace XT, a java.lang.NullPointerException error is logged when bootstrapping the object store or when accessing Site Preferences/Access Role.\n\nHere's the error stack,\n\nError Stack Trace extracted from the J2EE Application Server error log:\n\njava.lang.NullPointerException\n\nat org.apache.jasper.runtime.JspWriterImpl.write(JspWriterImpl.java:421)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefAccessRolesInfoPage.renderRoleMembers(PrefAccessRolesInfoPage.java:254)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefAccessRolesInfoPage.renderRole(PrefAccessRolesInfoPage.java:220)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefBootstrapInfoPage.renderAdminRole(PrefBootstrapInfoPage.java:131)\n\nat com.filenet.wcm.apps.server.ui.info.prefs.PrefBootstrapInfoPage.render(PrefBootstrapInfoPage.java:303)",
    "ground_truth": "1. Change the **User Display Name** Attribute or **Group Display Name** Attribute to a valid LDAP entry such as cn, displayName or uid.\n\n2. Restart the FileNet Content Engine and **Workplace XT** instances.",
    "answer": "To resolve the NullPointerException you are encountering in FileNet Workplace XT, follow these steps:\n\n1. **Access FileNet Enterprise Manager (FEM)**: Log in to your FEM console.\n\n2. **Check Directory Services Configuration**:\n   - Navigate to the Directory Services Configuration settings.\n   - Verify the entries for the **User Display Name Attribute** and **Group Display Name Attribute**.\n\n3. **Update Attributes**:\n   - Ensure that these attributes are set to valid LDAP entries. Common valid entries include:\n     - `cn`\n     - `displayName`\n     - `uid`\n   - If they are currently set to invalid values, update them accordingly.\n\n4. **Restart Services**:\n   - After making the changes, restart both the **FileNet Content Engine** and the **Workplace XT** instances to apply the new settings.\n\n5. **Test the Application**: Log back into FileNet Workplace XT and check if the issue persists.\n\nBy ensuring that the User and Group Display Name Attributes are correctly configured, you should be able to resolve the NullPointerException error. If the problem continues, further investigation may be required.",
    "id": "TECHQA_DEV_Q051_1"
  },
  {
    "question_id": "TECHQA_DEV_Q052",
    "question": "Why do I still get \"certificate expired\" error after adding new certificate?\nThe remote SSL vendor has provided us a new certificate to replace an expiring one. We have added the new certificate to the appropriate Datapower validation credential, however, connections are still failing with \"certificate expired\":\n\nmpgw(Inbound_MPG): tid(51005)[request][10.20xx.xx] gtid(51345): certificate validation failed for '/C=US/O=People Services/OU=IT/CN=test.site.com' against 'My_ValCred': certificate has expired",
    "ground_truth": "1. Disable/enable the certificate object.\n   If the replacement certificate has the same file name of the expired certificate, you **MUST** disable the certificate object in order to clear all cached references to the expired certificate.",
    "answer": "The \"certificate expired\" error you're encountering, despite adding a new certificate, may be due to a few common issues. Here are actionable steps to resolve the problem:\n\n1. **Check the Certificate Chain**: Ensure that you have the complete certificate chain (personal, intermediate, and root certificates). Sometimes, the new certificate may be chained, and missing intermediate certificates can lead to validation failures.\n\n2. **Update the Configuration**: Verify that the DataPower configuration is referencing the new certificate files correctly. Navigate to the SSL Proxy Profile -> Crypto Profile -> Crypto Key and Certificate objects in the WebGUI to confirm that the new certificate files are being used.\n\n3. **Disable/Enable the Certificate Object**: If the new certificate has the same file name as the expired one, you must disable and then enable the certificate object in DataPower. This action clears any cached references to the expired certificate.\n\n4. **Check for Cached References**: If the above steps do not resolve the issue, consider restarting the DataPower appliance to clear any lingering cached references to the expired certificate.\n\n5. **Review Logs**: Check the DataPower logs for any additional error messages that might provide more context on the failure.\n\nBy following these steps, you should be able to resolve the \"certificate expired\" error. If the issue persists, further investigation into the specific configuration and logs may be necessary.",
    "id": "TECHQA_DEV_Q052_1"
  },
  {
    "question_id": "TECHQA_DEV_Q053",
    "question": "After uninstalling Portal 8.0 only from my WAS environment my subsequent attempts to install Portal 8.0 into that same existing WAS fails.\nI installed Portal 8.0.0.1 CF12 with an existing WAS 8.0.0.8 application server and everything was successful. I want to script my install so I uninstalled Portal 8.0.0.1 only and was left with an existing WAS 8.0.0.8...as before. However, when I attempt to reinstall Portal 8.0.0.1 into that same existing WAS 8.0.0.8 to test my scripting I get the following error immediately:\n\nERROR: The required version 8.0.0.5 or later of WebSphere Application Server has not been detected on this system. Select the WebSphere Application Server Package to install WebSphere Application Server and WebSphere Portal.\n\nIIM shows WAS as installed, so I am not sure what is causing this behavior when it installed fine just a few hours ago.",
    "ground_truth": "1. Navigate to the **AppServer** folder and remove the following files.\n   - **lib/ext/commons-codec-1.3.jar**\n   - lib/ext/commons-httpclient-3.0.1.jar\n   - lib/ext/openid4java-full-0.9.5.jar\n   - lib/ext/wp.auth.base.sua_RedirectServletFilter.jar\n   - lib/ext/wp.auth.base.sua_loginmodule.jar\n   - lib/ext/wp.auth.tai.jar\n   - lib/wp.user.connections.jar\n   - lib/wp.wire.jar\n   - **plugins/com.ibm.patch.was.plugin.jar**\n   - plugins/com.ibm.wp.was.plugin.jar\n   - plugins/wp.ext.jar\n   - properties/jndi.properties",
    "answer": "To resolve the issue with reinstalling Portal 8.0.0.1 into your existing WebSphere Application Server (WAS) 8.0.0.8, follow these steps:\n\n1. **Navigate to the AppServer folder** where your WAS is installed.\n\n2. **Remove the following files** that may not have been correctly deleted during the uninstallation of Portal:\n   - `lib/ext/commons-codec-1.3.jar`\n   - `lib/ext/commons-httpclient-3.0.1.jar`\n   - `lib/ext/openid4java-full-0.9.5.jar`\n   - `lib/ext/wp.auth.base.sua_RedirectServletFilter.jar`\n   - `lib/ext/wp.auth.base.sua_loginmodule.jar`\n   - `lib/ext/wp.auth.tai.jar`\n   - `lib/wp.user.connections.jar`\n   - `lib/wp.wire.jar`\n   - `plugins/com.ibm.patch.was.plugin.jar`\n   - `plugins/com.ibm.wp.was.plugin.jar`\n   - `plugins/wp.ext.jar`\n   - `properties/jndi.properties`\n\n3. **After removing these files**, open the IBM Installation Manager (IIM) and click on the **Recheck Status** button. This should update the status to indicate that \"All prerequisites are met.\"\n\n4. **Attempt to reinstall Portal 8.0.0.1** again into the existing WAS.\n\nBy following these steps, you should be able to successfully reinstall Portal without encountering the previous error regarding the WebSphere Application Server version.",
    "id": "TECHQA_DEV_Q053_1"
  },
  {
    "question_id": "TECHQA_DEV_Q055",
    "question": "Table \"\".\"\" could not be found\nWhen doing a table mapping with DB2 as source, selecting a table which contains special characters on column comments like:\n\nCOMMENT ON COLUMN .. IS 'Test comment ‘1’ complete';\n\nMapping fails with following error message: Table . could not be found in the database.",
    "ground_truth": "1. **Reinsert**  data with codepage conversion enforced by setting the operation system codepage matching to the codepage of data to be inserted",
    "answer": "The error message \"Table . could not be found in the database\" when performing table mapping with DB2 is likely due to the presence of special characters in the column comments that are not being handled correctly. Here are the steps you can take to resolve this issue:\n\n1. **Check for Invalid Characters**: Ensure that the column comments do not contain invalid UTF-8 characters. You can use a hex editor to verify the encoding of the characters in the comments.\n\n2. **Delete Invalid Rows**: If you find rows with incorrect Unicode codepoints, delete them from the table using:\n   ```sql\n   DELETE FROM your_table_name WHERE your_condition;\n   ```\n\n3. **Set Correct Locale**: Make sure your operating system locale matches the codepage of the data you are working with. You can set the locale to UTF-8 by running:\n   ```bash\n   export LANG=en_US.UTF-8\n   export LC_CTYPE=\"en_US.UTF-8\"\n   ```\n\n4. **Create Database with UTF-8**: If you haven't already, create a database that uses UTF-8 encoding:\n   ```sql\n   CREATE DATABASE your_db_name USING CODESET utf-8 TERRITORY US;\n   ```\n\n5. **Insert Data with Correct Encoding**: When inserting data, ensure that the data is in UTF-8 format. If you are using a command line processor (CLP), ensure that the data being inserted is also UTF-8 encoded. You can insert data like this:\n   ```sql\n   INSERT INTO your_table_name (column_name) VALUES ('Ã'), ('³'), ('©');\n   ```\n\n6. **Verify Inserted Data**: After inserting, verify that the data has been correctly converted to UTF-8 by running:\n   ```sql\n   SELECT column_name, HEX(column_name) FROM your_table_name;\n   ```\n\nBy following these steps, you should be able to resolve the issue with the table mapping and avoid the error regarding the table not being found. If the problem persists, further investigation into the specific characters and their encoding may be necessary.",
    "id": "TECHQA_DEV_Q055_1"
  },
  {
    "question_id": "TECHQA_DEV_Q063",
    "question": "Hide a page in dotedit step\nI am working on datacap 8.1 version. I have 2 pages in a batch. Page 1 with status as 1, Page 2 with status as 20. Both are of same page type. In verification step (dotedit) I want to hide the page which is with status 20. I have given status 20 in ignored page status in web administrator for verify. But still when I navigate through pages in dotedit batch view the respective panel is loading. I am able to submit the batch even if I have one page in a batch with 20 as status.\n\nIs there any way to delete the page (we have multiple same type of pages in a batch) from dotedit based on the page status?",
    "ground_truth": "1. Use the **DeleteChildType** from the **Validations** library.\n   Run it from the parent of the object to be deleted and specifying the specific child.",
    "answer": "To hide or delete a page with status 20 in the dotedit step of Datacap 8.1, you can follow these steps:\n\n1. **Create a Special Page Type**: Create a new page type at the batch level, for example, \"DeleteMe\".\n\n2. **Identify the Page**: Use an action to identify the page with status 20. You can create a rule that checks for this status. For instance, you might use a custom action that identifies pages based on their status.\n\n3. **Delete the Page**: Create a rule that uses the `DeleteChildType` action to remove the identified pages. Attach this rule at the batch level. The rule should look something like this:\n   - `DeleteChildType(DeleteMe)`\n\n4. **Run the Rule**: Ensure that this rule is executed during the verification step so that any pages with status 20 are removed before the user navigates through the batch.\n\nBy following these steps, you should be able to hide or delete the page with status 20 from the dotedit view. If you encounter any issues, ensure that the rules are correctly configured and that the page type is properly set up.",
    "id": "TECHQA_DEV_Q063_1"
  },
  {
    "question_id": "TECHQA_DEV_Q067",
    "question": "BPM AppTarget startup hangs during startup\nDuring startup of the apptarget, JVM hangs with the following messages\n\n[9/8/14 14:11:01:709 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W - The system has been waiting for the group replication lock to be released for the last 10 minutes. [9/8/14 14:11:32:810 CDT] 00000022 ThreadMonitor W WSVR0605W: Thread \"server.startup : 0\" (0000001f) has been active for 654582 milliseconds and may be hung. There is/are 1 thread(s) in total in the server that may be hung. at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:896) at com.lombardisoftware.server.core.GroupCore.getAllGroups(GroupCore.java:545) at com.lombardisoftware.server.ejb.security.SecurityCore.listAllGroups(SecurityCore.java:566) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37) at java.lang.reflect.Method.invoke(Method.java:611) ... [9/8/14 14:21:02:662 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W - The system has been waiting for the group replication lock to be released for the last 20 minutes. [9/8/14 14:31:03:193 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W -The system has been waiting for the group replication lock to be released for the last 30 minutes. [9/8/14 14:41:03:749 CDT] 0000001f wle W com.lombardisoftware.server.core.GroupCore getAllGroups() CWLND0004W -The system has been waiting for the group replication lock to be released for the last 40 minutes.",
    "ground_truth": "1. Make a backup copy of the wimconfig.xml file.\n\n2. Edit the wimconfig.xml file.\n\n3. Change the connectTimeout value.\n   Search for the line containing connectTimeout in the wimconfig.xml file and change the value from connectTimeout=\"20\" to **connectTimeout=\"0\"**.\n\n4. Save the wimconfig.xml file.\n\n5. Restart the WebSphere Application Server / **IBM Business Process Manager** environment.",
    "answer": "To resolve the issue of the BPM AppTarget hanging during startup, you should perform the following steps:\n\n1. **Check for LDAP Connection Issues**: The logs indicate that the system is waiting for the group replication lock, which may be related to LDAP connection timeouts. Ensure that your LDAP server is reachable and functioning properly.\n\n2. **Adjust LDAP Timeout Settings**:\n   - Use the wsadmin command to set the LDAP connection timeout to 0 (indefinite wait):\n     ```bash\n     $AdminTask updateIdMgrLDAPServer {-id AD -connectTimeout 0}\n     $AdminConfig save\n     ```\n   - Alternatively, you can edit the `wimconfig.xml` file directly:\n     - Locate the file in one of the following paths:\n       - `{WAS_HOME}\\profiles\\profile_name\\config\\cells\\cell_name\\wim\\config\\wimconfig.xml`\n       - `profile_root/conf/cells/cell_name/wim/config/wimconfig.xml`\n     - Make a backup of the file.\n     - Change the line `connectTimeout=\"20\"` to `connectTimeout=\"0\"` and save the file.\n\n3. **Restart the Environment**: After making the changes, a complete restart of the WebSphere Application Server / IBM Business Process Manager environment is required for the changes to take effect.\n\n4. **Monitor the Startup**: After the restart, monitor the logs to ensure that the startup completes successfully and that there are no further timeout or hanging issues.\n\nBy following these steps, you should be able to resolve the startup hanging issue with the BPM AppTarget.",
    "id": "TECHQA_DEV_Q067_1"
  },
  {
    "question_id": "TECHQA_DEV_Q071",
    "question": "Why is Connection Refused on the ITCAM Managing Server?\nITCAM Data Collector connection to the Managing Server fails with Connection Refused.",
    "ground_truth": "1. Specify a 'valid' IP address for the MS in the **<MS_HOME>/bin/setenv.sh** file,  and in ITCAM 6.1, the **ms.properties** file.",
    "answer": "The \"Connection Refused\" error when the ITCAM Data Collector (DC) attempts to connect to the Managing Server (MS) may occur if the MS's hostname resolves to an IP address that cannot be reached from the DC. To resolve this issue, follow these steps:\n\n1. **Specify a Valid IP Address**:\n   - Instead of using the hostname, directly specify a valid IP address for the MS in the configuration files.\n\n   For ITCAM 6.0 (or earlier):\n   - Edit the `<MS_HOME>/bin/setenv.sh` file:\n     ```\n     KERNEL_HOST01=<ip addr of MS>\n     KERNEL_HOST02=<ip addr of MS>\n     ```\n\n   For ITCAM 6.1:\n   - Edit the `<MS_HOME>/bin/setenv.sh` file:\n     ```\n     KERNEL_HOST01=<ip addr of MS>\n     am_socket_bindip=<ip addr of MS>\n     am_socket_exportip=<ip addr of MS>\n     ```\n   - Also, modify the `<MS_HOME>/etc/ms.properties` file:\n     ```\n     kernel.hosts=<ip addr of MS>:9122:9120:9118\n     ```\n\n2. **Check Network Connectivity**:\n   - Use the `nslookup <MS_host_name>` command to determine the IP addresses associated with the MS hostname.\n   - For each IP address returned, test connectivity by issuing the `ping <ip_address>` command.\n\n3. **Firewall Considerations**:\n   - If there is a firewall with Network Address Translation (NAT) enabled, ensure that all resolved IPs can reach the MS. You may need to make network changes to allow this.\n\nBy following these steps, you should be able to resolve the \"Connection Refused\" issue. If the problem persists, further investigation into network configurations may be necessary.",
    "id": "TECHQA_DEV_Q071_1"
  },
  {
    "question_id": "TECHQA_DEV_Q072",
    "question": "Help with Security Bulletin: Multiple vulnerabilities in IBM Java Runtime affect WMB and IIB\nI need to understand details regarding Security Bulletin: Multiple vulnerabilities in IBM Java Runtime affect WebSphere Message Broker and IBM Integration Bus. Where can I find this information?",
    "ground_truth": "1. Evaluate your code to determine whether the complete list of vulnerabilities are applicable to your code.\n\n2. Refer to the **IBM Java SDK Security Bulletin** for a complete list of vulnerabilities.",
    "answer": "To find detailed information regarding the Security Bulletin on multiple vulnerabilities in IBM Java Runtime affecting WebSphere Message Broker (WMB) and IBM Integration Bus (IIB), you can refer to the following resources:\n\n1. **IBM Security Bulletin**: This bulletin outlines the vulnerabilities and the affected versions. You can access it directly through the IBM support page.\n\n2. **Planned Maintenance Release Dates**: For information on maintenance releases, visit: [IBM Support Document](http://www.ibm.com/support/docview.wss?uid=swg27006308).\n\n3. **Remediation/Fixes**: Specific fixes for affected versions are available:\n   - For IBM Integration Bus V10.0.0.0-10.0.0.8, see [Fix Pack 10.0.0.9](http://www-01.ibm.com/support/docview.wss?uid=swg24043686).\n   - For IBM Integration Bus V9.0.0.0-9.0.0.7, see [Fix Pack 9.0.0.8](http://www-01.ibm.com/support/docview.wss?uid=swg24043751).\n   - For WebSphere Message Broker V8.0.0.0-8.0.0.8, see [Fix Pack 8.0.0.9](https://www.ibm.com/support/docview.wss?uid=swg24043806).\n\n4. **Subscribe for Updates**: To stay informed about future security bulletins, consider subscribing to My Notifications at [IBM My Notifications](http://www-01.ibm.com/software/support/einfo.html).\n\nThese resources should provide you with comprehensive information regarding the vulnerabilities and necessary actions.",
    "id": "TECHQA_DEV_Q072_1"
  },
  {
    "question_id": "TECHQA_DEV_Q077",
    "question": "I need to transfer my SPSS 24 licence to a new computer\nI need to transfer my SPSS 24 license to a new machine. I have only used my activation code on one computer so far, and that computer was found to be defective which has led me to get a new computer. I was able to download SPSS 24 Gradpack onto the new computer, but every time I put in the activation code, the program gives me an error message saying that I am not allowed to generate any new licenses.",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To transfer your SPSS 24 license to your new computer, follow these steps:\n\n1. **Contact Your Vendor**: Since you are using the SPSS Grad Pack, you need to reach out to the vendor from whom you purchased the software. They can assist you with the license transfer process. Here are some options:\n   - Hearne: [Hearne Software](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n   - On the Hub: [On the Hub](http://onthehub.com/)\n   - StudentDiscounts.com: [StudentDiscounts](http://studentdiscounts.com/contact-us.aspx)\n   - JourneyEd: [JourneyEd](https://www.journeyed.com/contact)\n   - thinkEDU: [thinkEDU Support](https://thinkedu.desk.com/)\n   - Studica: [Studica Support](http://www.studica.com/technical-support)\n\n2. **Provide Necessary Information**: When you contact them, be ready to provide your activation code and details about your previous installation. This will help them assist you more effectively.\n\n3. **Follow Their Instructions**: The vendor will guide you through the process of deactivating the license on the defective computer and activating it on your new machine.\n\nIf you encounter any further issues, make sure to document any error messages and share them with the vendor for more specific assistance.",
    "id": "TECHQA_DEV_Q077_1"
  },
  {
    "question_id": "TECHQA_DEV_Q090",
    "question": "RTW eclipse license error\nI get a RTW eclipse license error on IM stating server is available, but license is not available. License is imported fine on license key admin and RPT floating license and RIT floating license shows on the  pc end on license key admin 8.1.3, but not showing on IM. \n\nRTW 8.5\n\nWhat to do?",
    "ground_truth": "1. Navigate to IBM Rational License Key Center website.\n   Access the IBM Rational License Key Center by visiting the URL: **http://www-01.ibm.com/software/rational/support/licensing/**.\n2. Return and generate the license file for IBM Rational Test Workbench Floating License.\n\n3. Download and Import the license file again.\n   \n4. Click on Start > IBM Rational > LMTools > Start/Stop/Reread tab to stop and start the license server.\n   \n5. Click on Start > IBM Rational > LMTools > Server Status to perform status enquiry.\n\n6. Reactivate the floating license for Rational Integration Tester using **Rational Installation Manager**.",
    "answer": "To resolve the RTW Eclipse license error you're experiencing with IBM Rational Integration Tester (RIT), follow these steps:\n\n1. **Verify License Key Configuration**:\n   - Open the Rational License Key Administrator on your license server.\n   - Ensure that the package `ibmrtw` is present and includes the components: `ibmrit ibmrft ibmrpt ibmrpt_pvu`. If this package is missing, you will need to generate a new license file.\n\n2. **Generate and Import License**:\n   - Go to the IBM Rational License Key Center [here](http://www-01.ibm.com/software/rational/support/licensing/).\n   - Generate a new license file for IBM Rational Test Workbench Floating License [here](https://www-304.ibm.com/support/docview.wss?uid=swg21308308).\n   - Download the new license file and import it into the Rational License Key Administrator.\n\n3. **Restart License Server**:\n   - Open LMTools (Start > IBM Rational > LMTools).\n   - Go to the \"Start/Stop/Reread\" tab and stop the license server, then start it again.\n\n4. **Check Server Status**:\n   - In LMTools, go to the \"Server Status\" tab and perform a status inquiry.\n   - Look for the line 'Users of ibmrit' to confirm that the license is being served correctly.\n\n5. **Reactivate Floating License**:\n   - Open IBM Installation Manager.\n   - Navigate to Manage Licenses and reactivate the floating license for Rational Integration Tester.\n\nAfter completing these steps, check if the license error persists in the Integration Tester. If you still encounter issues, please provide additional details for further assistance.",
    "id": "TECHQA_DEV_Q090_1"
  },
  {
    "question_id": "TECHQA_DEV_Q099",
    "question": "Is ITCAM Agent for WebSphere Applications 7.2.0.0.7 available?\nIs ITCAM Agent for WebSphere Applications 7.2.0.0.7 available?",
    "ground_truth": "1. Go to the link: **http://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAMAD_WS-IF0007&includeSupersedes=0&source=fc**.",
    "answer": "Yes, ITCAM Agent for WebSphere Applications version 7.2.0.0.7 is available. You can find it on IBM's Fix Central at the following link: [ITCAM Agent 7.2.0.0.7](http://www.ibm.com/support/fixcentral/swg/quickorder?product=ibm/Tivoli/Tivoli+Composite+Application+Manager+for+Applications&release=All&platform=All&function=fixId&fixids=7.2.0.0-TIV-ITCAMAD_WS-IF0007&includeSupersedes=0&source=fc).",
    "id": "TECHQA_DEV_Q099_1"
  },
  {
    "question_id": "TECHQA_DEV_Q106",
    "question": "Why does WebSphere DataPower spike with a high CPU rate when a WebSphere MQ connection is unavailable?\nI have noticed when my MQ backends go down unexpectedly it can result in a high CPU rate on DataPower. And how can I resolve this?",
    "ground_truth": "1. Change the **Retry Attempts** parameter on the **Configure MQ Queue Manager** window from 0 to some number.",
    "answer": "The high CPU usage on WebSphere DataPower when a WebSphere MQ connection is unavailable is likely due to the default configuration settings for Retry Attempts and Retry Interval. When the Retry Attempts is set to 0, DataPower will continuously retry the connection every second, leading to excessive CPU usage.\n\nTo resolve this issue, you should adjust the configuration settings for the MQ Queue Manager as follows:\n\n1. **Open the Configure MQ Queue Manager window.**\n2. **Change the following parameters:**\n   - **Retry Attempts:** Change from 0 to 6.\n   - **Retry Interval:** Change from 1 second to 10 seconds.\n   - **Long Retry Interval:** Change from 1800 seconds (30 minutes) to 600 seconds (10 minutes).\n\nWith this configuration, DataPower will attempt to reconnect 6 times at 10-second intervals. If the connection fails after 6 attempts, it will then retry every 10 minutes, significantly reducing CPU load during outages.\n\nMake these changes to help mitigate the CPU spikes when the MQ backend is down.",
    "id": "TECHQA_DEV_Q106_1"
  },
  {
    "question_id": "TECHQA_DEV_Q108",
    "question": "Why do I get \"OSS version is not suitable for installation\" when attempting to install the MQ 5.3.1 base version on a HP Integrity NonStop Server BladeSystem?\nI am trying to install the MQ 5.3.1 base version on a HP Integrity NonStop Server BladeSystem, but it complains saying that the \"OSS version is not suitable for installation\". My OSS version is J06.14 and it looks to be a supported version according to the System Requirements site:\n\nhttp://www-01.ibm.com/support/docview.wss?uid=swg27006797\n\nWhy am I getting this error message?",
    "ground_truth": "1. Ensure the HP Integrity NonStop Server H-Series system runs on **H06.23.01** or later.",
    "answer": "The error message \"OSS version is not suitable for installation\" indicates that your current OSS version (J06.14) may not meet the minimum requirements for the version of WebSphere MQ you are trying to install. \n\nAccording to the context provided, for the HP Integrity NonStop BladeSystem, the minimum mandatory OSS version for V5.3.1.12 is J06.14.00 or later. However, if you are attempting to install a version earlier than V5.3.1.12, it may not be compatible with J06.14.\n\nTo resolve this issue, ensure that you are installing WebSphere MQ V5.3.1.12 or later. If you are already attempting to install V5.3.1.12 and still encountering this error, verify that your OSS version is indeed J06.14.00 or later, as any earlier sub-version may not be supported.\n\nIf you continue to experience issues, consider upgrading your OSS to a more recent version or consult IBM support for further assistance.",
    "id": "TECHQA_DEV_Q108_1"
  },
  {
    "question_id": "TECHQA_DEV_Q110",
    "question": "Why does our Websphere application server hang when we apply Microsoft patch on our database server?\nWhy does our Websphere application server hang when we apply Microsoft patch on our database server?",
    "ground_truth": "1. Immediately purge the pool by invoking the purgePoolContents operation of the data source MBean with the immediate option using Jacl or Jython.\n   - Jacl: **$AdminControl invoke $ds purgePoolContents immediate**\n   - Jython: **AdminControl.invoke(ds, \"purgePoolContents\", \"immediate\")**",
    "answer": "The hanging of your WebSphere application server when applying a Microsoft patch on your database server may be related to invalidated connections in the connection pool. When the patch is applied, it could disrupt existing connections, causing the application server to hang while it waits for these connections to become valid again.\n\nTo resolve this issue, you can manually purge the connection pool of your WebSphere Application Server. Here’s how to do it using the wsadmin console:\n\n1. **List all data sources** to identify the one you are using:\n   - Using Jacl:\n     ```\n     $AdminControl queryNames *:type=DataSource,*\n     ```\n   - Using Jython:\n     ```python\n     AdminControl.queryNames(\"*:type=DataSource,*\")\n     ```\n\n2. **Initialize a variable** for your specific data source (replace \"Default Datasource\" with your actual data source name):\n   - Using Jacl:\n     ```\n     set name \"Default Datasource\"\n     set ds [$AdminControl queryNames *:type=DataSource,name=$name,*]\n     ```\n   - Using Jython:\n     ```python\n     name = \"Default Datasource\"\n     ds = AdminControl.queryNames(\"*:type=DataSource,name=\"+name+\",*\")\n     ```\n\n3. **Purge the connection pool** immediately:\n   - Using Jacl:\n     ```\n     $AdminControl invoke $ds purgePoolContents immediate\n     ```\n   - Using Jython:\n     ```python\n     AdminControl.invoke(ds, \"purgePoolContents\", \"immediate\")\n     ```\n\nAfter purging the connection pool, monitor the application server to see if the hanging issue is resolved. If the problem persists, further investigation into the specific patch and its compatibility with your database and application server may be necessary.",
    "id": "TECHQA_DEV_Q110_1"
  },
  {
    "question_id": "TECHQA_DEV_Q112",
    "question": "Why does nco_confpack -export fail with the message \"Tool in menu but not found\"?\nI tried to export OMNIbus configuration using nco_confpack command and I get the following message:\r\nTool in menu but not found, menu: AlertsMenu, tool: Close\r\nI've also tried using it with -list command and I get the same error.",
    "ground_truth": "1. Recreate the tool\n   \n2. Associate it with the **menu**\n   \n3. Try to run the command again\n   ",
    "answer": "The error message \"Tool in menu but not found\" indicates that the nco_confpack command is trying to access a tool that is no longer available in the specified menu. In your case, it seems that the AlertsMenu is referencing a tool called \"Close\" that does not exist.\n\nTo resolve this issue, you should recreate the missing tool and associate it with the AlertsMenu. Here are the steps you can follow:\n\n1. **Identify the Missing Tool**: Confirm that the tool \"Close\" is indeed missing from the AlertsMenu.\n\n2. **Recreate the Tool**: Use the appropriate configuration commands or scripts to recreate the \"Close\" tool. This may involve editing configuration files or using a GUI tool if available.\n\n3. **Associate the Tool with the Menu**: Ensure that the recreated tool is properly associated with the AlertsMenu.\n\n4. **Retry the Command**: After recreating and associating the tool, try running the nco_confpack command again with the -export or -list option.\n\nIf you continue to experience issues, you may need to consult the documentation for your specific version of OMNIbus or reach out to IBM support for further assistance.",
    "id": "TECHQA_DEV_Q112_1"
  },
  {
    "question_id": "TECHQA_DEV_Q122",
    "question": "Importing Asset GL Errors\nWhen importing or syncing with assets, I receive the following error for the glaccount.\n\nInternal Server Error\nError 500: nested exception is: psdi.util.MXAccessException: BMXAA4198E - The GL attribute TLOAMNEWGLACCOUNT on object {1} requires an organization. Specify a value in the Organization field.",
    "ground_truth": "1. Add the following field or tag to your inbound message.\n   Include the tag <NEWORGID>xxx</NEWORGID> in the XML message, where xxx is the **ORGID** value.",
    "answer": "To resolve the \"BMXAA4198E - The GL attribute TLOAMNEWGLACCOUNT on object {1} requires an organization\" error when importing assets, you need to include the organization ID in your inbound message. Follow these steps:\n\n1. **Modify Your Inbound Message**: If you are sending XML, add the following tag to your message:\n   ```xml\n   <NEWORGID>xxx</NEWORGID>\n   ```\n   Replace `xxx` with the actual ORGID value.\n\n2. **Update Object Structure**:\n   - Go to **Integration > Object Structures** in your system.\n   - Query the relevant object structure you are using for the import.\n   - From the **Select Action** menu, choose **Exclude/Include Fields**.\n   - Navigate to the **Non-Persistent Fields** tab and ensure that **NEWORGID** is included.\n\nBy ensuring that the `NEWORGID` field is present in your message and included in the object structure, you should be able to resolve the error and successfully import your assets.",
    "id": "TECHQA_DEV_Q122_1"
  },
  {
    "question_id": "TECHQA_DEV_Q132",
    "question": "What is the meaning of value \"unknown\" for ITCAM WAS Application Status attribute?\nWhat is the meaning of value \"unknown\" for ITCAM WAS Application Status attribute?",
    "ground_truth": "1. Enable the situation **WasAppDiscovered**.\n   If this situation is not enabled, then the user should enable it.\n2. Assign the situation to the **ITCAM App Server** managing system list.",
    "answer": "The value \"unknown\" for the ITCAM WAS Application Status attribute indicates that the baselining process has not yet started or has not been calculated for the monitored application. To resolve this, you need to enable baselining for your application. Follow these steps:\n\n1. Log in to your TEPS (Tivoli Enterprise Portal Server).\n2. Navigate to Application Health, right-click, and select Workspace, then Application Registry. Check if the baselining columns are blank; if they are, baselining has not started.\n3. Again, go to Application Health, right-click, and select Workspace, then Application Health status. If you see \"Unknown,\" it confirms that baselining is not active.\n4. Highlight your application, click the small yellow chain link in the first unnamed column, and select Application Configuration Details.\n5. In the bottom panel, select the line that says \"All,\" right-click it, and choose Take Action. From the dropdown, select Start_Baselining.\n6. Enter the desired Period (e.g., 2 days), Update_Interval (e.g., every 2 hours), and set Run_Clean to 1 for a clean start.\n\nOnce you have enabled baselining and it runs for a typical load period, the status should change from \"unknown\" to \"Good,\" \"Fair,\" or \"Bad\" based on the application's performance against the established thresholds.",
    "id": "TECHQA_DEV_Q132_1"
  },
  {
    "question_id": "TECHQA_DEV_Q141",
    "question": "Why is OCR is putting multiple lines on one line?\nI am running an APT application, and multiple detail lines are getting put on a single line within my .TXT file.  Is there something I can do about this?",
    "ground_truth": "1. Add the following action prior to **NormalizeCCO**.\n   ",
    "answer": "The issue you're experiencing with OCR merging multiple lines into a single line in your .TXT file is likely due to the way the NormalizeCCO process handles text recognition. To resolve this, you can adjust the parameters used in the NormalizeCCO action.\n\nHere’s what you can do:\n\n1. **Adjust the Offset Parameter**: Before running NormalizeCCO, set the first parameter to a lower value than the default (which is 50%). This parameter determines the percentage of vertical offset required for two words to be considered on separate lines. \n\n   - For example, if you set this value to 35%, any two words that are vertically offset by more than 35% of their height will be treated as separate lines. \n\n2. **Test Different Values**: If you still encounter issues, try experimenting with even lower values (e.g., 30% or 25%) to see if that helps in correctly separating the lines.\n\nBy adjusting this parameter, you should be able to improve the line separation in your output file. If the problem persists, further investigation into the quality of the input images may be necessary.",
    "id": "TECHQA_DEV_Q141_1"
  },
  {
    "question_id": "TECHQA_DEV_Q145",
    "question": "Why is the reload() not clearing the attribute cache so I can see my newly updated LDAP data in real time?\nWhy is the reload() not clearing the attribute cache so I can see my newly updated LDAP data in real time?",
    "ground_truth": "1. Please refer to the Recommended Updates page for delivery information.\n   Visit the URL **http://www.ibm.com/support/docview.wss?rs=180&uid=swg27004980** to get information about the delivery of the fix, which is targeted for inclusion in fix packs **8.0.0.13** and **8.5.5.9**.",
    "answer": "The issue you're experiencing with the `reload()` function not clearing the attribute cache for your updated LDAP data is likely due to the use of the `clearEntity` mode in the IBM WebSphere Application Server's Virtual Member Manager (VMM). When this mode is used, the cache may not be cleared properly if there is a discrepancy between the base entry and the name in the repository.\n\nTo resolve this issue, you can take the following steps:\n\n1. **Check Your Configuration**: Ensure that the base entry used matches the name in the repository. If they are different, this could be causing the cache not to clear.\n\n2. **Update to the Latest Fix Pack**: IBM has released fixes for this issue in specific fix packs. Make sure you are using at least:\n   - WebSphere Application Server V8.0 Fix Pack 13 (8.0.0.13)\n   - WebSphere Application Server V8.5.5 Fix Pack 9 (8.5.5.9) or later\n\n   You can find the fix packs and their details here: [IBM Fix Packs](http://www.ibm.com/support/docview.wss?rs=180&uid=swg27004980).\n\n3. **Test the Fix**: After updating to the appropriate fix pack, test the `reload()` function again to see if it now clears the cache and reflects the updated LDAP data.\n\nIf the problem persists after these steps, you may need to consult IBM support for further assistance.",
    "id": "TECHQA_DEV_Q145_1"
  },
  {
    "question_id": "TECHQA_DEV_Q153",
    "question": "Can we create Match design specification db in xmeta\nCould you please let me know if we can create schema for Match design\nspecification database in xmeta db.",
    "ground_truth": "1. Start from an empty **Database**.",
    "answer": "Yes, you can create a schema for a Match design specification database in xMeta, but it is important to follow specific guidelines to ensure that the database functions correctly and does not become corrupted.\n\n1. **Avoid Using the Default XMETA Database**: Start with a completely empty database instead of the default XMETA database.\n\n2. **Database Creation Requirements**:\n   - **Character Set**: Set the CHARACTERSET to AL32UTF for Oracle databases; the default is fine for SQL; and use codepage UTF-8 and page size 32K for DB2.\n   - **Permissions**: Ensure each user has permission to create tables and has read/write access in the database.\n   - **Database Space Calculation**: Determine the minimum required space based on the number of passes in the match specification, the number of input records, the input record length, and add 100 bytes as filler.\n\n3. **DSN Configuration**: If this is a distributed installation, ensure that ODBC is defined on both the client and server with the same name.\n\n4. **Follow Guidelines for Maintenance**: Each user should have their own database to avoid overwriting results, and separate tables for results from each design should be maintained.\n\nMake sure to refer to the IBM QualityStage documentation for more detailed steps on configuring the Match Designer with your newly created database.",
    "id": "TECHQA_DEV_Q153_1"
  },
  {
    "question_id": "TECHQA_DEV_Q154",
    "question": "Why are some Datatypes corrupt after Impact cluster failover/failback ?\nRunning Impact 7.1.0.11. The symptom is whenever Impact does a failover, a couple DataTypes\nturn out empty.\n\nI've checked the type files before and after Impact failover and the difference happens in the property\n\n*.SQL.USERPARAMETERS\n\nThis property no longer exists for the corrupted datatypes\".",
    "ground_truth": "1. Add the property to **$NCHOME/impact/etc/<SERVERNAME>_server.props** file\n   This property should be set with a size limit that can be 8192, 16384, 32768, etc.\n2. Add the property to all ImpactServers in the Cluster\n\n3. Restart the ImpactServer to enable the property\n   Ensure that the ImpactServer started as **Primary** has the correct, uncorrupted **.type** file to be replicated across the Cluster.",
    "answer": "The issue you're experiencing with some DataTypes turning empty after a failover in Impact 7.1.0.11 is likely due to the USERPARAMETERS property exceeding the character limit during replication. To resolve this, you need to increase the file size limit for the USERPARAMETERS property.\n\nHere are the steps to fix the problem:\n\n1. **Edit the Server Properties File**:\n   - Locate the server properties file for each ImpactServer in your cluster. The file is typically found at `$NCHOME/impact/etc/<SERVERNAME>_server.props`.\n\n2. **Add the Property**:\n   - Add the following property to the file, adjusting the size limit as needed (e.g., 8192, 16384, 32768, etc.):\n     ```\n     userparameters.size.limit=<desired_size>\n     ```\n   - Ensure that the size you choose can accommodate the total length of the USERPARAMETERS property name and its definition.\n\n3. **Remove Trailing Whitespace**:\n   - Make sure there are no trailing whitespace characters on the property line, as these can invalidate the property.\n\n4. **Restart the ImpactServers**:\n   - After making the changes, restart all ImpactServers in the cluster. Ensure that the server that starts as Primary has the correct, uncorrupted .type file to replicate across the cluster.\n\n5. **Verify the Changes**:\n   - After the restart, check the DataTypes to confirm that the USERPARAMETERS property is now correctly replicated and not empty.\n\nBy following these steps, you should be able to resolve the issue with corrupted DataTypes after failover/failback. If the problem persists, further investigation may be required.",
    "id": "TECHQA_DEV_Q154_1"
  },
  {
    "question_id": "TECHQA_DEV_Q161",
    "question": "Netcool/Impact 7.1.0: The StateChange value being used by the OMNIbusEventReader is too high\nThe value being used is a date and time in the future and as such is preventing the EventReader from capturing the current events.",
    "ground_truth": "1. Stop the EventReader.\n\n2. Open the EventReader for edit.\n   \n3. Click the **Clear State** button.\n   \n4. Exit the editor.\n   \n5. Restart the EventReader.\n   ",
    "answer": "To resolve the issue with the OMNIbusEventReader using a future-dated StateChange value, follow these steps:\n\n### Manual Solution via GUI:\n1. **Stop the EventReader**: Access the EventReader in the GUI and stop it.\n2. **Edit the EventReader**: Open the EventReader for editing.\n3. **Clear State**: Click the \"Clear State\" button to reset the StateChange value.\n4. **Restart the EventReader**: Exit the editor and restart the EventReader.\n\n### Command Line Solution:\nIf you prefer using the Command Line Interface, you can execute the following commands:\n\n1. **Connect to the ObjectServer**:\n   ```bash\n   telnet [Hostname] [Port]\n   ```\n\n2. **Run the ClearState.sh script**:\n   You can create a script named `ClearState.sh` that includes the following logic:\n   ```bash\n   ANN=\"AcquireStateChange\"; \n   Log(2,ID+ANN); \n   Script=\"/opt/IBM/netcool/impact/bin/CheckState.sh\"; \n   Parameter=\"password\"; \n   JRExecAction(Script, Parameter, false, 30); \n   NumExecOutput=Length(ExecOutput); \n   Log(3,ID+ANN+\": NumExecOutput: \"+NumExecOutput); \n   \n   If(NumExecOutput >= 1) \n   {  \n      Log(ID+ANN+\": CurrentStateChange: \"+HumanStateChange+\" is greater than CurrentTime: \"+HumanCurrentTime); \n      Log(ID+ANN+\": !!! Clearing EventReader State !!!\"); \n      Script=\"/opt/IBM/netcool/impact/bin/ClearState.sh\"; \n      Parameter=\"password\"; \n      JRExecAction(Script, Parameter, false, 30); \n   }\n   ```\n\n3. **Execute the script**: Run the `ClearState.sh` script to stop the EventReader, clear the StateChange value, and restart it.\n\nBy following either of these methods, you should be able to reset the StateChange value and allow the EventReader to capture current events again.",
    "id": "TECHQA_DEV_Q161_1"
  },
  {
    "question_id": "TECHQA_DEV_Q162",
    "question": "Is there a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager?\nIs there a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager?",
    "ground_truth": "1. Consult the security bulletin Vulnerability in **Apache Commons** affects IBM WebSphere Application Server",
    "answer": "Yes, there is a security vulnerability in the IBM WebSphere Application Server shipped with IBM Tivoli Netcool Configuration Manager, identified as CVE-2015-7450. This vulnerability could allow a remote attacker to execute arbitrary code on the system due to the deserialization of data with the Java InvokerTransformer class.\n\nTo remediate this issue, you should upgrade to a fixed version of the product. The following versions are recommended:\n\n- For ITNCM version 6.4.1.3, apply the fix available at: [Fix for ITNCM 6.4.1.3](http://www-933.ibm.com/support/fixcentral/swg/downloadFixes?parent=ibm~Tivoli&product=ibm/Tivoli/Tivoli+Netcool+Configuration+Manager&release=6.4.1.3&platform=All&function=fixId&fixids=ITNCM_6.4.1.3_IF001&includeRequisites=1&includeSupersedes=0&downloadMethod=http)\n\n- For ITNCM version 6.3.0.6, apply the fix available at: [Fix for ITNCM 6.3.0.6](http://www-933.ibm.com/support/fixcentral/swg/selectFixes?parent=ibm%7ETivoli&product=ibm/Tivoli/Tivoli+Netcool+Configuration+Manager&release=6.3.0.6&platform=All&function=all)\n\nFor further details on the vulnerability and fixes, consult the security bulletin linked in the context.",
    "id": "TECHQA_DEV_Q162_1"
  },
  {
    "question_id": "TECHQA_DEV_Q167",
    "question": "How do I recreate all the Oracle Text indexes for the Atlas database\nHow do I recreate all the Oracle Text indexes for the Atlas database ?",
    "ground_truth": "1. Shutdown the application server running the Atlas applications.\n   \n2. Locate the script drop_ctxsys_indexes.sql to drop the Oracle Text indexes.\n   Locate the script drop_ctxsys_indexes.sql to drop the Oracle Text indexes from the following folder in the Atlas release: **Atlas\\Schema\\Deploy\\smf\\db\\etc\\oracle**\n3. Open up a command window to that directory and execute the script using SQL Plus.\n   Open up a command window to that directory and execute the script using SQL Plus: **sqlplus <user>/<password>@<database> @drop_ctxsys_indexes.sql**\n4. Locate the scripts, setup_ctxsys_objects.sql and create_ctxsys_indexes.sql.\n   Locate the scripts, setup_ctxsys_objects.sql and create_ctxsys_indexes.sql, used to create the Oracle Text preferences and indexes from the following folder in the Atlas release. The <version> folder will differ depending on which version you are currently running: **Atlas\\Schema\\Deploy\\smf\\db\\release\\<version>\\oracle\\create\\schema**\n5. Open up a command window to that directory and execute the scripts using SQL Plus.\n   Open up a command window to that directory and execute the scripts using SQL Plus: **sqlplus <user>/<password>@<database> @setup_ctxsys_objects.sql**, **sqlplus <user>/<password>@<database> @create_ctxsys_indexes.sql**\n6. Start the application server running the Atlas applications.\n   ",
    "answer": "To recreate all the Oracle Text indexes for the Atlas database, follow these steps:\n\n1. **Shutdown the Application Server**: Ensure that the application server running the Atlas applications is shut down.\n\n2. **Drop Existing Indexes**:\n   - Locate the script `drop_ctxsys_indexes.sql` in the following directory:\n     ```\n     Atlas\\Schema\\Deploy\\smf\\db\\etc\\oracle\n     ```\n   - Open a command window in that directory and execute the script using SQL Plus:\n     ```\n     sqlplus <user>/<password>@<database> @drop_ctxsys_indexes.sql\n     ```\n\n3. **Create New Indexes**:\n   - Locate the scripts `setup_ctxsys_objects.sql` and `create_ctxsys_indexes.sql` in the following directory (the `<version>` folder will vary based on your current version):\n     ```\n     Atlas\\Schema\\Deploy\\smf\\db\\release\\<version>\\oracle\\create\\schema\n     ```\n   - Open a command window in that directory and execute the scripts using SQL Plus:\n     ```\n     sqlplus <user>/<password>@<database> @setup_ctxsys_objects.sql\n     sqlplus <user>/<password>@<database> @create_ctxsys_indexes.sql\n     ```\n\n4. **Restart the Application Server**: Once the indexes have been recreated, start the application server running the Atlas applications.\n\nMake sure you have the necessary permissions and access to the Atlas database before performing these steps.",
    "id": "TECHQA_DEV_Q167_1"
  },
  {
    "question_id": "TECHQA_DEV_Q171",
    "question": "Error: \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" occurs at portal startup\nWe are using Portal Server 8.5 and when starting the Portal server we see following error:\n\n0000005e MBeanStarter E com.ibm.wps.scripting.server.MBeanStarter loadExtensions failed to load extension: key: ServerExt.applications / value: com.ibm.wps.scripting.server.ApplicationServerExtensions\n\nHow can we resolve this error?",
    "ground_truth": "1. Use the WebSphere Portal & WCM Combined Cumulative Fix 05 (PI31198) that is available for Portal version **8.5.0.0** from **Fix Central**.",
    "answer": "To resolve the \"MBEANSTARTER LOADEXTENSIONS FAILED TO LOAD EXTENSION\" error in Portal Server 8.5, follow these steps:\n\n1. Open the WebSphere Application Server (WAS) admin console.\n2. Navigate to **Resources > Resource environment providers**.\n3. Locate **WPScriptingService** and click on **Custom properties**.\n4. Find the entry with the name **ServerExt.applications** and the value **com.ibm.wps.scripting.server.ApplicationServerExtensions**.\n5. Delete this entry.\n6. Save your changes and restart the Portal server.\n\nThis should resolve the error during startup. If the issue persists, consider applying the latest cumulative fix for WebSphere Portal 8.5.0.0, which includes a code fix for this problem. You can find the fix at the IBM Fix Central website.",
    "id": "TECHQA_DEV_Q171_1"
  },
  {
    "question_id": "TECHQA_DEV_Q181",
    "question": "Get all data that\\'s registred today\nVersion: \nMxLoader 4.7.4\n                        \n\nProblem:\nIs it possible to do something like this:\nreportdate >= TODAY()?\n\nI cant get it to work but i would like to get all the data that has been registred today today.",
    "ground_truth": "1. Replace getdate() MSSQL function by **DB2 CURRENT DATE** special register.\n",
    "answer": "To retrieve all data that has been registered today in Maximo using DB2 or Oracle, you can use the following SQL queries:\n\nFor DB2:\n```sql\nWHERE reportdate >= CURRENT DATE\n```\n\nFor Oracle:\n```sql\nWHERE reportdate >= SYSDATE\n```\n\nMake sure to adjust the query according to your existing SQL structure. This will give you all entries from today onwards.",
    "id": "TECHQA_DEV_Q181_1"
  },
  {
    "question_id": "TECHQA_DEV_Q186",
    "question": "Silent uninstall of ITCAM for MQ agent fails\nRunning silent uninstall of the ITCAM for MQ agent with this command: start /wait setup /z\"/sfMQ_Silent_Uninstall.txt\" /s /f2\"C:\\temp\\silent_setup.log\" fails with this message in the Abort_*.trc file: SEVERE: You must agree to the License Agreement.\n\nThe MQ_Silent_Uninstall.txt does contain this line: License Agreement=I agree to use the software only in accordance with the installed license.",
    "ground_truth": "1. Specify the complete path to the **silent response file** while launching the silent install.",
    "answer": "To resolve the issue with the silent uninstall of the ITCAM for MQ agent failing due to the license agreement, ensure that you specify the complete path to the silent response file in your command. \n\nModify your command as follows:\n\n```bash\nstart /wait setup /z\"/sfC:\\path\\to\\your\\MQ_Silent_Uninstall.txt\" /s /f2\"C:\\temp\\silent_setup.log\"\n```\n\nMake sure to replace `C:\\path\\to\\your\\` with the actual directory where `MQ_Silent_Uninstall.txt` is located. This should help the uninstall process recognize the license agreement and proceed without errors.",
    "id": "TECHQA_DEV_Q186_1"
  },
  {
    "question_id": "TECHQA_DEV_Q196",
    "question": "Error while installing SpSS modeler trial version\nI have downloaded the SPSS modeller trial version (18.1) (64 bit) and trying to install the same. I get the following error 1152: Error extracting modelerClient64.msi to the temporary location",
    "ground_truth": "1. Transfer the **files** again.",
    "answer": "The error 1152 you are encountering while installing SPSS Modeler trial version is likely due to issues with the temporary location where the installer is trying to extract files. Here are some steps you can take to resolve the issue:\n\n1. **Check Available Space**: Ensure that there is enough free space in your temporary directory. You can check this by navigating to your temporary folder, typically located at `C:\\Users\\<YourUsername>\\AppData\\Local\\Temp`.\n\n2. **Permissions**: Make sure you have the necessary permissions to write to the temporary location. You can try running the installer as an administrator by right-clicking on the installer file and selecting \"Run as administrator.\"\n\n3. **Re-download the Installer**: The downloaded file may be corrupted. Use a tool like MD5 to verify the integrity of the file, or simply download the SPSS Modeler trial version again from the official source.\n\n4. **Clear Temporary Files**: Clear out any unnecessary files in your temporary folder to free up space and avoid conflicts.\n\n5. **Try a Different Location**: If the problem persists, you can try changing the temporary folder location. You can do this by setting the `TEMP` and `TMP` environment variables to a different directory with sufficient space.\n\nAfter following these steps, try running the installer again. If you continue to experience issues, consider reaching out to the IBM Modeler forum for further assistance.",
    "id": "TECHQA_DEV_Q196_1"
  },
  {
    "question_id": "TECHQA_DEV_Q201",
    "question": "Why are HTML documents not rendering  and just shown as plain text after upgrading and installing ifixes to BPM?\nAfter upgrading BPM, my HTML documents that were once rendering are no longer being displayed correctly and are being shown as plain text. This is happening in multiple web browses.",
    "ground_truth": "1. Install IBM Business Process Manager interim fix **JR50092**.",
    "answer": "The issue you're experiencing with HTML documents rendering as plain text after upgrading BPM is likely due to the default configuration that maps the `text/html` MIME type to `text/plain`. This is a security measure to prevent potentially malicious HTML content from being executed in the browser.\n\nTo resolve this issue, you need to modify the `100Custom.xml` configuration file to explicitly allow the `text/html` MIME type. Here’s how you can do that:\n\n1. Locate the `100Custom.xml` file in your BPM installation directory.\n2. Open the file in a text editor.\n3. Add the following lines to override the default mapping:\n\n   ```xml\n   <document-attachment-download-mime-types>\n       <mime-type-map>\n           <from>text/html</from>\n           <to>text/html</to>\n       </mime-type-map>\n   </document-attachment-download-mime-types>\n   ```\n\n4. Save the changes to the `100Custom.xml` file.\n5. Restart your BPM server for the changes to take effect.\n\nAfter completing these steps, your HTML documents should render correctly instead of being displayed as plain text. If you continue to experience issues, please check for any additional configurations or restrictions that may be in place.",
    "id": "TECHQA_DEV_Q201_1"
  },
  {
    "question_id": "TECHQA_DEV_Q202",
    "question": "Why is installation manager cores when try to install netcool using GUI mode in AIX 7.1?\nIBM Installation Manager Cores when running in GUI mode on AIX 7.1",
    "ground_truth": "1. Install the **gtk+** RPM and dependencies on **AIX**\n   ",
    "answer": "To resolve the issue of IBM Installation Manager causing a core dump when trying to install Netcool using GUI mode on AIX 7.1, you need to ensure that the required gtk libraries are installed on your system. Follow these steps:\n\n1. **Install gtk Libraries**: The IBM Installation Manager requires the gtk+ RPM and its dependencies to be available. Use the package manager on AIX to install the gtk libraries. If you do not have the libraries, you can typically find and download them from the IBM support site or use your system's package management tools.\n\n2. **Verify Installation**: After installation, verify that the gtk libraries are correctly installed by checking for their presence in the library path:\n   ```\n   ls /usr/lib | grep gtk\n   ```\n\n3. **Check Java Environment**: Make sure that your Java environment is correctly set up, and that the JAVA_HOME environment variable points to the correct Java installation.\n\n4. **Use Alternative Installation Modes**: If the GUI mode continues to give trouble, consider using the console mode, command-line mode, or silent mode for installation, which do not require the gtk libraries. More information can be found in the Installation Manager Information Center.\n\nIf these steps do not resolve the issue, further investigation may be required to analyze logs or configurations specific to your environment.",
    "id": "TECHQA_DEV_Q202_1"
  },
  {
    "question_id": "TECHQA_DEV_Q209",
    "question": "How to change the maximum string length for properties in FileNet Administration Console for Content Engine (ACCE)\nI am trying to change the maximum string length in ACCE like we do in FileNet Enterprise Manager, but in the more Tab, I am not seeing the option. In this case, how can I change it?",
    "ground_truth": "1. Launch **ACCE**\n   \n2. Expand the object stores folder and click the object store to open the **Object store** tab\n   \n3. Expand the Data Design folder and Classes folder. Click the document class to open **Document Class** tab\n   \n4. From Properties tab, open **Property Definitions** drop down and select the property definition you want to modify\n   \n5. ACCE will open that property definition in a new Properties tab\n   \n6. Modify the property definition as required\n   \n7. Go back to the **Class Definition** tab and click Save\n   ",
    "answer": "To change the maximum string length for properties in the IBM Administration Console for Content Engine (ACCE), follow these steps:\n\n1. Launch ACCE.\n2. Expand the object stores folder and click on the object store to open the Object Store tab.\n3. Expand the Data Design folder and then the Classes folder. Click on the document class you want to modify to open the Document Class tab.\n4. In the Properties tab, open the Property Definitions dropdown and select the property definition you wish to modify.\n5. ACCE will open that property definition in a new Properties tab.\n6. Modify the maximum string length as required.\n7. Go back to the Class Definition tab and click Save to apply your changes.\n\nMake sure to review your changes before saving to ensure they meet your requirements.",
    "id": "TECHQA_DEV_Q209_1"
  },
  {
    "question_id": "TECHQA_DEV_Q216",
    "question": "Error message 1311 when attempting to install SPSS 23 on Windows 10.\nI have downloaded SPSS 23 onto a Windows 10 operating system. The computer previously had SPSS, however the computer crashed and SPSS needs be installed on the new operating system. When trying to install the program the following error message appears Error 1311. Source file not found.\n\nScreenshot attached.\nerror-messg.png (50.7 kB)",
    "ground_truth": "1. Stop the installation.\n   \n2. Extract all of the files in the compressed (.zip file) to a new folder.\n   \n3. Run the installer executable (**setup.exe**) from that new folder.\n   ",
    "answer": "To resolve the \"Error 1311. Source file not found\" message when installing SPSS 23 on Windows 10, follow these steps:\n\n1. **Stop the Installation**: If the installation is currently running, cancel it.\n\n2. **Extract the Files**:\n   - Right-click on the downloaded compressed file (.zip).\n   - Select the 'Extract All' option from the drop-down menu.\n   - Click the 'Extract' button to decompress the files. This will create a new folder containing the extracted files in the same location as the .zip file.\n\n3. **Run the Installer**:\n   - Navigate to the new folder that contains the extracted files.\n   - Locate and double-click on the 'setup.exe' file to start the installation process.\n\nBy extracting the files first, you ensure that all necessary components are available for the installation, which should prevent the error from occurring. If you encounter any further issues, please let me know!",
    "id": "TECHQA_DEV_Q216_1"
  },
  {
    "question_id": "TECHQA_DEV_Q221",
    "question": "App Connect Professional (formerly Cast Iron) Studio not launching\nWhen trying to start App Connect Professional (formerly Cast Iron) Studio tool, the application appears but after few seconds it crashes with no error message or warning.",
    "ground_truth": "1. Start the Studio through the command line interface using the following command: **CastIronStudio.exe -J-Xmx1024m**\n   This command starts the Studio by executing the 'CastIronStudio.exe' file and allocates a memory size of '1024' MB to the Studio instead of the default value of 512 MB.",
    "answer": "To resolve the issue of App Connect Professional (formerly Cast Iron) Studio crashing without any error message, you can try increasing the heap memory allocated to the application. Here's how to do it:\n\n1. Open a command line interface (Command Prompt on Windows).\n2. Navigate to the directory where `CastIronStudio.exe` is located.\n3. Run the following command to start the Studio with increased heap memory:\n\n   ```\n   CastIronStudio.exe -J-Xmx1024m\n   ```\n\nThis command allocates 1024 MB of heap memory to the Studio instead of the default value which may be too low (512 MB). You can adjust the \"1024\" value based on your system's performance.\n\nIf the issue persists after increasing the heap memory, consider using garbage collection from within Studio to free up unused space or check the XML Schema preference settings.\n\nIf none of these steps work, you may need to contact IBM Cast Iron Support for further assistance.",
    "id": "TECHQA_DEV_Q221_1"
  },
  {
    "question_id": "TECHQA_DEV_Q224",
    "question": "How do we set HttpOnly and secure flag in Oracle Weblogic 12c to secure IBM Atlas?\nHow do we set HttpOnly and secure flag in Oracle Weblogic 12c to secure IBM Atlas?",
    "ground_truth": "1. Undeploy any existing PolicyAtlas deployments using Oracle Weblogic console\n   \n2. Open the **PolicyAtlas.ear** file using a tool like 7zip or similar and update weblogic.xml file with the changes below\n   Update the weblogic.xml file to include the following session descriptor changes: **<wls:session-descriptor><wls:cookie-secure>true</wls:cookie-secure><wls:cookie-http-only>true</wls:cookie-http-only><wls:url-rewriting-enabled>false</wls:url-rewriting-enabled></wls:session-descriptor>**\n3. Save the changes by updating the ear file\n   \n4. Redeploy the updated ear file using Oracle Weblogic console\n   ",
    "answer": "To set the HttpOnly and secure flags in Oracle Weblogic 12c for IBM Atlas, follow these steps:\n\n1. **Undeploy Existing PolicyAtlas**: Use the Oracle Weblogic console to undeploy any existing PolicyAtlas deployments.\n\n2. **Modify weblogic.xml**:\n   - Open the `PolicyAtlas.ear` file using a tool like 7zip or a similar archive tool.\n   - Locate the `weblogic.xml` file within the `PolicyAtlas.ear`.\n   - Update the `weblogic.xml` file to include the following configuration:\n\n   ```xml\n   <wls:session-descriptor>\n       <wls:cookie-secure>true</wls:cookie-secure>\n       <wls:cookie-http-only>true</wls:cookie-http-only>\n       <wls:url-rewriting-enabled>false</wls:url-rewriting-enabled>\n   </wls:session-descriptor>\n   ```\n\n3. **Save Changes**: After making the changes, save the updated `PolicyAtlas.ear` file.\n\n4. **Redeploy the Updated EAR File**: Use the Oracle Weblogic console to redeploy the modified `PolicyAtlas.ear` file.\n\nBy following these steps, you will successfully set the HttpOnly and secure flags to enhance the security of your IBM Atlas application.",
    "id": "TECHQA_DEV_Q224_1"
  },
  {
    "question_id": "TECHQA_DEV_Q229",
    "question": "Can I hide left menu pane for specific application?\nIs it possible to disable the left navigation pane menu for certain application?",
    "ground_truth": "1. Edit the **incident.xml**.\n\n2. Import back the **incident.xml** and save.",
    "answer": "Yes, you can hide the left navigation pane for a specific application by modifying the application presentation XML. To disable the left navigation pane for the Incident application, follow these steps:\n\n1. Locate the `incident.xml` file.\n2. Edit the `<presentation>` tag to include `systemnav=\"false\"`. Change it from:\n   ```xml\n   <presentation apphelp=\"com.ibm.tusc.doc,incident/incident.html\" beanclass=\"com.ibm.tsd.pminc.webclient.beans.PmIncidentAppBean\" id=\"incident\" mboname=\"INCIDENT\" orderby=\"TICKETID\" resultstableid=\"results_showlist\" version=\"7.1.0.0\">\n   ```\n   to:\n   ```xml\n   <presentation apphelp=\"com.ibm.tusc.doc,incident/incident.html\" beanclass=\"com.ibm.tsd.pminc.webclient.beans.PmIncidentAppBean\" id=\"incident\" mboname=\"INCIDENT\" orderby=\"TICKETID\" resultstableid=\"results_showlist\" version=\"7.1.0.0\" systemnav=\"false\">\n   ```\n\n3. Import the modified `incident.xml` back into your system and save the changes.\n\nAfter completing these steps, the left navigation pane will no longer be visible in the Incident application.",
    "id": "TECHQA_DEV_Q229_1"
  },
  {
    "question_id": "TECHQA_DEV_Q234",
    "question": "TCR 2.1.1 Fixpack 2 installation failed\nI need to install Fixpack 2 on my TCR 2.1.1 environment, but the installation keeps failing with error:\n\n     ACUOSI0050E External command action failed with return code 1.\n\nI was not able to understand why it is failing. Can you please help providing suggestion to perform a correct troubleshooting ?\n\nThanks",
    "ground_truth": "1. Double check the **permission bit** for the involved directory tree.\n\n2. In case, temporarily set them to give **write** authorization to the user account.\n\n3. Run again the installation program.\n   ",
    "answer": "To resolve the installation failure of TCR 2.1.1 Fixpack 2 with the error ACUOSI0050E, follow these steps:\n\n1. **Check Permissions**: Ensure that the user account you are using to run the installation has the necessary write permissions on the directory tree involved in the installation. Specifically, check the following directories:\n   - `/opt/IBM/tivoli/tipv2Components/TCRComponent`\n   - `/opt/IBM/tivoli/tipv2`\n   - `/opt/IBM/tivoli/tipv2/profiles/TIPProfile/installedApps/TIPCell/IBM Cognos 8.ear/p2pd.war/tivoli/ITM/images/`\n\n2. **Modify Permissions**: If the user does not have the required permissions, temporarily adjust the permissions to grant write access. You can do this using the `chmod` command. For example:\n   ```bash\n   sudo chmod -R u+w /opt/IBM/tivoli/tipv2Components/TCRComponent\n   sudo chmod -R u+w /opt/IBM/tivoli/tipv2\n   sudo chmod -R u+w /opt/IBM/tivoli/tipv2/profiles/TIPProfile/installedApps/TIPCell/IBM\\ Cognos\\ 8.ear/p2pd.war/tivoli/ITM/images/\n   ```\n\n3. **Review Log Files**: Check the log file `IBM_Tivoli_Common_Reporting_2.1_1_FP2.log` and the error file `tcr211_Embedded_FP2_run_cognos_copy_ear_update.err` for more specific error messages that can provide additional context on what might be causing the failure.\n\n4. **Retry Installation**: After adjusting the permissions, attempt to run the Fixpack installation again.\n\nBy ensuring the correct permissions are set, you should be able to resolve the installation issue. If the problem persists, further investigation into the log files may be necessary.",
    "id": "TECHQA_DEV_Q234_1"
  },
  {
    "question_id": "TECHQA_DEV_Q239",
    "question": "Cannot launch RFT 8.2\nHello.\n\nCould anyone can help to see why I cannot launch RFT 8.2? When I launch RFT. I get an error message--\"An error has occurred. See the log file...\" I check the log file. It shows\n\n!SESSION Mon Nov 04 12:46:16 CST 2013 ------------------------------------------\n!ENTRY org.eclipse.equinox.launcher 4 0 2013-11-04 12:46:16.359\n!MESSAGE Exception launching the Eclipse Platform:\n!STACK\njava.lang.ClassNotFoundException: org.eclipse.core.runtime.adaptor.EclipseStarter\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:423)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:653)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:619)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:616)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1407)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1383)\n\nIf I launch RFT with -clean or -vm option, the same phenomenon occurs.",
    "ground_truth": "1. Delete the user's **.eclipse/ibm.software.delivery.platform_7.5.0_????** directory.\n   For example, run command **rm -rf /home/joe/.eclipse/ibm.software.delivery.platform_7.5.0_1529064711** to delete the specified directory.\n2. Relaunch the package.\n   ",
    "answer": "To resolve the issue of not being able to launch RFT 8.2 due to the \"ClassNotFoundException\" error, you can follow these steps:\n\n1. **Delete the Eclipse Configuration Directory**: Navigate to your home directory and delete the specific Eclipse configuration directory that may be causing the problem. You can do this by running the following command in your terminal:\n\n   ```bash\n   rm -rf ~/.eclipse/ibm.software.delivery.platform_7.5.0_???? \n   ```\n\n   Replace `????` with the appropriate version number if necessary. For example, it might look like this:\n\n   ```bash\n   rm -rf ~/.eclipse/ibm.software.delivery.platform_7.5.0_1529064711\n   ```\n\n2. **Relaunch RFT**: After deleting the directory, try launching RFT 8.2 again.\n\nThis workaround addresses the issue of outdated Eclipse configuration that can affect the startup of the application. If the problem persists after following these steps, further investigation may be required.",
    "id": "TECHQA_DEV_Q239_1"
  },
  {
    "question_id": "TECHQA_DEV_Q240",
    "question": "Port number error starting 9.0 Launcher\nI'm attempting to start up v9.0 for the first time with one .msl file on a Windows server and get the following error.  I also have v8.4 on this server and it starts fine.  I do not have v8.4 running when I attempt to start v9.0.\n\nCannot recognize if the system RecordChangeSystem.msl; has started. Reason: Server is unable to get the status of the system on port number 6,002.\n\nI have the port range set to 7000/8000.  I've never seen this error before.\n\nAny help?  Thanks.",
    "ground_truth": "1. Obtain patch for APAR **PI64816**.\n   ",
    "answer": "The error you are encountering with the v9.0 Launcher regarding the port number 6,002 suggests that the server is unable to communicate on that port. Since you have set the port range to 7000/8000, it is likely that the port 6,002 is outside of this range, which could be causing the issue.\n\nHere are some steps you can take to resolve the problem:\n\n1. **Check Port Configuration**: Ensure that the configuration for the v9.0 Launcher is set to use the correct port range (7000-8000). You may need to adjust the settings to ensure that the Launcher is not trying to use port 6,002.\n\n2. **Firewall Settings**: Verify that your firewall settings allow traffic on the port range you have configured (7000-8000). If the firewall is blocking the necessary ports, the Launcher will not be able to start properly.\n\n3. **Check for Conflicts**: Make sure that no other applications or services are using the port 6,002. You can use tools like `netstat` to check for port usage.\n\n4. **Review Logs**: Look at the logs for any additional error messages that might provide more context about the issue. This can help identify if there are other underlying problems.\n\n5. **Restart Services**: Sometimes, simply restarting the Launcher or the server can resolve port-related issues.\n\nIf these steps do not resolve the issue, you may need to consult the documentation for v9.0 or reach out to IBM support for further assistance.",
    "id": "TECHQA_DEV_Q240_1"
  },
  {
    "question_id": "TECHQA_DEV_Q244",
    "question": "How to clear Errors Found in crm_mon\nHow to clear Errors Found in crm_mon",
    "ground_truth": "1. Run the **cib_tools.pl** script.\n   Execute the command **/opt/nz-hwsupport/pts/cib_tools.pl** in the terminal.",
    "answer": "To clear the errors found in `crm_mon`, follow these steps:\n\n1. Open a terminal on your system.\n2. Run the CIB tools script by executing the following command:\n   ```\n   /opt/nz-hwsupport/pts/cib_tools.pl\n   ```\n3. Once the script runs, it will display the current cluster status and any failed resources.\n4. When prompted with a list of failed resources, select the resource you want to clear by entering the corresponding number. For example, if you want to clear `fencing_route_to_ha2_start_0`, type `0` and press Enter.\n5. The script will invoke the command to clear the selected resource. You should see a message indicating that the resource was cleared successfully.\n6. Repeat the process for any other failed resources as needed.\n\nIf you encounter any issues or if the errors persist, please provide additional details for further assistance.",
    "id": "TECHQA_DEV_Q244_1"
  },
  {
    "question_id": "TECHQA_DEV_Q245",
    "question": "Problem with XMLLIB->VALIDATEEX during XML Validation\nI am using XMLLIB VALIDATEXX in WTX 8.3.0.5 for XML Validations and it is running fine on Windows.\nWhen deployed same code on zos map is executing in loop(output card having rule with xmllib method call is not completing) \nPlease suggest.Thanks",
    "ground_truth": "1. Add the XML toolkit **xml4c** library directory to the **LIBPATH** environment variable.\n   Execute the command: **export LIBPATH=$LIBPATH:/usr/lpp/ixm/xslt4c-1_11/lib/** (example)",
    "answer": "To resolve the issue with XMLLIB->VALIDATEEX running in a loop on z/OS, you need to ensure that the XML toolkit xml4c library directory is included in the LIBPATH environment variable. The error message indicates that the required module `libxslt4c.1_11_0q.dll` is not found, which suggests that the library path is not correctly set.\n\nHere are the steps to fix the problem:\n\n1. Identify the correct path to the XML toolkit xml4c library on your z/OS system. It is typically located in a directory like `/usr/lpp/ixm/xslt4c-1_11/lib/`.\n\n2. Update the LIBPATH environment variable to include this directory. You can do this by executing the following command in your shell:\n\n   ```bash\n   export LIBPATH=$LIBPATH:/usr/lpp/ixm/xslt4c-1_11/lib/\n   ```\n\n3. After updating the LIBPATH, re-run your map to see if the issue is resolved.\n\nIf the problem persists, ensure that the library files are indeed present in the specified directory and that you have the necessary permissions to access them.",
    "id": "TECHQA_DEV_Q245_1"
  },
  {
    "question_id": "TECHQA_DEV_Q254",
    "question": "Why do I receive the message, \"IKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION. \" for a TSO SEND command?\nIf you issue the TSO SEND command in a batch job and receive this message:\n\nIKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION.\nIKJ79154I REASON CODE X'00000004'.",
    "ground_truth": "1. Code a facility class for the **FEK.CMD.SEND** and **FEK.CMD.SEND.CLEAR**\n   ",
    "answer": "The message \"IKJ79154I INSTALLATION EXIT IKJEESX0 REQUESTED TERMINATION\" along with reason code X'00000004' indicates an authorization issue related to the TSO SEND command in a batch job. Specifically, this occurs because the necessary facility class definitions for FEK.CMD.SEND and FEK.CMD.SEND.CLEAR have not been coded.\n\nTo resolve this issue, follow these steps:\n\n1. **Code the Security Definitions**: You need to define the appropriate facility for the TSO SEND command. Here is an example of how to do this in your security configuration:\n\n   ```plaintext\n   RDEFINE FACILITY (FEK.CMD.SEND.**) UACC(READ) -\n   DATA('z/OS EXPLORER - SEND COMMAND') \n\n   RDEFINE FACILITY (FEK.CMD.SEND.CLEAR.**) UACC(NONE) -\n   DATA('z/OS EXPLORER - CLEAR SEND BUFFER') \n\n   PERMIT FEK.CMD.SEND.CLEAR.** CLASS(FACILITY) -\n   ID(STCRSE) ACCESS(READ) \n\n   SETROPTS RACLIST(FACILITY) REFRESH\n   ```\n\n2. **Apply the Definitions**: Execute the defined commands in your security system (such as RACF) to ensure that the necessary permissions are set.\n\n3. **Testing**: After updating the definitions, try issuing the TSO SEND command again in your batch job to see if the error persists.\n\nMake sure you have the necessary administrative rights to execute these commands, or coordinate with your system administrator if required. If you still encounter issues, further investigation into your security settings may be needed.",
    "id": "TECHQA_DEV_Q254_1"
  },
  {
    "question_id": "TECHQA_DEV_Q257",
    "question": "How to control SDMS database size?\nHi,\n\nITCAM for SOA 7.1.1 was installed about 3 years ago. I already know that SDMS database size may increase with no limit. Has anyone found a way to keep under control this behavior?\n\nThanks",
    "ground_truth": "1. Schedule a daily job to run the **kd4TrimDB2db** utility.\n   This step involves setting up a regular task that executes the **kd4TrimDB2db** utility every day to maintain only the latest 24 hours of data.",
    "answer": "To control the size of the SDMS database in ITCAM for SOA 7.1.1, you can implement a regular pruning strategy using the `kd4TrimDB2db` utility. Since there is no automatic mechanism for pruning in this version, you will need to schedule a daily job to run this utility. This will help you keep only the latest 24 hours of data in the database.\n\nFor more detailed instructions, you can refer to the following Wiki page: [Pruning SDMS Relationship Metrics Tables](https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/Tivoli+Composite+Application+Manager/page/Pruning+SDMS+Relationship+Metrics+Tables).\n\nPlease note that ITCAM for SOA 7.1.1 is out of support since April 30, 2015, so consider upgrading to a newer version for better features and support.",
    "id": "TECHQA_DEV_Q257_1"
  },
  {
    "question_id": "TECHQA_DEV_Q260",
    "question": "Crash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\nCrash happened due to \"PI50993:Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577)\"\n\nDetails of gpf crash events: A VerifyError was thrown due to \"Inaccessible class\" at offset 39(0x27) of the method executeInternal(Lorg/springframework/http/HttpHeaders;[B)Lorg/springfram ework/http/client/ClientHttpResponse of the above class org/springframework/http/client/HttpComponentsClientHttpRequest.\n\nLooking at method the bytecodes :\n\n31 invokespecial 15 org/apache/http/entity/ByteArrayEntity.([B)V 34 astore 4 36 aload3 37 aload 4 39 invokeinterface2 41 invokeinterface 16 org/apache/http/HttpEntityEnclosingRequest.setEntity(Lorg/apache/http/Ht tpEntity;)V\n\nThe above sequence of bytecodes indicates it created an instance of org/apache/http/entity/ByteArrayEntity, trying to cast it to type Lorg/apache/http/HttpEntity; which in turns led to the \"Inaccessible class\" VerifyError message.\n\nIt is clear that class org/apache/http/HttpEntity was not loaded at all:\n\n    allclasses | grep org/apache/http/HttpEntity",
    "ground_truth": "1. Update the application with **HTTPCore** and **HTTPClient** libraries bundled.",
    "answer": "To resolve the crash caused by the \"Inaccessible class\" VerifyError related to the Apache HTTPComponents vulnerabilities in WebSphere Application Server (CVE-2012-6153, CVE-2014-3577), you should follow these steps:\n\n1. **Apply the Fix**: Ensure that you have applied the PI50993 fix for your version of WebSphere Application Server. You can download the fix from the IBM Fix Central or the provided links in the context.\n\n2. **Update Dependencies**: After applying the fix, you may encounter a `NoClassDefFoundError` due to the HTTPCore and HTTPClient libraries no longer being visible to your application. To resolve this:\n   - Update your application to include the necessary HTTPCore and HTTPClient libraries that are compatible with the version of WebSphere you are using. You may need to bundle these libraries with your application.\n\n3. **Review Installation Instructions**: Check the `readme.txt` file included with the fix for detailed installation instructions and any additional steps that may be required.\n\n4. **Test the Application**: After making the updates, thoroughly test your application to ensure that the crash is resolved and that there are no further issues.\n\nIf you continue to experience problems, consider reaching out to IBM Support for further assistance.",
    "id": "TECHQA_DEV_Q260_1"
  },
  {
    "question_id": "TECHQA_DEV_Q263",
    "question": "How can I check the health of my IBM PureApplication System?\nHow can I check the health of my IBM PureApplication System?\nAre there steps to verify that my system is healthy? Is this something I can do, or does IBM have to verify the health of my system?",
    "ground_truth": "1. Consider forwarding the **PureApplication System Events** to an external monitoring system, such as IBM Netcool/OMIbus.\n\n2. Enable the call home feature.",
    "answer": "To check the health of your IBM PureApplication System, follow these steps:\n\n1. **Access the System Health Check Report**:\n   - Navigate to the System Console.\n   - Go to **System > System Troubleshooting**.\n   - Click on **System Health Check** to view a consolidated report of the system's health.\n\n2. **Monitor High Availability Status**:\n   - In the System Console, go to **Troubleshooting** and expand the **High Availability** section.\n   - Ensure that the overall status under **Service Code** is \"Online\".\n\n3. **Check for Problems**:\n   - Go to **System > Problems** in the System Console.\n   - This view should be empty. If there are any listed problems, they need to be addressed.\n\n4. **Inspect Storage Nodes**:\n   - Navigate to **Hardware > Storage Devices**.\n   - Check the status of all Storage Nodes and Storage Node Expansions. Ensure that the counts for Disk Drives, LUNs, and Storage Controller Ports are equal for each node.\n\n5. **Consider External Monitoring**:\n   - Forward PureApplication System Events to an external monitoring system, such as IBM Netcool/OMIbus, and enable the call home feature for proactive monitoring.\n\n6. **Regular Checks**:\n   - Perform these checks weekly for a full health check and every couple of days for a lite health check.\n\nIf you encounter any issues or if the information displayed is not as expected, document the findings and consider contacting IBM Support for further assistance.",
    "id": "TECHQA_DEV_Q263_1"
  },
  {
    "question_id": "TECHQA_DEV_Q266",
    "question": "How to install Packaging utility?\nHow to install Packaging utility?",
    "ground_truth": "1. Use **Installation Manager** to install and update **Packaging Utility**.\n   ",
    "answer": "To install the Packaging Utility, follow these steps:\n\n1. **Check Installation Manager**: Ensure that Installation Manager is installed on your system. If it is not installed, you will need to download the Packaging Utility files, which include Installation Manager.\n\n2. **Download the Installer**: If Installation Manager is not installed, download the installer package for Packaging Utility, which is named `pu.offering.disk.platform_version.zip`. Replace `platform` with your operating system and `version` with the desired version of Packaging Utility.\n\n3. **Run the Installer**: \n   - If you have Installation Manager installed, you can add the downloaded package as a repository and use it to install or update Packaging Utility.\n   - If you are installing without Installation Manager, run the install command from the downloaded package.\n\n4. **Install or Update Without Downloading**: If you have Installation Manager installed and internet access, you can install or update Packaging Utility directly from the Packaging Utility repository on www.ibm.com without downloading files. You will need an IBM user name and password to access the repository.\n\n5. **Refer to Documentation**: For detailed instructions specific to your operating system (Windows, Linux, UNIX, Mac OS X), refer to the IBM Installation Manager Knowledge Center for installation and update procedures.\n\nFor more information, you can visit the [IBM Knowledge Center](http://www.ibm.com/support/knowledgecenter/SSDV2W/im_family_welcome.html).",
    "id": "TECHQA_DEV_Q266_1"
  },
  {
    "question_id": "TECHQA_DEV_Q271",
    "question": "Problem with Postal database in Parascript\nHi\n\ni am working with Parascript and i have installed successfully in my local system by folloing this guide [ Parascript FieldScript for Taskmaster Guide ]\n\nhere i can able to create vocabulary file, but storing multiple values into this the values are overridden and i do not understand how to create a postal database and access it\n\nis that postal database is separate component ,,?? do we need to get somewhere and install ,,? they just mention in Guide the use of actions only\n\nand does this parascript really helps to get better recognize.",
    "ground_truth": "1. Obtain refreshed data from **Passport Advantage** on a regular schedule so that you avoid issues that are associated with disabled address information.",
    "answer": "To create and access a postal database in Parascript, you need to download the associated data disk that contains the United States Postal Service (USPS) database. This database is available through Passport Advantage, and it is essential for proper address recognition.\n\nHere are the steps you should follow:\n\n1. **Sign in to Passport Advantage**: Use your IBM ID to log in. If you do not have an IBM ID, you will need to register for one.\n\n2. **Download the USPS Database**: Once logged in, locate the Parascript FieldScript for IBM Datacap and download the data disk that includes the USPS database.\n\n3. **Regular Updates**: Be aware that the address information in the USPS database is automatically disabled 105 days after the date of issue. IBM refreshes this data on the 14th day of every month, so ensure you download the updated database regularly to avoid issues.\n\n4. **Refer to the Guide**: For specific actions and how to implement the postal database in your application, refer to the \"Parascript FieldScript for Taskmaster Guide\" that you mentioned.\n\nBy following these steps, you should be able to create and access the postal database effectively. If you have further questions about the recognition capabilities of Parascript, please refer to the documentation or support resources provided by IBM.",
    "id": "TECHQA_DEV_Q271_1"
  },
  {
    "question_id": "TECHQA_DEV_Q275",
    "question": "Jobtask long description\nHow do I modify the JP sheet to include the JOBTASK Long description in the query.  I have tried JOBTASK.DESCRIPTION.DESCRIPTION_LONGDESCRITION and other combinations but they do not seem to work.",
    "ground_truth": "1. Go To Integration -> Integration Object\n   \n2. Click Select Action -> Exclude/Include Fields\n\n3. On the Persistent Fields tab, exclude **HASLD**\n   \n4. On the Non-Persistent Fields tab, include **DESCRIPTION_LONGDESCRIPTION**",
    "answer": "To modify the JP sheet to include the JOBTASK long description in your query, follow these steps based on the version of Maximo you are using:\n\n### For Maximo 6.x MEA:\n1. Go to **Integration -> Integration Object**.\n2. On the **Persistent Fields** tab, exclude `HASLD`.\n3. On the **Non-Persistent Fields** tab, include `DESCRIPTION_LONGDESCRIPTION`.\n\n### For Maximo 7.x MIF:\n1. Go to **Integration -> Object Structures**.\n2. Click **Select Action -> Exclude/Include Fields**.\n3. On the **Persistent Fields** tab, exclude `HASLD`.\n4. On the **Non-Persistent Fields** tab, include `DESCRIPTION_LONGDESCRIPTION`.\n\n### XML Configuration:\nWhen sending data via XML, ensure you add the long description tag in your inbound XML as follows:\n```xml\n<DESCRIPTION_LONGDESCRIPTION>xxxxx</DESCRIPTION_LONGDESCRIPTION>\n```\nDo not include the `HASLD` tag, as this will be set automatically.\n\n### Additional Notes:\n- If you are using flat files or interface tables, you must use an alias for `DESCRIPTION_LONGDESCRIPTION` on DB2 and SQL Server due to the column name length restriction (over 18 characters).\n- If your object structure has multiple MBOs with long descriptions, use unique aliases for each column name.\n\nBy following these steps, you should be able to successfully include the JOBTASK long description in your query.",
    "id": "TECHQA_DEV_Q275_1"
  },
  {
    "question_id": "TECHQA_DEV_Q283",
    "question": "Hello - I recently installed SPSS 20, my temporary period for running spss has expired, I am in need of the actual license code to fully install. my Lock code is: 4-20C30\nHello - I recently installed SPSS 20, my temporary period for running spss has expired, I am in need of the actual license code to fully install. my Lock code is: 4-20C30 . please help!",
    "ground_truth": "1. Contact your **vendor**",
    "answer": "To obtain the actual license code for your SPSS 20 installation, you will need to contact the vendor from whom you purchased the software. Here are some options for support:\n\n1. **Hearne**: [Hearne Software Support](http://www.hearne.software/Software/SPSS-Grad-Packs-for-Students-by-IBM/FAQ)\n2. **On the Hub**: [On the Hub Support](http://onthehub.com/)\n3. **StudentDiscounts.com**: [StudentDiscounts Support](http://studentdiscounts.com/contact-us.aspx)\n4. **JourneyEd**: [JourneyEd Support](https://www.journeyed.com/contact)\n5. **thinkEDU**: [thinkEDU Support](https://thinkedu.desk.com/)\n6. **Studica**: [Studica Technical Support](http://www.studica.com/technical-support)\n\nReach out to one of these vendors with your Lock code (4-20C30) to get assistance with your licensing issue.",
    "id": "TECHQA_DEV_Q283_1"
  },
  {
    "question_id": "TECHQA_DEV_Q292",
    "question": "Content Engine System Health Page page doesn't reflect correctly, Fixed Content Advise and Storage Area showing unavailable.\nContent Engine System Health Page page doesn't reflect correctly, Fixed Content Advise and Storage Area showing unavailable.",
    "ground_truth": "1. Verify the Content Engine Bootstrap User has **Full Control** on the Object Store and all associated Storage Areas.\n   \n2. Inspect Storage Area security by right-clicking on the **Object Store**.\n   \n3. Choose Properties.\n   \n4. Select the **All Properties** radio button and view the Storage Area property name.\n   \n5. Click on the drop down list to select the Storage Area.\n   \n6. The Storage Area properties screen will appear.\n   \n7. Verify the Security tab allows the Content Engine Bootstrap User has Full Control.\n   ",
    "answer": "To resolve the issue of the Content Engine System Health Page not reflecting correctly, with Fixed Content Devices and Storage Areas showing as unavailable, follow these steps:\n\n1. **Verify Permissions**: Ensure that the Content Engine Bootstrap User has Full Control permissions on the Object Store and all associated Storage Areas.\n   \n2. **Check Storage Area Security**:\n   - Right-click on the Object Store in the FileNet administration console.\n   - Select **Properties**.\n   - Choose the **All Properties** radio button to view the Storage Area property name.\n   - From the drop-down list, select the relevant Storage Area.\n   - In the Storage Area properties screen, navigate to the **Security** tab.\n   - Confirm that the Content Engine Bootstrap User has Full Control permissions.\n\n3. **Review Logs**: Check the `p8_server_error` log for any E_ACCESS_DENIED errors, which indicate insufficient access rights. If found, address the permissions accordingly.\n\nBy ensuring the correct permissions are set, the health page should reflect the correct status for Fixed Content Devices and Storage Areas. If the issue persists after these steps, further investigation may be required.",
    "id": "TECHQA_DEV_Q292_1"
  },
  {
    "question_id": "TECHQA_DEV_Q296",
    "question": "Does the BPM internal Document Store work with IBM DB2 pureScale?\nI use IBM DB2 pureScale with my BPM installation. During startup of the server and initialization of the internal document store I see hanging threads in the systemOut.log and the process will not finish. How can this be solved?",
    "ground_truth": "1. Have a single DB2 **pureScale** member active during FileNet CM addon installation.\n",
    "answer": "The BPM internal Document Store does not work optimally with IBM DB2 pureScale when multiple members are active, as this can lead to excessive SQL locking and lock timeouts during initialization. To resolve the issue you're experiencing with hanging threads during startup, you should ensure that only a single DB2 pureScale member is active while initializing the internal document store. \n\nHere are the steps to follow:\n\n1. **Deactivate Other Members**: Temporarily deactivate all but one of the DB2 pureScale members.\n2. **Restart the BPM Server**: Start the BPM server again to initialize the internal document store.\n3. **Monitor Logs**: Check the systemOut.log and DB2 diagnostic logs for any lock timeout error messages. If the process completes successfully, you can proceed to the next step.\n4. **Reactivate Members**: Once the initialization is complete, you can bring the other DB2 members back online.\n\nThis approach should help you avoid the lock timeouts and allow the initialization process to finish successfully.",
    "id": "TECHQA_DEV_Q296_1"
  },
  {
    "question_id": "TECHQA_DEV_Q298",
    "question": "can Datacap support to Arabic language?\ncan Datacap support to Arabic language?",
    "ground_truth": "1. License NovoDynamics NovoVarus separately.\n\n2. Install it on the **Rulerunner** machine where the Datacap Studio actions for Arabic (**Datacap.Libraries.NovoDynamics**) will be running.",
    "answer": "Yes, Datacap does support the Arabic language. However, to utilize Arabic language support, you need to separately license the NovoDynamics NovoVarus and install it on the Rulerunner machine where the Datacap Studio actions for Arabic will be running. Make sure to follow the installation instructions for proper setup.",
    "id": "TECHQA_DEV_Q298_1"
  },
  {
    "question_id": "TECHQA_DEV_Q299",
    "question": "Netcool/Impact 6.1.1: Policy Custom Function not getting variable value\nNetcool/Impact 6.1.1: Policy Custom Function not getting variable value\n\nCustom Function call:\n\n     ProcessFunction(GotNodes[0].AlertKey); \n\nof a result set acquired by GetByFilter:\n\n     GotNodes=GetByFilter(ObjServ_Alerts_DT, Node=\"'\"+@Node+\"'\", False); \n\nstill fails to use the acquired variable even when there is a value for both GotNodes and GotNodes[0].AlertKey",
    "ground_truth": "1. Assign the variable prior to the function call.\n   This ensures that the value is passed to the **User Defined Function**.",
    "answer": "To resolve the issue of the Custom Function not receiving the variable value in Netcool/Impact 6.1.1, you should ensure that the variable is assigned before the function call. \n\nInstead of directly calling the function with `ProcessFunction(GotNodes[0].AlertKey);`, first assign the value to a variable, and then pass that variable to the function. Here’s how you can rewrite your code:\n\n```plaintext\nAlertKeyValue = GotNodes[0].AlertKey; \nProcessFunction(AlertKeyValue);\n```\n\nThis approach ensures that the value is properly passed to the User Defined Function, which should help avoid the NULL style error you are encountering. If the problem persists, double-check that `GotNodes` is indeed populated and that `GotNodes[0].AlertKey` contains a valid value before the function call.",
    "id": "TECHQA_DEV_Q299_1"
  },
  {
    "question_id": "TECHQA_DEV_Q300",
    "question": "DB2 Non Reclaimable Storage .\nWe have tablespaces defined under DB2 9.5 that apparently are not able\nto reclaim storage back to the OS, but does that mean DB2 cannot reuse\nthis space as well?",
    "ground_truth": "1. Create **DMS** or automatic storage tablespaces in DB2 version **9.7** or later.\n",
    "answer": "In DB2, if a tablespace has the `RECLAIMABLE_SPACE_ENABLED` monitor element set to 1, it means that the tablespace is enabled for reclaimable storage. However, if the tablespace was created in DB2 version 9.5 or earlier, it will not be able to reclaim storage back to the operating system, as this feature was introduced in DB2 version 9.7.\n\nIn your case, the `TEMPSPACE1` tablespace is of type SMS (System Managed Space), which does not support reclaimable storage at all, as indicated by the `RECLAIMABLE_SPACE_ENABLED` value of 0. \n\nTo summarize:\n- DB2 can reuse space in tablespaces that are enabled for reclaimable storage (like `SYSCATSPACE` and `USERSPACE1`), but it cannot reclaim storage back to the OS if they were created in versions prior to 9.7.\n- For SMS tablespaces like `TEMPSPACE1`, reclaimable storage is not applicable.\n\nIf you need to utilize reclaimable storage, consider migrating your tablespaces to DB2 version 9.7 or later and ensure they are created as DMS (Database Managed Space) or automatic storage tablespaces.",
    "id": "TECHQA_DEV_Q300_1"
  },
  {
    "question_id": "TECHQA_DEV_Q303",
    "question": "Why are the users unable to login to Web GUI 8.1 after I modify timeout to 2147483647 in security.xml file ?\nI followed the Web GUI 8.1 reference guide here to switching off the session timeout\n\nhttp://www-01.ibm.com/support/knowledgecenter/SSSHTQ_8.1.0/com.ibm.netcool_OMNIbus.doc_8.1.0/webtop/wip/task/web_adm_settimeout.html\n\nAfter I edited /config/cells/JazzSMNode01Cell/security.xml file, modified timeout setting to 2147483647, users are not able to login anymore.",
    "ground_truth": "1. Navigate to the specified directory on DASH server.\n   On DASH server, navigate to **<JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF**\n2. Take a backup of **consoleProperties.xml**.\n\n3. Open **consoleProperties.xml** in edit-mode.\n\n4. Search for **LTPAFIX** and change the value from 'true' to 'false'.",
    "answer": "The issue you're experiencing with users being unable to log in to Web GUI 8.1 after setting the session timeout to 2147483647 is due to the fact that this value is too large and causes a condition that prevents logins. To resolve this, you need to modify the `consoleProperties.xml` file to set the `LTPAFIX` property to \"false\". Here are the steps to do this:\n\n1. On the DASH server, navigate to the following directory:\n   ```\n   <JazzSM Home>/profile/config/cells/JazzSMNode01Cell/applications/isc.ear/deployments/isc/isclite.war/WEB-INF\n   ```\n\n2. Take a backup of the `consoleProperties.xml` file.\n\n3. Open `consoleProperties.xml` in edit mode.\n\n4. Search for the line containing `LTPAFIX` and change the value from \"true\" to \"false\". It should look like this:\n\n   Before:\n   ```xml\n   <consoleproperties:console-property id=\"LTPAFIX\" value=\"true\"/>\n   ```\n\n   After:\n   ```xml\n   <consoleproperties:console-property id=\"LTPAFIX\" value=\"false\"/>\n   ```\n\n5. Save the changes to the file.\n\n6. Restart the DASH server.\n\nAfter completing these steps, users should be able to log in successfully.",
    "id": "TECHQA_DEV_Q303_1"
  },
  {
    "question_id": "TECHQA_DEV_Q305",
    "question": "Cognos Analytics - Images not displayed in PDF/Excel, working in HTML\nI've just completed an upgrade to Cognos Analytics 11.0.3. When running existing reports in HTML, the images are displayed but when I try to run them in PDF/Excel they are not.",
    "ground_truth": "1. Open up IIS **7.5**\n   \n2. Click on the root folder of your Cognos installation (E.g. C1021GA) in the navigation pane on the left side\n   \n3. When the root folder is selected, double-click **Authentication**\n   \n4. Ensure that **anonymous** access is enabled\n   \n5. Repeat steps 3 and 4 for the image folder and its parent folder.\n   \n6. If the user is concerned about security, they may want to restrict the child-folders (E.g. cgi-bin) and change the authentication settings accordingly\n   \n7. Run the report in export as Excel **2007** and PDF\n   ",
    "answer": "To resolve the issue of images not displaying in PDF/Excel outputs in Cognos Analytics 11.0.3, follow these steps:\n\n1. **Check Image Permissions**:\n   - Open IIS 7.5.\n   - Navigate to the root folder of your Cognos installation (e.g., C1021GA).\n   - Double-click on 'Authentication' and ensure that **anonymous access** is enabled for both the root folder and the image folder.\n\n2. **Verify Image Location**:\n   - Ensure that the images are located in the correct directory specified in your report. If not, place the images in the correct directory.\n\n3. **Use Process Monitor**:\n   - Download and run the Process Monitor tool on the machine where Cognos is installed.\n   - Open the report in Cognos Workspace.\n   - Start capturing events in Process Monitor.\n   - Export the report to Excel 2007 or PDF.\n   - Stop capturing events and search for the image name in Process Monitor to identify any access issues.\n\n4. **Run the Report Again**:\n   - After making the necessary adjustments, try running the report again in both PDF and Excel formats.\n\nBy following these steps, you should be able to resolve the issue with images not displaying in your PDF/Excel outputs. If the problem persists, further investigation may be needed.",
    "id": "TECHQA_DEV_Q305_1"
  },
  {
    "question_id": "TECHQA_DEV_Q306",
    "question": "Unable to view batches in DotEdit\nHi all,\n\nIs there any limitation to view batches in Dot Edit client application, because I am unable to see batches with QID more than 1119.\n\nAlso unable to see batches with status as \"Pending\".",
    "ground_truth": "1. Backup the **\\Datacap\\DotEdit\\apps.ini** file.\n   If the file does not exist, create a new apps.ini file or copy it from **\\Datacap\\tmweb.net**.\n2. Open it in notepad.exe or other editor.\n\n3. Find the app to be modified (for example [APT]).\n\n4. Add a new line containing **BatchLimit=xxx**.\n\n5. Save the file.",
    "answer": "To resolve the issue of not being able to view batches with QID more than 1119 and those with the status \"Pending\" in DotEdit, you may need to adjust the batch display limit. Here's how to do it:\n\n1. **Backup the Configuration File**: Navigate to `\\Datacap\\DotEdit\\` and create a backup of the `apps.ini` file. If this file does not exist, you can create a new one by copying it from `\\Datacap\\tmweb.net`.\n\n2. **Open the Configuration File**: Use Notepad or any text editor to open the `apps.ini` file.\n\n3. **Edit the Batch Limit**:\n   - Look for the application section (for example, `[APT]`). If it does not exist, create a new section with the application name in square brackets.\n   - Add a line that says `BatchLimit=xxx`, where `xxx` is the new limit you wish to set for the number of batches displayed.\n\n4. **Save Changes**: After making the changes, save the file.\n\n**Additional Notes**:\n- Ensure you have IBM Datacap version 8.1, Fix Pack 1, or newer installed.\n- Be aware that increasing the batch limit may result in slower response times.\n\nAfter making these changes, restart DotEdit and check if you can now view the batches that were previously not displayed. If the problem persists, consider checking for other potential issues such as user permissions or filters that may be applied within DotEdit.",
    "id": "TECHQA_DEV_Q306_1"
  }
]