# TechSupportEval

TechSupportEval is an automated evaluation framework for technical support QA.

## Introduction

TechSupportEval introduces two novel techniques:

* **ClozeFact**: This method formulates fact verification as a cloze test, utilizing an LLM to fill in missing key terms, ensuring precise matching of key information.

* **StepRestore**: This technique shuffles the ground truth steps and uses an LLM to reconstruct the steps in the correct order, verifying both the step sequence and completeness.

As shown in the illustrative example below:

![Pipeline](images/pipeline.png)

We propose a benchmark dataset built upon the publicly available TechQA dataset, which includes responses generated by various levels of QA systems. TechSupportEval achieves an AUC of 0.91, outperforming the state-of-the-art method by 7.6%.

Detailed results is shown in the table below:

![Evaluation result](images/evaluation_result.png)

## Usage

To use this evaluation framework, follow these steps:

1. Download the repository and navigate to the directory

    ```bash
    cd TechSupportEval
    ```

2. Set up the environment (Conda recommended)

    ```bash
    conda create --name=tseval python=3.10  
    conda activate tseval  
    pip install -r requirements.txt  
    ```

3. Configure the LLM for evaluation

    By default, we use OpenAI's GPT-4o-mini for evaluation.

    ```bash
    cp .env.example .env  
    ```

    Then, update `.env` with your `OPENAI_API_KEY` and optionally `OPENAI_API_BASE`.

4. Run an example test

    ```bash
    python -m tseval.metric examples/1.json  
    ```

### Command format

```bash
python -m tseval.metric <input_path> [output_path]
```

`<input_path>`: A JSON file containing three required fields: `question`, `ground_truth`, and `answer`.

The evaluation results will be displayed in the console.

If `<output_path>` is specified, a JSON report will be saved to that location.

### Example outputs

The evaluation results for `examples/1.json` and `examples/2.json` are available in:
- `examples/1_result.json`
- `examples/2_result.json`
